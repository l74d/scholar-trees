(S (NP (NP (JJ Mini-batch) (NN sub-sampling)) (PP (IN in) (NP (JJ neural) (NN network) (NN training)))) (VP (VBZ is) (ADJP (JJ unavoidable)) (, ,) (PP (JJ due) (TO to) (NP (NP (VBG growing) (NNS data) (NNS demands)) (, ,) (NP (NP (JJ memory-limited) (JJ computational) (NNS resources)) (PP (JJ such) (IN as) (NP (NP (JJ graphical) (VBG processing) (NNS units)) (PRN (-LRB- -LRB-) (NP (NNP GPUs)) (-RRB- -RRB-))))) (, ,) (CC and) (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (JJ on-line) (NN learning))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN study))) (NP (PRP we)) (VP (ADVP (RB specifically)) (VBP distinguish) (PP (IN between) (NP (NP (NP (JJ static) (JJ mini-batch) (JJ sub-sampled) (NN loss) (NNS functions)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NNS mini-batches)) (VP (VBP are) (VP (ADVP (RB intermittently)) (VBN fixed) (PP (IN during) (NP (NN training))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (ADJP (NN smooth) (CC but) (JJ biased)) (NN loss) (NNS functions)))))))))) (: ;) (CC and) (NP (NP (DT the) (JJ dynamic) (JJ sub-sampling) (NN equivalent)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (JJ new) (NNS mini-batches)) (VP (VBP are) (VP (VBN sampled) (PP (IN at) (NP (DT every) (NN loss) (NN evaluation))) (, ,) (S (VP (NN trading) (NP (NN bias)) (PP (IN for) (NP (NP (NN variance)) (PP (IN in) (NP (ADJP (VBG sampling) (JJ induced)) (NNS discontinuities))))))))))))))) (. .))
(S (NP (DT These)) (VP (NN render) (S (NP (NP (VBD automated) (NN optimization) (NNS strategies)) (PP (JJ such) (IN as) (NP (NN minimization) (NN line) (NNS searches)))) (ADJP (JJ ineffective))) (, ,) (SBAR (IN since) (S (S (NP (JJ critical) (NNS points)) (VP (MD may) (RB not) (VP (VB exist)))) (CC and) (S (NP (NN function) (NNS minimizers)) (VP (VBP find) (NP (JJ spurious) (, ,) (ADJP (NN discontinuity) (VBD induced)) (NN minima))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ suggests) (S (VP (VBG recasting) (NP (DT the) (NN optimization) (NN problem)) (S (VP (TO to) (VP (VB find) (NP (NP (JJ stochastic) (JJ non-negative) (VBN associated) (JJ gradient) (NN projection) (NNS points)) (PRN (-LRB- -LRB-) (NP (NNP SNN-GPPs)) (-RRB- -RRB-))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (NNP SNN-GPP) (NN optimality) (NN criterion)) (VP (VBZ is) (ADJP (ADJP (RBR less) (JJ susceptible) (PP (TO to) (NP (ADJP (NN sub-sampling) (JJ induced)) (NNS discontinuities)))) (PP (IN than) (NP (JJ critical) (NNS points) (CC or) (NNS minimizers)))))))) (. .))
(S (NP (PRP We)) (VP (VBP conduct) (NP (DT a) (JJ visual) (NN investigation)) (, ,) (S (VP (VBG comparing) (NP (NP (NP (JJ local) (NN minimum)) (CC and) (NP (NNP SNN-GPP) (NN optimality) (NNS criteria))) (PP (IN in) (NP (NP (DT the) (NN loss) (NNS functions)) (PP (IN of) (NP (DT a) (JJ simple) (JJ neural) (NN network) (NN training) (NN problem))) (PP (IN for) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (JJ popular) (NN activation) (NNS functions))))))))))) (. .))
(S (SBAR (IN Since) (S (NP (NNP SNN-GPPs)) (VP (ADVP (NN better)) (VBP approximate) (NP (NP (DT the) (NN location)) (PP (IN of) (NP (JJ true) (NNS optima)))) (, ,) (SBAR (ADVP (RB particularly)) (WRB when) (S (VP (VBG using) (NP (NP (JJ smooth) (NN activation) (NNS functions)) (PP (IN with) (NP (JJ high) (NN curvature) (NNS characteristics)))))))))) (, ,) (NP (PRP we)) (VP (VBP postulate) (SBAR (DT that) (S (NP (NP (NN line) (VBZ searches)) (VP (VBG locating) (NP (NNP SNN-GPPs)))) (VP (MD can) (VP (VB contribute) (ADVP (RB significantly)) (PP (TO to) (S (VP (VBG automating) (NP (JJ neural) (NN network) (NN training)))))))))))
