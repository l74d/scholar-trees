(S (NP (NP (VBN Reduced) (NN precision) (NN computation)) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks)))) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (JJ key) (NNS areas)) (VP (VBG addressing) (S (NP (DT the) (NN widening)) (VP (VB compute) (NP (NP (NN gap)) (VP (VBN driven) (PP (IN by) (NP (NP (DT an) (JJ exponential) (NN growth)) (PP (IN in) (NP (NN model) (NN size)))))))))))))) (. .))
(S (PP (IN In) (NP (JJ recent) (NNS years))) (, ,) (NP (NML (JJ deep) (NN learning)) (NN training)) (VP (VBZ has) (ADVP (RB largely)) (VP (VBN migrated) (PP (IN to) (NP (NML (CD 16) (HYPH -) (NN bit)) (NN precision))) (, ,) (PP (IN with) (NP (NP (JJ significant) (NNS gains)) (PP (IN in) (NP (NML (NN performance) (CC and) (NN energy)) (NN efficiency))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NNS attempts) (S (VP (TO to) (VP (VB train) (NP (NNS DNNs)) (PP (IN at) (NP (NML (CD 8) (HYPH -) (NN bit)) (NN precision))))))) (VP (VBP have) (VP (VBN met) (PP (IN with) (NP (JJ significant) (NNS challenges))) (PP (IN because) (PP (IN of) (NP (NP (DT the) (JJR higher) (NN precision)) (CC and) (NP (NP (JJ dynamic) (NN range) (NNS requirements)) (PP (IN of) (ADVP (RB back))) (PP (HYPH -) (NP (NN propagation))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (NN method)) (S (VP (TO to) (VP (VB train) (NP (JJ deep) (JJ neural) (NNS networks)) (S (VP (VBG using) (NP (NP (NML (CD 8) (HYPH -) (NN bit)) (JJ floating) (NN point) (NN representation)) (PP (IN for) (NP (NNS weights) (, ,) (NNS activations) (, ,) (NNS errors) (, ,) (CC and) (NNS gradients)))))))))) (. .))
(S (PP (IN In) (NP (NP (NN addition)) (PP (IN to) (S (VP (VBG reducing) (S (VP (VB compute) (NP (NN precision))))))))) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VBD reduced) (NP (DT the) (NN precision) (NNS requirements)) (PP (IN for) (NP (NP (DT the) (NN master) (NN copy)) (PP (IN of) (NP (NNS weights))))) (PP (IN from) (NP (QP (CD 32) (HYPH -) (NN bit) (IN to) (CD 16) (HYPH -) (NN bit))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NN accuracy)) (PP (IN across) (NP (NP (NML (JJ multiple) (NNS data)) (NNS sets) (PRN (-LRB- -LRB-) (NP (NN imagenet) (HYPH -) (NN 1K) (, ,) (NN WMT16)) (-RRB- -RRB-))) (CC and) (NP (NP (DT a) (JJR broader) (NN set)) (PP (IN of) (NP (NNS workloads))) (PRN (-LRB- -LRB-) (NP (NP (NNP Resnet) (HYPH -) (CD 18/34/50)) (, ,) (NP (NNP GNMT)) (, ,) (NP (NNP Transformer))) (-RRB- -RRB-))))) (SBAR (IN than) (S (ADVP (RB previously)) (VP (VBN reported))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (DT an) (NML (JJ enhanced) (NN loss)) (NN scaling) (NN method)) (S (VP (TO to) (VP (VB augment) (NP (NP (DT the) (VBN reduced) (JJ subnormal) (NN range)) (PP (IN of) (NP (NML (CD 8) (HYPH -) (NN bit)) (JJ floating) (NN point))) (PP (IN for) (NP (VBN improved) (NN error) (NN propagation)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP examine) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (NN quantization) (NN noise)))) (PP (IN on) (NP (NN generalization)))) (CC and) (VP (VB propose) (NP (DT a) (JJ stochastic) (VBG rounding) (NN technique)) (S (VP (TO to) (VP (VB address) (NP (NN gradient) (NN noise))))))) (. .))
(S (PP (IN As) (NP (NP (DT a) (NN result)) (PP (IN of) (S (VP (VBG applying) (NP (PDT all) (DT these) (NNS techniques))))))) (, ,) (NP (PRP we)) (VP (VBP report) (NP (ADJP (RB slightly) (JJR higher)) (NN validation) (NN accuracy)) (PP (VBN compared) (PP (IN to) (NP (JJ full) (NN precision) (NN baseline))))) (. .))
