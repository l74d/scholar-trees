(S (NP (NP (JJ Conventional) (NN reinforcement) (VBG learning) (NNS methods)) (PP (IN for) (NP (NNP Markov) (NN decision) (VBZ processes)))) (VP (RB rely) (PP (IN on) (NP (JJ weakly-guided) (, ,) (JJ stochastic) (NNS searches))) (S (VP (TO to) (VP (VB drive) (NP (DT the) (NN learning) (NN process)))))) (. .))
(S (NP (NP (PRP It))) (VP (MD can) (ADVP (RB therefore)) (VP (VB be) (ADJP (JJ difficult)) (S (VP (TO to) (VP (VB predict) (SBAR (WHNP (WP what) (NN agent) (NNS behaviors)) (S (VP (MD might) (VP (VB emerge)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (NP (DT an) (JJ information-theoretic) (NN cost) (NN function)) (PP (IN for) (S (VP (VBG performing) (NP (NP (VBN constrained) (JJ stochastic) (NNS searches)) (SBAR (WHNP (WDT that)) (S (VP (VBP promote) (NP (NP (DT the) (NN formation)) (PP (IN of) (NP (ADJP (JJ risk-averse) (TO to) (JJ risk-favoring)) (NNS behaviors))))))))))))) (. .))
(S (S (NP (DT This) (NN cost) (NN function)) (VP (VBZ is) (NP (NP (DT the) (NN value)) (PP (IN of) (NP (NN information))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ provides) (NP (NP (DT the) (JJ optimal) (NN trade-off)) (PP (IN between) (NP (NP (NP (DT the) (JJ expected) (NN return)) (PP (IN of) (NP (DT a) (NN policy)))) (CC and) (NP (NP (DT the) (NN policy) (POS 's)) (NN complexity))))))))))) (: ;) (S (NP (NN policy) (NN complexity)) (VP (VBZ is) (VP (VP (VBN measured) (PP (IN by) (NP (NP (NN number)) (PP (IN of) (NP (NNS bits)))))) (CC and) (VP (VBN controlled) (PP (IN by) (NP (NP (DT a) (JJ single) (NN hyperparameter)) (PP (IN on) (NP (DT the) (NN cost) (NN function))))))))) (. .))
(S (SBAR (IN As) (S (NP (DT the) (NN policy) (NN complexity)) (VP (VBZ is) (VP (VBN reduced))))) (, ,) (NP (DT the) (NNS agents)) (VP (MD will) (VP (ADVP (RB increasingly)) (VB eschew) (NP (JJ risky) (NNS actions)))) (. .))
(S (NP (DT This)) (VP (VBZ reduces) (NP (NP (DT the) (NN potential)) (PP (IN for) (NP (JJ high) (VBN accrued) (NNS rewards))))) (. .))
(S (SBAR (IN As) (S (NP (DT the) (NN policy) (NN complexity)) (VP (NNS increases)))) (, ,) (NP (DT the) (NNS agents)) (VP (MD will) (VP (VB take) (NP (NNS actions)) (, ,) (ADVP (RB regardless) (PP (IN of) (NP (DT the) (NN risk)))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB raise) (NP (DT the) (JJ long-term) (NNS rewards)))))))) (. .))
(S (NP (DT The) (JJ obtainable) (NN reward)) (VP (VBZ depends) (PP (IN on) (NP (NP (DT a) (JJ single) (, ,) (JJ tunable) (NN hyperparameter)) (SBAR (WHNP (WDT that)) (S (VP (VBZ regulates) (NP (NP (DT the) (NN degree)) (PP (IN of) (NP (NN policy) (NN complexity)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ value-of-information-based) (NNS policies))) (PP (IN on) (NP (NP (DT a) (JJ stochastic) (NN version)) (PP (IN of) (NP (NNP Ms.) (NNP Pac-Man))))))) (. .))
(S (NP (NP (DT A) (JJ major) (NN component)) (PP (IN of) (NP (DT this) (NN paper)))) (VP (VBZ is) (NP (NP (DT the) (NN demonstration) (SBAR (IN that) (S (NP (NP (VBZ ranges)) (PP (IN of) (NP (NN policy) (NN complexity) (NNS values)))) (VP (VBP yield) (NP (JJ different) (NN game-play) (NNS styles)))))) (CC and) (S (VP (VBG explaining) (SBAR (WHADVP (WRB why)) (S (NP (DT this)) (VP (NN occurs)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (JJ reinforcement-learning) (NN search) (NN mechanism)) (VP (VBZ is) (ADJP (ADJP (RBR more) (JJ efficient)) (PP (IN than) (NP (NP (DT the) (NNS others)) (SBAR (S (NP (PRP we)) (VP (VBP utilize))))))))))) (. .))
(S (NP (DT This) (NN result)) (VP (VBZ implies) (SBAR (IN that) (S (NP (NP (DT the) (NN value)) (PP (IN of) (NP (NN information) (NN theory)))) (VP (VBZ is) (ADJP (JJ appropriate) (PP (IN for) (S (VP (VBG framing) (NP (NP (DT the) (JJ exploitation-exploration) (NN trade-off)) (PP (IN in) (NP (NN reinforcement) (NN learning)))))))))))) (. .))
