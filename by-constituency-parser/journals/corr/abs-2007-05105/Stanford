(S (SBAR (WHADVP (WRB When)) (S (VP (VBG using) (NP (NML (JJ large) (HYPH -) (NN batch)) (NN training)) (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (JJ stochastic) (NN gradient) (NN descent)))))))) (, ,) (NP (VBG learning) (NNS rates)) (VP (MD must) (VP (VB adapt) (PP (IN to) (NP (NP (JJ new) (NN batch) (NNS sizes)) (PP (IN in) (NP (NN order))))) (S (VP (TO to) (VP (VP (VB maximize) (NP (NN speed) (HYPH -) (NNS ups))) (CC and) (VP (VB preserve) (NP (NN model) (NN quality)))))))) (. .))
(S (S (VP (VBG Re-tuning) (NP (NN learning) (NNS rates)))) (VP (VBZ is) (ADJP (NP (NN resource)) (JJ intensive)) (, ,) (SBAR (IN while) (S (NP (VBN fixed) (NN scaling) (NNS rules)) (ADVP (RB often)) (VP (VBP degrade) (NP (NN model) (NN quality)))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NNP AdaScale) (NNP SGD)) (, ,) (NP (NP (DT an) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (ADVP (RB reliably)) (VP (VBZ adapts) (NP (NN learning) (NNS rates)) (PP (IN to) (NP (NML (JJ large) (HYPH -) (NN batch)) (NN training))))))))) (. .))
(S (PP (IN By) (S (ADVP (RB continually)) (VP (VBG adapting) (PP (IN to) (NP (NP (DT the) (NN gradient) (POS 's)) (NN variance)))))) (, ,) (NP (NNP AdaScale)) (ADVP (RB automatically)) (VP (VBZ achieves) (NP (NP (NN speed) (HYPH -) (NNS ups)) (PP (IN for) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NN batch) (NNS sizes))))))) (. .))
(S (S (NP (PRP We)) (ADVP (RB formally)) (VP (VBP describe) (SBAR (S (NP (NP (DT this) (NN quality)) (PP (IN with) (NP (NP (NNP AdaScale) (POS 's)) (NN convergence)))) (VP (VBD bound)))) (, ,) (SBAR (SBAR (WHNP (WDT which)) (S (VP (VBZ maintains) (NP (JJ final) (JJ objective) (NNS values))))) (, ,) (RB even) (SBAR (IN as) (S (NP (NN batch) (NNS sizes)) (VP (VBP grow) (ADJP (JJ large)))))))) (CC and) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS iterations)))) (VP (VBZ decreases))) (. .))
(S (PP (IN In) (NP (JJ empirical) (NNS comparisons))) (, ,) (S (NP (NNP AdaScale) (NNS trains)) (ADVP (RB well)) (PP (IN beyond) (NP (NP (DT the) (NN batch) (NN size) (NNS limits)) (PP (IN of) (NP (JJ popular) (NML (`` ") (JJ linear) (NML (NN learning) (NN rate)) (NN scaling) ('' ")) (NNS rules)))))) (. .))
(S (NP (DT This)) (VP (VBZ includes) (NP (NML (JJ large) (HYPH -) (NN batch)) (NN training)) (PP (IN with) (NP (NP (DT no) (NN model) (NN degradation)) (PP (IN for) (NP (NML (NML (NN machine) (NN translation)) (, ,) (NML (NN image) (NN classification)) (, ,) (NML (NN object) (NN detection)) (, ,) (CC and) (NML (NN speech) (NN recognition))) (NNS tasks)))))) (. .))
(S (S (NP (NP (NNP AdaScale) (POS 's)) (JJ qualitative) (NN behavior)) (VP (VBZ is) (ADJP (JJ similar) (PP (IN to) (NP (NP (DT that)) (PP (IN of) (NP (`` ") (ADJP (JJ warm) (HYPH -) (RP up)) ('' ") (NNS heuristics)))))))) (, ,) (CC but) (S (PP (IN unlike) (NP (ADJP (JJ warm) (HYPH -) (RP up)))) (, ,) (NP (DT this) (NN behavior)) (VP (VBZ emerges) (ADVP (RB naturally)) (PP (IN from) (NP (DT a) (JJ principled) (NN mechanism))))) (. .))
(S (NP (DT The) (NN algorithm)) (VP (VBZ introduces) (NP (NP (JJ negligible) (JJ computational) (NN overhead)) (CC and) (NP (DT no) (JJ new) (NNS hyperparameters))) (, ,) (S (VP (VBG making) (S (NP (NNP AdaScale)) (NP (NP (DT an) (JJ attractive) (NN choice)) (PP (IN for) (NP (NP (NML (JJ large) (HYPH -) (NN scale)) (NN training)) (PP (IN in) (NP (NN practice)))))))))) (. .))
