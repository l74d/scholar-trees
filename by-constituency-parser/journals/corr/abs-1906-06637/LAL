(S (PP (IN In) (NP (JJ recent) (NNS years))) (, ,) (NP (NP (DT an) (VBG increasing) (NN number)) (PP (IN of) (NP (JJ neural) (NN network) (NNS models)))) (VP (VBP have) (VP (VBN included) (NP (NNS derivatives)) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (VB inputs))))) (PP (IN in) (NP (PRP$ their) (NN loss) (NNS functions))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (NP (JJ so-called) (JJ double) (NN backpropagation)) (PP (IN for) (NP (JJ first-order) (NN optimization))))))))) (. .))
(S (ADVP (RB However)) (, ,) (ADVP (IN so) (RB far)) (NP (NP (DT no) (JJ general) (NN description)) (PP (IN of) (NP (DT the) (JJ involved) (NNS derivatives)))) (VP (NNS exists)) (. .))
(S (ADVP (RB Here)) (, ,) (NP (PRP we)) (VP (VBP cover) (NP (NP (DT a) (JJ wide) (NN array)) (PP (IN of) (NP (JJ special) (NNS cases)))) (PP (IN in) (NP (NP (DT a) (ADJP (RB very) (JJ general)) (NNP Hilbert) (NN space) (NN framework)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB provide) (NP (NP (JJ optimized) (NN backpropagation) (NNS rules)) (PP (IN for) (NP (JJ many) (JJ real-world) (NNS scenarios))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ includes) (NP (NP (DT the) (NN reduction)) (PP (IN of) (NP (NP (NNS calculations)) (PP (IN for) (NP (NP (NNS Frobenius-norm-penalties)) (PP (IN on) (NP (NNS Jacobians))))))) (PP (IN by) (NP (RB roughly) (DT a) (JJ third))) (PP (IN for) (NP (ADJP (RB locally) (JJ linear)) (NN activation) (NNS functions))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VP (VBP provide) (NP (NP (DT a) (NN description)) (PP (IN of) (NP (NP (DT the) (JJ discontinuous) (NN loss) (NN surface)) (PP (IN of) (NP (NNP ReLU) (NNS networks))) (PP (DT both) (IN in) (NP (NP (DT the) (NNS inputs)) (CC and) (NP (DT the) (NNS parameters)))))))) (CC and) (VP (VB demonstrate) (SBAR (WHADVP (WRB why)) (S (NP (DT the) (NNS discontinuities)) (VP (VBP do) (RB not) (VP (VB pose) (NP (DT a) (JJ big) (NN problem)) (PP (IN in) (NP (NN reality))))))))) (. .))
