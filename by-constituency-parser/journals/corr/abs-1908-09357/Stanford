(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP consider) (NP (ADJP (NN self) (HYPH -) (JJ supervised)) (NN representation) (NN learning)) (S (VP (TO to) (VP (VB improve) (NP (NN sample) (NN efficiency)) (PP (IN in) (NP (NN reinforcement) (NN learning)))))) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (JJ forward) (NN prediction) (NN objective)) (PP (IN for) (S (ADVP (RB simultaneously)) (VP (VBG learning) (NP (NP (NNS embeddings)) (PP (IN of) (NP (NP (NNS states)) (CC and) (NP (NN action) (NNS sequences))))))))) (. .))
(S (NP (DT These) (NNS embeddings)) (VP (VBP capture) (NP (NP (DT the) (NN structure)) (PP (IN of) (NP (NP (DT the) (NN environment) (POS 's)) (NNS dynamics)))) (, ,) (S (VP (VBG enabling) (NP (JJ efficient) (NN policy) (NN learning))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (PRP$ our) (NN action) (NNS embeddings)) (ADVP (RB alone)) (VP (VBP improve) (NP (NP (DT the) (NN sample) (NN efficiency)) (CC and) (NP (NP (NN peak) (NN performance)) (PP (IN of) (NP (NML (NN model) (HYPH -) (JJ free)) (NN RL))))) (PP (IN on) (NP (NP (NN control)) (PP (IN from) (NP (ADJP (JJ low) (HYPH -) (JJ dimensional)) (NNS states))))))))) (. .))
(S (PP (IN By) (S (VP (VBG combining) (NP (NML (NN state) (CC and) (NN action)) (NNS embeddings))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (JJ efficient) (NN learning)) (PP (IN of) (NP (NML (JJ high) (HYPH -) (NN quality)) (NNS policies)))) (PP (IN on) (NP (NP (ADJP (NN goal) (HYPH -) (VBN conditioned)) (JJ continuous) (NN control)) (PP (IN from) (NP (NP (NN pixel) (NNS observations)) (PP (IN in) (NP (QP (QP (RB only) (CD 1) (HYPH -) (CD 2)) (CD million)) (NN environment) (NNS steps)))))))) (. .))
