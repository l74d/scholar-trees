(S (NP (NP (NN Lack)) (PP (IN of) (NP (NP (NN performance)) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBZ comes) (PP (IN to) (NP (NP (JJ continual) (NN learning)) (PP (IN over) (NP (NP (JJ non-stationary) (NNS distributions)) (PP (IN of) (NP (NNS data))))))))))))) (VP (VBZ remains) (NP (DT a) (JJ major) (NN challenge)) (PP (IN in) (S (VP (VBG scaling) (NP (JJ neural) (NN network) (NN learning)) (PP (IN to) (NP (JJR more) (JJ human) (JJ realistic) (NNS settings))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (DT a) (JJ new) (NN conceptualization)) (PP (IN of) (NP (NP (DT the) (JJ continual) (NN learning) (NN problem)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (DT a) (ADJP (RB temporally) (JJ symmetric)) (NN trade) (HYPH -) (NN off)) (PP (IN between) (NP (NN transfer) (CC and) (NN interference)))))))))) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN optimized) (PP (IN by) (S (VP (VBG enforcing) (NP (NN gradient) (NN alignment)) (PP (IN across) (NP (NNS examples))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VB propose) (NP (NP (DT a) (JJ new) (NN algorithm)) (, ,) (NP (NP (NML (NNP Meta) (HYPH -) (NNP Experience)) (NML (NNP Replay) (-LRB- -LRB-) (NNP MER) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT that)) (S (ADVP (RB directly)) (VP (VBZ exploits) (NP (DT this) (NN view)) (PP (IN by) (S (VP (VBG combining) (NP (NN experience) (NN replay)) (PP (IN with) (NP (NP (NN optimization)) (VP (VBN based) (NP (NN meta) (HYPH -) (NN learning)))))))))))))) (. .))
(S (NP (DT This) (NN method)) (VP (VBZ learns) (NP (NP (NNS parameters)) (SBAR (WHNP (WDT that)) (S (VP (VBP make) (NP (NN interference)) (PP (VBN based) (PP (IN on) (NP (NP (NP (JJ future) (NNS gradients)) (ADJP (RBR less) (JJ likely))) (CC and) (NP (NP (NN transfer)) (PP (VBN based) (PP (IN on) (NP (NP (JJ future) (NNS gradients)) (ADJP (RBR more) (JJ likely)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP conduct) (NP (NNS experiments)) (PP (IN across) (NP (NP (JJ continual) (JJ lifelong) (JJ supervised) (NN learning) (NNS benchmarks)) (CC and) (NP (JJ non-stationary) (NN reinforcement)))) (S (VP (VBG learning) (NP (NNS environments)) (S (VP (VBG demonstrating) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (ADVP (RB consistently)) (VP (VBZ outperforms) (ADVP (RB recently)) (NP (NP (VBN proposed) (NNS baselines)) (PP (IN for) (NP (JJ continual) (NN learning)))))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN gap)) (PP (IN between) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN MER) (CC and) (NN baseline) (NNS algorithms)))))) (VP (VBZ grows) (NP (DT both)) (SBAR (SBAR (IN as) (S (NP (DT the) (NN environment)) (VP (VBZ gets) (NP (JJR more)) (S (ADJP (JJ non-stationary)))))) (CC and) (SBAR (IN as) (S (NP (NP (DT the) (NN fraction)) (PP (IN of) (NP (NP (DT the) (JJ total) (NNS experiences)) (VP (VBN stored))))) (VP (VBZ gets) (ADJP (JJR smaller)))))))))) (. .))
