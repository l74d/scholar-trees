(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (NN framework)) (PP (IN for) (NP (VBN distributed) (, ,) (NML (IN in) (HYPH -) (NN storage)) (NN training))) (PP (IN of) (NP (NP (JJ neural) (NNS networks)) (PP (IN on) (NP (NP (NNS clusters)) (PP (IN of) (NP (NML (JJ computational) (NN storage)) (NNS devices))))))))) (. .))
(S (NP (JJ Such) (NNS devices)) (ADVP (RB not) (RB only)) (VP (VP (VBP contain) (NP (NN hardware) (NNS accelerators))) (CC but) (ADVP (RB also)) (VP (VB eliminate) (NP (NP (NNS data) (NN movement)) (PP (IN between) (NP (DT the) (NN host) (CC and) (NN storage)))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (DT both) (VBN improved) (NML (NN performance) (CC and) (NN power)) (NNS savings))))))) (. .))
(S (ADVP (RBR More) (RB importantly)) (, ,) (NP (NP (DT this) (NML (PP (IN in) (HYPH -) (NP (NN storage)))) (NN processing) (NN style)) (PP (IN of) (NP (NN training)))) (VP (VBZ ensures) (SBAR (IN that) (S (NP (JJ private) (NNS data)) (ADVP (RB never)) (VP (VBZ leaves) (NP (DT the) (NN storage)) (PP (IN while) (S (ADVP (RB fully)) (VP (VBG controlling) (NP (NP (DT the) (NN sharing)) (PP (IN of) (NP (JJ public) (NNS data))))))))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (PRT (RP up)) (PP (IN to) (NP (NP (CD 2.7) (SYM x) (NN speedup)) (CC and) (NP (CD 69) (NN %)))) (NP-TMP (NP (NP (NN reduction)) (PP (IN in) (NP (NN energy) (NN consumption)))) (CC and) (NP (NP (DT no) (JJ significant) (NN loss)) (PP (IN in) (NP (NN accuracy)))))) (. .))
