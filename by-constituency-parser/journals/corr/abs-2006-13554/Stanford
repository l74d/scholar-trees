(S (NP (JJ Robust) (NN loss) (NNS functions)) (VP (VBP are) (ADJP (JJ essential) (PP (IN for) (S (VP (VBG training) (NP (NP (ADJP (JJ accurate) (JJ deep)) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-)) (PP (IN in) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (JJ noisy) (-LRB- -LRB-) (JJ incorrect) (-RRB- -RRB-) (NNS labels)))))))))) (. .))
(S (NP (PRP It)) (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (SBAR (IN that) (S (NP (DT the) (ADJP (RB commonly) (VBN used)) (NML (NML (NNP Cross) (NNP Entropy)) (-LRB- -LRB-) (NML (NN CE)) (-RRB- -RRB-)) (NN loss)) (VP (VBZ is) (RB not) (ADJP (JJ robust) (PP (IN to) (NP (JJ noisy) (NNS labels)))))))))) (. .))
(S (SBAR (IN Whilst) (S (NP (JJ new) (NN loss) (NNS functions)) (VP (VBP have) (VP (VBN been) (VP (VBN designed)))))) (, ,) (NP (PRP they)) (VP (VBP are) (ADVP (RB only)) (ADJP (RB partially) (JJ robust))) (. .))
(S (S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (ADVP (RB theoretically)) (VP (VBP show) (PP (IN by) (S (VP (VBG applying) (NP (NP (DT a) (JJ simple) (NN normalization)) (SBAR (WHNP (WDT that))))))))) (: :) (S (NP (DT any) (NN loss)) (VP (MD can) (VP (VB be) (VP (VBN made) (S (ADJP (JJ robust))) (PP (IN to) (NP (JJ noisy) (NNS labels))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (NN practice))) (, ,) (S (ADVP (RB simply)) (VP (VBG being) (ADJP (JJ robust)))) (VP (VBZ is) (RB not) (ADJP (JJ sufficient) (PP (IN for) (NP (DT a) (NN loss) (NN function)))) (S (VP (TO to) (VP (VB train) (NP (JJ accurate) (NNS DNNs)))))) (. .))
(S (PP (IN By) (S (VP (VBG investigating) (NP (JJ several) (JJ robust) (NN loss) (NNS functions))))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP suffer) (PP (IN from) (NP (NP (DT a) (NN problem)) (PP (IN of) (NP (NN underfitting))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (NN framework) (S (VP (TO to) (VP (VB build) (SBAR (S (NP (JJ robust) (NN loss)) (VP (VBZ functions) (NP (VBN called) (JJ Active) (NML (NNP Passive) (NN Loss)))))))))) (PRN (-LRB- -LRB-) (NP (NN APL)) (-RRB- -RRB-))) (. .))
(S (NP (NNP APL)) (VP (VBZ combines) (SBAR (S (NP (CD two) (JJ robust) (NN loss)) (VP (VBZ functions) (SBAR (IN that) (S (ADVP (RB mutually)) (VP (VB boost) (NP (DT each) (JJ other))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NN benchmark) (NNS datasets)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT the) (NN family)) (PP (IN of) (NP (JJ new) (NN loss)))) (VP (VBZ functions) (SBAR (S (S (VP (VBN created) (PP (IN by) (NP (PRP$ our) (NNP APL) (NN framework))))) (VP (MD can) (ADVP (RB consistently)) (VP (VB outperform) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NNS methods)) (PP (PP (IN by) (NP (JJ large) (NNS margins))) (, ,) (RB especially) (PP (IN under) (NP (NP (JJ large) (NN noise) (NNS rates)) (PP (JJ such) (IN as) (NP (QP (CD 60) (NN %) (CC or) (CD 80) (NN %)) (JJ incorrect) (NNS labels)))))))))))))) (. .))
