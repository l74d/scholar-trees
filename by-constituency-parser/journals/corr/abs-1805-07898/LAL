(S (S (PP (IN In) (NP (NNP Deep) (NNP Learning))) (, ,) (NP (NP (NNP Stochastic) (NNP Gradient) (NNP Descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))) (VP (VBZ is) (ADVP (RB usually)) (VP (VBN selected) (PP (IN as) (NP (DT a) (NN training) (NN method))) (PP (IN because) (IN of) (NP (PRP$ its) (NN efficiency)))))) (: ;) (S (ADVP (RB however)) (, ,) (S (ADVP (RB recently)) (, ,) (NP (NP (DT a) (NN problem)) (PP (IN in) (NP (NNP SGD)))) (VP (NNS gains) (NP (NN research) (NN interest)))) (: :) (S (S (NP (NP (JJ sharp) (NN minima)) (PP (IN in) (NP (NP (NNP Deep) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP DNNs)) (-RRB- -RRB-))))) (VP (VBP have) (NP (JJ poor) (NN generalization)))) (: ;) (S (ADVP (RB especially)) (, ,) (NP (JJ large-batch) (NNP SGD)) (VP (VBZ tends) (S (VP (TO to) (VP (VB converge) (PP (TO to) (NP (JJ sharp) (NN minima)))))))))) (. .))
(S (NP (NP (PRP It))) (VP (VBZ becomes) (NP (DT an) (JJ open) (NN question)) (SBAR (IN whether) (S (S (VP (VBG escaping) (NP (JJ sharp) (NN minima)))) (VP (MD can) (VP (VB improve) (NP (DT the) (NN generalization))))))) (. .))
(S (S (VP (TO To) (VP (VB answer) (NP (DT this) (NN question))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ SmoothOut) (NN framework)) (SBAR (S (VP (TO to) (VP (VP (VB smooth) (PRT (RP out)) (NP (NP (JJ sharp) (NN minima)) (PP (IN in) (NP (NNP DNNs))))) (CC and) (VP (ADVP (RB thereby)) (VP (VB improve) (NP (NN generalization)))))))))) (. .))
(S (PP (IN In) (NP (DT a) (NN nutshell))) (, ,) (NP (NNP SmoothOut)) (VP (VP (VBZ perturbs) (NP (NP (JJ multiple) (NNS copies)) (PP (IN of) (NP (DT the) (NNP DNN)))) (PP (IN by) (NP (NN noise) (NN injection)))) (CC and) (VP (NNS averages) (NP (DT these) (NNS copies)))) (. .))
(S (S (S (VP (VBG Injecting) (NP (NNS noises)) (PP (TO to) (NP (NNP SGD))))) (VP (VBZ is) (VP (ADVP (RB widely)) (VBN used) (PP (IN in) (NP (DT the) (NN literature)))))) (, ,) (CC but) (S (NP (NNP SmoothOut)) (VP (NNS differs) (PP (IN in) (NP (NP (NNS lots)) (PP (IN of) (NP (NP (NNS ways)) (: :) (NP (NP (PRN (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (NP (DT a) (JJ de-noising) (NN process)) (VP (VBZ is) (VP (VBN applied) (PP (IN before) (NP (NN parameter) (NN updating)))))) (: ;) (S (PRN (-LRB- -LRB-) (CD 2) (-RRB- -RRB-)) (NP (NN noise) (NN strength)) (VP (VBZ is) (VP (VBN adapted) (PP (TO to) (NP (VB filter) (NN norm)))))) (: ;) (NP (PRN (-LRB- -LRB-) (CD 3) (-RRB- -RRB-)) (NP (NP (DT an) (JJ alternative) (NN interpretation)) (PP (IN on) (NP (NP (DT the) (NN advantage)) (PP (IN of) (NP (NN noise) (NN injection))))) (, ,) (PP (IN from) (NP (NP (DT the) (NN perspective)) (PP (IN of) (NP (NN sharpness) (CC and) (NN generalization))))))) (: ;) (NP (X (-LRB- -LRB-) (CD 4) (-RRB- -RRB-)) (NP (NP (NN usage)) (PP (IN of) (NP (NP (JJ uniform) (NN noise)) (PP (RB instead) (IN of) (NP (JJ Gaussian) (NN noise)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (NNP SmoothOut)) (VP (MD can) (VP (VB eliminate) (NP (JJ sharp) (NN minima))))))) (. .))
(S (S (S (VP (VBG Training) (NP (JJ multiple) (NNP DNN) (NNS copies)))) (VP (VBZ is) (ADJP (JJ inefficient)))) (, ,) (S (NP (PRP we)) (ADVP (VBP further)) (VP (VB propose) (NP (NP (DT an) (JJ unbiased) (NN stochastic) (NNP SmoothOut)) (SBAR (WHNP (WDT which)) (S (ADVP (RB only)) (VBZ introduces) (NP (NP (DT the) (NN overhead)) (PP (IN of) (NP (NP (NN noise) (NN injecting) (CC and) (JJ de-noising)) (PP (IN per) (NP (NN batch))))))))))) (. .))
(S (NP (NP (NP (DT An) (JJ adaptive) (NN variant)) (PP (IN of) (NP (NNP SmoothOut)))) (, ,) (NP (NNP AdaSmoothOut)) (, ,)) (VP (VBZ is) (ADVP (RB also)) (VP (VBN proposed) (S (VP (TO to) (VP (VB improve) (NP (NN generalization))))))) (. .))
(S (PP (IN In) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS experiments))))) (, ,) (NP (NNP SmoothOut) (CC and) (NP (NNP AdaSmoothOut))) (VP (ADVP (RB consistently)) (VB improve) (NP (NN generalization)) (PP (IN in) (NP (NP (DT both) (JJ small-batch) (CC and) (JJ large-batch) (NN training)) (PP (IN on) (NP (NP (DT the) (NN top)) (PP (IN of) (NP (JJ state-of-the-art) (NNS solutions)))))))) (. .))
