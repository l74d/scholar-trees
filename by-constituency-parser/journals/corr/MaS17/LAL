(S (S (VP (TO To) (VP (VB speed) (PRT (RP up)) (NP (DT the) (NN training) (NN process))))) (, ,) (NP (JJ many) (VBG existing) (NNS systems)) (VP (VBP use) (NP (JJ parallel) (NN technology)) (PP (IN for) (NP (NN online) (NN learning) (NN algorithms)))) (. .))
(S (ADVP (RB However)) (, ,) (NP (JJS most) (NN research)) (ADVP (RB mainly)) (VP (VBZ focus) (PP (IN on) (NP (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))) (CONJP (RB instead) (IN of)) (NP (JJ other) (NN algorithms))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP propose) (NP (NP (DT a) (JJ generic) (NN online) (NN parallel) (VBG learning) (NN framework)) (PP (IN for) (NP (JJ large) (NN margin) (NNS models))))) (, ,) (CC and) (ADVP (RB also)) (VP (VB analyze) (NP (PRP$ our) (NN framework)) (PP (IN on) (NP (NP (JJ popular) (JJ large) (NN margin) (NN algorithms)) (, ,) (PP (VBG including) (NP (NP (NNP MIRA)) (CC and) (NP (NNP Structured) (NNP Perceptron)))))))) (. .))
(S (NP (PRP$ Our) (NN framework)) (VP (VBZ is) (ADJP (ADJP (JJ lock-free)) (CC and) (ADJP (JJ easy) (SBAR (S (VP (TO to) (VP (VB implement) (PP (IN on) (NP (VBG existing) (NNS systems)))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NNS systems)) (PP (IN with) (NP (PRP$ our) (NN framework)))) (VP (MD can) (VP (VB gain) (NP (ADJP (IN near) (JJ linear)) (NN speed) (RP up)) (PP (IN by) (S (VP (VBG increasing) (NP (VBG running) (NNS threads))))) (, ,) (CC and) (PP (IN with) (NP (NP (DT no) (NN loss)) (PP (IN in) (NP (NN accuracy)))))))))) (. .))
