(S (PP (IN In) (NP (NN order) (S (VP (TO to) (VP (VB extract) (NP (DT the) (JJS best) (JJ possible) (NN performance)) (PP (IN from) (NP (JJ asynchronous) (JJ stochastic) (NN gradient)))))))) (NP (NN descent) (CD one)) (VP (MD must) (VP (VP (VB increase) (NP (DT the) (NN mini-batch) (NN size))) (CC and) (VP (VB scale) (NP (DT the) (NN learning) (NN rate)) (ADVP (RB accordingly))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (VP (VB achieve) (NP (JJ further) (NN speedup))))))) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (NN technique)) (SBAR (WHNP (WDT that)) (FRAG (NP (NML (NNS delays) (NN gradient)) (NNS updates)) (ADVP (RB effectively)) (VP (VBG increasing) (NP (DT the) (NN mini-batch) (NN size))))))) (. .))
(S (ADVP (RB Unfortunately)) (PP (IN with) (NP (NP (DT the) (NN increase)) (PP (IN of) (NP (NN mini-batch) (NN size))))) (NP (PRP we)) (VP (VBP worsen) (NP (NP (NP (DT the) (JJ stale) (NN gradient) (NN problem)) (PP (IN in) (NP (ADJP (JJ asynchronous) (JJ stochastic)) (NN gradient) (NN descent) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))))) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (NP (DT the) (NN model) (NN convergence)) (ADJP (JJ poor)))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (NP (JJ local) (NNS optimizers)) (SBAR (WHNP (WDT which)) (S (VP (VBP mitigate) (NP (DT the) (JJ stale) (NN gradient) (NN problem)))))) (CC and) (ADVP (RB together) (PP (IN with) (NP (JJ fine) (NN tuning)))) (NP (NP (PRP$ our) (NN momentum)) (SBAR (S (NP (PRP we)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB train) (NP (NP (DT a) (NML (JJ shallow) (NN machine) (NN translation)) (NN system)) (ADJP (NP (CD 27) (NN %)) (JJR faster))) (PP (IN than) (NP (NP (DT an) (VBN optimized) (NN baseline)) (PP (IN with) (NP (NP (JJ negligible) (NN penalty)) (PP (IN in) (NP (NN BLEU))))))))))))))))) (. .))
