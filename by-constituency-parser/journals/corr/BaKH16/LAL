(S (S (VP (VBG Training) (NP (JJ state-of-the-art) (, ,) (JJ deep) (JJ neural) (NNS networks)))) (VP (VBZ is) (ADJP (RB computationally) (JJ expensive))) (. .))
(S (NP (NP (CD One) (NN way)) (SBAR (S (VP (TO to) (VP (VB reduce) (NP (DT the) (NN training) (NN time))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB normalize) (NP (NP (DT the) (NNS activities)) (PP (IN of) (NP (DT the) (NNS neurons)))))))) (. .))
(S (NP (NP (DT A) (ADJP (RB recently) (VBN introduced)) (NN technique)) (VP (VBN called) (S (NP (NN batch) (NN normalization))))) (VP (VBZ uses) (NP (NP (DT the) (NN distribution)) (PP (IN of) (NP (NP (DT the) (JJ summed) (NN input)) (PP (TO to) (NP (DT a) (NN neuron))))) (PP (IN over) (NP (NP (DT a) (NN mini-batch)) (PP (IN of) (NP (NN training) (NNS cases)))))) (S (VP (TO to) (VP (VB compute) (NP (NP (DT a) (NN mean) (CC and) (NN variance)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADVP (RB then)) (VP (VBN used) (S (VP (TO to) (VP (VB normalize) (NP (NP (DT the) (JJ summed) (NN input)) (PP (TO to) (NP (DT that) (NN neuron))) (PP (IN on) (NP (DT each) (NN training) (NN case)))))))))))))))) (. .))
(S (NP (DT This)) (VP (ADVP (RB significantly)) (VBZ reduces) (NP (NP (DT the) (NN training) (NN time)) (PP (IN in) (NP (JJ feed-forward) (JJ neural) (NNS networks))))) (. .))
(S (ADVP (RB However)) (, ,) (S (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NN batch) (NN normalization)))) (VP (VBZ is) (ADJP (JJ dependent) (PP (IN on) (NP (DT the) (JJ mini-batch) (NN size)))))) (CC and) (S (NP (NP (PRP it))) (VP (VBZ is) (RB not) (ADJP (JJ obvious)) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB apply) (NP (PRP it)) (PP (TO to) (NP (VB recurrent) (JJ neural) (NNS networks))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP transpose) (NP (JJ batch) (NN normalization)) (PP (IN into) (NP (JJ layer) (NN normalization))) (PP (IN by) (S (VP (VBG computing) (NP (NP (DT the) (NN mean) (CC and) (NN variance)) (VP (VBN used) (PP (IN for) (NP (NN normalization)))) (PP (IN from) (NP (NP (DT all)) (PP (IN of) (NP (NP (DT the) (VBN summed) (NNS inputs)) (PP (TO to) (NP (NP (DT the) (NNS neurons)) (PP (IN in) (NP (DT a) (NN layer))))))) (PP (IN on) (NP (DT a) (JJ single) (NN training) (NN case)))))))))) (. .))
(S (PP (IN Like) (NP (NN batch) (NN normalization))) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VBP give) (NP (DT each) (NN neuron)) (NP (NP (PRP$ its) (JJ own) (JJ adaptive) (NN bias) (CC and) (NN gain)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN applied) (PP (PP (IN after) (NP (DT the) (NN normalization))) (CC but) (PP (IN before) (NP (DT the) (NN non-linearity)))))))))) (. .))
(S (PP (IN Unlike) (NP (NN batch) (NN normalization))) (, ,) (NP (JJ layer) (NN normalization)) (VP (NNS performs) (NP (RB exactly) (DT the) (JJ same) (NN computation)) (PP (IN at) (NP (NN training) (CC and) (NN test) (NNS times)))) (. .))
(S (NP (NP (PRP It))) (VP (VBZ is) (ADVP (RB also)) (ADJP (RB straightforward)) (S (VP (TO to) (VP (VB apply) (PP (TO to) (NP (VB recurrent) (JJ neural) (NNS networks))) (PP (IN by) (S (VP (VBG computing) (NP (DT the) (NN normalization) (NNS statistics)) (ADVP (RB separately)) (PP (IN at) (NP (DT each) (NN time) (NN step)))))))))) (. .))
(S (NP (NNP Layer) (NN normalization)) (VP (VBZ is) (ADJP (RB very) (JJ effective) (PP (IN at) (S (VP (VBG stabilizing) (NP (NP (DT the) (JJ hidden) (NN state) (NNS dynamics)) (PP (IN in) (NP (NN recurrent) (NNS networks))))))))) (. .))
(S (ADVP (RB Empirically)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ layer) (NN normalization)) (VP (MD can) (VP (ADVP (RB substantially)) (VB reduce) (NP (DT the) (NN training) (NN time)) (PP (VBN compared) (PP (IN with) (NP (ADJP (RB previously) (VBN published)) (NNS techniques))))))))) (. .))
