(S (NP (NP (NP (ADJP (NN State) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (JJ convolutional) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-)) (VP (VBN used) (PP (IN in) (NP (NN vision) (NNS applications))))) (VP (VBP have) (NP (NP (JJ large) (NNS models)) (PP (IN with) (NP (JJ numerous) (NNS weights))))) (. .))
(S (S (VP (VBG Training) (NP (DT these) (NNS models)))) (VP (VBZ is) (ADVP (RB very)) (VP (VB compute) (HYPH -) (CC and) (PP (NP (NN memory)) (NP (NP (HYPH -) (NN resource)) (ADJP (JJ intensive)))))) (. .))
(S (S (NP (JJ Much) (NN research)) (VP (VBZ has) (VP (VBN been) (VP (VP (VBN done) (PP (IN on) (NP (NN pruning)))) (CC or) (VP (VBG compressing) (NP (DT these) (NNS models)) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (NN inference)))))))))))) (, ,) (CC but) (S (NP (JJ little) (NN work)) (VP (VBZ has) (VP (VBN addressed) (NP (NP (DT the) (NNS costs)) (PP (IN of) (NP (NN training))))))) (. .))
(S (NP (PRP We)) (VP (VBP focus) (ADVP (RB precisely)) (PP (IN on) (NP (VBG accelerating) (NN training)))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NNP PruneTrain)) (, ,) (NP (NP (DT a) (ADJP (NN cost) (HYPH -) (JJ efficient)) (NN mechanism)) (SBAR (WHNP (WDT that)) (S (ADVP (RB gradually)) (VP (VBZ reduces) (NP (DT the) (NN training) (NN cost)) (PP (IN during) (NP (NN training))))))))) (. .))
(S (NP (NNP PruneTrain)) (VP (VBZ uses) (NP (NP (DT a) (JJ structured) (NML (NN group) (HYPH -) (NN lasso)) (NN regularization) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ drives) (NP (NP (DT the) (NN training) (NN optimization)) (PP (IN toward) (NP (DT both) (NML (NML (JJ high) (NN accuracy)) (CC and) (NML (JJ small) (NN weight))) (NNS values))))))))) (. .))
(S (NP (JJ Small) (NNS weights)) (VP (MD can) (ADVP (RB then)) (VP (VB be) (ADVP (RB periodically)) (VP (VBN removed) (PP (IN by) (S (VP (VBG reconfiguring) (NP (DT the) (NN network) (NN model)) (PP (IN to) (NP (DT a) (JJR smaller) (CD one))))))))) (. .))
(S (PP (IN By) (S (VP (VBG using) (NP (NP (DT a) (ADJP (JJ structured) (HYPH -) (NN pruning)) (NN approach)) (CC and) (NP (NP (JJ additional) (NN reconfiguration) (NNS techniques)) (SBAR (S (NP (PRP we)) (VP (VBP introduce))))))))) (, ,) (NP (DT the) (VBN pruned) (NN model)) (VP (MD can) (ADVP (RB still)) (VP (VB be) (ADVP (RB efficiently)) (VP (VBN processed) (PP (IN on) (NP (DT a) (NNP GPU) (NN accelerator)))))) (. .))
(S (ADVP (RB Overall)) (PRN (, ,) (S (NP (NNP PruneTrain)) (VP (VBZ achieves) (NP (NP (DT a) (NN reduction)) (PP (IN of) (NP (NP (CD 39) (NN %)) (PP (IN in) (NP (NP (DT the) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN training)))) (NN time)) (PP (IN of) (NP (NP (NN ResNet50)) (PP (IN for) (NP (NNP ImageNet)))))))))) (PP (IN by) (S (VP (VBG reducing) (NP (NN computation) (NN cost)) (PP (IN by) (NP (NP (CD 40) (NN %)) (PP (IN in) (NP (NNS FLOPs)))))))))) (, ,)) (NP (NN memory)) (VP (VBZ accesses) (PP (IN by) (NP (NP (CD 37) (NN %)) (PP (IN for) (NP (NP (ADJP (NP (NN memory) (NN bandwidth)) (VBN bound)) (NNS layers)) (, ,) (CC and) (NP (NP (DT the) (NN inter-accelerator) (NN communication)) (PP (IN by) (NP (CD 55) (NN %))))))))) (. .))
