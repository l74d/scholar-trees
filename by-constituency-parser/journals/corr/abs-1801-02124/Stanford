(S (NP (DT This) (NN paper)) (VP (VBZ considers) (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (NP (JJ inverse) (NN reinforcement)) (VP (VBG learning) (PP (IN in) (NP (NML (CD zero) (HYPH -) (NN sum)) (JJ stochastic) (NNS games))) (SBAR (WHADVP (WRB when)) (S (NP (JJ expert) (NNS demonstrations)) (VP (VBP are) (VP (VBN known) (S (VP (TO to) (VP (VB be) (ADJP (RB not) (JJ optimal)))))))))))))) (. .))
(S (PP (VBN Compared) (PP (IN to) (NP (NP (JJ previous) (NNS works)) (SBAR (WHNP (WDT that)) (S (VP (VBP decouple) (NP (NP (NNS agents)) (PP (IN in) (NP (DT the) (NN game)))) (PP (IN by) (S (VP (VBG assuming) (NP (NN optimality)) (PP (IN in) (NP (NN expert) (NNS strategies)))))))))))) (, ,) (S (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ new) (JJ objective) (NN function)) (SBAR (WHNP (WDT that)) (S (ADVP (RB directly)) (VP (VBZ pits) (NP (NP (NNS experts)) (PP (IN against) (NP (NNP Nash) (NN Equilibrium) (NNS strategies)))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP design) (NP (DT an) (NN algorithm)) (S (VP (TO to) (VP (VB solve) (PP (IN for) (NP (DT the) (NN reward) (NN function))) (PP (IN in) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (NP (JJ inverse) (NN reinforcement)) (VP (VBG learning) (PP (IN with) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (PP (IN as) (NP (NN model) (NNS approximations))))))))))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (VBG setting))) (NP (DT the) (NN model) (CC and) (NN algorithm)) (VP (VBP do) (RB not) (ADJP (JJ decouple) (PP (IN by) (NP (NN agent))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (VP (VB find) (NP (NP (NNP Nash) (NNP Equilibrium)) (PP (IN in) (NP (NML (JJ large) (HYPH -) (NN scale)) (NNS games))))))))) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VP (VBP propose) (NP (DT an) (JJ adversarial) (NN training) (NN algorithm)) (PP (IN for) (NP (NML (CD zero) (HYPH -) (NN sum)) (JJ stochastic) (NNS games)))) (, ,) (CC and) (VP (VB show) (NP (NP (DT the) (JJ theoretical) (NN appeal)) (PP (IN of) (NP (NP (NN non-existence)) (PP (IN of) (NP (JJ local) (NN optima)))))) (PP (IN in) (NP (PRP$ its) (JJ objective) (NN function))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (JJ numerical) (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (PRP$ our) (NNP Nash) (NN Equilibrium)) (CC and) (NP (NN inverse) (NN reinforcement))) (VP (VBG learning) (NP (NP (NP (NNS algorithms)) (NP (NN address) (NNS games))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (RB not) (ADJP (JJ amenable) (PP (IN to) (NP (NP (JJ previous) (NNS approaches)) (VP (VBG using) (NP (JJ tabular) (NNS representations)))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (PP (IN with) (NP (JJ sub-optimal) (NN expert) (NNS demonstrations))) (NP (PRP$ our) (NNS algorithms)) (VP (VBP recover) (NP (DT both) (NN reward) (NNS functions) (CC and) (NNS strategies)) (PP (IN with) (NP (JJ good) (NN quality)))) (. .))
