(S (NP (DT This) (NN paper)) (VP (VBZ considers) (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (JJ inverse) (NN reinforcement) (VBG learning))) (PP (IN in) (NP (JJ zero-sum) (JJ stochastic) (NNS games))) (SBAR (WHADVP (WRB when)) (S (NP (JJ expert) (NNS demonstrations)) (VP (VBP are) (VP (VBN known) (S (VP (TO to) (VP (VB be) (ADJP (RB not) (JJ optimal))))))))))) (. .))
(S (PP (VBN Compared) (PP (TO to) (NP (NP (JJ previous) (NNS works)) (SBAR (WHNP (WDT that)) (S (VP (VBP decouple) (NP (NP (NNS agents)) (PP (IN in) (NP (DT the) (NN game)))) (PP (IN by) (S (VP (VBG assuming) (NP (NN optimality)) (PP (IN in) (NP (JJ expert) (NNS strategies)))))))))))) (, ,) (S (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ new) (JJ objective) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB directly)) (VBZ pits) (NP (NNS experts)) (PP (IN against) (NP (NNP Nash) (NNP Equilibrium) (NNS strategies))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP design) (NP (NP (DT an) (NN algorithm)) (SBAR (S (VP (TO to) (VP (VB solve) (PP (IN for) (NP (DT the) (NN reward) (NN function))) (PP (IN in) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (JJ inverse) (NN reinforcement) (VBG learning))))) (PP (IN with) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (PP (IN as) (NP (NN model) (NNS approximations)))))))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (VBG setting))) (NP (DT the) (NN model) (CC and) (NNS algorithm)) (VP (VBP do) (RB not) (VP (VB decouple) (PP (IN by) (NP (NN agent))))) (. .))
(S (SBAR (IN In) (NN order) (S (VP (TO to) (VP (VB find) (NP (NNP Nash) (NNP Equilibrium)) (PP (IN in) (NP (JJ large-scale) (NNS games))))))) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VP (VBP propose) (NP (NP (DT an) (JJ adversarial) (NN training) (NN algorithm)) (PP (IN for) (NP (JJ zero-sum) (JJ stochastic) (NNS games))))) (, ,) (CC and) (VP (VB show) (NP (NP (DT the) (JJ theoretical) (NN appeal)) (PP (IN of) (NP (NP (NN non-existence)) (PP (IN of) (NP (JJ local) (NN optima))) (PP (IN in) (NP (PRP$ its) (JJ objective) (NN function)))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (JJ numerical) (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (PRP$ our) (NNP Nash) (NNP Equilibrium) (CC and) (JJ inverse) (NN reinforcement) (VBG learning) (JJ algorithms)) (VP (NN address) (NP (NP (NNS games)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (RB not) (ADJP (JJ amenable) (PP (TO to) (NP (NP (JJ previous) (NNS approaches)) (VP (VBG using) (NP (JJ tabular) (NNS representations)))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (PP (IN with) (NP (JJ sub-optimal) (JJ expert) (NNS demonstrations))) (NP (PRP$ our) (NN algorithms)) (VP (VB recover) (NP (DT both) (NP (NN reward) (NNS functions)) (CC and) (NP (NNS strategies))) (PP (IN with) (NP (JJ good) (NN quality)))) (. .))
