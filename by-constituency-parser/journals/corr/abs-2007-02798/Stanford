(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (JJ new) (NN type)) (PP (IN of) (NP (NP (JJ generative) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (ADVP (RB quickly)) (VP (VB learn) (NP (DT a) (NN latent) (NN representation)) (PP (IN without) (NP (DT an) (NN encoder)))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (S (VP (VP (VBG initialising) (NP (DT a) (NN latent) (NN vector)) (PP (IN with) (NP (NNS zeros)))) (, ,) (ADVP (RB then)) (VP (VBG using) (NP (NP (NNS gradients)) (PP (IN of) (NP (DT the) (NNS data))))) (NP (JJ fitting) (NN loss))))) (PP (IN with) (NP (NN respect))) (PP (IN to) (NP (DT this) (CD zero) (NN vector))) (PP (IN as) (NP (JJ new) (JJ latent) (NNS points))))) (. .))
(S (NP (DT The) (NN approach)) (VP (VP (VBZ has) (NP (JJ similar) (NNS characteristics)) (PP (IN to) (NP (NNS autoencoders)))) (CC but) (VP (PP (IN with) (NP (DT a) (ADJP (JJR simpler)) (ADJP (RB naturally) (VBN balanced)) (NN architecture))))) (, ,) (CC and) (VP (VBZ is) (VP (VBN demonstrated) (PP (IN in) (NP (NP (DT a) (JJ variational) (NN autoencoder) (NN equivalent)) (SBAR (WHNP (WDT that)) (S (VP (VBZ permits) (NP (NN sampling))))))))) (. .))
(S (NP (DT This)) (ADVP (RB also)) (VP (VBZ allows) (NP (JJ implicit) (NN representation) (NNS networks)) (S (VP (TO to) (VP (VB learn) (NP (NP (DT a) (NN space)) (PP (IN of) (NP (JJ implicit) (NNS functions)))) (PP (IN without) (S (VP (VBG requiring) (NP (DT a) (NN hypernetwork)))))))) (, ,) (S (VP (VBG retaining) (NP (PRP$ their) (NN representation) (NNS advantages)) (PP (IN with) (NP (JJR fewer) (NNS parameters)))))) (. .))
