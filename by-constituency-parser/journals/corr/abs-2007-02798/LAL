(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (JJ new) (NN type)) (PP (IN of) (NP (JJ generative) (NN model))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (ADVP (RB quickly)) (VB learn) (NP (DT a) (JJ latent) (NN representation)) (PP (IN without) (NP (DT an) (NN encoder)))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (S (VP (VP (VBG initialising) (NP (DT a) (JJ latent) (NN vector)) (PP (IN with) (NP (NNS zeros)))) (, ,) (ADVP (RB then)) (VP (VBG using) (NP (NP (NNS gradients)) (PP (IN of) (NP (DT the) (NNS data) (NN fitting) (NN loss))) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (DT this) (NN zero) (NN vector)))))) (PP (IN as) (NP (JJ new) (NN latent) (NNS points))))))))) (. .))
(S (NP (DT The) (NN approach)) (VP (VP (VBZ has) (NP (NP (NP (JJ similar) (NNS characteristics)) (PP (TO to) (NP (NNS autoencoders)))) (CC but) (PP (IN with) (NP (DT a) (NN simpler) (ADJP (RB naturally) (JJ balanced)) (NN architecture))))) (, ,) (CC and) (VP (VBZ is) (VP (VBN demonstrated) (PP (IN in) (NP (NP (DT a) (JJ variational) (NN autoencoder) (NN equivalent)) (SBAR (WHNP (IN that)) (S (VP (VBZ permits) (NP (VBG sampling)))))))))) (. .))
(S (NP (DT This)) (ADVP (RB also)) (VP (VBZ allows) (S (NP (JJ implicit) (NN representation) (NNS networks)) (VP (TO to) (VP (VB learn) (NP (NP (DT a) (NN space)) (PP (IN of) (NP (JJ implicit) (NNS functions)))) (PP (IN without) (S (VP (VBG requiring) (NP (DT a) (NN hypernetwork))))) (, ,) (S (VP (VBG retaining) (NP (PRP$ their) (NN representation) (NNS advantages)) (PP (IN with) (NP (JJR fewer) (NNS parameters))))))))) (. .))
