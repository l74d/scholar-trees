(S (NP (PRP We)) (VP (VBP explore) (NP (JJ deep) (JJ autoregressive) (NN Transformer) (NNS models)) (PP (IN in) (NP (NP (NN language) (NN modeling)) (PP (IN for) (NP (NN speech) (NN recognition)))))) (. .))
(S (NP (PRP We)) (VP (VBP focus) (PP (IN on) (NP (CD two) (NNS aspects)))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP revisit) (NP (NN Transformer) (NN model) (NNS configurations)) (ADVP (RB specifically)) (PP (IN for) (NP (NN language) (NN modeling)))) (. .))
(SINV (S (NP (PRP We)) (VP (VBP show) (NP (ADJP (ADVP (RB that) (RB well)) (VBN configured)) (NN Transformer) (NNS models)))) (VP (VBP outperform) (NP (PRP$ our) (NN baseline) (NNS models)) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (JJ shallow) (NN stack)) (PP (IN of) (NP (NNP LSTM)))))) (S (ADJP (JJ recurrent)))) (NP (NML (JJ neural) (NN network)) (NNS layers)) (. .))
(S (NP (PRP We)) (VP (VBP carry) (PRT (RP out)) (NP (NP (NNS experiments)) (PP (IN on) (NP (NP (DT the) (NML (JJ open) (HYPH -) (NN source)) (NNP LibriSpeech) (NML (CD 960) (NN hr)) (NN task)) (, ,) (PP (IN for) (NP (DT both) (NN 200K) (NN vocabulary) (NML (NML (NN word) (HYPH -) (NN level)) (CC and) (NML (NN 10K))) (NN byte) (HYPH -) (NN pair)))))) (S (VP (VBG encoding) (NP (NML (NN subword) (HYPH -) (NN level)) (NN language) (NN modeling))))) (. .))
(S (NP (PRP We)) (VP (VBP apply) (NP (PRP$ our) (NML (NN word) (HYPH -) (NN level)) (NNS models)) (PP (IN to) (NP (NP (NP (NML (JJ conventional) (NN hybrid)) (NN speech) (NN recognition)) (PP (IN by) (NP (NN lattice) (NN rescoring)))) (, ,) (CC and) (NP (DT the) (NML (NN subword) (HYPH -) (NN level)) (NNS models)))) (PP (IN to) (NP (NP (NN attention)) (VP (VBN based) (NP (NML (NN encoder) (HYPH -) (NN decoder)) (NNS models)) (PP (IN by) (NP (JJ shallow) (NN fusion))))))) (. .))
(S (ADVP (RB Second)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ deep) (NN Transformer) (NN language) (NNS models)) (VP (VBP do) (RB not) (VP (VB require) (NP (JJ positional) (NN encoding))))))) (. .))
(S (NP (DT The) (JJ positional) (NN encoding)) (VP (VBZ is) (NP (NP (DT an) (JJ essential) (NN augmentation)) (PP (IN for) (NP (NP (DT the) (ADJP (NN self) (HYPH -) (NN attention)) (NN mechanism)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ invariant) (PP (IN to) (NP (NN sequence) (NN ordering))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (JJ autoregressive) (NN setup))) (, ,) (NP (ADJP (RB as))) (VP (VBZ is) (NP (NP (DT the) (NN case)) (PP (IN for) (NP (NP (NN language) (NN modeling)) (, ,) (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NP (NP (NN information) (NNS increases)) (PP (IN along) (NP (DT the) (NN position) (NN dimension)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (DT a) (JJ positional) (NN signal)) (PP (IN by) (NP (PRP$ its) (JJ own)))))))))))))) (. .))
(S (NP (NP (DT The) (NN analysis)) (PP (IN of) (NP (NN attention) (NNS weights)))) (VP (VBZ shows) (SBAR (IN that) (S (NP (JJ deep) (ADJP (JJ autoregressive) (NP (NN self) (HYPH -) (NN attention))) (NNS models)) (VP (MD can) (ADVP (RB automatically)) (VP (VB make) (NP (NP (NN use)) (PP (IN of) (NP (JJ such) (JJ positional) (NN information))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (S (VP (VBG removing) (NP (DT the) (JJ positional)) (S (VP (VBG encoding) (ADVP (RB even) (RB slightly)))))) (VP (VBZ improves) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT these) (NNS models)))))))) (. .))
