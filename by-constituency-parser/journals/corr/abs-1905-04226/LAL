(S (NP (PRP We)) (VP (VBP explore) (NP (JJ deep) (JJ autoregressive) (NNP Transformer) (NNS models)) (PP (IN in) (NP (NP (NN language) (NN modeling)) (PP (IN for) (NP (NN speech) (NN recognition)))))) (. .))
(S (NP (PRP We)) (VP (VBP focus) (PP (IN on) (NP (CD two) (NNS aspects)))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP revisit) (NP (NP (NNP Transformer) (NN model) (NNS configurations)) (PP (ADVP (RB specifically)) (IN for) (NP (NN language) (NN modeling))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (DT that) (S (NP (ADJP (RB well) (VBN configured)) (NNP Transformer) (NNS models)) (VP (IN outperform) (NP (NP (PRP$ our) (NN baseline) (NNS models)) (VP (VBN based) (PP (IN on) (NP (NP (DT the) (JJ shallow) (NN stack)) (PP (IN of) (NP (NNP LSTM) (NN recurrent) (JJ neural) (NN network) (NNS layers))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP carry) (PRT (RP out)) (NP (NNS experiments)) (PP (IN on) (NP (DT the) (JJ open-source) (NNP LibriSpeech) (CD 960hr) (NN task))) (, ,) (PP (IN for) (NP (DT both) (NP (CD 200K) (JJ vocabulary) (NN word-level)) (CC and) (ADJP (CD 10K) (JJ byte-pair) (VBG encoding) (JJ subword-level)) (NN language) (NN modeling)))) (. .))
(S (NP (PRP We)) (VP (VP (VBP apply) (NP (PRP$ our) (JJ word-level) (NNS models)) (PP (TO to) (NP (JJ conventional) (JJ hybrid) (NN speech) (NN recognition))) (PP (IN by) (NP (NN lattice) (NN rescoring)))) (, ,) (CC and) (VP (NP (DT the) (JJ subword-level) (NNS models)) (PP (TO to) (NP (ADJP (NN attention) (VBN based)) (JJ encoder-decoder) (NNS models))) (PP (IN by) (NP (JJ shallow) (NN fusion))))) (. .))
(S (ADVP (JJ Second)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ deep) (NNP Transformer) (NN language) (NNS models)) (VP (VBP do) (RB not) (VP (VB require) (NP (JJ positional) (NN encoding))))))) (. .))
(S (NP (DT The) (JJ positional) (NN encoding)) (VP (VBZ is) (NP (NP (DT an) (JJ essential) (NN augmentation)) (PP (IN for) (NP (NP (DT the) (NN self-attention) (NN mechanism)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ invariant) (PP (TO to) (NP (VB sequence) (NN ordering))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (JJ autoregressive) (NN setup))) (, ,) (SBAR (IN as) (S (VP (VBZ is) (NP (DT the) (NN case)) (PP (IN for) (NP (NN language) (NN modeling)))))) (, ,) (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NN information)))) (VP (NNS increases) (PP (IN along) (NP (NP (DT the) (NN position) (NN dimension)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (DT a) (JJ positional) (NN signal)) (PP (IN by) (NP (PRP$ its) (JJ own))))))))) (. .))
(S (NP (NP (DT The) (NN analysis)) (PP (IN of) (NP (NN attention) (NNS weights)))) (VP (VBZ shows) (SBAR (IN that) (S (NP (JJ deep) (JJ autoregressive) (NN self-attention) (NNS models)) (VP (MD can) (ADVP (RB automatically)) (VP (VB make) (NP (NN use)) (PP (IN of) (NP (JJ such) (JJ positional) (NN information)))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (S (VP (VBG removing) (NP (DT the) (JJ positional) (VBG encoding)))) (VP (ADVP (RB even) (RB slightly)) (VBZ improves) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT these) (NNS models)))))))) (. .))
