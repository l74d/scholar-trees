(S (NP (DT This) (NN paper)) (VP (VBZ presents) (NP (NP (DT a) (JJ novel) (NN optimization) (NN method)) (PP (IN for) (S (VP (VBG maximizing) (NP (NP (NN generalization)) (PP (IN over) (NP (NP (NNS tasks)) (PP (IN in) (NP (NN meta-learning))))))))))) (. .))
(S (NP (NP (DT The) (NN goal)) (PP (IN of) (NP (NN meta-learning)))) (VP (VBZ is) (S (VP (TO to) (VP (VB learn) (NP (NP (DT a) (NN model)) (PP (IN for) (NP (NP (DT an) (NN agent)) (VP (VBG adapting) (ADVP (RB rapidly)) (SBAR (WHADVP (WRB when)) (S (VP (VBN presented) (PP (IN with) (NP (ADJP (RB previously) (JJ unseen)) (NNS tasks)))))))))))))) (. .))
(S (NP (NNS Tasks)) (VP (VBP are) (VP (VBN sampled) (PP (IN from) (NP (NP (DT a) (JJ specific) (NN distribution)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN assumed) (S (VP (TO to) (VP (VB be) (ADJP (JJ similar)) (PP (IN for) (NP (ADJP (DT both) (VBN seen) (CC and) (JJ unseen)) (NNS tasks)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP focus) (PP (IN on) (NP (NP (DT a) (NN family)) (PP (IN of) (NP (NP (NP (JJ meta-learning) (NNS methods)) (VP (VBG learning) (NP (NP (NP (JJ initial) (NNS parameters)) (PP (IN of) (NP (DT a) (NN base) (NN model)))) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (JJ fine-tuned) (ADVP (RB quickly)) (PP (IN on) (NP (DT a) (JJ new) (NN task))) (, ,) (PP (IN by) (NP (JJ few) (JJ gradient) (NNS steps))))))))))) (PRN (-LRB- -LRB-) (NP (NNP MAML)) (-RRB- -RRB-))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (S (VP (VBG pushing) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT the) (NN model)))) (PP (TO to) (NP (NP (DT a) (NN direction)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNS tasks)) (VP (VBP have) (NP (NP (JJR more) (NN agreement)) (PP (IN upon))))))))))))) (. .))
(S (SBAR (IN If) (S (NP (NP (DT the) (NNS gradients)) (PP (IN of) (NP (DT a) (NN task)))) (VP (NN agree) (PP (IN with) (NP (DT the) (NNS parameters) (JJ update) (NN vector)))))) (, ,) (ADVP (RB then)) (NP (PRP$ their) (JJ inner) (NN product)) (VP (MD will) (VP (VB be) (NP (DT a) (JJ large) (JJ positive) (NN value)))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (PP (VBN given) (NP (NP (DT a) (NN batch)) (PP (IN of) (NP (NP (NNS tasks)) (SBAR (S (VP (TO to) (VP (VB be) (VP (VBN optimized) (PP (IN for))))))))))) (, ,) (NP (PRP we)) (VP (VBP associate) (NP (DT a) (JJ positive) (PRN (-LRB- -LRB-) (JJ negative) (-RRB- -RRB-)) (NN weight)) (PP (TO to) (NP (NP (DT the) (NN loss) (NN function)) (PP (IN of) (NP (DT a) (NN task))))) (, ,) (SBAR (IN if) (S (NP (NP (DT the) (JJ inner) (NN product)) (PP (IN between) (NP (NP (PRP$ its) (NNS gradients)) (CC and) (NP (NP (DT the) (NN average)) (PP (IN of) (NP (NP (DT the) (NNS gradients)) (PP (IN of) (NP (NP (DT all) (NNS tasks)) (PP (IN in) (NP (DT the) (NN batch))))))))))) (VP (VBZ is) (NP (DT a) (JJ positive) (PRN (-LRB- -LRB-) (JJ negative) (-RRB- -RRB-)) (NN value)))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (NP (DT the) (NN degree)) (PP (IN of) (NP (NP (DT the) (NN contribution)) (PP (IN of) (NP (DT a) (NN task))) (PP (TO to) (NP (DT the) (NN parameter) (VBZ updates)))))) (VP (VBZ is) (VP (VBN controlled) (PP (IN by) (S (VP (VBG introducing) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NNS weights)) (PP (IN on) (NP (NP (DT the) (NN loss) (NN function)) (PP (IN of) (NP (DT the) (NNS tasks))))))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (MD can) (VP (VB be) (VP (ADVP (RB easily)) (VBN integrated) (PP (IN with) (NP (NP (DT the) (JJ current) (JJ meta-learning) (NN algorithms)) (PP (IN for) (NP (JJ neural) (NNS networks)))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ yields) (NP (NP (NNS models)) (PP (IN with) (NP (JJR better) (NN generalization))) (PP (VBN compared) (PP (TO to) (NP (NNP MAML) (CC and) (NNP Reptile))))))))) (. .))
