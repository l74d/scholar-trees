(S (S (SBAR (IN As) (S (NP (NP (CD one)) (PP (IN of) (NP (JJ standard) (NNS approaches)))) (VP (TO to) (VP (VB train) (NP (JJ deep) (JJ neural) (NNS networks)))))) (, ,) (NP (NN dropout)) (VP (VBZ has) (VP (VBN been) (VP (VBN applied) (PP (IN to) (S (VP (VB regularize) (NP (JJ large) (NNS models)) (S (VP (TO to) (VP (VB avoid) (NP (NN overfitting)))))))))))) (, ,) (CC and) (S (NP (NP (DT the) (NN improvement)) (PP (IN in) (NP (NP (NN performance)) (PP (IN by) (NP (NN dropout)))))) (VP (VBZ has) (VP (VBN been) (VP (VBN explained) (PP (IN as) (S (VP (VBG avoiding) (NP (NP (NN co-adaptation)) (PP (IN between) (NP (NNS nodes))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNS correlations)) (PP (IN between) (NP (NNS nodes)))) (VP (VBP are) (PP (VBN compared) (PP (IN after) (S (VP (VBG training) (NP (DT the) (NNS networks)) (PP (IN with) (CC or) (IN without) (NP (NN dropout)))))))))) (, ,) (NP (CD one) (NN question)) (VP (VBZ arises) (SBAR (IN if) (S (NP (NN co-adaptation) (NN avoidance)) (VP (VBZ explains) (NP (DT the) (NN dropout) (NN effect)) (ADVP (RB completely)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (JJ additional) (NN explanation)) (PP (IN of) (SBAR (WHADVP (WRB why)) (S (NP (NN dropout)) (VP (VP (VBZ works)) (CC and) (VP (VB propose) (NP (DT a) (JJ new) (NN technique)) (S (VP (TO to) (VP (VB design) (NP (JJR better) (NN activation) (NNS functions)))))))))))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NN dropout)) (VP (MD can) (VP (VB be) (VP (VBN explained) (PP (IN as) (NP (DT an) (NN optimization) (NN technique))) (S (VP (TO to) (VP (VB push) (NP (DT the) (NN input)) (PP (IN towards) (NP (NP (DT the) (NN saturation) (NN area)) (PP (IN of) (NP (JJ nonlinear) (NN activation) (NN function))))) (PP (IN by) (NP (NP (VBG accelerating) (NN gradient) (NN information)) (VP (VBG flowing) (ADVP (RB even)) (PP (IN in) (NP (NP (DT the) (NN saturation) (NN area)) (PP (IN in) (NP (NN backpropagation))))))))))))))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (NP (NN input)) (PP (IN to) (NP (DT the) (NN activation) (NN function)))) (VP (MD can) (VP (VB climb) (PP (IN onto) (NP (NP (DT the) (NN saturation) (NN area)) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (NP (DT the) (NN network)) (ADJP (RBR more) (JJ robust))) (SBAR (IN because) (S (NP (DT the) (NN model)) (VP (VBZ converges) (PP (IN on) (NP (DT a) (JJ flat) (NN region))))))))))))) (. .))
(S (NP (NN Experiment) (NNS results)) (VP (VP (VBP support) (NP (NP (PRP$ our) (NN explanation)) (PP (IN of) (NP (NN dropout))))) (CC and) (VP (VB confirm) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN GAAF) (NN technique)) (VP (VBZ improves) (NP (NP (NML (NN image) (NN classification)) (NN performance)) (PP (IN with) (NP (VBN expected) (NNS properties))))))))) (. .))
