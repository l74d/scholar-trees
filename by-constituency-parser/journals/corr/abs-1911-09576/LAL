(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN approach)) (PP (TO to) (S (VP (VBG addressing) (NP (NP (DT the) (ADJP (ADJP (NN vanishing)) (PRN (-LRB- -LRB-) (CC or) (VBG exploding) (-RRB- -RRB-))) (NN gradient) (NN problem)) (PP (IN in) (NP (JJ deep) (JJ neural) (NNS networks))))))))) (. .))
(S (NP (PRP We)) (VP (VBP construct) (NP (NP (DT a) (JJ new) (NN architecture)) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks))) (SBAR (WHADVP (WRB where)) (S (NP (NP (NP (DT all) (NNS layers)) (PRN (-LRB- -LRB-) (PP (IN except) (NP (DT the) (NN output) (NN layer))) (-RRB- -RRB-))) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBP are) (NP (NP (DT a) (NN combination)) (PP (IN of) (NP (NP (NN rotation) (, ,) (NN permutation) (, ,) (JJ diagonal) (, ,) (CC and) (NN activation) (NNS sublayers)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (DT all) (ADJP (NN volume) (VBG preserving))))))))))))) (. .))
(S (NP (NP (DT This) (NN control)) (PP (IN on) (NP (DT the) (NN volume)))) (VP (VBZ forces) (S (NP (DT the) (NN gradient)) (PRN (-LRB- -LRB-) (PP (IN on) (NP (NN average))) (-RRB- -RRB-)) (VP (TO to) (VP (VP (VB maintain) (NP (NN equilibrium))) (CC and) (VP (RB not) (VB explode) (CC or) (VB vanish)))))) (. .))
(S (S (NP (JJ Volume-preserving) (JJ neural) (NNS networks)) (VP (NN train) (ADVP (RB reliably) (, ,) (RB quickly) (CC and) (RB accurately)))) (CC and) (S (NP (DT the) (NN learning) (NN rate)) (VP (VBZ is) (ADJP (JJ consistent)) (PP (IN across) (NP (NP (NNS layers)) (PP (IN in) (NP (JJ deep) (JJ volume-preserving) (JJ neural) (NNS networks))))))) (. .))
(S (S (VP (TO To) (VP (VB demonstrate) (NP (DT this))))) (NP (PRP we)) (VP (VB apply) (NP (PRP$ our) (JJ volume-preserving) (JJ neural) (NN network) (NN model)) (PP (TO to) (NP (CD two) (JJ standard) (NNS datasets)))) (. .))
