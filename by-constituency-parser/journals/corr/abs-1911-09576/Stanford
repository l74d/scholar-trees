(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (JJ novel) (NN approach)) (PP (IN to) (S (VP (VP (VP (VBG addressing) (NP (DT the) (VBG vanishing))) (-LRB- -LRB-) (CC or) (VP (VBG exploding)) (-RRB- -RRB-)) (NP (NP (NN gradient) (NN problem)) (PP (IN in) (NP (JJ deep) (JJ neural) (NNS networks)))))))) (. .))
(S (NP (PRP We)) (VP (VBP construct) (NP (DT a) (JJ new) (NN architecture)) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks))) (SBAR (WHADVP (WRB where)) (S (NP (NP (NP (DT all) (NNS layers)) (-LRB- -LRB-) (PP (IN except) (NP (DT the) (NN output) (NN layer))) (-RRB- -RRB-)) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBP are) (NP (NP (NP (DT a) (NN combination)) (PP (IN of) (NP (NP (NN rotation)) (, ,) (NP (NN permutation)) (, ,) (NP (JJ diagonal)) (, ,) (CC and) (NP (NN activation) (NNS sublayers))))) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (NP (NP (DT all) (NN volume)) (VP (VBG preserving))))))))))) (. .))
(S (NP (NP (DT This) (NN control)) (PP (IN on) (NP (DT the) (NN volume)))) (VP (VBZ forces) (NP (NP (DT the) (NN gradient)) (-LRB- -LRB-) (PP (IN on) (NP (JJ average))) (-RRB- -RRB-)) (S (VP (TO to) (VP (VP (VB maintain) (NP (NN equilibrium))) (CC and) (RB not) (VP (VB explode) (CC or) (VB vanish)))))) (. .))
(S (S (S (VP (NN Volume) (HYPH -) (VBG preserving) (NP (JJ neural) (NNS networks)))) (VP (VBP train) (ADVP (RB reliably)) (, ,) (ADVP (RB quickly) (CC and) (RB accurately)))) (CC and) (S (NP (DT the) (NN learning) (NN rate)) (VP (VBZ is) (ADJP (JJ consistent) (PP (IN across) (NP (NP (NNS layers)) (PP (IN in) (NP (ADJP (NP (JJ deep) (NN volume)) (HYPH -) (VBG preserving)) (JJ neural) (NNS networks)))))))) (. .))
(S (S (VP (TO To) (VP (VB demonstrate) (NP (DT this))))) (NP (PRP we)) (VP (VBP apply) (NP (NP (PRP$ our) (NN volume)) (HYPH -) (SBAR (S (VP (VBG preserving) (NP (JJ neural) (NN network) (NN model)) (PP (IN to) (NP (CD two) (JJ standard) (NNS datasets)))))))) (. .))
