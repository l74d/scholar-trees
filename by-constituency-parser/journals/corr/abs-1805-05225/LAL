(S (NP (PRP We)) (VP (VBP compare) (NP (NP (NP (DT the) (JJ fast) (NN training) (CC and) (VBG decoding) (NN speed)) (PP (IN of) (NP (NP (NNP RETURNN)) (PP (IN of) (NP (NN attention) (NNS models))))) (PP (IN for) (NP (NN translation))) (, ,) (PP (JJ due) (PP (TO to) (NP (VB fast) (NNP CUDA) (NNP LSTM) (NNS kernels))))) (, ,) (CC and) (NP (DT a) (JJ fast) (NN pure) (NNP TensorFlow) (NN beam) (NN search) (NN decoder)))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (S (NP (NP (DT a) (JJ layer-wise) (NN pretraining) (NN scheme)) (PP (IN for) (NP (JJ recurrent) (NN attention) (NNS models)))) (VP (VBZ gives) (NP (NP (ADJP (QP (IN over) (CD 1)) (NN %)) (NNP BLEU) (NN improvement)) (ADJP (NN absolute))))) (CC and) (S (NP (PRP it)) (VP (VBZ allows) (S (VP (TO to) (VP (VB train) (NP (JJ deeper) (NN recurrent) (NN encoder) (NNS networks)))))))))) (. .))
(S (VP (VBG Promising) (NP (NP (JJ preliminary) (NNS results)) (PP (IN on) (NP (NN max))))) (. .))
(S (NP (VBN expected) (NNP BLEU) (NN training)) (VP (VBP are) (VP (VBN presented))) (. .))
(S (NP (PRP We)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VP (VB train) (NP (NP (NP (JJ state-of-the-art) (NNS models)) (PP (IN for) (NP (NN translation)))) (CC and) (NP (NP (JJ end-to-end) (NNS models)) (PP (IN for) (NP (JJ speech) (NN recognition)))))) (CC and) (VP (NN show) (NP (NNS results)) (PP (IN on) (NP (NP (NNP WMT) (CD 2017)) (CC and) (NP (NNP Switchboard)))))))))) (. .))
(S (S (NP (NP (DT The) (NN flexibility)) (PP (IN of) (NP (NNP RETURNN)))) (VP (VBZ allows) (S (NP (DT a) (JJ fast) (NN research) (NN feedback) (NN loop)) (VP (TO to) (VP (VB experiment) (PP (IN with) (NP (JJ alternative) (NNS architectures)))))))) (, ,) (CC and) (S (NP (PRP$ its) (NN generality)) (VP (VBZ allows) (S (VP (TO to) (VP (VB use) (NP (PRP it)) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNS applications)))))))))) (. .))
