(S (NP (PRP We)) (VP (VBP present) (NP (NP (NP (DT a) (ADJP (RB theoretically) (VBN grounded)) (NN approach)) (PP (IN to) (NP (NN train) (JJ deep) (JJ neural) (NNS networks)))) (, ,) (PP (VBG including) (NP (NP (ADJP (JJ recurrent)) (NNS networks)) (, ,) (NP (NP (NN subject)) (PP (IN to) (NP (ADJP (NN class) (HYPH -) (JJ dependent)) (NN label) (NN noise)))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (CD two) (NNS procedures)) (PP (IN for) (NP (NP (NN loss) (NN correction)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ agnostic) (PP (IN to) (NP (NP (DT both) (NN application) (NN domain)) (CC and) (NP (NN network) (NN architecture)))))))))))) (. .))
(S (NP (PRP They)) (ADVP (RB simply)) (VP (VB amount) (PP (IN to) (NP (NP (ADVP (IN at) (RBS most)) (DT a) (NML (NN matrix) (NN inversion) (CC and) (NN multiplication))) (, ,) (SBAR (S (VP (VBD provided) (SBAR (IN that) (S (NP (PRP we)) (VP (VBP know) (NP (NP (DT the) (NN probability)) (PP (IN of) (NP (NP (DT each) (NN class)) (VP (VBG being) (VP (VBN corrupted) (PP (IN into) (NP (DT another))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (NP (PRP one)) (VP (MD can) (VP (VB estimate) (NP (NP (DT these) (NNS probabilities)) (, ,) (S (S (VP (VBG adapting) (NP (NP (DT a) (JJ recent) (NN technique)) (PP (IN for) (NP (NN noise) (NN estimation)))) (PP (IN to) (NP (DT the) (NN multi-class) (NN setting))))) (, ,) (CC and) (ADVP (RB thus)) (S (VP (VBG providing) (NP (DT an) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NN framework))))))))))) (. .))
(S (S (NP (NP (NP (NP (JJ Extensive) (NNS experiments)) (PP (IN on) (NP (NNP MNIST) (, ,) (NNP IMDB) (, ,) (NNP CIFAR) (HYPH -) (CD 10) (, ,)))) (NP (NN CIFAR) (HYPH -) (CD 100))) (CC and) (NP (NP (DT a) (NML (JJ large) (NN scale)) (NN dataset)) (PP (IN of) (NP (NN clothing) (NNS images))))) (VP (VBG employing) (NP (NP (DT a) (NN diversity)) (PP (IN of) (NP (NNS architectures)))))) (NFP ---) (S (S (VP (VP (VBG stacking) (ADJP (JJ dense) (, ,) (JJ convolutional))) (, ,) (VP (VBG pooling)))) (, ,) (NP (NP (NN dropout)) (, ,) (NP (NP (NN batch) (NN normalization)) (, ,) (NP (NN word) (NN embedding)) (, ,) (NP (NN LSTM)) (CC and) (NP (JJ residual) (NNS layers))) (, ---)) (VP (VBP demonstrate) (NP (NP (DT the) (NN noise) (NN robustness)) (PP (IN of) (NP (PRP$ our) (NNS proposals)))))) (. .))
(S (ADVP (RB Incidentally)) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VBP prove) (SBAR (IN that) (, ,) (S (SBAR (WHADVP (WRB when)) (S (NP (NN ReLU)) (VP (VBZ is) (NP (DT the) (JJ only) (NN non-linearity))))) (, ,) (NP (DT the) (NN loss) (NN curvature)) (VP (VBZ is) (ADJP (JJ immune) (PP (IN to) (NP (ADJP (NN class) (HYPH -) (JJ dependent)) (NN label) (NN noise)))))))) (. .))
