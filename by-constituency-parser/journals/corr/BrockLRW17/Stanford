(S (NP (NP (DT The) (JJ early) (NNS layers)) (PP (IN of) (NP (DT a) (JJ deep) (JJ neural) (NN net)))) (VP (VP (VBP have) (NP (DT the) (JJS fewest) (NNS parameters))) (, ,) (CC but) (VP (VB take) (PRT (RP up)) (NP (DT the) (RBS most) (JJ computation)))) (. .))
(S (PP (IN In) (NP (DT this) (JJ extended) (NN abstract))) (, ,) (NP (PRP we)) (VP (VBP propose) (PP (IN to) (NP (S (ADVP (RB only)) (VP (VB train) (NP (NP (DT the) (JJ hidden) (NNS layers)) (PP (IN for) (NP (NP (NP (NP (DT a) (NN set) (NN portion)) (PP (IN of) (NP (DT the) (NN training) (NN run)))) (, ,) (VP (VBG freezing) (NP (PRP them)) (PRT (RP out)))) (NML (NML (CD one)) (HYPH -) (PP (IN by) (HYPH -) (NP (CD one))))))))) (CC and) (S (VP (VBG excluding) (NP (PRP them)) (PP (IN from) (NP (DT the) (JJ backward) (NN pass)))))))) (. .))
(S (PP (IN Through) (NP (NP (NNS experiments)) (PP (IN on) (NP (NNP CIFAR))))) (, ,) (NP (PRP we)) (ADVP (RB empirically)) (VP (VBP demonstrate) (SBAR (IN that) (FRAG (NP (NP (NNP FreezeOut) (NNS yields)) (PP (NP (NNS savings)) (IN of))) (ADVP (RB up) (PP (IN to) (NP (NML (CD 20) (NN %)) (NML (NN wall) (HYPH -) (NN clock)) (NN time)))) (PP (IN during) (NP (NN training))) (PP (IN with) (NP (NP (NP (NML (CD 3) (NN %)) (NN loss)) (PP (IN in) (NP (NP (NN accuracy)) (PP (IN for) (NP (NNPS DenseNets)))))) (, ,) (NP (NP (DT a) (NML (CD 20) (NN %)) (NN speedup)) (PP (IN without) (NP (NP (NN loss)) (PP (IN of) (NP (NP (NN accuracy)) (PP (IN for) (NP (NNPS ResNets)))))))) (, ,) (CC and) (NP (NP (DT no) (NN improvement)) (PP (IN for) (NP (NNP VGG) (NNS networks))))))))) (. .))
(S (NP (PRP$ Our) (NN code)) (VP (VBZ is) (ADJP (RB publicly) (JJ available) (PP (IN at) (NP (NP (DT this)) (SBAR (S (VP (VBZ https) (NP (NN URL))))))))))
