(S (S (ADVP (RB Typically)) (, ,) (NP (NP (JJ Ultra-deep) (JJ neural) (NN network)) (-LRB- -LRB-) (NP (NNP UDNN)) (-RRB- -RRB-)) (VP (VBZ tends) (S (VP (TO to) (VP (VB yield) (NP (NML (JJ high) (HYPH -) (NN quality)) (NN model))))))) (, ,) (CC but) (S (NP (PRP$ its) (NN training) (NN process)) (VP (VBZ is) (ADVP (RB usually)) (NP (NP (NN resource)) (ADJP (ADJP (JJ intensive)) (CC and) (ADJP (NN time) (HYPH -) (VBG consuming)))))) (. .))
(S (NP (NP (JJ Modern) (NNP GPU) (POS 's)) (JJ scarce) (NNP DRAM) (NN capacity)) (VP (VBZ is) (NP (NP (DT the) (JJ primary) (NN bottleneck)) (SBAR (WHNP (WDT that)) (S (VP (VBZ hinders) (NP (NP (DT the) (NN trainability)) (CC and) (NP (NP (DT the) (NN training) (NN efficiency)) (PP (IN of) (NP (NNP UDNN)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (`` ") (NNP AccUDNN) ('' ")) (, ,) (NP (NP (DT an) (NN accelerator)) (SBAR (WHNP (WDT that)) (S (VP (VBZ aims) (S (VP (TO to) (VP (VB make) (NP (NP (DT the) (JJ utmost) (NN use)) (PP (IN of) (NP (JJ finite) (NNP GPU) (NN memory) (NNS resources)))) (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (NP (DT the) (NN training) (NN process)) (PP (IN of) (NP (NNP UDNN)))))))))))))))) (. .))
(S (NP (NNP AccUDNN)) (ADVP (RB mainly)) (VP (VBZ includes) (NP (NP (CD two) (NNS modules)) (: :) (NP (NP (NN memory) (NN optimizer)) (CC and) (NP (NN hyperparameter) (NN tuner))))) (. .))
(S (S (NP (NN Memory) (NN optimizer)) (VP (VBZ develops) (NP (DT a) (ADJP (NP (NN performance) (HYPH -) (NN model)) (VBN guided)) (NML (NML (JJ dynamic) (NN swap) (NN out)) (HYPH /) (PP (IN in) (NP (NN strategy))))) (, ,) (PP (IN by) (S (VP (VBG offloading) (NP (JJ appropriate) (NNS data)) (S (VP (TO to) (VP (VB host) (NP (NN memory)))))))))) (, ,) (NP (NNP GPU) (NN memory) (NN footprint)) (VP (MD can) (VP (VB be) (ADVP (RB significantly)) (VP (VBN slashed) (S (VP (TO to) (VP (VB overcome) (NP (NP (DT the) (NN restriction)) (PP (IN of) (NP (NP (NN trainability)) (PP (IN of) (NP (NNP UDNN)))))))))))) (. .))
(S (PP (IN After) (S (VP (VBG applying) (NP (DT the) (NML (NN memory) (NN optimization)) (NN strategy))))) (, ,) (NP (NN hyperparameter) (NN tuner)) (VP (VBZ is) (VP (VBN designed) (S (VP (TO to) (VP (VB explore) (NP (NP (DT the) (ADJP (NP (NN efficiency)) (HYPH -) (JJ optimal)) (NN minibatch) (NN size)) (CC and) (NP (DT the) (VBN matched) (NN learning) (NN rate)))))))) (. .))
(S (NP (NNS Evaluations)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NNP AccUDNN)) (VP (VBZ cuts) (PRT (RP down)) (NP (NP (DT the) (NNP GPU) (NN memory) (NN requirement)) (PP (IN of) (NP (NP (NNP ResNet) (HYPH -) (CD 152)) (PP (IN from) (NP (NP (QP (JJR more) (IN than) (CD 24)) (NNS GB)) (PP (TO to) (NP (CD 8) (NN GB)))))))))))) (. .))
(S (PP (IN In) (NP (NN turn))) (, ,) (PP (VBN given) (NP (CD 12) (NNP GB) (NNP GPU) (NN memory) (NN budget))) (, ,) (NP (DT the) (ADJP (NP (NN efficiency)) (HYPH -) (JJ optimal)) (NN minibatch) (NN size)) (VP (MD can) (VP (VB reach) (NP (QP (CD 4.2) (SYM x)) (JJR larger)) (PP (IN than) (NP (JJ original) (NNP Caffe))))) (. .))
(S (S (VP (VBG Benefiting) (PP (IN from) (NP (NP (NP (JJR better) (NN utilization)) (PP (IN of) (NP (NP (JJ single) (NNP GPU) (POS 's)) (NN computing) (NNS resources)))) (CC and) (NP (NP (JJR fewer) (NN parameter) (NN synchronization)) (PP (IN of) (NP (JJ large) (NN minibatch) (NN size)))))))) (, ,) (NP (QP (CD 7.7) (SYM x)) (NML (NN speed) (HYPH -) (NN up))) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (NP (NP (CD 8) (NNS GPUs) (POS ')) (NN cluster))) (PP (IN without) (NP (NP (DT any) (NN communication) (NN optimization)) (CC and) (NP (DT no) (NN accuracy) (NNS losses)))))) (. .))
