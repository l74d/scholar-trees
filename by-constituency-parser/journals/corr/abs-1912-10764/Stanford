(S (NP (NP (JJ Deep) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-)) (VP (VBP depend) (PP (IN on) (NP (NP (DT the) (NN storage)) (PP (IN of) (NP (NP (DT a) (JJ large) (NN number)) (PP (IN of) (NP (NP (NNS parameters)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ consumes) (NP (NP (DT an) (JJ important) (NN portion)) (PP (IN of) (NP (NP (DT the) (NN energy)) (VP (VBN used) (PP (IN during) (NP (NN inference))))))))))))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ considers) (NP (NP (DT the) (NN case)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (NN energy) (NN usage)) (PP (IN of) (NP (NN memory) (NNS elements)))) (VP (MD can) (VP (VB be) (VP (VBN reduced) (PP (IN at) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (VBN reduced) (NN reliability)))))))))))) (. .))
(S (NP (DT A) (NN training) (NN algorithm)) (VP (VBZ is) (VP (VBN proposed) (S (VP (TO to) (VP (VB optimize) (NP (NP (DT the) (NN reliability)) (PP (IN of) (NP (DT the) (NN storage)))) (PP (ADVP (RB separately)) (IN for) (NP (NP (DT each) (NN layer)) (PP (IN of) (NP (DT the) (NN network))))) (, ,) (PP (IN while) (S (VP (VBG incurring) (NP (DT a) (JJ negligible) (NN complexity) (NN overhead)) (PP (VBN compared) (PP (IN to) (NP (DT a) (JJ conventional) (JJ stochastic) (NN gradient) (NN descent) (NN training)))))))))))) (. .))
