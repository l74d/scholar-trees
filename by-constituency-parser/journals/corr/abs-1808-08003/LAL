(S (NP (NN Sequence-to-Sequence) (NNS models)) (VP (VBD were) (VP (VBN introduced) (S (VP (TO to) (VP (VB tackle) (NP (NP (JJ many) (JJ real-life) (NNS problems)) (PP (IN like) (NP (NP (NN machine) (NN translation)) (, ,) (NP (NN summarization)) (, ,) (NP (NN image) (NN captioning)) (, ,) (FW etc))))))))) (. .))
(S (NP (DT The) (JJ standard) (NN optimization) (NNS algorithms)) (VP (VBP are) (ADVP (RB mainly)) (VP (VBN based) (PP (IN on) (NP (NP (JJ example-to-example) (NN matching)) (PP (IN like) (NP (NP (JJ maximum) (NN likelihood) (NN estimation)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN known) (S (VP (TO to) (VP (VB suffer) (PP (IN from) (NP (NNS data) (NN sparsity) (NN problem)))))))))))))))) (. .))
(S (ADVP (RB Here)) (NP (PRP we)) (VP (VBP present) (NP (NP (DT an) (NN alternate) (NN view)) (SBAR (S (VP (TO to) (VP (VB explain) (NP (JJ sequence-to-sequence) (NN learning)) (PP (IN as) (NP (NP (DT a) (NN distribution) (NN matching) (NN problem)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT each) (NN source) (CC or) (NN target) (NN example)) (VP (VBZ is) (VP (VBN viewed) (S (VP (TO to) (VP (VB represent) (NP (NP (DT a) (JJ local) (NN latent) (NN distribution)) (PP (IN in) (NP (DT the) (NN source) (CC or) (NN target) (NN domain))))))))))))))))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (PRP we)) (VP (VBP interpret) (NP (JJ sequence-to-sequence) (NN learning)) (PP (IN as) (S (VP (VBG learning) (NP (DT a) (JJ transductive) (NN model)) (S (VP (TO to) (VP (VB transform) (NP (DT the) (NN source) (JJ local) (NN latent) (NNS distributions)) (S (VP (TO to) (VP (VB match) (NP (PRP$ their) (JJ corresponding) (NN target) (NNS distributions)))))))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (NN framework))) (, ,) (NP (PRP we)) (VP (VBP approximate) (NP (DT both) (DT the) (NN source) (CC and) (NN target) (JJ latent) (NNS distributions)) (PP (IN with) (NP (NP (JJ recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NN augmenter)) (-RRB- -RRB-))))) (. .))
(S (PP (IN During) (NP (NN training))) (, ,) (NP (DT the) (JJ parallel) (NNS augmenters)) (VP (VBP learn) (S (VP (TO to) (VP (ADVP (RBR better)) (VB approximate) (NP (DT the) (JJ local) (NN latent) (NNS distributions))))) (, ,) (SBAR (IN while) (S (NP (DT the) (NN sequence) (NN prediction) (NN model)) (VP (VBZ learns) (S (VP (TO to) (VP (VB minimize) (NP (NP (DT the) (NNP KL-divergence)) (PP (IN of) (NP (NP (DT the) (VBN transformed) (NN source) (NNS distributions)) (CC and) (NP (DT the) (JJ approximated) (NN target) (NNS distributions)))))))))))) (. .))
(S (NP (DT This) (NN algorithm)) (VP (MD can) (VP (VB alleviate) (NP (NP (DT the) (NNS data) (NN sparsity) (NNS issues)) (PP (IN in) (NP (NN sequence) (NN learning)))) (PP (IN by) (S (VP (VP (ADVP (RB locally)) (VBG augmenting) (NP (RBR more) (JJ unseen) (NNS data) (NNS pairs))) (CC and) (VP (VBG increasing) (NP (NP (DT the) (NN model) (POS 's)) (NN robustness)))))))) (. .))
(S (NP (NP (NNS Experiments)) (VP (VBN conducted) (PP (IN on) (NP (NP (NN machine) (NN translation)) (CC and) (NP (NN image) (VBG captioning)))))) (VP (ADVP (RB consistently)) (VB demonstrate) (NP (NP (DT the) (NN superiority)) (PP (IN of) (NP (PRP$ our) (VBN proposed) (NN algorithm))) (PP (IN over) (NP (DT the) (JJ other) (VBG competing) (NNS algorithms))))) (. .))
