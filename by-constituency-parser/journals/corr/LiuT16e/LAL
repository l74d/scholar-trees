(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ projected) (JJ semi-stochastic) (NN gradient) (NN descent) (NN method)) (PP (IN with) (NP (NN mini-batch))) (PP (IN for) (S (VP (VBG improving) (NP (NP (DT both) (NX (DT the) (NX (NX (JJ theoretical) (NN complexity)) (CC and) (NX (JJ practical) (NN performance))))) (PP (IN of) (NP (NP (DT the) (JJ general) (JJ stochastic) (NN gradient) (NN descent) (NN method)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB prove) (NP (JJ linear) (NN convergence)) (PP (IN under) (NP (JJ weak) (JJ strong) (NN convexity) (NN assumption)))))))) (. .))
(S (NP (DT This)) (VP (VBZ requires) (NP (NP (DT no) (JJ strong) (NN convexity) (NN assumption)) (PP (IN for) (S (VP (VBG minimizing) (NP (NP (DT the) (NN sum)) (PP (IN of) (NP (NP (JJ smooth) (JJ convex) (NNS functions)) (ADJP (VBP subject) (PP (TO to) (NP (DT a) (JJ compact) (JJ polyhedral) (NN set)))))))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ remains) (ADJP (JJ popular)) (PP (IN across) (NP (NN machine) (NN learning) (NN community)))))))) (. .))
(S (NP (PRP$ Our) (NNP PS2GD)) (VP (VP (VBZ preserves) (NP (NP (NP (DT the) (JJ low-cost)) (PP (IN per) (NP (NN iteration)))) (CC and) (NP (JJ high) (NN optimization) (NN accuracy))) (PP (IN via) (NP (JJ stochastic) (JJ gradient) (JJ variance-reduced) (NN technique)))) (, ,) (CC and) (VP (VBZ admits) (NP (NP (DT a) (JJ simple) (JJ parallel) (NN implementation)) (PP (IN with) (NP (NNS mini-batches)))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NNP PS2GD)) (VP (VBZ is) (ADVP (RB also)) (ADJP (JJ applicable) (PP (TO to) (NP (NP (JJ dual) (NN problem)) (PP (IN of) (NP (NP (NNP SVM)) (PP (IN with) (NP (JJ hinge) (NN loss))))))))) (. .))
