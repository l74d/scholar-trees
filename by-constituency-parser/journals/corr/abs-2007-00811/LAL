(S (PP (IN For) (S (VP (VBG deploying) (NP (DT a) (JJ deep) (NN learning) (NN model)) (PP (IN into) (NP (NN production)))))) (, ,) (NP (PRP it)) (VP (VBZ needs) (S (VP (TO to) (VP (VB be) (ADJP (DT both) (JJ accurate) (CC and) (JJ compact))))) (S (VP (TO to) (VP (VB meet) (NP (DT the) (NN latency) (CC and) (NN memory) (NNS constraints)))))) (. .))
(S (NP (DT This)) (ADVP (RB usually)) (VP (NNS results) (PP (IN in) (NP (NP (DT a) (NN network)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (ADJP (ADJP (JJ deep)) (PRN (-LRB- -LRB-) (S (VP (TO to) (VP (VB ensure) (NP (NN performance))))) (-RRB- -RRB-))) (CC and) (ADVP (RB yet)) (ADJP (ADJP (JJ thin)) (PRN (-LRB- -LRB-) (S (VP (TO to) (VP (VB improve) (NP (JJ computational) (NN efficiency))))) (-RRB- -RRB-)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (JJ efficient) (NN method)) (SBAR (S (VP (TO to) (VP (VB train) (NP (DT a) (JJ deep) (NN thin) (NN network)) (PP (IN with) (NP (DT a) (JJ theoretic) (NN guarantee))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ is) (VP (VBN motivated) (PP (IN by) (NP (NN model) (NN compression))))) (. .))
(S (NP (PRP It)) (VP (VBZ consists) (PP (IN of) (NP (CD three) (NNS stages)))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VP (ADVP (RB sufficiently)) (VBP widen) (NP (DT the) (JJ deep) (NN thin) (NN network))) (CC and) (VP (NN train) (NP (PRP it)) (PP (IN until) (NP (NN convergence))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (PRP we)) (VP (VBP use) (NP (DT this) (JJ well-trained) (JJ deep) (JJ wide) (NN network)) (S (VP (TO to) (VP (VP (VB warm) (PRT (RP up))) (PRN (-LRB- -LRB-) (CC or) (VB initialize) (-RRB- -RRB-)) (NP (DT the) (JJ original) (NN deep) (JJ thin) (NN network)))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (NP (NP (NN layerwise) (NN imitation)) (PRN (, ,) (S (NP (WDT that)) (VP (VBZ is))) (, ,)) (S (VP (VBG forcing) (S (NP (DT the) (JJ thin) (NN network)) (VP (TO to) (VP (VB mimic) (NP (NP (DT the) (JJ intermediate) (NNS outputs)) (PP (IN of) (NP (DT the) (JJ wide) (NN network)))) (PP (PP (IN from) (NP (NN layer))) (PP (TO to) (NP (NN layer))))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (ADVP (VBP further)) (VP (ADVP (JJ fine)) (NN tune) (NP (DT this) (ADJP (RB already) (JJ well-initialized)) (NN deep) (JJ thin) (NN network))) (. .))
(S (NP (DT The) (JJ theoretical) (NN guarantee)) (VP (VBZ is) (VP (VBN established) (PP (IN by) (S (VP (VBG using) (NP (DT the) (JJ neural) (JJ mean) (NN field) (NN analysis))))))) (. .))
(S (NP (PRP It)) (VP (VBZ demonstrates) (NP (NP (DT the) (NN advantage)) (PP (IN of) (NP (PRP$ our) (NN layerwise) (NN imitation) (NN approach))) (PP (IN over) (NP (NN backpropagation))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP conduct) (NP (JJ large-scale) (JJ empirical) (NNS experiments)) (S (VP (TO to) (VP (VB validate) (NP (DT the) (VBN proposed) (NN method)))))) (. .))
(S (PP (IN By) (S (VP (VBG training) (PP (IN with) (NP (PRP$ our) (NN method)))))) (, ,) (S (NP (NNP ResNet50)) (VP (MD can) (VP (VB outperform) (NP (NNP ResNet101))))) (, ,) (CC and) (S (NP (NNP BERT) (NNP Base)) (VP (MD can) (VP (VB be) (ADJP (JJ comparable) (PP (IN with) (NP (NNP BERT) (NNP Large))))))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNP ResNet101)) (CC and) (NP (NNP BERT) (NNP Large))) (VP (VBP are) (VP (VBN trained) (PP (IN under) (NP (NP (DT the) (JJ standard) (NN training) (NNS procedures)) (PP (IN as) (PP (IN in) (NP (DT the) (NN literature)))))))))) (. .))
