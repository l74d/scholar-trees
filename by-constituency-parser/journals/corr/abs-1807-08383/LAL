(S (NP (JJ Stochastic) (NNP Gradient) (NNP TreeBoost)) (VP (VBZ is) (ADVP (RB often)) (VP (VBN found) (PP (IN in) (NP (NP (JJ many) (VBG winning) (NNS solutions)) (PP (IN in) (NP (JJ public) (NNS data) (NN science) (NNS challenges))))))) (. .))
(S (ADVP (RB Unfortunately)) (, ,) (NP (DT the) (JJS best) (NN performance)) (VP (VP (VBZ requires) (NP (JJ extensive) (NN parameter) (VBG tuning))) (CC and) (VP (MD can) (VP (VB be) (ADJP (VBN prone) (PP (TO to) (NP (VBG overfitting))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NNP PaloBoost)) (, ,) (NP (NP (DT a) (JJ Stochastic) (NNP Gradient) (NNP TreeBoost) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ uses) (NP (JJ novel) (NN regularization) (NNS techniques)) (S (VP (TO to) (VP (VB guard) (PP (IN against) (NP (VBG overfitting))))))) (CC and) (VP (VBZ is) (ADJP (JJ robust) (PP (TO to) (NP (VB parameter) (NNS settings))))))))))) (. .))
(S (NP (NNP PaloBoost)) (VP (VBZ uses) (NP (DT the) (JJ under-utilized) (JJ out-of-bag) (NNS samples)) (S (VP (TO to) (VP (VP (VB perform) (NP (JJ gradient-aware) (NN pruning))) (CC and) (VP (NN estimate) (NP (JJ adaptive) (NN learning) (NNS rates))))))) (. .))
(S (PP (IN Unlike) (NP (NP (JJ other) (JJ Stochastic) (NNP Gradient) (NNP TreeBoost) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (DT the) (JJ out-of-bag) (NNS samples)) (S (VP (TO to) (VP (VB estimate) (NP (NN test) (NNS errors)))))))))) (, ,) (NP (NNP PaloBoost)) (VP (VBZ treats) (NP (DT the) (NNS samples)) (PP (IN as) (NP (NP (DT a) (JJ second) (NN batch)) (PP (IN of) (NP (NN training) (NNS samples))))) (S (VP (TO to) (VP (VP (VB prune) (NP (DT the) (NNS trees))) (CC and) (VP (VBP adjust) (NP (DT the) (NN learning) (NNS rates))))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (NP (NNP PaloBoost)) (VP (MD can) (VP (ADVP (RB dynamically)) (VB adjust) (NP (NP (JJ tree) (NNS depths)) (CC and) (NX (VBG learning) (NNS rates))) (S (VP (TO to) (VP (VB achieve) (NP (NP (NP (RBR faster) (VBG learning)) (PP (IN at) (NP (DT the) (NN start)))) (CC and) (NP (NP (JJR slower) (NN learning)) (SBAR (IN as) (S (NP (DT the) (NN algorithm)) (VP (NNS converges))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP illustrate) (SBAR (WHADVP (WRB how)) (S (NP (DT these) (NN regularization) (NNS techniques)) (VP (MD can) (VP (VB be) (VP (ADVP (RB efficiently)) (VBN implemented))))))) (CC and) (VP (VB propose) (NP (NP (DT a) (JJ new) (NN formula)) (PP (IN for) (S (VP (VBG calculating) (NP (NN feature) (NN importance))))) (SBAR (S (VP (TO to) (VP (VB reflect) (NP (DT the) (NX (NX (NN node) (NNS coverages)) (CC and) (NX (VBG learning) (NNS rates))))))))))) (. .))
(S (NP (NP (JJ Extensive) (JJ experimental) (NNS results)) (PP (IN on) (NP (CD seven) (NNS datasets)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NNP PaloBoost)) (VP (VP (VBZ is) (ADJP (JJ robust) (PP (TO to) (NP (VBG overfitting))))) (, ,) (VP (VBZ is) (NP (NP (RBR less) (NN sensitivity)) (PP (TO to) (NP (DT the) (NNS parameters))))) (, ,) (CC and) (VP (MD can) (ADVP (RB also)) (VP (ADVP (RB effectively)) (VB identify) (NP (JJ meaningful) (NNS features)))))))) (. .))
