(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NP (VBG Learning) (NN Off-Policy)) (PP (IN with) (NP (NNP Online) (NNP Planning)))) (PRN (-LRB- -LRB-) (NP (NNP LOOP)) (-RRB- -RRB-))) (, ,) (S (VP (VBG combining) (NP (NP (DT the) (NNS techniques)) (PP (IN from) (NP (ADJP (JJ model-based) (CC and) (JJ model-free)) (NN reinforcement) (VBG learning) (NNS algorithms))))))) (. .))
(S (NP (DT The) (NN agent)) (VP (VP (VBZ learns) (NP (NP (DT a) (NN model)) (PP (IN of) (NP (DT the) (NN environment))))) (, ,) (CC and) (ADVP (RB then)) (VP (VBZ uses) (NP (JJ trajectory) (NN optimization)) (PP (IN with) (NP (DT the) (JJ learned) (NN model))) (S (VP (TO to) (VP (VB select) (NP (NNS actions))))))) (. .))
(S (S (VP (TO To) (VP (VB sidestep) (NP (NP (DT the) (NN myopic) (NN effect)) (PP (IN of) (NP (JJ fixed) (NN horizon) (NN trajectory) (NN optimization))))))) (, ,) (NP (DT a) (NN value) (NN function)) (VP (VBZ is) (VP (VBN attached) (PP (TO to) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (DT the) (NN planning) (NN horizon))))))) (. .))
(S (NP (DT This) (NN value) (NN function)) (VP (VBZ is) (VP (VBN learned) (PP (IN through) (NP (JJ off-policy) (NN reinforcement) (NN learning))) (, ,) (S (VP (VBG using) (NP (JJ trajectory) (NN optimization)) (PP (IN as) (NP (PRP$ its) (NN behavior) (NN policy))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (`` ``) (JJ actor-guided) ('' '') (NN trajectory) (NN optimization)) (S (VP (TO to) (VP (VB mitigate) (NP (NP (DT the) (JJ actor-divergence) (NN issue)) (PP (IN in) (NP (DT the) (VBN proposed) (NN method)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP benchmark) (NP (PRP$ our) (NNS methods)) (PP (IN on) (NP (JJ continuous) (NN control) (NNS tasks)))) (CC and) (VP (NN demonstrate) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ offers) (NP (NP (DT a) (JJ significant) (NN improvement)) (PP (IN over) (NP (DT the) (JJ underlying) (ADJP (JJ model-based) (CC and) (JJ model-free)) (NN algorithms))))))))) (. .))
