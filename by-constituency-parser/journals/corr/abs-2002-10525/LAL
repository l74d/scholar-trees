(S (NP (NP (JJ Multi-agent) (JJ adversarial) (NN inverse) (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP MA-AIRL)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (DT a) (JJ recent) (NN approach)) (SBAR (WHNP (IN that)) (S (VP (VBZ applies) (NP (JJ single-agent) (NNP AIRL)) (PP (TO to) (NP (NP (NN multi-agent) (NNS problems)) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP seek) (S (VP (TO to) (VP (VB recover) (NP (DT both) (NP (NP (NNS policies)) (PP (IN for) (NP (PRP$ our) (NNS agents)))) (CC and) (NP (NP (NN reward) (NNS functions)) (SBAR (WHNP (WDT that)) (S (VP (VBP promote) (NP (JJ expert-like) (NN behavior)))))))))))))))))))) (. .))
(S (S (SBAR (IN While) (S (NP (NNP MA-AIRL)) (VP (VBZ has) (NP (NP (JJ promising) (NNS results)) (PP (IN on) (NP (JJ cooperative) (CC and) (JJ competitive) (NNS tasks))))))) (, ,) (NP (PRP it)) (VP (VP (VBZ is) (ADJP (JJ sample-inefficient))) (CC and) (VP (VBZ has) (ADVP (RB only)) (VP (VBN been) (VP (VBN validated) (ADVP (RB empirically)) (PP (IN for) (NP (NP (JJ small) (NNS numbers)) (PP (IN of) (NP (NNS agents)))))))))) (: —) (S (NP (PRP$ its) (NN ability) (S (VP (TO to) (VP (VB scale) (PP (TO to) (NP (JJ many) (NNS agents))))))) (VP (VBZ remains) (NP (DT an) (JJ open) (NN question)))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ multi-agent) (NN inverse) (NNP RL) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (ADJP (JJR more) (JJ sample-efficient) (CC and) (JJ scalable)) (PP (IN than) (NP (JJ previous) (NNS works))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP employ) (NP (NP (JJ multi-agent) (JJ actor-attention-critic)) (PRN (-LRB- -LRB-) (NP (NNP MAAC)) (-RRB- -RRB-)) (: —) (NP (DT an) (JJ off-policy) (JJ multi-agent) (NNP RL) (PRN (-LRB- -LRB-) (NNP MARL) (-RRB- -RRB-)) (NN method)) (: —)) (PP (IN for) (NP (NP (DT the) (NNP RL) (JJ inner) (NN loop)) (PP (IN of) (NP (DT the) (NN inverse) (NNP RL) (NN procedure)))))) (. .))
(S (PP (IN In) (S (VP (VBG doing) (ADVP (RB so))))) (, ,) (NP (PRP we)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB increase) (NP (NP (JJ sample) (NN efficiency)) (PP (VBN compared) (PP (TO to) (NP (JJ state-of-the-art) (NNS baselines))))) (, ,) (PP (IN across) (NP (ADJP (DT both) (JJ small-) (CC and) (JJ large-scale)) (NNS tasks)))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NP (DT the) (NNP RL) (NNS agents)) (VP (VBD trained) (PP (IN on) (NP (NP (DT the) (NNS rewards)) (VP (VBN recovered) (PP (IN by) (NP (PRP$ our) (NN method)))))))) (VP (ADVP (RBR better)) (VB match) (NP (DT the) (NNS experts)) (PP (IN than) (NP (NP (DT those)) (VP (VBN trained) (PP (IN on) (NP (NP (DT the) (NNS rewards)) (VP (VBN derived) (PP (IN from) (NP (DT the) (NNS baselines)))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP$ our) (NN method)) (VP (VBZ requires) (NP (ADJP (RB far) (JJR fewer)) (JJ agent-environment) (NNS interactions)) (, ,) (SBAR (ADVP (RB particularly)) (IN as) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS agents)))) (VP (NNS increases))))) (. .))
