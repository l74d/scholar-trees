(S (NP (NP (DT The) (VBG increasing) (NN complexity)) (PP (IN of) (NP (NML (JJ deep) (NN learning)) (NNS architectures)))) (VP (VBZ is) (VP (VBG resulting) (PP (IN in) (NP (NN training) (NN time))) (S (VP (VBG requiring) (NP (NP (NNS weeks)) (CC or) (RB even) (NP (NNS months))))))) (. .))
(S (S (NP (DT This) (JJ slow) (NN training)) (VP (VBZ is) (ADJP (JJ due) (PP (IN in) (NP (NN part)))) (PP (IN to) (NP (NP (VBG vanishing) (NNS gradients)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT the) (NNS gradients)) (VP (VBN used) (PP (IN by) (NP (NP (RB back) (HYPH -) (NN propagation)) (SBAR (S (VP (VP (VBP are) (ADJP (RB extremely) (JJ large) (PP (IN for) (NP (NNS weights)))) (S (VP (VBG connecting) (NP (JJ deep) (NNS layers)))) (PRN (-LRB- -LRB-) (NP (NP (NNS layers)) (PP (IN near) (NP (DT the) (NN output) (NN layer)))) (-RRB- -RRB-))) (, ,) (CC and) (VP (ADJP (RB extremely) (JJ small)) (PP (IN for) (NP (NP (JJ shallow) (NNS layers)) (-LRB- -LRB-) (PP (IN near) (NP (DT the) (NN input) (NN layer))) (-RRB- -RRB-)))))))))))))))) (: ;) (S (NP (DT this)) (VP (VBZ results) (PP (IN in) (NP (NP (JJ slow) (NN learning)) (PP (IN in) (NP (DT the) (JJ shallow) (NNS layers))))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (PRP it)) (VP (VBZ has) (ADVP (RB also)) (VP (VBN been) (VP (VBN shown) (SBAR (IN that) (S (PP (IN in) (NP (NP (ADJP (RB highly) (JJ non-convex)) (NNS problems)) (, ,) (PP (JJ such) (IN as) (NP (JJ deep) (JJ neural) (NNS networks))))) (, ,) (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (NN proliferation)) (PP (IN of) (NP (NP (NML (JJ high) (HYPH -) (NN error)) (NML (JJ low) (NN curvature)) (NN saddle) (NNS points)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ slows) (PRT (RP down)) (S (VP (VBG learning) (ADVP (RB dramatically)))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP attempt) (S (VP (TO to) (VP (VB overcome) (NP (NP (DT the) (CD two)) (PP (IN above) (NP (NNS problems)))) (PP (IN by) (S (VP (VBG proposing) (NP (NP (NP (DT an) (NN optimization) (NN method)) (PP (IN for) (NP (NN training) (JJ deep) (JJ neural) (NNS networks)))) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NP (NN learning) (NNS rates)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (DT both) (ADJP (JJ specific) (PP (IN to) (NP (NP (DT each) (NN layer)) (PP (IN in) (NP (NP (DT the) (NN network)) (CC and) (NP (JJ adaptive)))))))))))))))))) (PP (IN to) (NP (NP (DT the) (NN curvature)) (PP (IN of) (NP (DT the) (NN function))))) (, ,) (S (VP (VBG increasing) (NP (DT the) (NN learning) (NN rate)) (PP (IN at) (NP (NML (JJ low) (NN curvature)) (NNS points))))))))) (. .))
(S (NP (DT This)) (VP (VBZ enables) (S (NP (PRP us)) (VP (TO to) (VP (VP (VB speed) (PRT (RP up)) (S (VP (VBG learning) (PP (IN in) (NP (NP (DT the) (JJ shallow) (NNS layers)) (PP (IN of) (NP (DT the) (NN network)))))))) (CC and) (ADVP (RB quickly)) (VP (VB escape) (NP (NML (JJ high) (HYPH -) (NN error)) (NML (JJ low) (NN curvature)) (NN saddle) (NNS points))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP test) (NP (PRP$ our) (NN method)) (PP (IN on) (NP (NP (JJ standard) (NML (NN image) (NN classification)) (NNS datasets)) (PP (JJ such) (IN as) (NP (NP (NN MNIST)) (, ,) (NP (NN CIFAR10)) (CC and) (NP (NNP ImageNet))))))) (, ,) (CC and) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (VP (VBZ increases) (NP (NN accuracy))) (CONJP (RB as) (RB well) (IN as)) (VP (VBZ reduces) (NP (DT the) (JJ required) (NN training) (NN time)) (PP (IN over) (NP (JJ standard) (NNS algorithms))))))))) (. .))
