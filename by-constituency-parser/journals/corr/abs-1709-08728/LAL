(S (NP (PRP We)) (VP (VBP study) (NP (NP (JJ stochastic) (NN optimization)) (PP (IN of) (NP (NP (JJ nonconvex) (NN loss) (NNS functions)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (NP (NP (JJ typical) (NNS objectives)) (PP (IN for) (S (VP (VBG training) (NP (JJ neural) (NNS networks))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (JJ stochastic) (NN approximation) (NN algorithms)) (SBAR (WHNP (WDT which)) (S (VP (VBP optimize) (NP (NP (NP (DT a) (NN series)) (PP (IN of) (NP (JJ regularized) (, ,) (JJ nonlinearized) (NNS losses)))) (PP (IN on) (NP (NP (JJ large) (NNS minibatches)) (PP (IN of) (NP (NNS samples)))))) (, ,) (S (VP (VBG using) (NP (RB only) (JJ first-order) (NN gradient) (NN information))))))))) (. .))
(S (NP (PRP$ Our) (NN algorithms)) (VP (VP (ADVP (RB provably)) (NN converge) (PP (TO to) (NP (NP (DT an) (JJ approximate) (JJ critical) (NN point)) (PP (IN of) (NP (DT the) (JJ expected) (NN objective))))) (PP (IN with) (NP (NP (RBR faster) (NNS rates)) (PP (IN than) (NP (VB minibatch) (JJ stochastic) (NN gradient) (NN descent)))))) (, ,) (CC and) (VP (VB facilitate) (NP (JJR better) (NN parallelization)) (PP (IN by) (S (VP (VBG allowing) (NP (JJR larger) (NNS minibatches))))))) (. .))
