(S (NP (NP (DT A) (NN number)) (PP (IN of) (NP (NNS results)))) (VP (VBP have) (ADVP (RB recently)) (VP (VBN demonstrated) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (S (VP (VBG incorporating) (NP (JJ various) (NNS constraints)) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (JJ deep) (NNS architectures)) (PP (IN in) (NP (NP (NN vision)) (CC and) (NP (NN machine) (NN learning))))))))))))) (. .))
(S (NP (DT The) (NNS advantages)) (VP (VBP range) (PP (PP (PP (IN from) (NP (NP (NNS guarantees)) (PP (IN for) (NP (JJ statistical) (NN generalization))))) (PP (TO to) (NP (JJR better) (NN accuracy)))) (PP (TO to) (NP (NN compression))))) (. .))
(S (CC But) (S (NP (NP (NN support)) (PP (IN for) (NP (JJ general) (NNS constraints))) (PP (IN within) (NP (ADJP (RB widely) (VBN used)) (NNS libraries)))) (VP (VBZ remains) (ADJP (JJ scarce)))) (CC and) (S (NP (NP (PRP$ their) (NN broader) (NN deployment)) (PP (IN within) (NP (NP (JJ many) (NNS applications)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB benefit) (PP (IN from) (NP (PRP them)))))))))) (VP (VBZ remains) (ADJP (JJ under-explored)))) (. .))
(S (NP (NP (NN Part)) (PP (IN of) (NP (DT the) (NN reason)))) (VP (VBZ is) (SBAR (IN that) (S (NP (NP (JJ Stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)) (, ,) (NP (NP (DT the) (NN workhorse)) (PP (IN for) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks)))))) (, ,)) (VP (VBZ does) (RB not) (ADVP (RB natively)) (VP (VB deal) (PP (IN with) (NP (NP (NNS constraints)) (PP (IN with) (NP (JJ global) (NN scope))))) (ADVP (RB very) (RB well))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP revisit) (NP (NP (DT a) (JJ classical) (JJ first) (NN order) (NN scheme)) (PP (IN from) (NP (JJ numerical) (NN optimization))) (, ,) (NP (NP (JJ Conditional) (NNP Gradients)) (PRN (-LRB- -LRB-) (NP (NNP CG)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (, ,) (ADVP (RB thus) (RB far)) (VP (VBD had) (NP (NP (VBN limited) (NN applicability)) (PP (IN in) (S (VP (VBG training) (NP (JJ deep) (NNS models)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (PP (IN via) (NP (JJ rigorous) (NN analysis))) (SBAR (WHADVP (WRB how)) (S (NP (JJ various) (NNS constraints)) (VP (MD can) (VP (VB be) (VP (ADVP (RB naturally)) (VBN handled) (PP (IN by) (NP (NP (NNS modifications)) (PP (IN of) (NP (DT this) (NN algorithm))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP provide) (NP (NN convergence) (NNS guarantees))) (CC and) (VP (VB show) (NP (NP (DT a) (NN suite)) (PP (IN of) (NP (NP (JJ immediate) (NNS benefits)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ possible))))) (: â€”) (PP (PP (IN from) (S (VP (VBG training) (NP (NNS ResNets)) (PP (IN with) (NP (NP (JJR fewer) (NNS layers)) (CC but) (NP (JJR better) (NN accuracy)))) (SBAR (ADVP (RB simply)) (IN by) (S (VP (VBG substituting) (PRT (IN in)) (NP (NP (PRP$ our) (NN version)) (PP (IN of) (NP (NNP CG)))))))))) (PP (TO to) (NP (NP (RBR faster) (NN training)) (PP (IN of) (NP (NNP GANs))) (PP (IN with) (NP (ADJP (ADJP (CD 50) (NN %)) (JJR fewer)) (NN epochs))) (PP (IN in) (NP (NN image) (NN inpainting) (NNS applications))))) (PP (TO to) (NP (NP (ADJP (VB provably) (JJR better)) (NN generalization) (NNS guarantees)) (VP (VBG using) (NP (NP (ADJP (RB efficiently) (JJ implementable)) (NNS forms)) (PP (IN of) (NP (ADJP (RB recently) (VBN proposed)) (NNS regularizers))))))))))))) (. .))
