(S (NP (EX There)) (VP (VBZ is) (NP (NP (DT a) (JJ neglected) (NN fact)) (PP (IN in) (NP (DT the) (JJ traditional) (NN machine) (VBG learning) (NNS methods))) (SBAR (IN that) (S (NP (DT the) (NNS data) (NN sampling)) (VP (MD can) (ADVP (RB actually)) (VP (VB lead) (PP (TO to) (NP (DT the) (NN solution) (NN sampling))))))))) (. .))
(S (NP (PRP We)) (VP (VBP consider) (S (NP (DT this) (NN observation)) (VP (TO to) (VP (VB be) (ADJP (JJ important)) (SBAR (IN because) (S (S (VP (VBG having) (S (NP (DT the) (NN solution) (VBG sampling)) (ADJP (JJ available))))) (VP (VBZ makes) (S (NP (NP (DT the) (JJ variable) (NN distribution) (NN estimation)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (DT a) (NN problem)) (PP (IN in) (NP (JJ many) (JJ learning-related) (NNS applications)))))) (, ,)) (ADJP (RBR more) (JJ tractable)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP implement) (NP (DT this) (NN idea)) (PP (IN on) (NP (NP (NN correlation) (NN filter)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (VP (VBN attracted) (NP (JJ much) (NN attention)) (PP (IN in) (NP (DT the) (JJ past) (JJ few) (NNS years))) (PP (JJ due) (TO to) (NP (NP (PRP$ its) (JJ high) (NN performance)) (PP (IN with) (NP (DT a) (JJ low) (JJ computational) (NN cost)))))))))))) (. .))
(S (ADVP (RBR More) (RB specifically)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN method)) (, ,) (VP (VBN named) (S (NP (NP (NN latent) (VBN constrained) (NN correlation) (NNS filters)) (PRN (-LRB- -LRB-) (NP (NNP LCCF)) (-RRB- -RRB-)))) (PP (IN by) (S (VP (VBG mapping) (NP (DT the) (NN correlation) (NNS filters)) (PP (TO to) (NP (DT a) (VBN given) (NN latent) (NN subspace))))))) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VB establish) (NP (NP (DT a) (JJ new) (NN learning) (NN framework)) (SBAR (WHNP (WDT that)) (S (VP (VBZ embeds) (NP (JJ distribution-related) (NNS constraints)) (PP (IN into) (NP (DT the) (JJ original) (NN problem)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (VBP further)) (VP (VB introduce) (NP (NP (DT a) (ADJP (NN subspace) (VBN based)) (VBG alternating) (NN direction) (NN method)) (PP (IN of) (NP (NNS multipliers))) (PRN (-LRB- -LRB-) (NP (NNP SADMM)) (-RRB- -RRB-)) (SBAR (S (VP (TO to) (VP (ADVP (RB efficiently)) (VB solve) (NP (NP (DT the) (NN optimization) (NN problem)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN proved) (S (VP (TO to) (VP (VB converge) (PP (IN at) (NP (DT the) (JJ saddle) (NN point))))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ is) (VP (ADVP (RB successfully)) (VBN applied) (PP (TO to) (NP (NP (CD two) (JJ different) (NNS tasks)) (VP (VBG inclduing) (NP (NP (NN eye) (NN localization)) (CC and) (NP (NN car) (NN detection)))))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NNP LCCF)) (VP (VBZ outperforms) (NP (DT the) (JJ state-of-the-art) (NNS methods)) (SBAR (WHADVP (WRB when)) (S (NP (NNS samples)) (VP (VBP are) (VP (VBN suffered) (PP (IN from) (NP (NN noise) (CC and) (NN occlusion))))))))))) (. .))
