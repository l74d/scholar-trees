(S (NP (NP (JJ Effective) (NN regularisation)) (PP (IN during) (NP (NN training)))) (VP (MD can) (VP (VB mean) (NP (NP (DT the) (NN difference)) (PP (IN between) (NP (NN success) (CC and) (NN failure))) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks)))))) (. .))
(S (ADVP (RB Recently)) (, ,) (NP (NN dither)) (VP (VBZ has) (VP (VBN been) (VP (VBN suggested) (PP (IN as) (NP (NP (JJ alternative)) (PP (TO to) (NP (VB dropout))))) (PP (IN for) (NP (NP (NN regularisation)) (PP (IN during) (NP (NP (JJ batch-averaged) (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN article))) (, ,) (S (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT these) (NNS methods)) (VP (VBP fail) (PP (IN without) (NP (NN batch) (NN averaging)))))))) (CC and) (S (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ new) (, ,) (JJ parallel) (NN regularisation) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (MD may) (VP (VB be) (VP (VBN used) (PP (IN without) (NP (NN batch) (NN averaging))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS results)) (PP (IN for) (NP (JJ parallel-regularised) (NNS non-batch-SGD)))) (VP (VBP are) (ADJP (RB substantially) (JJR better) (PP (IN than) (SBAR (WHNP (WP what)) (S (VP (VBZ is) (ADJP (JJ possible)) (PP (IN with) (NP (NN batch-SGD))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP$ our) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NN dither) (CC and) (NN dropout)) (VP (VBP are) (ADJP (JJ complimentary)))))) (. .))
