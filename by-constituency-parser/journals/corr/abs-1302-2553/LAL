(S (NP (PRP We)) (VP (VBP consider) (S (NP (DT an) (NN agent)) (VP (VBG interacting) (PP (IN with) (NP (DT an) (NN environment))) (PP (IN in) (NP (NP (DT a) (JJ single) (NN stream)) (PP (IN of) (NP (NNS actions) (, ,) (NNS observations) (, ,) (CC and) (NNS rewards))))) (, ,) (PP (IN with) (NP (DT no) (NN reset)))))) (. .))
(S (NP (DT This) (NN process)) (VP (VBZ is) (RB not) (VP (VBN assumed) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (NNP Markov) (NNP Decision) (NNP Process)) (PRN (-LRB- -LRB-) (NP (NNP MDP)) (-RRB- -RRB-)))))))) (. .))
(S (ADVP (RB Rather)) (, ,) (NP (DT the) (NN agent)) (VP (VBZ has) (NP (NP (JJ several) (NNS representations)) (PRN (-LRB- -LRB-) (S (VP (VBG mapping) (NP (NP (NNS histories)) (PP (IN of) (NP (JJ past) (NNS interactions)))) (PP (TO to) (NP (DT a) (JJ discrete) (NN state) (NN space))))) (-RRB- -RRB-)) (PP (IN of) (NP (DT the) (NN environment))) (PP (IN with) (NP (JJ unknown) (NNS dynamics))) (, ,) (SBAR (WHNP (WHNP (RB only) (DT some)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (NN result) (PP (IN in) (NP (DT an) (NNP MDP)))))))) (. .))
(S (NP (DT The) (NN goal)) (VP (VBZ is) (S (VP (TO to) (VP (VB minimize) (NP (NP (DT the) (JJ average) (JJ regret) (NN criterion)) (PP (IN against) (NP (NP (DT an) (NN agent)) (SBAR (WHNP (WP who)) (S (VP (VP (VBZ knows) (NP (NP (DT an) (NNP MDP) (NN representation)) (VP (VBG giving) (NP (DT the) (JJS highest) (JJ optimal) (NN reward))))) (, ,) (CC and) (VP (VBZ acts) (ADVP (RB optimally)) (PP (IN in) (NP (PRP it)))))))))))))) (. .))
(S (NP (NP (JJ Recent) (NN regret) (VBZ bounds)) (PP (IN for) (NP (DT this) (NN setting)))) (VP (VBP are) (PP (IN of) (NP (NN order) ($ $) (NNP O) (PRN (-LRB- -LRB-) (NNP T^) (PRN (-LRB- -LCB-) (CD 2/3) (-RRB- -RCB-)) (-RRB- -RRB-)) ($ $))) (PP (IN with) (NP (NP (DT an) (JJ additive) (NN term)) (ADJP (ADJP (JJ constant)) (RB yet) (ADJP (JJ exponential) (PP (IN in) (NP (NP (DT some) (NNS characteristics)) (PP (IN of) (NP (DT the) (JJ optimal) (NNP MDP)))))))))) (. .))
