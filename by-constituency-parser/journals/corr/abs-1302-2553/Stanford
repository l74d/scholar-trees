(S (NP (PRP We)) (VP (VBP consider) (NP (NP (DT an) (NN agent)) (VP (VBG interacting) (PP (IN with) (NP (NP (DT an) (NN environment)) (PP (IN in) (NP (NP (DT a) (JJ single) (NN stream)) (PP (IN of) (NP (NNS actions) (, ,) (NNS observations) (, ,) (CC and) (NNS rewards))))))))) (, ,) (PP (IN with) (NP (DT no) (NN reset)))) (. .))
(S (NP (DT This) (NN process)) (VP (VBZ is) (RB not) (VP (VBN assumed) (S (VP (TO to) (VP (VB be) (NP (DT a) (NNP Markov) (NN Decision) (NN Process))))) (PRN (-LRB- -LRB-) (NP (NN MDP)) (-RRB- -RRB-)))) (. .))
(S (ADVP (RB Rather)) (, ,) (NP (DT the) (NN agent)) (VP (VBZ has) (NP (NP (NP (JJ several) (NNS representations)) (-LRB- -LRB-) (NP (NP (VBG mapping) (NNS histories)) (PP (IN of) (NP (JJ past) (NNS interactions))) (PP (IN to) (NP (DT a) (JJ discrete) (NN state) (NN space)))) (-RRB- -RRB-)) (PP (IN of) (NP (NP (NP (DT the) (NN environment)) (PP (IN with) (NP (JJ unknown) (NNS dynamics)))) (, ,) (SBAR (WHNP (NP (QP (RB only) (DT some))) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBP result) (PP (IN in) (NP (DT an) (NN MDP)))))))))) (. .))
(S (NP (DT The) (NN goal)) (VP (VBZ is) (S (VP (TO to) (VP (VB minimize) (NP (DT the) (JJ average) (NN regret) (NN criterion)) (PP (IN against) (NP (NP (DT an) (NN agent)) (SBAR (WHNP (WP who)) (S (VP (VP (VBZ knows) (NP (DT an) (NN MDP) (NN representation)) (S (VP (VBG giving) (NP (DT the) (JJS highest) (JJ optimal) (NN reward))))) (, ,) (CC and) (VP (VBZ acts) (ADVP (RB optimally)) (PP (IN in) (NP (PRP it))))))))))))) (. .))
(S (NP (NP (JJ Recent) (NN regret) (NNS bounds)) (PP (IN for) (NP (DT this) (NN setting)))) (VP (VBP are) (NP (PP (IN of) (NP (NN order))) (NP (NP ($ $)) (INTJ (UH O)) (NP (-LRB- -LRB-) (NP (NN T) (SYM ^)) (NP (-LRB- {) (CD 2/3) (-RRB- })) (-RRB- -RRB-))) (NP (NP ($ $)) (PP (IN with) (NP (DT an) (JJ additive) (NN term)))) (NP (NP (JJ constant) (ADJP (RB yet) (JJ exponential) (PP (IN in) (NP (DT some)))) (NNS characteristics)) (PP (IN of) (NP (DT the) (JJ optimal) (NN MDP)))))) (. .))
