(S (NP (NN Optimization) (NNS techniques)) (VP (VBP are) (PP (IN of) (NP (JJ great) (NN importance))) (S (VP (TO to) (VP (ADVP (RB effectively) (CC and) (RB efficiently)) (VB train) (NP (NP (DT a) (JJ deep) (JJ neural) (NN network)) (PRN (-LRB- -LRB-) (NP (NNP DNN)) (-RRB- -RRB-))))))) (. .))
(S (NP (PRP It)) (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (SBAR (IN that) (S (S (VP (VBG using) (NP (NP (DT the) (ADJP (JJ first) (CC and) (JJ second) (NN order)) (NNS statistics)) (PRN (-LRB- -LRB-) (NN e.g.) (, ,) (NP (NN mean) (CC and) (NN variance)) (-RRB- -RRB-))) (S (VP (TO to) (VP (VB perform) (NP (NNP Z-score) (NN standardization)) (PP (IN on) (NP (NP (NP (NN network) (NNS activations)) (CC or) (NP (NN weight) (NNS vectors))) (, ,) (PP (JJ such) (IN as) (NP (NP (NP (NN batch) (NN normalization)) (PRN (-LRB- -LRB-) (NP (NNP BN)) (-RRB- -RRB-))) (CC and) (NP (NP (JJ weight) (NN standardization)) (PRN (-LRB- -LRB-) (NP (NNP WS)) (-RRB- -RRB-)))))))))))) (, ,) (VP (MD can) (VP (VB improve) (NP (DT the) (NN training) (NN performance))))))))) (. .))
(S (S (ADJP (NN Different) (PP (IN from) (NP (NP (DT these) (VBG existing) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB mostly)) (VBP operate) (PP (IN on) (NP (NNS activations) (CC or) (NNS weights)))))))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ new) (NN optimization) (NN technique)) (, ,) (ADVP (RB namely)) (NP (NP (JJ gradient) (NN centralization)) (PRN (-LRB- -LRB-) (NP (NNP GC)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ operates) (ADVP (RB directly)) (PP (IN on) (NP (NNS gradients))) (PP (IN by) (S (VP (VBG centralizing) (NP (DT the) (NN gradient) (NNS vectors)) (S (VP (TO to) (VP (VB have) (NP (CD zero) (NN mean)))))))))))))) (. .))
(S (NP (NNP GC)) (VP (MD can) (VP (VB be) (VP (VBN viewed) (PP (IN as) (NP (NP (DT a) (JJ projected) (NN gradient) (NN descent) (NN method)) (PP (IN with) (NP (DT a) (JJ constrained) (NN loss) (NN function)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP GC)) (VP (MD can) (VP (VB regularize) (NP (DT both) (DT the) (NN weight) (NN space) (CC and) (NX (NN output) (NN feature) (NN space))) (SBAR (IN so) (IN that) (S (NP (PRP it)) (VP (MD can) (VP (VB boost) (NP (NP (DT the) (NN generalization) (NN performance)) (PP (IN of) (NP (NNP DNNs))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NNP GC)) (VP (VBZ improves) (NP (NP (DT the) (NNP Lipschitzness)) (PP (IN of) (NP (NP (DT the) (NN loss) (NN function)) (CC and) (NP (PRP$ its) (NN gradient))))) (SBAR (IN so) (IN that) (S (NP (DT the) (NN training) (NN process)) (VP (VBZ becomes) (ADJP (RBR more) (JJ efficient) (CC and) (JJ stable)))))) (. .))
(S (NP (NNP GC)) (VP (VP (VBZ is) (ADJP (RB very) (JJ simple) (SBAR (S (VP (TO to) (VP (VB implement))))))) (CC and) (VP (MD can) (VP (VB be) (VP (ADVP (RB easily)) (VBN embedded) (PP (IN into) (NP (VBG existing) (NN gradient) (VBN based) (NNP DNN) (NNS optimizers))) (PP (IN with) (NP (NP (QP (RB only) (CD one)) (NN line)) (PP (IN of) (NP (NN code))))))))) (. .))
(S (NP (PRP It)) (VP (MD can) (ADVP (RB also)) (VP (VB be) (VP (ADVP (RB directly)) (VBN used) (S (VP (TO to) (VP (VB fine-tune) (NP (DT the) (JJ pre-trained) (NNP DNNs)))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (PP (IN on) (NP (NP (JJ various) (NNS applications)) (, ,) (PP (VBG including) (NP (NP (JJ general) (NN image) (NN classification)) (, ,) (NP (JJ fine-grained) (NN image) (NN classification)) (, ,) (NP (NN detection)) (CC and) (NN segmentation))) (, ,)))) (VP (NN demonstrate) (SBAR (IN that) (S (NP (NNP GC)) (VP (MD can) (ADVP (RB consistently)) (VP (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NNP DNN) (NN learning))))))))) (. .))
(S (NP (NP (DT The) (NN code)) (PP (IN of) (NP (NNP GC)))) (VP (MD can) (VP (VB be) (VP (VBN found) (PP (IN at) (NP (DT this) (NN https) (NNP URL)))))))
