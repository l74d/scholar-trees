(S (SBAR (WHADVP (WRB When)) (S (VP (VBG training) (NP (JJ neural) (NNS models))))) (, ,) (NP (NP (PRP it))) (VP (VBZ is) (ADJP (JJ common)) (S (VP (TO to) (VP (VB combine) (NP (JJ multiple) (NN loss) (NNS terms)))))) (. .))
(S (NP (NP (DT The) (NN balancing)) (PP (IN of) (NP (DT these) (NNS terms)))) (VP (VP (VBZ requires) (NP (JJ considerable) (JJ human) (NN effort))) (CC and) (VP (VBZ is) (ADJP (RB computationally) (VBG demanding)))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NP (DT the) (JJ optimal) (NN trade-off)) (PP (IN between) (NP (DT the) (NN loss) (NN term)))) (VP (MD can) (VP (VB change) (SBAR (IN as) (S (NP (NN training)) (VP (NNS progresses)))) (, ,) (PP (ADVP (RB especially)) (IN for) (NP (JJ adversarial) (NNS terms))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP generalize) (NP (DT the) (NNP Adam) (NN optimization) (NN algorithm)) (S (VP (TO to) (VP (VB handle) (NP (JJ multiple) (NN loss) (NNS terms)))))) (. .))
(S (NP (DT The) (NN guiding) (NN principle)) (VP (VBZ is) (SBAR (IN that) (S (PP (IN for) (NP (DT every) (NN layer))) (, ,) (NP (NP (DT the) (JJ gradient) (NN magnitude)) (PP (IN of) (NP (DT the) (NNS terms)))) (VP (MD should) (VP (VB be) (VP (VBN balanced))))))) (. .))
(S (PP (TO To) (NP (DT this) (NN end))) (, ,) (NP (NP (DT the) (NNP Multi-Term) (NNP Adam)) (PRN (-LRB- -LRB-) (NP (NNP MTAdam)) (-RRB- -RRB-))) (VP (VP (VBZ computes) (NP (NP (DT the) (NN derivative)) (PP (IN of) (NP (DT each) (NN loss) (NN term)))) (ADVP (RB separately))) (, ,) (VP (NNS infers) (NP (NP (DT the) (JJ first) (CC and) (JJ second) (NNS moments)) (PP (IN per) (NP (NP (NN parameter)) (CC and) (NP (NN loss) (NN term)))))) (, ,) (CC and) (VP (VBZ calculates) (NP (DT a) (JJ first) (NN moment)) (PP (IN for) (NP (NP (DT the) (NN magnitude)) (PP (IN per) (NP (NN layer))) (PP (IN of) (NP (NP (DT the) (NNS gradients)) (VP (VBG arising) (PP (IN from) (NP (DT each) (NN loss)))))))))) (. .))
(S (NP (DT This) (NN magnitude)) (VP (VBZ is) (VP (VBN used) (S (VP (TO to) (VP (ADVP (RB continuously)) (VB balance) (NP (DT the) (NNS gradients)) (PP (IN across) (NP (DT all) (NNS layers))) (, ,) (PP (IN in) (NP (NP (DT a) (NN manner)) (SBAR (WHNP (IN that)) (S (VP (DT both) (VP (NNS varies) (PP (IN from) (NP (CD one) (NN layer))) (PP (TO to) (NP (DT the) (JJ next)))) (CC and) (VP (ADVP (RB dynamically)) (NNS changes) (PP (IN over) (NP (NN time)))))))))))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG training) (PP (IN with) (NP (DT the) (JJ new) (NN method))))) (VP (VBZ leads) (PP (PP (TO to) (NP (NP (VB fast) (NN recovery)) (PP (IN from) (NP (JJ suboptimal) (JJ initial) (NN loss) (NN weighting))))) (CC and) (PP (TO to) (NP (NP (VBG training) (NNS outcomes)) (SBAR (WHNP (WDT that)) (S (VP (VBP match) (NP (JJ conventional) (NN training)) (PP (IN with) (NP (NP (DT the) (JJ prescribed) (NNS hyperparameters)) (PP (IN of) (NP (DT each) (NN method))))))))))))))) (. .))
