(S (SBAR (WHADVP (WRB When)) (S (VP (VBG training) (NP (JJ neural) (NNS models))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ common) (S (VP (TO to) (VP (VB combine) (NP (JJ multiple) (NN loss) (NNS terms))))))) (. .))
(S (NP (NP (DT The) (NN balancing)) (PP (IN of) (NP (DT these) (NNS terms)))) (VP (VP (VBZ requires) (NP (JJ considerable) (JJ human) (NN effort))) (CC and) (VP (VBZ is) (ADVP (RB computationally)) (VP (VBG demanding)))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NP (DT the) (JJ optimal) (NN trade) (HYPH -) (NN off)) (PP (IN between) (NP (DT the) (NN loss) (NN term)))) (VP (MD can) (VP (VB change) (SBAR (IN as) (S (NP (NN training)) (VP (VP (VBZ progresses)) (, ,) (ADVP (RB especially)) (VP (PP (IN for) (NP (JJ adversarial) (NNS terms))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP generalize) (NP (DT the) (NNP Adam) (NN optimization) (NN algorithm)) (S (VP (TO to) (VP (VB handle) (NP (JJ multiple) (NN loss) (NNS terms)))))) (. .))
(S (NP (DT The) (VBG guiding) (NN principle)) (VP (VBZ is) (SBAR (IN that) (S (PP (IN for) (NP (DT every) (NN layer))) (, ,) (NP (NP (DT the) (NN gradient) (NN magnitude)) (PP (IN of) (NP (DT the) (NNS terms)))) (VP (MD should) (VP (VB be) (VP (VBN balanced))))))) (. .))
(S (PP (IN To) (NP (DT this) (NN end))) (, ,) (NP (NP (DT the) (NNP Multi-Term) (NNP Adam)) (-LRB- -LRB-) (NP (NNP MTAdam)) (-RRB- -RRB-)) (VP (VP (VBZ computes) (NP (NP (DT the) (NN derivative)) (PP (IN of) (NP (DT each) (NN loss) (NN term)))) (ADVP (RB separately))) (, ,) (VP (VBZ infers) (NP (NP (DT the) (ADJP (JJ first) (CC and) (JJ second)) (NNS moments)) (PP (IN per) (NP (NN parameter) (CC and) (NN loss) (NN term))))) (, ,) (CC and) (VP (VBZ calculates) (NP (DT a) (JJ first) (NN moment)) (PP (IN for) (NP (NP (DT the) (NN magnitude)) (PP (IN per) (NP (NP (NN layer)) (PP (IN of) (NP (NP (DT the) (NNS gradients)) (VP (VBG arising) (PP (IN from) (NP (DT each) (NN loss)))))))))))) (. .))
(S (NP (DT This) (NN magnitude)) (VP (VBZ is) (VP (VBN used) (S (VP (TO to) (ADVP (RB continuously)) (VP (VB balance) (NP (DT the) (NNS gradients)) (PP (IN across) (NP (DT all) (NNS layers)))))) (, ,) (PP (IN in) (NP (NP (DT a) (NN manner)) (SBAR (WHNP (WDT that)) (S (DT both) (VP (VP (VBZ varies) (PP (IN from) (NP (CD one) (NN layer))) (PP (IN to) (NP (DT the) (JJ next)))) (CC and) (ADVP (RB dynamically)) (VP (VBZ changes) (PP (IN over) (NP (NN time))))))))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NN training)) (PP (IN with) (NP (DT the) (JJ new) (NN method)))) (VP (VBZ leads) (PP (PP (IN to) (NP (NP (JJ fast) (NN recovery)) (PP (IN from) (NP (JJ suboptimal) (JJ initial) (NN loss) (NN weighting))))) (CC and) (PP (IN to) (NP (NP (NN training) (NNS outcomes)) (SBAR (WHNP (WDT that)) (S (VP (VBP match) (NP (JJ conventional) (NN training)) (PP (IN with) (NP (NP (DT the) (VBN prescribed) (NNS hyperparameters)) (PP (IN of) (NP (DT each) (NN method))))))))))))))) (. .))
