(S (NP (PRP We)) (VP (VBP present) (NP (DT a) (JJ novel) (NN algorithm)) (S (VP (TO to) (VP (VB train) (NP (NP (DT a) (JJ deep) (NML (NN Q) (HYPH -) (VBG learning)) (NN agent)) (VP (VBG using) (NP (NML (JJ natural) (HYPH -) (NN gradient)) (NNS techniques)))))))) (. .))
(S (NP (PRP We)) (VP (VBP compare) (NP (DT the) (JJ original) (JJ deep) (NML (NN Q) (HYPH -) (NN network) (-LRB- -LRB-) (NN DQN) (-RRB- -RRB-)) (NN algorithm)) (PP (IN to) (NP (NP (PRP$ its) (NML (JJ natural) (HYPH -) (NN gradient)) (NN counterpart)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP refer) (PP (IN to) (PP (IN as) (NP (NNP NGDQN))))))))) (, ,) (PP (IN on) (NP (NP (DT a) (NN collection)) (PP (IN of) (NP (JJ classic) (NN control) (NNS domains)))))) (. .))
(S (PP (IN Without) (S (VP (VBG employing) (NP (NN target) (NNS networks))))) (, ,) (NP (NNP NGDQN)) (ADVP (RB significantly)) (VP (VP (VBZ outperforms) (NP (NN DQN)) (PP (IN without) (NP (NN target) (NNS networks)))) (, ,) (CC and) (VP (VBZ performs) (ADJP (ADJP (DT no) (JJR worse)) (PP (IN than) (NP (NP (NN DQN)) (PP (IN with) (NP (NN target) (NNS networks)))))) (, ,) (S (VP (VBG suggesting) (SBAR (IN that) (S (NP (NNP NGDQN)) (VP (VP (VBZ stabilizes) (NP (NN training))) (CC and) (VP (MD can) (VP (VB help) (S (VP (VB reduce) (NP (DT the) (NN need)) (PP (IN for) (NP (JJ additional) (NN hyperparameter) (NN tuning)))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP find) (SBAR (IN that) (S (NP (NNP NGDQN)) (VP (VBZ is) (ADJP (ADJP (RBR less) (JJ sensitive)) (PP (IN to) (NP (NN hyperparameter) (NN optimization)))) (ADVP (JJ relative) (PP (IN to) (NP (NNP DQN)))))))) (. .))
(S (ADVP (RB Together)) (NP (DT these) (NNS results)) (VP (VBP suggest) (SBAR (IN that) (S (NP (NML (JJ natural) (HYPH -) (NN gradient)) (NNS techniques)) (VP (MD can) (VP (VB improve) (NP (NML (NN value) (HYPH -) (NN function)) (NN optimization)) (PP (IN in) (NP (JJ deep) (NN reinforcement) (NN learning)))))))) (. .))
