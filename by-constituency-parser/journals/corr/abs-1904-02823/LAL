(S (NP (NP (NNP Binarized) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP BNNs)) (-RRB- -RRB-))) (VP (MD can) (VP (ADVP (RB significantly)) (VB reduce) (NP (NP (DT the) (NX (NX (NN inference) (NN latency)) (CC and) (NX (NN energy) (NN consumption)))) (PP (IN in) (NP (JJ resource-constrained) (NNS devices)))) (PP (JJ due) (TO to) (NP (NP (PRP$ their) (JJ pure-logical) (NN computation)) (CC and) (NP (JJR fewer) (NN memory) (NNS accesses)))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG training) (NP (NNP BNNs)))) (VP (VBZ is) (ADJP (JJ difficult)) (SBAR (IN since) (S (NP (DT the) (NN activation) (NN flow)) (VP (NNS encounters) (NP (VP (NP (NN degeneration) (, ,) (NN saturation) (, ,) (CC and))) (JJ gradient) (NN mismatch) (NNS problems)))))) (. .))
(S (NP (NNP Prior) (NN work)) (VP (VBZ alleviates) (NP (DT these) (NNS issues)) (PP (IN by) (S (VP (VP (VP (VBG increasing) (NP (NN activation) (NNS bits))) (CC and) (VP (VBG adding) (NP (JJ floating-point) (NN scaling) (NNS factors)))) (, ,) (VP (ADVP (RB thereby)) (VBG sacrificing) (NP (NP (NNP BNN) (POS 's)) (NN energy) (NN efficiency))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP propose) (S (VP (TO to) (VP (VB use) (NP (NN distribution) (NN loss)) (S (VP (TO to) (VP (ADVP (RB explicitly)) (VB regularize) (NP (DT the) (NN activation) (NN flow))))))))) (, ,) (CC and) (VP (VB develop) (NP (NP (DT a) (NN framework)) (SBAR (S (VP (TO to) (VP (ADVP (RB systematically)) (VB formulate) (NP (DT the) (NN loss))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NN distribution) (NN loss)) (VP (MD can) (VP (ADVP (RB consistently)) (VB improve) (NP (NP (DT the) (NN accuracy)) (PP (IN of) (NP (NNP BNNs)))) (PP (IN without) (S (VP (VBG losing) (NP (PRP$ their) (NN energy) (NNS benefits)))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (S (VP (VBD equipped) (PP (IN with) (NP (DT the) (VBN proposed) (NN regularization))))) (, ,) (NP (NNP BNN) (NN training)) (VP (VBZ is) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (JJ robust) (PP (TO to) (NP (NP (DT the) (NN selection)) (PP (IN of) (NP (NP (NNS hyper-parameters)) (PP (VBG including) (NP (NP (NN optimizer)) (CC and) (NP (VBG learning) (NN rate)))))))))))))) (. .))
