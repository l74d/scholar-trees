(S (NP (NP (JJ Recent) (NNS advances)) (PP (IN in) (NP (JJ deep) (NN reinforcement) (NN learning)))) (VP (VBP have) (VP (VBN demonstrated) (NP (NP (DT the) (NN capability)) (PP (IN of) (S (VP (VBG learning) (NP (JJ complex) (NN control) (NNS policies)) (PP (IN from) (NP (NP (JJ many) (NNS types)) (PP (IN of) (NP (NNS environments))))))))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (VP (VBG learning) (NP (NP (NNS policies)) (PP (IN for) (NP (ADJP (NN safety) (HYPH -) (JJ critical)) (NNS applications))))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ essential) (S (VP (TO to) (VP (VP (VB be) (ADJP (JJ sensitive) (PP (IN to) (NP (NNS risks))))) (CC and) (VP (VB avoid) (NP (JJ catastrophic) (NNS events)))))))) (. .))
(S (PP (IN Towards) (NP (DT this) (NN goal))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (NML (NN actor) (HYPH -) (NN critic)) (NN framework)) (SBAR (WHNP (WDT that)) (S (NP (NP (NNS models)) (UCP (NP (NP (DT the) (NN uncertainty)) (PP (IN of) (NP (DT the) (NN future)))) (CC and) (ADVP (RB simultaneously)))) (VP (VBZ learns) (NP (DT a) (NN policy)) (PP (VBN based) (PP (IN on) (NP (DT that) (NN uncertainty) (NN model))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (PP (VBN given) (NP (NP (DT a) (NN distribution)) (PP (IN of) (NP (NP (DT the) (JJ future) (NN return)) (PP (IN for) (NP (DT any) (NN state) (CC and) (NN action))))))) (, ,) (NP (PRP we)) (VP (VBP optimize) (NP (NNS policies)) (PP (IN for) (NP (NP (VBG varying) (NNS levels)) (PP (IN of) (NP (JJ conditional) (NN Value) (HYPH -) (NML (NN at) (HYPH -) (NN Risk))))))) (. .))
(S (NP (DT The) (NML (S (VP (VBN learned)))) (NN policy)) (VP (MD can) (VP (VB map) (NP (DT the) (JJ same) (NN state)) (PP (IN to) (NP (JJ different) (NNS actions))) (PP (VBG depending) (PP (IN on) (NP (NP (DT the) (NN propensity)) (PP (IN for) (NP (NN risk)))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (PRP$ our) (NN approach)))) (PP (IN in) (NP (NP (DT the) (NN domain)) (PP (IN of) (NP (VBG driving) (NNS simulations))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP learn) (NP (NP (NNS maneuvers)) (PP (IN in) (NP (CD two) (NNS scenarios)))))))) (. .))
(S (NP (NP (PRP$ Our)) (VP (VBN learned) (NP (NN controller)))) (VP (MD can) (ADVP (RB dynamically)) (VP (VB select) (NP (NNS actions)) (PP (IN along) (NP (NP (DT a) (JJ continuous) (NN axis)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (ADJP (JJ safe) (CC and) (JJ conservative)) (NNS behaviors)) (VP (VBP are) (VP (VBN found) (PP (IN at) (NP (CD one) (NN end))) (SBAR (IN while) (S (NP (JJR riskier) (NNS behaviors)) (VP (VBP are) (VP (VBN found) (PP (IN at) (NP (DT the) (JJ other))))))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBG testing) (PP (IN with) (NP (ADJP (RB very) (JJ different)) (NN simulation) (NNS parameters)))))) (, ,) (NP (PRP$ our) (ADJP (NN risk) (HYPH -) (JJ averse)) (NNS policies)) (VP (VBP generalize) (ADJP (RB significantly) (JJR better)) (PP (VBN compared) (PP (IN to) (NP (NP (JJ other) (NN reinforcement)) (VP (VBG learning) (NP (NNS approaches))))))) (. .))
