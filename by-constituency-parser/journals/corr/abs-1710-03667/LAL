(S (NP (PRP We)) (VP (VBP perform) (NP (NP (DT an) (JJ average) (NN case) (NN analysis)) (PP (IN of) (NP (NP (DT the) (NN generalization) (NNS dynamics)) (PP (IN of) (NP (NP (JJ large) (JJ neural) (NNS networks)) (VP (VBD trained) (S (VP (VBG using) (NP (JJ gradient) (NN descent))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP study) (NP (NP (DT the) (JJ practically-relevant) (`` ``) (JJ high-dimensional) ('' '') (NN regime)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ free) (NNS parameters))) (PP (IN in) (NP (DT the) (NN network)))) (VP (VBZ is) (UCP (PP (IN on) (NP (NP (DT the) (NN order)) (PP (IN of)))) (CC or) (ADJP (RB even) (JJR larger) (PP (IN than))) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS examples))) (PP (IN in) (NP (DT the) (NN dataset)))))))))) (. .))
(S (S (VP (VBG Using) (NP (NP (JJ random) (NN matrix) (NN theory)) (CC and) (NP (NP (JJ exact) (NNS solutions)) (PP (IN in) (NP (JJ linear) (NNS models))))))) (, ,) (NP (PRP we)) (VP (VP (VBP derive) (NP (NP (DT the) (NN generalization) (NN error) (CC and) (NN training) (NN error) (NNS dynamics)) (PP (IN of) (NP (NN learning))))) (CC and) (VP (VB analyze) (SBAR (WHADVP (WRB how)) (S (NP (PRP they)) (VP (VBP depend) (PP (IN on) (NP (NP (NP (DT the) (NN dimensionality)) (PP (IN of) (NP (NNS data)))) (CC and) (NP (NP (UCP (NN signal) (PP (TO to) (VB noise))) (NN ratio)) (PP (IN of) (NP (DT the) (NN learning) (NN problem))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (JJ gradient) (NN descent) (VBG learning)))) (VP (ADVP (RB naturally)) (VB protect) (PP (IN against) (NP (VBG overtraining) (CC and) (VBG overfitting))) (PP (IN in) (NP (JJ large) (NNS networks))))))) (. .))
(S (NP (NN Overtraining)) (VP (VP (VBZ is) (ADJP (VBN worst)) (PP (IN at) (NP (NP (JJ intermediate) (NN network) (NNS sizes)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (JJ effective) (NN number)) (PP (IN of) (NP (JJ free) (NNS parameters)))) (VP (VBP equals) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS samples)))))))))) (, ,) (CC and) (VP (ADVP (RB thus)) (MD can) (VP (VB be) (VP (VBN reduced) (PP (IN by) (S (VP (VBG making) (S (NP (DT a) (NN network)) (ADJP (JJR smaller) (CC or) (JJR larger)))))))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (PP (IN in) (NP (DT the) (JJ high-dimensional) (NN regime))) (, ,) (NP (JJ low) (NN generalization) (NN error)) (VP (VBZ requires) (S (VP (VBG starting) (PP (IN with) (NP (JJ small) (JJ initial) (NNS weights)))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VP (VB turn) (PP (TO to) (NP (JJ non-linear) (JJ neural) (NNS networks)))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG making) (S (NP (NNS networks)) (ADJP (RB very) (JJ large))))) (VP (VBZ does) (RB not) (VP (VB harm) (NP (PRP$ their) (NN generalization) (NN performance)))))))) (. .))
(S (PP (IN On) (NP (DT the) (JJ contrary))) (, ,) (NP (PRP it)) (VP (MD can) (PP (IN in) (NP (NN fact))) (VP (VB reduce) (NP (NN overtraining)) (, ,) (PP (ADVP (RB even)) (IN without) (NP (NP (JJ early) (NN stopping) (CC or) (NX (NN regularization))) (PP (IN of) (NP (DT any) (NN sort))))))) (. .))
(S (NP (PRP We)) (VP (VBP identify) (NP (NP (NP (CD two) (JJ novel) (NNS phenomena)) (VP (VBG underlying) (NP (DT this) (NN behavior)) (PP (IN in) (NP (JJ overcomplete) (NNS models))))) (: :) (S (S (ADVP (RB first)) (, ,) (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (JJ frozen) (NN subspace)) (PP (IN of) (NP (DT the) (NNS weights))) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT no) (NN learning)) (VP (VBZ occurs) (PP (IN under) (NP (JJ gradient) (NN descent))))))))) (: ;) (CC and) (S (ADVP (JJ second)) (, ,) (NP (NP (DT the) (JJ statistical) (NNS properties)) (PP (IN of) (NP (DT the) (JJ high-dimensional) (JJ regime)))) (VP (NN yield) (NP (NP (JJ better-conditioned) (NN input) (NNS correlations)) (SBAR (WHNP (WDT which)) (S (VP (VBP protect) (PP (IN against) (NP (NN overtraining)))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (JJ naive) (NN application)) (PP (IN of) (NP (NP (JJ worst-case) (NNS theories)) (PP (JJ such) (IN as) (NP (NNP Rademacher) (NN complexity)))))) (VP (VBP are) (ADJP (JJ inaccurate)) (PP (IN in) (S (VP (VBG predicting) (NP (NP (DT the) (NN generalization) (NN performance)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks))))))))))) (, ,) (CC and) (VP (VB derive) (NP (NP (DT an) (NN alternative) (NN bound)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ incorporates) (NP (DT the) (NX (NX (JJ frozen) (NN subspace)) (CC and) (NX (NN conditioning) (NNS effects))))) (CC and) (VP (ADVP (RB qualitatively)) (VBZ matches) (NP (NP (DT the) (NN behavior)) (VP (VBN observed) (PP (IN in) (NP (NN simulation)))))))))))) (. .))
