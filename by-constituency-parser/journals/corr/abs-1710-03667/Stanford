(S (NP (PRP We)) (VP (VBP perform) (NP (NP (DT an) (JJ average) (NN case) (NN analysis)) (PP (IN of) (NP (NP (DT the) (NN generalization) (NNS dynamics)) (PP (IN of) (NP (NP (JJ large) (JJ neural) (NNS networks)) (VP (VBN trained) (S (VP (VBG using) (NP (NN gradient) (NN descent))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP study) (NP (NP (DT the) (ADJP (RB practically) (HYPH -) (JJ relevant)) (`` ") (ADJP (JJ high) (HYPH -) (JJ dimensional)) (`` ") (NN regime)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (JJ free) (NNS parameters)) (PP (IN in) (NP (DT the) (NN network)))))) (VP (VBZ is) (PP (IN on) (NP (NP (DT the) (NN order)) (PP (IN of) (NP (NP (QP (CC or) (RB even)) (JJR larger)) (PP (IN than) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS examples)) (PP (IN in) (NP (DT the) (NN dataset)))))))))))))))) (. .))
(S (S (VP (VBG Using) (NP (NP (NML (JJ random) (NN matrix)) (NN theory)) (CC and) (NP (NP (JJ exact) (NNS solutions)) (PP (IN in) (NP (JJ linear) (NNS models))))))) (, ,) (NP (PRP we)) (VP (VP (VBP derive) (NP (NP (DT the) (NN generalization) (NN error)) (CC and) (NP (NP (NN training) (NN error) (NNS dynamics)) (PP (IN of) (NP (NN learning)))))) (CC and) (VP (VB analyze) (SBAR (WHADVP (WRB how)) (S (NP (PRP they)) (VP (VBP depend) (PP (IN on) (NP (NP (DT the) (NN dimensionality)) (PP (IN of) (NP (NNS data) (CC and) (NN signal))))) (PP (IN to) (NP (NP (NN noise) (NN ratio)) (PP (IN of) (NP (DT the) (NN learning) (NN problem)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (NN gradient) (NN descent) (NN learning)))) (ADVP (RB naturally)) (VP (VB protect) (PP (IN against) (NP (NN overtraining) (CC and) (NN overfitting))) (PP (IN in) (NP (JJ large) (NNS networks))))))) (. .))
(S (NP (NN Overtraining)) (VP (VBZ is) (ADJP (ADJP (JJS worst)) (PP (IN at) (NP (JJ intermediate) (NN network) (NNS sizes)))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (JJ effective) (NN number)) (PP (IN of) (NP (JJ free) (NNS parameters)))) (VP (VP (VBZ equals) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS samples))))) (, ,) (CC and) (ADVP (RB thus)) (VP (MD can) (VP (VB be) (VP (VBN reduced) (PP (IN by) (S (VP (VBG making) (S (NP (DT a) (NN network)) (ADJP (JJR smaller) (CC or) (JJR larger))))))))))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (PP (IN in) (NP (DT the) (ADJP (JJ high) (HYPH -) (JJ dimensional)) (NN regime))) (, ,) (NP (NML (JJ low) (NN generalization)) (NN error)) (VP (VBZ requires) (S (VP (VBG starting) (PP (IN with) (NP (JJ small) (JJ initial) (NNS weights)))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VP (VBP turn) (PP (IN to) (NP (JJ non-linear) (JJ neural) (NNS networks)))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG making) (S (NP (NNS networks)) (ADJP (RB very) (JJ large))))) (VP (VBZ does) (RB not) (VP (VB harm) (NP (PRP$ their) (NN generalization) (NN performance)))))))) (. .))
(S (PP (IN On) (NP (DT the) (NN contrary))) (, ,) (NP (PRP it)) (VP (MD can) (PP (IN in) (NP (NN fact))) (VP (VB reduce) (NP (NP (NP (NN overtraining)) (, ,) (ADVP (RB even) (PP (IN without) (NP (JJ early) (NN stopping))))) (CC or) (NP (NP (NN regularization)) (PP (IN of) (NP (DT any) (NN sort))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP identify) (NP (CD two) (JJ novel) (NNS phenomena)) (S (VP (VBG underlying) (NP (NP (DT this) (NN behavior)) (PP (IN in) (NP (NN overcomplete) (NNS models)))))))) (: :) (S (ADVP (RB first)) (, ,) (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (JJ frozen) (NN subspace)) (PP (IN of) (NP (NP (NP (DT the) (NNS weights)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT no) (NN learning)) (VP (VBZ occurs) (PP (IN under) (NP (NN gradient) (NN descent))))))) (: ;) (CC and) (ADVP (RB second)) (, ,) (NP (NP (ADJP (NP (NP (DT the) (JJ statistical) (NNS properties)) (PP (IN of) (NP (NP (DT the) (ADJP (JJ high) (HYPH -) (JJ dimensional)) (NN regime) (NN yield)) (ADVP (RBR better))))) (HYPH -) (VBN conditioned)) (NN input) (NNS correlations)) (SBAR (WHNP (WDT which)) (S (VP (VBP protect) (PP (IN against) (NP (NN overtraining)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (JJ naive) (NN application)) (PP (IN of) (NP (NP (NML (JJS worst) (HYPH -) (NN case)) (NNS theories)) (PP (JJ such) (IN as) (NP (NNP Rademacher) (NN complexity)))))) (VP (VP (VBP are) (ADJP (JJ inaccurate) (PP (IN in) (S (VP (VBG predicting) (NP (NP (DT the) (NN generalization) (NN performance)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks))))))))) (, ,) (CC and) (VP (VBP derive) (NP (NP (DT an) (NN alternative)) (VP (VBN bound) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ incorporates) (NP (DT the) (JJ frozen) (NML (NN subspace) (CC and) (NN conditioning)) (NNS effects))) (CC and) (VP (ADVP (RB qualitatively)) (VBZ matches) (NP (NP (DT the) (NN behavior)) (VP (VBN observed) (PP (IN in) (NP (NN simulation)))))))))))))))) (. .))
