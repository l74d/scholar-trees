(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (NN reinforcement) (VBG learning) (NN agent)) (SBAR (S (VP (TO to) (VP (VB solve) (NP (JJ hard) (NN exploration) (NNS games)) (PP (IN by) (S (VP (VBG learning) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (JJ directed) (JJ exploratory) (NNS policies))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP construct) (NP (DT an) (JJ episodic) (JJ memory-based) (JJ intrinsic) (NN reward)) (S (VP (VBG using) (NP (NP (JJ k-nearest) (NNS neighbors)) (PP (IN over) (NP (NP (DT the) (NN agent) (POS 's)) (JJ recent) (NN experience)))) (S (VP (TO to) (VP (VB train) (NP (DT the) (JJ directed) (NN exploratory) (NNS policies))))))) (, ,) (S (ADVP (RB thereby)) (VP (VBG encouraging) (S (NP (DT the) (NN agent)) (VP (TO to) (ADVP (RB repeatedly)) (VP (VB revisit) (NP (NP (DT all) (NNS states)) (PP (IN in) (NP (PRP$ its) (NN environment)))))))))) (. .))
(S (NP (DT A) (JJ self-supervised) (NN inverse) (NNS dynamics) (NN model)) (VP (VBZ is) (VP (VBN used) (S (VP (TO to) (VP (VB train) (NP (NP (DT the) (NNS embeddings)) (PP (IN of) (NP (DT the) (JJS nearest) (NN neighbour) (NN lookup)))) (, ,) (S (VP (VBG biasing) (NP (DT the) (NN novelty) (NN signal)) (PP (NNS towards) (SBAR (WHNP (WP what)) (S (NP (DT the) (NN agent)) (VP (MD can) (VP (VB control))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP employ) (NP (NP (DT the) (NN framework)) (PP (IN of) (NP (NP (NNP Universal) (NNP Value) (NNP Function) (NNP Approximators)) (PRN (-LRB- -LRB-) (NP (NNP UVFA)) (-RRB- -RRB-))))) (S (VP (TO to) (VP (ADVP (RB simultaneously)) (VB learn) (NP (NP (JJ many) (VBN directed) (NN exploration) (NNS policies))) (PP (IN with) (NP (DT the) (JJ same) (JJ neural) (NN network))) (, ,) (PP (IN with) (NP (NP (JJ different) (NNS trade-offs)) (PP (IN between) (NP (NN exploration) (CC and) (NN exploitation))))))))) (. .))
(S (PP (IN By) (S (VP (VBG using) (NP (DT the) (JJ same) (JJ neural) (NN network)) (PP (IN for) (NP (NP (JJ different) (NNS degrees)) (PP (IN of) (NP (NN exploration/exploitation)))))))) (, ,) (NP (NN transfer)) (VP (VBZ is) (VP (VBN demonstrated) (PP (IN from) (NP (NP (ADJP (RB predominantly) (JJ exploratory)) (NNS policies)) (VP (VBG yielding) (NP (JJ effective) (JJ exploitative) (NNS policies))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN method)) (VP (MD can) (VP (VB be) (VP (VBN incorporated) (S (VP (TO to) (VP (VB run) (PP (IN with) (NP (NP (JJ modern) (VBN distributed) (NNP RL) (NNS agents)) (SBAR (WHNP (WDT that)) (S (VP (VBP collect) (NP (NP (JJ large) (NNS amounts)) (PP (IN of) (NP (NN experience)))) (PP (IN from) (NP (NP (JJ many) (NNS actors)) (VP (VBG running) (PP (IN in) (NP (NN parallel))) (PP (IN on) (NP (JJ separate) (NN environment) (NNS instances))))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ doubles) (NP (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (NN base) (NN agent)))) (PP (IN in) (NP (NP (DT all) (JJ hard) (NN exploration)) (PP (IN in) (NP (DT the) (NNP Atari-57) (NN suite)))))) (SBAR (IN while) (S (VP (VBG maintaining) (NP (DT a) (ADJP (RB very) (JJ high)) (NN score)) (PP (IN across) (NP (DT the) (VBG remaining) (NNS games)))))) (, ,) (S (VP (VBG obtaining) (NP (NP (DT a) (JJ median) (NN human) (VBD normalised) (NN score)) (PP (IN of) (NP (CD 1344.0) (NN %))))))) (. .))
(S (ADVP (RB Notably)) (, ,) (NP (DT the) (VBN proposed) (NN method)) (VP (VBZ is) (NP (NP (DT the) (JJ first) (NN algorithm)) (SBAR (S (VP (TO to) (VP (VB achieve) (NP (JJ non-zero) (NNS rewards)) (PRN (-LRB- -LRB-) (PP (IN with) (NP (NP (DT a) (JJ mean) (NN score)) (PP (IN of) (NP (CD 8,400))))) (-RRB- -RRB-)) (PP (IN in) (NP (NP (DT the) (NN game)) (PP (IN of) (NP (NN Pitfall))))))))))) (. !))
(PP (IN without) (S (VP (VBG using) (NP (NP (NNS demonstrations)) (CC or) (NP (JJ hand-crafted) (NNS features))))) (. .))
