(S (NP (DT The) (NNP Transformer) (NN model)) (VP (VBZ is) (ADJP (RB widely) (JJ successful) (PP (IN on) (NP (JJ many) (JJ natural) (NN language) (NN processing) (NNS tasks))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (JJ quadratic) (NN complexity)) (PP (IN of) (NP (JJ self-attention)))) (VP (NN limit) (NP (NP (PRP$ its) (NN application)) (PP (IN on) (NP (JJ long) (NN text))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (S (VP (VBG adopting) (NP (NP (DT a) (JJ fine-to-coarse) (NN attention) (NN mechanism)) (PP (IN on) (NP (JJ multi-scale) (NNS spans)))) (PP (IN via) (NP (NP (JJ binary) (NN partitioning)) (PRN (-LRB- -LRB-) (NP (NNP BP)) (-RRB- -RRB-)))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NNP BP-Transformer)) (PRN (-LRB- -LRB-) (NP (NP (NNP BPT)) (PP (IN for) (ADJP (JJ short)))) (-RRB- -RRB-)))) (. .))
(S (NP (NNP BPT)) (VP (VBZ has) (NP (NP (DT a) (JJ good) (NN balance)) (PP (IN between) (NP (NP (NN computation) (NN complexity)) (CC and) (NP (NN model) (NN capacity)))))) (. .))
(S (NP (NP (DT A) (NN series)) (PP (IN of) (NP (NP (NNS experiments)) (PP (IN on) (NP (NP (JJ text) (NN classification)) (, ,) (NP (NN machine) (NN translation)) (CC and) (NP (NN language) (NN modeling))))))) (VP (NNS shows) (SBAR (S (NP (NNP BPT)) (VP (VBZ has) (NP (NP (DT a) (JJ superior) (NN performance)) (PP (IN for) (NP (RB long) (NN text))) (PP (IN than) (NP (JJ previous) (NN self-attention) (NNS models)))))))) (. .))
(S (NP (NP (PRP$ Our) (NX (NX (NN code)) (, ,) (NX (NNS hyperparameters)) (CC and) (NX (NNP CUDA) (NNS kernels)))) (PP (IN for) (NP (JJ sparse) (NN attention)))) (VP (VBP are) (ADJP (JJ available)) (PP (IN in) (NP (NNP PyTorch)))) (. .))
