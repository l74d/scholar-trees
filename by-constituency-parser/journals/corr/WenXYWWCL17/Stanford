(S (NP (NP (NML (JJ High) (NN network)) (NN communication) (NN cost)) (PP (IN for) (NP (VBG synchronizing) (NNS gradients) (CC and) (NNS parameters)))) (VP (VBZ is) (NP (NP (DT the) (ADJP (RB well) (HYPH -) (VBN known)) (NN bottleneck)) (PP (IN of) (NP (VBN distributed) (NN training))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NNP TernGrad)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (JJ ternary) (NNS gradients)) (S (VP (TO to) (VP (VB accelerate) (NP (NP (VBN distributed) (JJ deep) (NN learning)) (PP (IN in) (NP (NNS data) (NN parallelism)))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ requires) (NP (NP (QP (RB only) (CD three)) (JJ numerical) (NNS levels)) (-LRB- {) (NP (HYPH -) (NN 1,0,1)) (-RRB- }) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (ADVP (RB aggressively)) (VP (VB reduce) (NP (DT the) (NN communication) (NN time)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB mathematically)) (VP (VBP prove) (NP (NP (DT the) (NN convergence)) (PP (IN of) (NP (NNP TernGrad)))) (PP (IN under) (NP (NP (DT the) (NN assumption)) (PP (IN of) (NP (DT a) (ADJP (VBN bound) (PP (IN on))) (NNS gradients)))))) (. .))
(S (S (VP (VBN Guided) (PP (IN by) (NP (DT the) (VBN bound))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ layer-wise) (NN ternarizing) (CC and) (NN gradient)) (VP (VBG clipping) (S (VP (TO to) (VP (VB improve) (NP (PRP$ its) (NN convergence)))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG applying) (NP (NNP TernGrad)) (PP (IN on) (NP (NNP AlexNet))))) (VP (VP (VBZ does) (RB not) (VP (VB incur) (NP (DT any) (NN accuracy) (NN loss)))) (CC and) (VP (MD can) (ADVP (RB even)) (VP (VB improve) (NP (NN accuracy)))))))) (. .))
(S (NP (NP (DT The) (NN accuracy) (NN loss)) (PP (IN of) (NP (NP (NNP GoogLeNet)) (VP (VBN induced) (PP (IN by) (NP (NNP TernGrad))))))) (VP (VBZ is) (NP (NP (QP (JJR less) (IN than) (CD 2)) (NN %)) (PP (IN on) (NP (JJ average))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (DT a) (NN performance) (NN model)) (VP (VBZ is) (VP (VBN proposed) (S (VP (TO to) (VP (VB study) (NP (NP (DT the) (NN scalability)) (PP (IN of) (NP (NNP TernGrad))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (NP (JJ significant) (NN speed) (NNS gains)) (PP (IN for) (NP (JJ various) (JJ deep) (JJ neural) (NNS networks)))) (. .))
(S (NP (PRP$ Our) (NN source) (NN code)) (VP (VBZ is) (ADJP (JJ available))) (. .))
