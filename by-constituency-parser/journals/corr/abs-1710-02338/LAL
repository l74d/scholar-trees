(S (S (VP (VBG Optimizing) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP DNNs)) (-RRB- -RRB-))))) (ADVP (RB often)) (VP (VBZ suffers) (PP (IN from) (NP (DT the) (JJ ill-conditioned) (NN problem)))) (. .))
(S (NP (PRP We)) (VP (VBP observe) (SBAR (IN that) (S (NP (NP (DT the) (JJ scaling-based) (NN weight) (NN space) (NN symmetry) (NN property)) (PP (IN in) (NP (JJ rectified) (JJ nonlinear) (NN network)))) (VP (MD will) (VP (VB cause) (NP (DT this) (JJ negative) (NN effect))))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB constrain) (NP (NP (DT the) (VBG incoming) (NNS weights)) (PP (IN of) (NP (DT each) (NN neuron)))) (S (VP (TO to) (VP (VB be) (NP (NP (JJ unit-norm)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN formulated) (PP (IN as) (NP (NP (DT an) (NN optimization) (NN problem)) (PP (IN over) (NP (NNP Oblique) (NN manifold))))))))))))))))) (. .))
(S (NP (NP (DT A) (ADJP (JJ simple) (RB yet) (JJ efficient)) (NN method)) (VP (VBD referred) (PP (TO to)) (PP (IN as) (NP (NP (NN projection) (VBN based) (JJ weight) (NN normalization)) (PRN (-LRB- -LRB-) (NP (NNP PBWN)) (-RRB- -RRB-)))))) (VP (VBZ is) (ADVP (RB also)) (VP (VBN developed) (S (VP (TO to) (VP (VB solve) (NP (DT this) (NN problem))))))) (. .))
(S (NP (NNP PBWN)) (VP (VBZ executes) (NP (NP (JJ standard) (NN gradient) (NNS updates)) (, ,) (VP (VBN followed) (PP (IN by) (S (VP (VBG projecting) (NP (DT the) (VBN updated) (NN weight)) (ADVP (RB back) (PP (TO to) (NP (NNP Oblique) (NN manifold)))))))))) (. .))
(S (NP (DT This) (VBN proposed) (NN method)) (VP (VP (VBZ has) (NP (NP (DT the) (NN property)) (PP (IN of) (NP (NN regularization))))) (CC and) (VP (NNS collaborates) (ADVP (RB well)) (PP (IN with) (NP (DT the) (ADJP (RB commonly) (VBN used)) (NN batch) (NN normalization) (NN technique))))) (. .))
(S (NP (PRP We)) (VP (VBP conduct) (NP (JJ comprehensive) (NNS experiments)) (PP (IN on) (NP (NP (JJ several) (JJ widely-used) (NN image) (NNS datasets)) (PP (VBG including) (NP (NP (NNP CIFAR-10)) (, ,) (NP (NNP CIFAR-100)) (, ,) (NP (NNP SVHN)) (CC and) (NP (NNP ImageNet)))))) (PP (IN for) (NP (NP (JJ supervised) (NN learning)) (PP (IN over) (NP (NP (DT the) (JJ state-of-the-art) (JJ convolutional) (JJ neural) (NNS networks)) (, ,) (PP (JJ such) (IN as) (NP (NP (NNP Inception)) (, ,) (NP (NNP VGG)) (CC and) (NP (JJ residual) (NNS networks))))))))) (. .))
(S (NP (DT The) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NP (NNP DNNs)) (PP (IN with) (NP (JJ different) (NNS architectures)))))) (ADVP (RB consistently)))))))))) (. .))
(S (S (NP (PRP We)) (ADVP (RB also)) (VP (VB apply) (NP (PRP$ our) (NN method)) (PP (TO to) (NP (NNP Ladder) (NN network))) (PP (IN for) (NP (NP (JJ semi-supervised) (NN learning)) (PP (IN on) (NP (NN permutation) (JJ invariant) (NNP MNIST) (NN dataset))))))) (, ,) (CC and) (S (S (NP (PRP$ our) (NN method)) (VP (VBZ outperforms) (NP (DT the) (JJ state-of-the-art) (NNS methods)))) (: :) (S (NP (PRP we)) (VP (VB obtain) (NP (JJ test) (NNS errors)) (PP (IN as) (NP (NP (CD 2.52) (NN %)) (, ,) (NP (CD 1.06) (NN %)) (, ,) (CC and) (NP (CD 0.91) (NN %)))) (PP (IN with) (NP (NP (QP (RB only) (CD 20) (, ,) (CD 50) (, ,) (CC and) (CD 100)) (VBD labeled) (NNS samples)) (, ,) (ADVP (RB respectively))))))) (. .))
