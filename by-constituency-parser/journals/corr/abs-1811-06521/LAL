(S (S (VP (TO To) (VP (VB solve) (NP (JJ complex) (NN real-world) (NNS problems)) (PP (IN with) (NP (NN reinforcement) (NN learning)))))) (, ,) (NP (PRP we)) (VP (MD can) (RB not) (VP (VB rely) (PP (IN on) (NP (ADJP (RB manually) (VBN specified)) (NN reward) (NNS functions))))) (. .))
(S (ADVP (RB Instead)) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB have) (S (NP (NNS humans)) (VP (VBP communicate) (NP (DT an) (NN objective)) (PP (TO to) (NP (DT the) (NN agent))) (ADVP (RB directly)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP combine) (NP (NP (NP (CD two) (NNS approaches)) (PP (TO to) (S (VP (VBG learning) (PP (IN from) (NP (JJ human) (NN feedback))))))) (: :) (NP (NP (JJ expert) (NNS demonstrations)) (CC and) (NP (JJ trajectory) (NNS preferences))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP train) (NP (DT a) (JJ deep) (JJ neural) (NN network)) (S (VP (TO to) (VP (VB model) (NP (DT the) (NN reward) (NN function)))))) (CC and) (VP (VB use) (NP (PRP$ its) (JJ predicted) (NN reward)) (S (VP (TO to) (VP (VB train) (NP (DT an) (JJ DQN-based) (JJ deep) (NN reinforcement) (VBG learning) (NN agent)) (PP (IN on) (NP (CD 9) (NNP Atari) (NNS games)))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VP (VBZ beats) (NP (DT the) (NN imitation) (VBG learning) (NN baseline)) (PP (IN in) (NP (CD 7) (NNS games)))) (CC and) (VP (NNS achieves) (NP (ADJP (RB strictly) (JJ superhuman)) (NN performance)) (PP (IN on) (NP (CD 2) (NNS games))) (PP (IN without) (S (VP (VBG using) (NP (NN game) (NNS rewards))))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (PRP we)) (VP (VP (VBP investigate) (NP (NP (DT the) (NN goodness)) (PP (IN of) (NP (NN fit))) (PP (IN of) (NP (DT the) (NN reward) (NN model))))) (, ,) (VP (JJ present) (NP (DT some) (NN reward) (VBG hacking) (NNS problems))) (, ,) (CC and) (VP (VB study) (NP (NP (DT the) (NNS effects)) (PP (IN of) (NP (NN noise))) (PP (IN in) (NP (DT the) (JJ human) (NNS labels)))))) (. .))
