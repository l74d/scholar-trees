(S (S (VP (VBG Learning) (PP (IN in) (NP (DT a) (JJ non-stationary) (NN environment))))) (VP (VBZ is) (NP (DT an) (JJ inevitable) (NN problem)) (SBAR (WHADVP (WRB when)) (S (VP (VBG applying) (NP (NML (NN machine) (NN learning)) (NN algorithm)) (PP (IN to) (NP (JJ real) (NN world) (NN environment))))))) (. .))
(S (S (VP (VBG Learning) (NP (JJ new) (NNS tasks)) (PP (IN without) (S (VP (VBG forgetting) (NP (DT the) (JJ previous) (NN knowledge))))))) (VP (VBZ is) (NP (NP (DT a) (NN challenge) (NN issue)) (PP (IN in) (NP (NN machine) (NN learning))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (ADJP (NP (NNP Kalman) (NNP Filter)) (VBN based)) (NN modifier) (S (VP (TO to) (VP (VB maintain) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ Neural) (NN Network) (NNS models)))) (PP (IN under) (NP (JJ non-stationary) (NNS environments)))))))) (. .))
(S (NP (DT The) (NN result)) (VP (VP (VBZ shows) (SBAR (IN that) (S (NP (PRP$ our) (VBN proposed) (NN model)) (VP (MD can) (VP (VB preserve) (NP (DT the) (JJ key) (NN information))))))) (CC and) (VP (VBZ adapts) (NP (JJR better)) (PP (IN to) (NP (DT the) (NNS changes))))) (. .))
(S (NP (NP (DT The) (NN accuracy)) (PP (IN of) (NP (VBN proposed) (NN model)))) (VP (VBZ decreases) (PP (IN by) (NP (NP (CD 0.4) (NN %)) (PP (IN in) (NP (PRP$ our) (NNS experiments))))) (, ,) (SBAR (IN while) (S (NP (NP (DT the) (NN accuracy)) (PP (IN of) (NP (JJ conventional) (NN model)))) (VP (VBZ decreases) (PP (IN by) (NP (NP (CD 90) (NN %)) (PP (IN in) (NP (DT the) (NNS drifts) (NN environment))))))))) (. .))
