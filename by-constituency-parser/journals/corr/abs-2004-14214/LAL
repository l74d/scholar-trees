(S (NP (NP (NN Implementation)) (PP (IN of) (NP (JJ quantized) (JJ neural) (NNS networks))) (PP (IN on) (NP (VBG computing) (NN hardware)))) (VP (VBZ leads) (PP (TO to) (NP (VB considerable) (NX (NX (NN speed) (RB up)) (CC and) (NX (NN memory) (NN saving)))))) (. .))
(S (ADVP (RB However)) (, ,) (S (NP (JJ quantized) (JJ deep) (NNS networks)) (VP (VBP are) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB train)))))))) (CC and) (S (NP (NN batch~normalization) (PRN (-LRB- -LRB-) (NP (NNP BatchNorm)) (-RRB- -RRB-)) (NN layer)) (VP (VBZ plays) (NP (DT an) (JJ important) (NN role)) (PP (IN in) (S (VP (VBG training) (NP (ADJP (NN full-precision) (CC and) (JJ quantized)) (NNS networks))))))) (. .))
(S (S (NP (NP (JJS Most) (NNS studies)) (PP (IN on) (NP (NNP BatchNorm)))) (VP (VBP are) (VP (VBN focused) (PP (IN on) (NP (NN full-precision) (NNS networks)))))) (, ,) (CC and) (S (NP (EX there)) (VP (VBZ is) (NP (NP (JJ little) (NN research)) (PP (IN in) (S (VP (JJ understanding) (NP (NP (NNP BatchNorm) (NN affect)) (PP (IN in) (NP (JJ quantized) (NN training))))))) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP address) (ADVP (RB here)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (S (NP (JJ BatchNorm)) (VP (NNS avoids) (NP (NP (NN gradient) (NN explosion)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (UCP (ADJP (JJ counter-intuitive)) (CC and) (VP (ADVP (RB recently)) (VBD observed) (PP (IN in) (NP (JJ numerical) (NNS experiments))) (PP (IN by) (NP (JJ other) (NNS researchers))))))))))))) (. .))
