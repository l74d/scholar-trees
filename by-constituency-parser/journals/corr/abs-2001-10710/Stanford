(S (NP (NP (DT The) (NML (JJ high) (NN energy)) (NN cost)) (PP (IN of) (S (VP (VBG processing) (NP (JJ deep) (JJ convolutional) (JJ neural) (NNS networks)))))) (VP (VBZ impedes) (NP (PRP$ their) (JJ ubiquitous) (NN deployment)) (PP (IN in) (NP (NP (ADJP (NN energy) (HYPH -) (VBN constrained)) (NNS platforms)) (PP (JJ such) (IN as) (NP (VBN embedded) (NNS systems) (CC and) (NN IoT) (NNS devices)))))) (. .))
(S (NP (DT This) (NN work)) (VP (VBZ introduces) (NP (JJ convolutional) (NNS layers)) (PP (IN with) (NP (NP (JJ pre-defined) (JJ sparse) (NN 2D) (NNS kernels)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (NP (NP (NN support) (NNS sets)) (SBAR (WHNP (WDT that)) (S (VP (VBP repeat) (ADVP (RB periodically)) (PP (IN within) (CC and) (IN across) (NP (NNS filters))))))))))))) (. .))
(S (PP (IN Due) (PP (IN to) (NP (NP (DT the) (JJ efficient) (NN storage)) (PP (IN of) (NP (PRP$ our) (JJ periodic) (JJ sparse) (NNS kernels)))))) (, ,) (NP (NP (DT the) (NN parameter)) (SBAR (S (NP (NNS savings)) (VP (MD can) (VP (VB translate) (PP (IN into) (NP (NP (JJ considerable) (NNS improvements)) (PP (IN in) (NP (NN energy) (NN efficiency))))) (PP (IN due) (IN to) (NP (VBN reduced) (NNP DRAM)))))))) (VP (VBZ accesses) (, ,) (S (ADVP (RB thus)) (VP (VBG promising) (NP (JJ significant) (NNS improvements)) (PP (IN in) (NP (NP (DT the) (NN trade) (HYPH -) (NN off)) (PP (IN between) (NP (NN energy) (NN consumption) (CC and) (NN accuracy))))) (PP (IN for) (NP (DT both) (NN training) (CC and) (NN inference)))))) (. .))
(S (S (VP (TO To) (VP (VB evaluate) (NP (DT this) (NN approach))))) (, ,) (NP (PRP we)) (VP (VBD performed) (NP (NNS experiments)) (PP (IN with) (NP (NP (CD two)) (VP (ADVP (RB widely)) (VBN accepted) (NP (NP (NNS datasets)) (, ,) (NP (NN CIFAR) (HYPH -) (CD 10)) (CC and) (NP (JJ Tiny) (NNP ImageNet))) (PP (IN in) (NP (NP (JJ sparse) (NNS variants)) (PP (IN of) (NP (NP (DT the) (NN ResNet18)) (CC and) (NP (NN VGG16) (NNS architectures)))))))))) (. .))
(SINV (PP (VBN Compared) (PP (IN to) (NP (NP (NN baseline) (NNS models)) (, ,) (NP (PRP$ our) (VBN proposed) (JJ sparse) (NNS variants))))) (VP (VBP require) (PRT (RP up)) (PP (IN to) (NP (CD 82) (NN %)))) (NP (NP (JJR fewer) (NN model) (NNS parameters)) (PP (IN with) (NP (NP (QP (CD 5.6) (NNS times) (JJR fewer)) (NNS FLOPs)) (PP (IN with) (NP (NP (JJ negligible) (NN loss)) (PP (IN in) (NP (NP (NN accuracy)) (PP (IN for) (NP (NP (NN ResNet18)) (PP (IN on) (NP (NN CIFAR) (HYPH -) (CD 10)))))))))))) (. .))
(S (PP (IN For) (NP (NP (NN VGG16)) (VP (VBN trained) (PP (IN on) (NP (JJ Tiny) (NNP ImageNet)))))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ requires) (NP (NP (QP (CD 5.8) (NNS times) (JJR fewer)) (NNS FLOPs)) (CC and) (NP (QP (IN up) (IN to) (CD 83.3)) (NN %)) (NP (NP (JJR fewer) (NN model) (NNS parameters)) (PP (IN with) (NP (NP (DT a) (NN drop)) (PP (IN in) (NP (NP (NML (JJ top) (HYPH -) (CD 5)) (-LRB- -LRB-) (NML (NN top) (HYPH -) (CD 1)) (-RRB- -RRB-) (NN accuracy)) (PP (IN of) (NP (QP (RB only) (CD 1.2)) (NN %))))))))) (PRN (-LRB- -LRB-) (NP (CD 2.1) (NN %)) (-RRB- -RRB-))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBD compared) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (PRP$ our) (VBN proposed) (NNS architectures)))) (PP (IN with) (NP (NP (DT that)) (PP (IN of) (NP (NNP ShuffleNet) (NN andMobileNetV2)))))) (. .))
(S (S (VP (VBG Using) (NP (JJ similar) (NNS hyperparameters) (CC and) (NNS FLOPs)))) (, ,) (NP (PRP$ our) (NN ResNet18) (NNS variants)) (VP (VBP yield) (NP (NP (DT an) (JJ average) (NN accuracy) (NN improvement)) (PP (IN of) (NP (CD 2.8) (NN %))))) (. .))
