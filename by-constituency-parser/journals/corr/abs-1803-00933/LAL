(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ distributed) (NN architecture)) (PP (IN for) (NP (NP (JJ deep) (NN reinforcement) (VBG learning)) (PP (IN at) (NP (NN scale))))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (S (NP (NNS agents)) (VP (TO to) (VP (VB learn) (ADVP (RB effectively)) (PP (IN from) (NP (NP (ADJP (NP (NP (NNS orders)) (PP (IN of) (NP (NN magnitude)))) (JJR more)) (NNS data)) (PP (IN than) (S (ADVP (RB previously)) (ADJP (JJ possible)))))))))))))) (. .))
(S (S (NP (DT The) (NN algorithm)) (VP (NNS decouples) (NP (VBG acting)) (PP (IN from) (NP (VBG learning))))) (: :) (S (S (NP (DT the) (NNS actors)) (VP (VP (VBP interact) (PP (IN with) (NP (NP (PRP$ their) (JJ own) (NNS instances)) (PP (IN of) (NP (DT the) (NN environment))))) (PP (IN by) (S (VP (VBG selecting) (NP (NNS actions)) (PP (VBG according) (PP (TO to) (NP (DT a) (VBN shared) (JJ neural) (NN network)))))))) (, ,) (CC and) (VP (VB accumulate) (NP (DT the) (VBG resulting) (NN experience)) (PP (IN in) (NP (DT a) (JJ shared) (NN experience) (NN replay) (NN memory)))))) (: ;) (S (NP (DT the) (NN learner)) (VP (VP (VBZ replays) (NP (NP (NNS samples)) (PP (IN of) (NP (NN experience))))) (CC and) (VP (VBZ updates) (NP (DT the) (JJ neural) (NN network)))))) (. .))
(S (NP (DT The) (NN architecture)) (VP (VBZ relies) (PP (IN on) (NP (JJ prioritized) (NN experience) (NN replay))) (S (VP (TO to) (VP (VB focus) (ADVP (RB only)) (PP (IN on) (NP (NP (DT the) (ADJP (RBS most) (JJ significant)) (NNS data)) (VP (VBN generated) (PP (IN by) (NP (DT the) (NNS actors)))))))))) (. .))
(S (NP (PRP$ Our) (NN architecture)) (VP (ADVP (RB substantially)) (VBZ improves) (NP (NP (DT the) (NN state)) (PP (IN of) (NP (DT the) (NN art))) (PP (IN on) (NP (DT the) (NNP Arcade) (NNP Learning) (NNP Environment)))) (, ,) (S (VP (VBG achieving) (NP (RBR better) (JJ final) (NN performance)) (PP (IN in) (NP (NP (DT a) (NN fraction)) (PP (IN of) (NP (DT the) (JJ wall-clock) (NN training) (NN time)))))))) (. .))
