(S (PP (IN With) (NP (NP (DT the) (VBG growing) (NN importance)) (PP (IN of) (NP (NP (JJ large) (NN network) (NNS models)) (CC and) (NP (JJ enormous) (NN training) (NNS datasets)))))) (, ,) (NP (NNS GPUs)) (VP (VBP have) (VP (VBN become) (S (ADJP (RB increasingly) (JJ necessary) (S (VP (TO to) (VP (VB train) (NP (JJ neural) (NNS networks))))))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (SBAR (RB largely) (IN because) (S (NP (JJ conventional) (NN optimization) (NNS algorithms)) (VP (VBP rely) (PP (IN on) (NP (NP (JJ stochastic) (NN gradient) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP do) (RB n't) (VP (VB scale) (ADVP (RB well)) (PP (IN to) (NP (NP (JJ large) (NNS numbers)) (PP (IN of) (NP (NP (NNS cores)) (PP (IN in) (NP (DT a) (NN cluster) (NN setting))))))))))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (NP (DT the) (NN convergence)) (PP (IN of) (NP (DT all) (NN gradient) (NNS methods))) (, ,) (PP (VBG including) (NP (NN batch) (NNS methods))) (, ,)) (VP (VBZ suffers) (PP (IN from) (NP (NP (JJ common) (NNS problems)) (PP (IN like) (NP (NP (NN saturation) (NNS effects)) (, ,) (NP (JJ poor) (NN conditioning)) (, ,) (CC and) (NP (NN saddle) (NNS points))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ explores) (NP (NP (DT an) (JJ unconventional) (NN training) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (S (VP (VBG alternating) (NP (NP (NN direction) (NNS methods)) (CC and) (NP (NNP Bregman) (NN iteration))) (S (VP (TO to) (VP (VB train) (NP (NNS networks)) (PP (IN without) (NP (NN gradient) (NN descent) (NNS steps))))))))))))) (. .))
(S (NP (DT The) (JJ proposed) (NN method)) (VP (VBZ reduces) (NP (DT the) (NN network) (NN training) (NN problem)) (PP (IN to) (NP (NP (DT a) (NN sequence)) (PP (IN of) (NP (NP (NN minimization) (NNS sub-steps)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (DT each) (VP (VB be) (VP (VBN solved) (ADVP (RB globally)) (PP (IN in) (NP (JJ closed) (NN form))))))))))))) (. .))
(S (NP (DT The) (JJ proposed) (NN method)) (VP (VBZ is) (ADJP (JJ advantageous)) (SBAR (IN because) (S (NP (PRP it)) (VP (VBZ avoids) (NP (NP (JJ many)) (PP (IN of) (NP (NP (DT the) (NNS caveats)) (SBAR (WHNP (WDT that)) (S (VP (VBP make) (NP (NN gradient) (NNS methods)) (ADVP (RB slow)) (PP (IN on) (NP (ADJP (RB highly) (JJ non-convex)) (NNS problems))))))))))))) (. .))
(S (NP (DT The) (NN method)) (VP (VBZ exhibits) (NP (NP (JJ strong) (NN scaling)) (PP (IN in) (NP (DT the) (VBN distributed) (NN setting)))) (, ,) (S (VP (VBG yielding) (NP (JJ linear) (NNS speedups)) (SBAR (RB even) (WHADVP (WRB when)) (S (VP (VBN split) (PP (IN over) (NP (NP (NNS thousands)) (PP (IN of) (NP (NNS cores))))))))))) (. .))
