(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT a) (JJ new) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (ADVP (RB significantly)) (VP (VBZ improves) (NP (NP (DT the) (NN efficiency)) (PP (IN of) (NP (NN exploration)))) (PP (IN for) (NP (NP (JJ deep) (NML (NN Q) (HYPH -) (VBG learning)) (NNS agents)) (PP (IN in) (NP (NN dialogue) (NNS systems)))))))))) (. .))
(S (NP (PRP$ Our) (NNS agents)) (VP (VB explore) (PP (IN via) (NP (NNP Thompson) (NN sampling))) (, ,) (S (VP (VBG drawing) (NP (NML (NNP Monte) (NNP Carlo)) (NNS samples)) (PP (IN from) (NP (DT a) (NML (NML (NNP Bayes)) (HYPH -) (PP (IN by) (HYPH -) (NP (NNP Backprop)))) (JJ neural) (NN network)))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG spiking) (NP (DT the) (NN replay) (NN buffer)) (PP (IN with) (NP (NP (NNS experiences)) (PP (IN from) (NP (QP (RB just) (DT a) (JJ few)) (JJ successful) (NNS episodes))))))) (VP (MD can) (VP (VB make) (NP (NN Q) (HYPH -) (VBG learning)) (S (ADJP (JJ feasible))) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (MD might) (ADVP (RB otherwise)) (VP (VB fail)))))))))) (. .))
