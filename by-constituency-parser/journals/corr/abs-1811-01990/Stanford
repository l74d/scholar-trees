(S (NP (PRP We)) (VP (VBP propose) (CC and) (VBP compare) (NP (NP (ADJP (NP (NP (NNS methods)) (PP (IN for) (NP (NN gradient)))) (HYPH -) (VBN based)) (NN domain) (NN adaptation)) (PP (IN of) (NP (ADJP (NN self) (HYPH -) (JJ attentive)) (NML (JJ neural) (NN machine) (NN translation)) (NNS models))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT a) (JJ large) (NN proportion)) (PP (IN of) (NP (NN model) (NNS parameters)))) (VP (MD can) (VP (VB be) (VP (VBN frozen) (PP (IN during) (NP (NP (NP (NN adaptation)) (PP (IN with) (ADJP (JJ minimal)))) (CC or) (NP (NP (DT no) (NN reduction)) (PP (IN in) (NP (NN translation) (NN quality)))))) (PP (IN by) (S (VP (VBG encouraging) (NP (JJ structured) (NN sparsity)) (PP (IN in) (NP (NP (DT the) (NN set)) (PP (IN of) (S (VP (VBN offset) (NP (NNS tensors)) (PP (IN during) (NP (NN learning))) (PP (IN via) (NP (NN group) (NN lasso) (NN regularization))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NP (NP (DT this) (NN technique)) (PP (IN for) (NP (DT both) (NN batch)))) (CC and) (NP (NP (JJ incremental) (NN adaptation)) (PP (IN across) (NP (NML (NML (NML (JJ multiple) (NNS data)) (NNS sets)) (CC and) (NML (NN language))) (NNS pairs)))))) (. .))
(S (NP (PRP$ Our) (NN system) (S (VP (NN architecture) (HYPH -) (VBG combining) (NP (NP (DT a) (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (ADJP (NN self) (HYPH -) (JJ attentive)) (NN model)) (PP (IN with) (NP (JJ compact) (NN domain) (NN adaptation))))))) (HYPH -) (VP (VBZ provides) (NP (NP (NML (JJ high) (NN quality)) (VBN personalized) (NN machine)) (NN translation) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (NP (NP (DT both) (NN space) (CC and) (NN time)) (ADJP (JJ efficient)))))))) (. .))
