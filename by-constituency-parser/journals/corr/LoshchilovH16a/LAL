(S (NP (NNP Restart) (NNS techniques)) (VP (VBP are) (ADJP (JJ common)) (PP (IN in) (NP (JJ gradient-free) (NN optimization))) (S (VP (TO to) (VP (VB deal) (PP (IN with) (NP (JJ multimodal) (NNS functions))))))) (. .))
(S (NP (JJ Partial) (NN warm) (NNS restarts)) (VP (VBP are) (ADVP (RB also)) (VP (VBG gaining) (NP (NN popularity)) (PP (IN in) (NP (JJ gradient-based) (NN optimization))) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN rate)) (PP (IN of) (NP (NN convergence)))) (PP (IN in) (NP (JJ accelerated) (NN gradient) (NNS schemes))) (S (VP (TO to) (VP (VB deal) (PP (IN with) (NP (JJ ill-conditioned) (NNS functions))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ simple) (JJ warm) (NN restart) (NN technique)) (PP (IN for) (NP (JJ stochastic) (NN gradient) (NN descent))) (SBAR (S (VP (TO to) (VP (VB improve) (NP (PRP$ its) (NN anytime) (NN performance)) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks))))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB empirically)) (VBD study) (NP (NP (PRP$ its) (NN performance)) (PP (IN on) (NP (NP (DT the) (NNP CIFAR-10) (CC and) (NNP CIFAR-100) (NNS datasets)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP demonstrate) (NP (JJ new) (JJ state-of-the-art) (NNS results)) (PP (IN at) (NP (NP (NP (CD 3.14) (NN %)) (CC and) (NP (CD 16.21) (NN %))) (, ,) (ADVP (RB respectively))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP demonstrate) (NP (PRP$ its) (NNS advantages)) (PP (PP (IN on) (NP (NP (DT a) (NN dataset)) (PP (IN of) (NP (NNP EEG) (NNS recordings))))) (CC and) (PP (IN on) (NP (NP (DT a) (JJ downsampled) (NN version)) (PP (IN of) (NP (DT the) (NNP ImageNet) (NN dataset))))))) (. .))
(S (NP (PRP$ Our) (NN source) (NN code)) (VP (VBZ is) (ADJP (JJ available)) (PP (IN at) (NP (DT this) (NN https) (NNP URL)))))
