(S (SBAR (IN While) (S (NP (JJ deep) (NN reinforcement) (NN learning)) (VP (NNS excels) (PP (IN at) (S (VP (VBG solving) (NP (NP (NNS tasks)) (SBAR (WHADVP (WRB where)) (S (NP (NP (JJ large) (NNS amounts)) (PP (IN of) (NP (NNS data)))) (VP (MD can) (VP (VB be) (VP (VBN collected) (PP (IN through) (NP (NP (ADJP (RB virtually) (JJ unlimited)) (NN interaction)) (PP (IN with) (NP (DT the) (NN environment))))))))))))))))) (, ,) (S (VP (VBG learning) (PP (IN from) (NP (JJ limited) (NN interaction))))) (VP (VBZ remains) (NP (DT a) (JJ key) (NN challenge))) (. .))
(S (NP (PRP We)) (VP (VBP posit) (SBAR (IN that) (S (NP (DT an) (NN agent)) (VP (MD can) (VP (VB learn) (ADVP (RBR more) (RB efficiently)) (SBAR (IN if) (S (NP (PRP we)) (VP (VBP augment) (NP (JJ reward) (NN maximization)) (PP (IN with) (NP (NP (JJ self-supervised) (NNS objectives)) (VP (VBN based) (PP (IN on) (NP (NP (NP (NN structure)) (PP (IN in) (NP (PRP$ its) (JJ visual) (NN input)))) (CC and) (NP (NP (JJ sequential) (NN interaction)) (PP (IN with) (NP (DT the) (NN environment))))))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NN method)) (, ,) (NP (NP (NNP Momentum) (NNP Predictive) (NNP Representations)) (PRN (-LRB- -LRB-) (NP (NNP MPR)) (-RRB- -RRB-))) (, ,)) (VP (VBZ trains) (S (NP (DT an) (NN agent)) (VP (TO to) (VP (VB predict) (NP (PRP$ its) (JJ own) (NN latent) (NN state) (NNS representations)) (PP (NP (JJ multiple) (NNS steps)) (IN into) (NP (DT the) (NN future))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP compute) (NP (NP (NN target) (NNS representations)) (PP (IN for) (NP (JJ future) (NNS states)))) (S (VP (VBG using) (NP (NP (DT an) (NN encoder)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (DT an) (JJ exponential) (NN moving) (NN average)) (PP (IN of) (NP (NP (DT the) (NN agent) (POS 's)) (NNS parameters)))))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP make) (NP (NNS predictions)) (S (VP (VBG using) (NP (DT a) (JJ learned) (NN transition) (NN model)))))) (. .))
(S (PP (IN On) (NP (PRP$ its) (JJ own))) (, ,) (NP (DT this) (NN future) (NN prediction) (JJ objective)) (VP (NNS outperforms) (NP (NP (VBP prior) (NNS methods)) (PP (IN for) (NP (NP (JJ sample-efficient) (JJ deep) (NN RL)) (PP (IN from) (NP (NNS pixels))))))) (. .))
(S (NP (PRP We)) (ADVP (VBP further)) (VP (VB improve) (NP (NN performance)) (PP (IN by) (S (VP (VBG adding) (NP (NP (NNS data) (NN augmentation))) (PP (TO to) (NP (DT the) (NN future) (NN prediction) (NN loss))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ forces) (S (NP (NP (DT the) (NN agent) (POS 's)) (NNS representations)) (VP (TO to) (VP (VB be) (ADJP (JJ consistent)) (PP (IN across) (NP (NP (JJ multiple) (NNS views)) (PP (IN of) (NP (DT an) (NN observation))))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (JJ full) (JJ self-supervised) (NN objective)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ combines) (NP (NP (NN future) (NN prediction)) (CC and) (NP (NNS data) (NN augmentation)))))) (, ,)) (VP (VBZ achieves) (NP (NP (DT a) (JJ median) (JJ human-normalized) (NN score)) (PP (IN of) (NP (CD 0.444))) (PP (IN on) (NP (NNP Atari)))) (PP (IN in) (NP (NP (DT a) (NN setting)) (VP (VBN limited) (PP (TO to) (NP (NP (NP (CD 100K) (NNS steps)) (PP (IN of) (NP (NN environment) (NN interaction)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (DT a) (ADJP (CD 66) (NN %)) (JJ relative) (NN improvement)) (PP (IN over) (NP (DT the) (JJ previous) (NN state-of-the-art))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (PP (ADVP (RB even)) (IN in) (NP (DT this) (JJ limited) (NN data) (NN regime))) (, ,) (NP (NNP MPR)) (VP (VBZ exceeds) (NP (JJ expert) (JJ human) (NNS scores)) (PP (IN on) (NP (QP (CD 6) (IN out) (IN of) (CD 26)) (NNS games)))) (. .))
