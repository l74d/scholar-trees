(S (ADVP (RB Recently)) (, ,) (NP (NN dropout)) (VP (VBZ has) (VP (VBN seen) (NP (NP (VBG increasing) (NN use)) (PP (IN in) (NP (JJ deep) (NN learning)))))) (. .))
(S (PP (IN For) (NP (JJ deep) (JJ convolutional) (JJ neural) (NNS networks))) (, ,) (NP (NN dropout)) (VP (VBZ is) (VP (VBN known) (S (VP (TO to) (VP (VB work) (ADVP (RB well)) (PP (IN in) (NP (JJ fully-connected) (NNS layers)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (PRP$ its) (NN effect)) (PP (IN in) (NP (JJ convolutional) (CC and) (VBG pooling) (NNS layers)))) (VP (VBZ is) (ADVP (RB still)) (RB not) (ADJP (JJ clear))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ demonstrates) (SBAR (IN that) (S (NP (NN max-pooling) (NN dropout)) (VP (VBZ is) (ADJP (JJ equivalent) (PP (TO to) (S (VP (ADVP (VB randomly)) (VBG picking) (NP (NN activation)) (PP (VBN based) (PP (IN on) (NP (DT a) (JJ multinomial) (NN distribution))) (PP (IN at) (NP (NN training) (NN time)))))))))))) (. .))
(S (PP (IN In) (NP (NP (NN light)) (PP (IN of) (NP (DT this) (NN insight))))) (, ,) (NP (PRP we)) (VP (VBP advocate) (S (VP (VBG employing) (NP (NP (PRP$ our) (VBN proposed) (JJ probabilistic) (VBD weighted) (NN pooling)) (, ,) (PP (RB instead) (IN of) (NP (ADJP (RB commonly) (VBN used)) (NN max-pooling))) (, ,)) (S (VP (TO to) (VP (VB act) (PP (IN as) (NP (NN model) (VBG averaging))) (PP (IN at) (NP (NN test) (NN time))))))))) (. .))
(S (NP (JJ Empirical) (NN evidence)) (VP (VBZ validates) (NP (NP (DT the) (NN superiority)) (PP (IN of) (NP (JJ probabilistic) (JJ weighted) (NN pooling))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (ADVP (RB empirically)) (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (JJ convolutional) (NN dropout)))) (VP (VBZ is) (RB not) (ADJP (JJ trivial)) (, ,) (PP (IN despite) (NP (NP (DT the) (ADJP (RB dramatically) (JJ reduced)) (NN possibility)) (PP (IN of) (NP (JJ over-fitting))) (PP (JJ due) (PP (TO to) (NP (DT the) (JJ convolutional) (NN architecture)))))))))) (. .))
(S (S (VP (ADVP (RB Elaborately)) (VBG designing) (NP (RP dropout) (VBG training)) (ADVP (RB simultaneously)) (PP (IN in) (NP (JJ max-pooling) (CC and) (JJ fully-connected) (NNS layers))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (NP (JJ state-of-the-art) (NN performance)) (PP (IN on) (NP (NNP MNIST)))) (, ,) (CC and) (NP (NP (ADJP (RB very) (JJ competitive)) (NNS results)) (PP (IN on) (NP (NNP CIFAR-10) (CC and) (NNP CIFAR-100)))) (, ,) (ADVP (JJ relative) (PP (TO to) (NP (NP (JJ other) (NNS approaches)) (PP (IN without) (NP (NNS data) (NN augmentation)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP compare) (NP (NP (NP (JJ max-pooling) (NN dropout)) (CC and) (NP (JJ stochastic) (NN pooling))) (, ,) (SBAR (WHNP (WHNP (DT both)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBP introduce) (NP (NP (NN stochasticity)) (VP (VBN based) (PP (IN on) (NP (JJ multinomial) (NNS distributions))) (PP (IN at) (NP (VBG pooling) (NN stage)))))))))) (. .))
