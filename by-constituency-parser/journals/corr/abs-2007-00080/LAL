(S (NP (PRP We)) (VP (VBP propose) (NP (NP (CD two) (JJ new) (JJ Q-learning) (NN algorithms)) (, ,) (NP (NP (NP (NNP Full-Q-Learning)) (PRN (-LRB- -LRB-) (NP (NNP FQL)) (-RRB- -RRB-))) (CC and) (NP (NP (JJ Elimination-Based) (NNP Half-Q-Learning)) (PRN (-LRB- -LRB-) (NP (NNP HQL)) (-RRB- -RRB-)))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBZ enjoy) (NP (NP (JJ improved) (NN efficiency) (CC and) (NN optimality)) (PP (IN in) (NP (RRC (DT the) (NN full-feedback) (CC and)) (DT the) (JJ one-sided-feedback) (NNS settings))) (PP (IN over) (NP (VBG existing) (JJ Q-learning) (NN algorithms))))))))) (. .))
(S (NP (PRP$ Our) (JJ regret) (NNS bounds)) (VP (VBP are) (RB not) (VP (VBN affected) (PP (IN by) (NP (DT the) (ADJP (RB possibly) (JJ huge)) (NN state) (CC and) (NN action) (NN space))))) (. .))
(S (NP (NP (PRP$ Our) (JJ numerical) (NNS experiments)) (VP (VBG using) (NP (DT the) (JJ classical) (NN inventory) (NN control) (NN problem)) (PP (IN as) (NP (DT an) (NN example))))) (VP (VP (NN demonstrate) (NP (NP (DT the) (JJ superior) (NN efficiency)) (PP (IN of) (NP (NNP FQL) (CC and) (NNP HQL))))) (, ,) (CC and) (VP (VBZ shows) (NP (NP (DT the) (NN potential)) (PP (IN of) (S (VP (VBG tailoring) (NP (NN reinforcement) (VBG learning) (NNS algorithms)) (PP (IN for) (NP (NP (JJR richer) (NN feedback) (NNS models)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (JJ prevalent) (PP (IN in) (NP (JJ many) (JJ natural) (NNS problems)))))))))))))) (. .))
