(S (NP (VBN Distributed) (JJ stochastic) (NN gradient) (NN descent) (PRN (-LRB- -LRB-) (NNP SGD) (-RRB- -RRB-)) (NN algorithms)) (VP (VBP are) (VP (ADVP (RB widely)) (VBN deployed) (PP (IN in) (S (VP (VBG training) (NP (JJ large-scale) (JJ deep) (NN learning) (NNS models))))) (, ,) (SBAR (IN while) (S (NP (NP (DT the) (NN communication) (NN overhead)) (PP (IN among) (NP (NNS workers)))) (VP (VBZ becomes) (NP (DT the) (JJ new) (NN system) (NN bottleneck))))))) (. .))
(S (NP (NP (ADJP (RB Recently) (VBN proposed)) (NN gradient) (NN sparsification) (NNS techniques)) (, ,) (NP (ADVP (RB especially)) (NP (NP (SBAR (FRAG (NNP Top-) ($ $) (VB k) ($ $))) (NN sparsification)) (PP (IN with) (NP (NN error) (NN compensation))) (PRN (-LRB- -LRB-) (NP (NNP TopK-SGD)) (-RRB- -RRB-)))) (, ,)) (VP (MD can) (VP (ADVP (RB significantly)) (VB reduce) (NP (DT the) (NN communication) (NN traffic)) (PP (IN without) (NP (NP (DT an) (JJ obvious) (NN impact)) (PP (IN on) (NP (DT the) (NN model) (NN accuracy))))))) (. .))
(S (NP (DT Some) (JJ theoretical) (NNS studies)) (VP (VBP have) (VP (VBN been) (VP (VBN carried) (PRT (IN out)) (S (VP (TO to) (VP (VB analyze) (NP (NP (DT the) (NN convergence) (NN property)) (PP (IN of) (NP (NNP TopK-SGD)))))))))) (. .))
(S (S (ADVP (RB However)) (, ,) (NP (VBG existing) (NNS studies)) (VP (VBP do) (RB not) (VP (VP (VB dive) (PP (IN into) (NP (NP (DT the) (NNS details)) (PP (IN of) (NP (NP (ADJP (NNP Top-) ($ $) (VB k) ($ $)) (NN operator)) (PP (IN in) (NP (JJ gradient) (NN sparsification)))))))) (CC and) (VP (NN use) (NP (NP (JJ relaxed) (NNS bounds)) (PRN (-LRB- -LRB-) (INTJ (NN e.g.)) (, ,) (NP (NP (JJ exact) (NN bound)) (PP (IN of) (NP (ADJP (NNP Random-) ($ $) (VB k)) ($ $)))) (-RRB- -RRB-))) (PP (IN for) (NP (NN analysis))))))) (: ;) (S (ADVP (VB hence)) (NP (DT the) (JJ derived) (NNS results)) (VP (MD can) (RB not) (VP (ADVP (RB well)) (VB describe) (NP (NP (DT the) (JJ real) (NN convergence) (NN performance)) (PP (IN of) (NP (NNP TopK-SGD))))))) (. .))
(S (PP (TO To) (NP (DT this) (NN end))) (, ,) (NP (PRP we)) (ADVP (RB first)) (VP (VBD study) (NP (NP (DT the) (JJ gradient) (NNS distributions)) (PP (IN of) (NP (NNP TopK-SGD)))) (PP (IN during) (NP (DT the) (NN training) (NN process))) (PP (IN through) (NP (JJ extensive) (NNS experiments)))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (ADVP (RB theoretically)) (VP (VB derive) (NP (NP (DT a) (JJR tighter) (NN bound)) (PP (IN for) (NP (DT the) (ADJP (QP (NNP Top-) ($ $) (VB k) ($ $))) (NN operator))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP exploit) (NP (NP (DT the) (NN property)) (PP (IN of) (NP (JJ gradient) (NN distribution)))) (S (VP (TO to) (VP (VB propose) (NP (NP (NP (DT an) (JJ approximate) (ADJP (JJ top-) ($ $) (VB k) ($ $)) (NN selection) (NN algorithm)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (NN computing-efficient) (PP (IN for) (NP (NNP GPUs))))))) (, ,)) (SBAR (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN scaling) (NN efficiency)) (PP (IN of) (NP (NNP TopK-SGD)))) (PP (IN by) (S (VP (ADVP (RB significantly)) (VBG reducing) (NP (DT the) (VBG computing) (NN overhead)))))))))))))) (. .))
