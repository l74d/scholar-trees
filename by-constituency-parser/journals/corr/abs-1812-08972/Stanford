(S (NP (EX There)) (VP (VBZ is) (ADVP (RB recently)) (NP (NP (DT a) (NN surge)) (PP (IN in) (NP (NP (NNS approaches)) (SBAR (WHNP (WDT that)) (S (VP (VBP learn) (NP (NP (ADJP (JJ low) (HYPH -) (JJ dimensional)) (NNS embeddings)) (PP (IN of) (NP (NP (NNS nodes)) (PP (IN in) (NP (NNS networks))))))))))))) (. .))
(S (SBAR (IN As) (S (NP (EX there)) (VP (VBP are) (NP (JJ many) (NML (NML (JJ large) (HYPH -) (NN scale)) (JJ real) (HYPH -) (NN world)) (NNS networks))))) (, ,) (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ inefficient) (PP (IN for) (NP (VBG existing) (NNS approaches)))) (S (VP (TO to) (VP (VP (VB store) (NP (NP (NNS amounts)) (PP (IN of) (NP (NP (NNS parameters)) (PP (IN in) (NP (NN memory))))))) (CC and) (VP (VB update) (NP (PRP them))) (NP (NN edge)) (PP (IN after) (NP (NN edge))))))) (. .))
(S (PP (IN With) (NP (NP (DT the) (NN knowledge)) (SBAR (IN that) (S (NP (NP (NNS nodes)) (VP (VBG having) (NP (JJ similar) (NN neighborhood)))) (VP (MD will) (VP (VB be) (ADJP (JJ close) (PP (IN to) (NP (NP (DT each) (JJ other)) (PP (IN in) (NP (VBG embedding) (NN space)))))))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NML (NNP COSINE) (PRN (-LRB- -LRB-) (NP (NNP COmpresSIve) (NNP NE)) (-RRB- -RRB-))) (NN algorithm)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ reduces) (NP (DT the) (NN memory) (NN footprint))) (CC and) (VP (VBZ accelerates) (NP (DT the) (NN training) (NN process)) (PP (IN by) (NP (NP (NNS parameters)) (VP (VBG sharing) (PP (IN among) (NP (JJ similar) (NNS nodes)))))))))))) (. .))
(S (NP (NNP COSINE)) (VP (VP (VBZ applies) (NP (NN graph) (NN partitioning) (NNS algorithms)) (PP (IN to) (NP (NNS networks)))) (CC and) (VP (VBZ builds) (NP (NP (NN parameter) (NN sharing) (NN dependency)) (PP (IN of) (NP (NP (NNS nodes)) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (NN result)) (PP (IN of) (NP (NN partitioning))))))))))) (. .))
(S (PP (IN With) (NP (NP (NNS parameters)) (VP (VBG sharing) (PP (IN among) (NP (JJ similar) (NNS nodes)))))) (, ,) (NP (NNP COSINE)) (VP (VBZ injects) (NP (JJ prior) (NN knowledge)) (PP (IN about) (NP (JJR higher) (JJ structural) (NN information))) (PP (IN into) (NP (NP (NN training) (NN process)) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (NP (NP (NN network) (VBG embedding)) (ADJP (RBR more) (JJ efficient) (CC and) (JJ effective))))))))) (. .))
(S (NP (NNP COSINE)) (VP (MD can) (VP (VP (VB be) (VP (VBN applied) (PP (IN to) (NP (DT any) (NN embedding) (NN lookup) (NN method))))) (CC and) (VP (VB learn) (NP (NML (JJ high) (HYPH -) (NN quality)) (NNS embeddings)) (PP (IN with) (NP (NML (NML (JJ limited) (NN memory)) (CC and) (NML (JJR shorter) (NN training))) (NN time)))))) (. .))
(S (NP (PRP We)) (VP (VBP conduct) (NP (NP (NNS experiments)) (PP (IN of) (NP (JJ multi-label) (NML (NN classification) (CC and) (NN link)) (NN prediction)))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (NNS baselines)) (CC and) (NP (PRP$ our) (NN model))) (VP (VBP have) (NP (DT the) (JJ same) (NN memory) (NN usage)))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP COSINE)) (VP (VBZ gives) (NP (NNS baselines)) (ADVP (IN up) (PP (IN to) (NP (NP (NP (NML (CD 23) (NN %)) (NN increase)) (PP (IN on) (NP (NN classification)))) (CC and) (NP (QP (IN up) (IN to) (CD 25)) (NN %))))) (NP (NP (NN increase)) (PP (IN on) (NP (NN link) (NN prediction)))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NP (NN time)) (PP (IN of) (NP (NP (DT all) (NN representation) (NN learning) (NNS methods)) (VP (VBG using) (NP (NNP COSINE)))))) (VP (VBZ decreases) (PP (IN from) (NP (QP (CD 30) (NN %) (IN to) (CD 70) (NN %))))) (. .))
