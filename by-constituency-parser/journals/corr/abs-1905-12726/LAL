(S (NP (NN Experience) (NN replay)) (VP (VP (VBZ is) (VP (ADVP (RB widely)) (VBN used) (PP (IN in) (NP (JJ deep) (NN reinforcement) (VBG learning) (NNS algorithms))))) (CC and) (VP (VBZ allows) (S (NP (NNS agents)) (VP (TO to) (VP (VP (VB remember)) (CC and) (VP (VB learn) (PP (IN from))) (NP (NP (NNS experiences)) (PP (IN from) (NP (DT the) (NN past))))))))) (. .))
(S (PP (IN In) (NP (DT an) (NN effort) (S (VP (TO to) (VP (VB learn) (ADVP (RBR more) (RB efficiently))))))) (, ,) (NP (NNS researchers)) (VP (VBD proposed) (NP (NP (JJ prioritized) (NN experience) (NN replay)) (PRN (-LRB- -LRB-) (NP (NNP PER)) (-RRB- -RRB-)) (SBAR (WHNP (WDT which)) (S (VP (VBZ samples) (NP (JJ important) (NNS transitions)) (ADVP (RBR more) (RB frequently))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (JJ Prioritized) (NNP Sequence) (NNP Experience) (NNP Replay)) (PRN (-LRB- -LRB-) (NP (NNP PSER)) (-RRB- -RRB-))) (NP (NP (DT a) (NN framework)) (PP (IN for) (S (VP (VBG prioritizing) (NP (NP (NNS sequences)) (PP (IN of) (NP (NN experience)))) (PP (IN in) (NP (DT an) (NN attempt) (S (VP (VP (TO to) (VP (DT both) (VP (VB learn) (ADVP (RBR more) (RB efficiently))))) (CC and) (VP (TO to) (VP (VB obtain) (NP (JJR better) (NN performance)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP compare) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NNP PER) (CC and) (NNP PSER) (VBG sampling) (NNS techniques))) (PP (PP (IN in) (NP (DT a) (JJ tabular) (JJ Q-learning) (NN environment))) (CC and) (PP (IN in) (NP (NNP DQN))) (PP (IN on) (NP (DT the) (NNP Atari) (CD 2600) (NN benchmark)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP prove) (ADVP (RB theoretically)) (SBAR (IN that) (S (NP (NNP PSER)) (VP (VBZ is) (VP (VBN guaranteed) (S (VP (TO to) (VP (VB converge) (ADVP (ADVP (JJR faster)) (PP (IN than) (NP (NNP PER)))))))))))) (CC and) (VP (ADVP (RB empirically)) (VB show) (SBAR (S (NP (NNP PSER)) (VP (ADVP (RB substantially)) (VBZ improves) (PP (IN upon) (NP (NNP PER)))))))) (. .))
