(S (NP (NN Transfer) (NN learning)) (VP (VBP have) (VP (VBN been) (ADVP (RB frequently)) (VP (VBN used) (S (VP (TO to) (VP (VB improve) (NP (JJ deep) (JJ neural) (NN network) (NN training)) (PP (IN through) (S (VP (VBG incorporating) (NP (NP (NNS weights)) (PP (IN of) (NP (JJ pre-trained) (NNS networks)))) (PP (IN as) (NP (NP (DT the) (NN starting) (HYPH -) (NN point)) (PP (IN of) (NP (NP (NN optimization)) (PP (IN for) (NP (NN regularization)))))))))))))))) (. .))
(S (SBAR (IN While) (S (NP (JJ deep) (NN transfer) (NN learning)) (VP (MD can) (ADVP (RB usually)) (VP (VB boost) (NP (DT the) (NN performance)) (PP (IN with) (NP (NP (JJR better) (NN accuracy)) (CC and) (NP (ADVP (RBR faster)) (NN convergence)))))))) (, ,) (S (VP (VBG transferring) (NP (NNS weights)) (PP (IN from) (NP (JJ inappropriate) (NNS networks))))) (VP (VP (VBZ hurts) (NP (NN training) (NN procedure))) (CC and) (VP (MD may) (VP (VB lead) (PP (IN to) (NP (ADJP (RB even) (JJR lower)) (NN accuracy)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (JJ deep) (NN transfer) (NN learning)) (PP (IN as) (S (VP (VBG minimizing) (NP (NP (DT a) (JJ linear) (NN combination)) (PP (IN of) (NP (JJ empirical) (NN loss) (CC and) (NN regularizer)))) (PP (VBN based) (PP (IN on) (NP (NP (JJ pre-trained) (NNS weights)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN regularizer)) (VP (MD would) (VP (VB restrict) (NP (DT the) (NN training) (NN procedure)) (PP (IN from) (S (VP (VBG lowering) (NP (DT the) (JJ empirical) (NN loss))))))))))))))) (, ,) (PP (IN with) (NP (NP (JJ conflicted) (NN descent) (NNS directions)) (-LRB- -LRB-) (NP (ADVP (FW e.g.)) (, ,) (NNS derivatives)) (-RRB- -RRB-)))) (. .))
(S (PP (VBG Following) (NP (DT the) (NN view))) (, ,) (NP (PRP we)) (VP (VBP propose) (SBAR (S (NP (NP (DT a) (JJ novel) (NN strategy)) (VP (VBG making) (NP (ADJP (NP (NN regularization)) (HYPH -) (VBN based)) (NML (NNP Deep) (NN Transfer))) (S (VP (VBG learning) (NP (NP (NNP Never) (NNP Hurt) (-LRB- -LRB-) (NNP DTNH) (-RRB- -RRB-)) (SBAR (IN that) (S (, ,) (PP (IN for) (NP (NP (DT each) (NN iteration)) (PP (IN of) (NP (NN training) (NN procedure))))) (, ,) (VP (VBZ computes) (NP (NP (DT the) (NNS derivatives)) (PP (IN of) (NP (DT the) (CD two) (NNS terms)))) (ADVP (RB separately)))))))))) (, ,) (ADVP (RB then)) (VP (VBZ re-estimates) (NP (NP (DT a) (JJ new) (NN descent) (NN direction)) (SBAR (WHNP (WDT that)) (S (VP (VBZ does) (RB not) (VP (VB hurt) (NP (DT the) (JJ empirical) (NN loss) (NN minimization)) (SBAR (IN while) (S (S (VP (VBG preserving) (NP (DT the) (NN regularization)))) (VP (VBZ affects) (PP (IN from) (NP (DT the) (JJ pre-trained) (NNS weights))))))))))))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP have) (VP (VBN been) (VP (VBN done) (S (VP (VBG using) (NP (JJ common) (NN transfer)) (S (VP (VBG learning) (NP (NP (NNS regularizers)) (, ,) (PP (JJ such) (IN as) (NP (NML (NML (NN L2) (HYPH -) (NN SP)) (CC and) (NML (NN knowledge))) (NN distillation))) (, ,) (PP (IN on) (NP (NP (NN top)) (PP (IN of) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NP (JJ deep) (NN transfer)) (VP (VBG learning) (NP (NP (NNS benchmarks)) (PP (VBG including) (NP (NP (NNP Caltech)) (, ,) (NP (NNP MIT) (NML (NML (JJ indoor) (CD 67)) (, ,) (NML (NN CIFAR) (HYPH -) (CD 10)) (CC and) (NML (NNP ImageNet)))))))))))))))))))))) (. .))
(S (NP (DT The) (JJ empirical) (NNS results)) (VP (VBP show) (SBAR (SBAR (IN that) (S (NP (NP (DT the) (VBN proposed) (NN descent) (NN direction)) (NP (NN estimation) (NN strategy) (NN DTNH))) (VP (MD can) (ADVP (RB always)) (VP (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ deep) (NML (NN transfer) (NN learning)) (NNS tasks)))) (PP (VBN based) (PP (IN on) (NP (NP (DT all)) (PP (IN above) (NP (NNS regularizers)))))))))) (, ,) (RB even) (SBAR (WHADVP (WRB when)) (S (VP (VBG transferring) (NP (JJ pre-trained) (NNS weights)) (PP (IN from) (NP (JJ inappropriate) (NNS networks)))))))) (. .))
(S (ADVP (DT All) (RB in) (RB all)) (, ,) (NP (NN DTNH) (NN strategy)) (VP (MD can) (VP (VB improve) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NNS regularizers)) (PP (IN in) (NP (DT all) (NNS cases))) (PP (IN with) (NP (NP (CD 0.1) (NN %)) (: --) (NP (NP (ADJP (NP (CD 7) (NN %)) (JJR higher)) (NN accuracy)) (PP (IN in) (NP (DT all) (NNS experiments)))))))) (. .))
