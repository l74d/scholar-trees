(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (JJ new) (NN optimization) (NN objective)) (PP (IN for) (NP (JJ value-based) (JJ deep) (NN reinforcement) (NN learning))))) (. .))
(S (NP (PRP We)) (VP (VBP extend) (NP (NP (JJ conventional) (NNP Deep) (NNP Q-Networks)) (PRN (-LRB- -LRB-) (NP (NNP DQNs)) (-RRB- -RRB-))) (PP (IN by) (S (VP (VBG adding) (NP (NP (DT a) (JJ model-learning) (NN component)) (VP (VBG yielding) (NP (DT a) (NN transcoder) (NN network)))))))) (. .))
(S (NP (NP (DT The) (NN prediction) (NNS errors)) (PP (IN for) (NP (DT the) (NN model)))) (VP (VBP are) (VP (VBN included) (PP (IN in) (NP (DT the) (JJ basic) (NNP DQN) (NN loss))) (PP (IN as) (NP (JJ additional) (NNS regularizers))))) (. .))
(S (NP (DT This) (VBD augmented) (JJ objective)) (VP (NNS leads) (PP (TO to) (NP (NP (DT a) (JJR richer) (NN training) (NN signal)) (SBAR (WHNP (WDT that)) (S (VP (VBZ provides) (NP (NN feedback)) (PP (IN at) (NP (DT every) (NN time) (NN step))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (SBAR (IN because) (S (S (VP (VBG learning) (NP (DT an) (NN environment) (NN model)))) (VP (NNS shares) (NP (DT a) (JJ common) (NN structure)) (PP (IN with) (NP (DT the) (NNP RL) (NN problem)))))) (, ,) (NP (PRP we)) (VP (VBP hypothesize) (SBAR (IN that) (S (NP (DT the) (VBG resulting) (JJ objective)) (VP (NNS improves) (NP (DT both) (NP (JJ sample) (NN efficiency)) (CC and) (NP (NN performance))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB empirically)) (VBP confirm) (NP (PRP$ our) (NN hypothesis)) (PP (IN on) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (NP (CD 20) (NNS games)) (PP (IN from) (NP (DT the) (NNP Atari) (NN benchmark))) (VP (VBG attaining) (NP (NP (JJ superior) (NNS results)) (PP (IN over) (NP (NN vanilla) (NNP DQN))) (PP (IN without) (NP (JJ model-based) (NN regularization)))))))))) (. .))
