(S (S (VP (VBG Training) (NP (ADJP (JJ deep) (JJ recurrent)) (NML (NML (JJ neural) (NN network)) (-LRB- -LRB-) (NML (NN RNN)) (-RRB- -RRB-)) (NNS architectures)))) (VP (VBZ is) (VP (VBN complicated) (PP (IN due) (IN to) (NP (DT the) (VBN increased) (NN network) (NN complexity))))) (. .))
(S (NP (DT This)) (VP (VBZ disrupts) (NP (NP (DT the) (NN learning)) (PP (IN of) (NP (NP (JJR higher) (NN order) (NNS abstracts)) (VP (VBG using) (NP (JJ deep) (NN RNN))))))) (. .))
(S (PP (IN In) (NP (NP (NN case)) (PP (IN of) (NP (NML (NN feed) (HYPH -) (JJ forward)) (NNS networks))))) (S (NP (VBG training) (JJ deep) (NNS structures)) (VP (VBZ is) (ADJP (JJ simple)))) (FRAG (CC and) (ADVP (ADVP (RBR faster)) (SBAR (IN while) (S (S (VP (VBG learning) (NP (NML (JJ long) (HYPH -) (NN term)) (JJ temporal) (NN information)))) (VP (VBZ is) (RB not) (ADJP (JJ possible))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (JJ residual) (NML (NML (NN memory) (JJ neural) (NN network)) (-LRB- -LRB-) (NML (NN RMN)) (-RRB- -RRB-)) (NN architecture)) (PP (IN to) (NP (NP (NN model) (NML (JJ short) (HYPH -) (NN time)) (NNS dependencies)) (VP (VBG using) (NP (NP (JJ deep) (NML (NN feed) (HYPH -) (JJ forward)) (NNS layers)) (VP (VBG having) (NP (NP (JJ residual)) (CC and) (NP (NN time) (VBN delayed) (NNS connections))))))))) (. .))
(S (S (NP (DT The) (JJ residual) (NN connection)) (VP (VBZ paves) (NP (NN way)) (S (VP (TO to) (VP (VB construct) (NP (JJR deeper) (NNS networks)) (PP (IN by) (S (VP (VBG enabling) (NP (NP (ADJP (JJ unhindered)) (NN flow)) (PP (IN of) (NP (NNS gradients)))))))))))) (CC and) (S (NP (DT the) (NN time) (NN delay) (NNS units)) (VP (VBP capture) (NP (JJ temporal) (NN information)) (PP (IN with) (NP (VBN shared) (NNS weights))))) (. .))
(S (NP (NP (DT The) (NN number)) (PP (IN of) (NP (NP (NNS layers)) (PP (IN in) (NP (NNP RMN)))))) (VP (VBZ signifies) (NP (CC both) (NP (DT the) (JJ hierarchical) (NN processing) (NN depth)) (CC and) (NP (JJ temporal) (NN depth)))) (. .))
(S (NP (NP (DT The) (JJ computational) (NN complexity)) (PP (IN in) (NP (NN training) (NN RMN)))) (VP (VBZ is) (ADJP (RB significantly) (JJR less)) (SBAR (WHADVP (WRB when)) (S (VP (VBN compared) (PP (IN to) (NP (ADJP (JJ deep) (JJ recurrent)) (NNS networks))))))) (. .))
(S (NP (NNP RMN)) (VP (VBZ is) (ADJP (JJ further) (SBAR (S (VP (VBD extended) (PP (IN as) (NP (JJ bi-directional) (NN RMN) (PRN (-LRB- -LRB-) (NP (NN BRMN)) (-RRB- -RRB-)))) (S (VP (TO to) (VP (VB capture) (NP (NP (DT both) (NN past)) (CC and) (NP (JJ future) (NN information))))))))))) (. .))
(S (NP (JJ Experimental) (NN analysis)) (VP (VBZ is) (VP (VBN done) (PP (IN on) (NP (NNP AMI) (NN corpus))) (PP (IN to) (VP (VB substantiate) (NP (NP (DT the) (NN capability)) (PP (IN of) (NP (NNP RMN)))) (PP (IN in) (S (VP (VBG learning) (NP (NP (NML (JJ long) (HYPH -) (NN term)) (NN information)) (CC and) (NP (JJ hierarchical) (NN information)))))))))) (. .))
(S (NP (NP (NNP Recognition) (NN performance)) (PP (IN of) (NP (NP (NNP RMN)) (VP (VBN trained) (PP (IN with) (NP (NP (CD 300) (NNS hours)) (PP (IN of) (NP (NN Switchboard) (NN corpus))))))))) (VP (VBZ is) (PP (VBN compared) (PP (IN with) (NP (JJ various) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN LVCSR) (NNS systems))))) (. .))
(S (NP (DT The) (NNS results)) (VP (VBP indicate) (SBAR (IN that) (S (NP (NML (NNP RMN) (CC and) (NNP BRMN)) (NNS gains)) (NP (NP (ADJP (NP (CD 6) (NN %) (CC and) (CD 3.8) (NN %)) (JJ relative)) (NN improvement)) (PP (IN over) (NP (NNP LSTM) (CC and) (NNP BLSTM) (NNS networks))))))) (. .))
