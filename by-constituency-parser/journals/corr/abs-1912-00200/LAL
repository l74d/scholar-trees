(S (NP (NNP Deep) (NNP Learning) (NNS models)) (VP (VBP have) (VP (VBN become) (NP (DT the) (JJ dominant) (NN approach)) (PP (IN in) (NP (JJ several) (NNS areas))) (PP (JJ due) (PP (TO to) (NP (PRP$ their) (JJ high) (NN performance)))))) (. .))
(S (ADVP (RB Unfortunately)) (, ,) (NP (NP (DT the) (NX (NX (NN size)) (CC and) (ADVP (NN hence)) (NP (JJ computational) (NNS requirements)))) (PP (IN of) (S (VP (NN operating) (NP (JJ such) (NNS models)))))) (VP (MD can) (VP (VB be) (ADJP (RB considerably) (JJ high)))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (DT this)) (VP (VBZ constitutes) (NP (NP (DT a) (NN limitation)) (PP (IN for) (NP (NP (NN deployment)) (PP (IN on) (NP (NP (ADJP (NP (NN memory) (CC and) (NN battery)) (VBD constrained)) (NNS devices)) (PP (JJ such) (IN as) (NP (NP (JJ mobile) (NNS phones)) (CC or) (NP (VBN embedded) (NNS systems)))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS limitations))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (ADJP (NN novel) (CC and) (JJ simple)) (NN pruning) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ compresses) (NP (JJ neural) (NNS networks)) (PP (IN by) (S (VP (VBG removing) (NP (JJ entire) (NNS filters) (CC and) (NNS neurons)) (PP (VBG according) (PP (TO to) (NP (NP (DT a) (JJ global) (NN threshold)) (PP (IN across) (NP (DT the) (NN network)))))) (PP (IN without) (NP (NP (DT any) (NN pre-calculation)) (PP (IN of) (NP (JJ layer) (NN sensitivity))))))))))))) (. .))
(S (NP (DT The) (VBG resulting) (NN model)) (VP (VBZ is) (ADJP (JJ compact)) (, ,) (ADJP (JJ non-sparse)) (, ,) (PP (IN with) (NP (NP (DT the) (JJ same) (NN accuracy)) (PP (IN as) (NP (DT the) (JJ non-compressed) (NN model))))) (, ,) (CC and) (VP (ADVP (JJS most) (RB importantly)) (VBZ requires) (NP (DT no) (JJ special) (NN infrastructure)) (PP (IN for) (NP (NN deployment))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (NP (NP (DT the) (NN viability)) (PP (IN of) (NP (PRP$ our) (NN method)))) (PP (IN by) (S (VP (VBG producing) (NP (NP (ADJP (RB highly) (VBN compressed)) (NNS models)) (, ,) (NP (SBAR (ADVP (RB namely)) (NP (NP (NP (NP (NNP VGG-16)) (, ,) (NP (NNP ResNet-56)) (, ,) (CC and) (NP (NNP ResNet-110))) (ADVP (RB respectively))) (PP (IN on) (NP (NNP CIFAR10))) (PP (IN without) (S (VP (VBG losing) (NP (DT any) (NN performance)) (PP (VBN compared) (PP (TO to) (NP (DT the) (NN baseline)))))))) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NP (NP (NNP ResNet-34)) (CC and) (NP (NNP ResNet-50))) (PP (IN on) (NP (NNP ImageNet))) (PP (IN without) (NP (NP (DT a) (JJ significant) (NN loss)) (PP (IN of) (NP (NN accuracy))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP provide) (NP (NP (DT a) (JJ well-retrained) (ADJP (CD 30) (NN %)) (VBD compressed) (NNP ResNet-50)) (SBAR (WHNP (IN that)) (S (VP (ADVP (RB slightly)) (VBZ surpasses) (NP (DT the) (NN base) (NN model) (NN accuracy))))))) (. .))
(FRAG (ADVP (RB Additionally)) (, ,) (VP (VBG compressing) (NP (NP (QP (JJR more) (IN than) (CD 56)) (NX (NX (NN %)) (CC and) (NX (CD 97) (NN %)))) (PP (IN of) (NP (NP (NNP AlexNet) (CC and) (NNP LeNet-5)) (ADVP (RB respectively)))))) (. .))
(S (ADVP (RB Interestingly)) (, ,) (NP (NP (DT the) (JJ resulted) (NNS models) (POS â€º)) (NN pruning) (NNS patterns)) (VP (VBP are) (ADJP (RB highly) (JJ similar) (PP (TO to) (NP (NP (DT the) (JJ other) (NNS methods)) (VP (VBG using) (NP (JJ layer) (NN sensitivity) (JJ pre-calculation) (NN step))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ does) (RB not) (ADVP (RB only)) (VP (RB exhibit) (NP (NP (JJ good) (NN performance)) (CC but) (SBAR (WHNP (WP what)) (S (VP (VBZ is) (ADVP (JJR more) (RB also)) (ADJP (JJ easy) (SBAR (S (VP (TO to) (VP (VB implement)))))))))))) (. .))
