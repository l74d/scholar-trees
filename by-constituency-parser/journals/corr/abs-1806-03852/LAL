(S (NP (JJ Modern) (JJ deep) (JJ artificial) (JJ neural) (NNS networks)) (VP (VBP have) (VP (VBN achieved) (NP (JJ impressive) (NNS results)) (PP (IN through) (NP (NP (NNS models)) (PP (IN with) (NP (NP (ADJP (NP (NP (NNS orders)) (PP (IN of) (NP (NN magnitude)))) (JJR more)) (NNS parameters)) (PP (IN than) (NP (NP (NN training) (NNS examples)) (SBAR (WHNP (WDT which)) (S (VP (VBP control) (NP (VBG overfitting)) (PP (IN with) (NP (NP (DT the) (NN help)) (PP (IN of) (NP (NN regularization)))))))))))))))) (. .))
(S (NP (NN Regularization)) (VP (MD can) (VP (VB be) (ADJP (ADJP (JJ implicit)) (PRN (, ,) (SBAR (IN as) (SINV (VP (VBZ is)) (NP (NP (DT the) (NN case)) (PP (IN of) (NP (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (CC and) (NP (NN parameter) (NN sharing))) (PP (IN in) (NP (JJ convolutional) (NNS layers))))))))) (, ,) (CC or) (ADJP (NN explicit))))) (. .))
(S (S (NP (NP (NNP Explicit) (NN regularization) (NNS techniques)) (, ,) (S (NP (ADJP (JJS most) (JJ common)) (NNS forms)) (VP (VBP are) (NP (NP (JJ weight) (NN decay)) (CC and) (NP (NN dropout))))) (, ,)) (VP (VBP have) (VP (VBN proven) (ADJP (JJ successful)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (JJ improved) (NN generalization)))))))) (, ,) (CC but) (S (NP (PRP they)) (VP (VP (ADVP (RB blindly)) (VB reduce) (NP (NP (DT the) (JJ effective) (NN capacity)) (PP (IN of) (NP (DT the) (NN model))))) (, ,) (VP (VB introduce) (NP (JJ sensitive) (NNS hyper-parameters))) (CC and) (VP (VB require) (NP (ADJP (JJR deeper) (CC and) (JJR wider)) (NNS architectures)) (S (VP (TO to) (VP (VB compensate) (PP (IN for) (NP (DT the) (JJ reduced) (NN capacity))))))))) (. .))
(S (PP (IN In) (NP (NN contrast))) (, ,) (NP (NNS data) (NN augmentation) (NNS techniques)) (VP (VBP exploit) (NP (NN domain) (NN knowledge)) (S (VP (TO to) (VP (VP (VB increase) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NN training) (NNS examples))))) (CC and) (VP (VB improve) (NP (NN generalization))) (PP (PP (IN without) (S (VP (VBG reducing) (NP (DT the) (JJ effective) (NN capacity))))) (CC and) (PP (IN without) (S (VP (VBG introducing) (NP (JJ model-dependent) (NNS parameters)))))) (, ,) (SBAR (IN since) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN applied) (PP (IN on) (NP (DT the) (NN training) (NNS data))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (ADVP (RB systematically)) (VBP contrast) (NP (NP (NNS data) (NN augmentation)) (CC and) (NP (JJ explicit) (NN regularization))) (PP (IN on) (NP (NP (CD three) (JJ popular) (NNS architectures)) (CC and) (NP (CD three) (NNS data) (NNS sets))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (NNS data) (NN augmentation)) (ADVP (RB alone))) (VP (VP (MD can) (VP (VB achieve) (NP (NP (NP (DT the) (JJ same) (NN performance)) (CC or) (ADJP (JJR higher))) (PP (IN as) (NP (VBN regularized) (NNS models)))))) (CC and) (VP (NNS exhibits) (NP (NP (ADJP (RB much) (JJR higher)) (NN adaptability)) (PP (TO to) (NP (NP (NP (NNS changes)) (PP (IN in) (NP (DT the) (NN architecture)))) (CC and) (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NN training) (NNS data)))))))))))) (. .))
