(S (NP (JJ Many) (NN computer) (NN vision) (NNS problems)) (VP (MD can) (VP (VB be) (VP (VBN posed) (PP (IN as) (S (VP (VBG learning) (NP (DT a) (JJ low-dimensional) (NN subspace)) (PP (IN from) (NP (JJ high) (JJ dimensional) (NNS data))))))))) (. .))
(S (NP (NP (DT The) (JJ low) (NN rank) (NN matrix) (NN factorization)) (PRN (-LRB- -LRB-) (NP (NNP LRMF)) (-RRB- -RRB-))) (VP (VBZ represents) (NP (DT a) (ADJP (RB commonly) (JJ utilized)) (NN subspace) (VBG learning) (NN strategy))) (. .))
(S (NP (NP (JJS Most)) (PP (IN of) (NP (DT the) (JJ current) (NNP LRMF) (NNS techniques)))) (VP (VBP are) (VP (VBN constructed) (PP (IN on) (NP (NP (DT the) (NN optimization) (NNS problems)) (VP (VBG using) (NP (NP (JJ L1-norm) (CC and) (JJ L2-norm) (NNS losses)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB mainly)) (VP (VBP deal) (PP (IN with) (NP (NP (NNP Laplacian) (CC and) (NNP Gaussian) (NNS noises)) (, ,) (ADVP (RB respectively))))))))))))) (. .))
(S (S (VP (TO To) (VP (VB make) (S (NP (NNP LRMF)) (ADJP (JJ capable) (PP (IN of) (S (VP (VBG adapting) (NP (ADJP (RBR more) (JJ complex)) (NN noise)))))))))) (, ,) (NP (DT this) (NN paper)) (VP (VP (VBZ proposes) (NP (DT a) (JJ new) (NNP LRMF) (NN model)) (PP (IN by) (S (VP (VBG assuming) (NP (NN noise)) (PP (IN as) (NP (NAC (NN Mixture) (PP (IN of) (NP (JJ Exponential) (NNP Power)))) (PRN (-LRB- -LRB-) (NNP MoEP) (-RRB- -RRB-)) (NNS distributions))))))) (CC and) (VP (VBZ proposes) (NP (DT a) (JJ penalized) (NNP MoEP) (PRN (-LRB- -LRB-) (NNP PMoEP) (-RRB- -RRB-)) (NN model)) (PP (IN by) (S (VP (VBG combining) (NP (DT the) (JJ penalized) (NN likelihood) (NN method)) (PP (IN with) (NP (NNP MoEP) (NNS distributions)))))))) (. .))
(S (NP (JJ Such) (VBG setting)) (VP (VBZ facilitates) (NP (NP (DT the) (JJ learned) (NNP LRMF) (NN model)) (ADJP (JJ capable) (PP (IN of) (S (VP (ADVP (RB automatically)) (VBG fitting) (NP (DT the) (JJ real) (NN noise)) (PP (IN through) (NP (NNP MoEP) (NNS distributions))))))))) (. .))
(S (NP (NP (DT Each) (NN component)) (PP (IN in) (NP (DT this) (NN mixture)))) (VP (VBZ is) (VP (VBN adapted) (PP (IN from) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (JJ preliminary) (UCP (NN super-) (CC or) (JJ sub-Gaussian)) (NNS candidates))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (PP (IN by) (S (VP (VBG facilitating) (NP (NP (DT the) (JJ local) (NN continuity)) (PP (IN of) (NP (NN noise) (NNS components))))))) (, ,) (NP (PRP we)) (VP (VP (VBD embed) (NP (NNP Markov) (JJ random) (NN field)) (PP (IN into) (NP (DT the) (NNP PMoEP) (NN model)))) (CC and) (VP (ADVP (RB further)) (VB propose) (NP (DT the) (JJ advanced) (NNP PMoEP-MRF) (NN model)))) (. .))
(S (NP (NP (DT An) (NN Expectation) (NNP Maximization) (PRN (-LRB- -LRB-) (NNP EM) (-RRB- -RRB-)) (NN algorithm)) (CC and) (NP (DT a) (JJ variational) (NNP EM) (PRN (-LRB- -LRB-) (NNP VEM) (-RRB- -RRB-)) (NN algorithm))) (VP (VBP are) (ADVP (RB also)) (VP (VBN designed) (S (VP (TO to) (VP (VB infer) (NP (NP (DT the) (NNS parameters)) (VP (VBN involved) (PP (IN in) (NP (NP (NP (DT the) (VBN proposed) (NNP PMoEP)) (CC and) (NP (DT the) (NNP PMoEP-MRF) (NN model))) (, ,) (ADVP (RB respectively))))))))))) (. .))
(S (NP (NP (DT The) (NN superseniority)) (PP (IN of) (NP (PRP$ our) (NNS methods)))) (VP (VBZ is) (VP (VBN demonstrated) (PP (IN by) (NP (NP (JJ extensive) (NNS experiments)) (PP (IN on) (NP (NP (JJ synthetic) (NNS data)) (, ,) (NP (NN face) (NN modeling)) (, ,) (NP (JJ hyperspectral) (NN image) (NN restoration)) (CC and) (NP (NN background) (NN subtraction)))))))) (. .))
