(S (PP (IN In) (NP (JJ many) (NN learning) (NNS situations))) (, ,) (NP (NP (NNS resources)) (PP (IN at) (NP (NN inference) (NN time)))) (VP (VBP are) (ADJP (ADJP (RB significantly) (RBR more) (JJ constrained)) (PP (IN than) (NP (NP (NNS resources)) (PP (IN at) (NP (NN training) (NN time))))))) (. .))
(NP (NP (NP (NP (DT This) (NN paper) (NNS studies)) (NP (DT a) (JJ general) (NN paradigm))) (, ,) (VP (VBN called) (NP (NP (NNP Differentiable) (NN ARchitecture) (NNP Compression) (-LRB- -LRB-) (NNP DARC) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBZ combines) (NP (NML (NN model) (NN compression) (CC and) (NN architecture)) (NN search)) (S (VP (TO to) (VP (VB learn) (NP (NNS models))))))))))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (NP (NN resource)) (HYPH -) (JJ efficient) (PP (IN at) (NP (NN inference) (NN time))))))) (. .))
(S (PP (VBN Given) (NP (DT a) (NML (NN resource) (HYPH -) (JJ intensive)) (NN base) (NN architecture))) (, ,) (NP (NNP DARC)) (VP (VBZ utilizes) (NP (DT the) (NN training) (NNS data)) (S (VP (TO to) (VP (VB learn) (SBAR (WHNP (WDT which)) (S (NP (NNS sub-components)) (VP (MD can) (VP (VB be) (VP (VBN replaced) (PP (IN by) (NP (JJR cheaper) (NNS alternatives)))))))))))) (. .))
(S (S (NP (DT The) (NML (JJ high) (HYPH -) (NN level)) (NN technique)) (VP (MD can) (VP (VB be) (VP (VBN applied) (PP (IN to) (NP (DT any) (JJ neural) (NN architecture))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP report) (NP (NNS experiments)) (PP (IN on) (NP (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (JJ convolutional) (JJ neural) (NNS networks)) (PP (IN for) (NP (NN image) (NN classification))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP give) (NP (NP (JJ theoretical) (NNP Rademacher) (NN complexity) (NNS bounds)) (PP (IN in) (NP (VBN simplified) (NNS cases)))) (, ,) (S (VP (VBG showing) (SBAR (WHADVP (WRB how)) (S (NP (NNP DARC)) (VP (VBZ avoids) (S (VP (VBG overfitting) (PP (IN despite) (NP (NN over-parameterization))))))))))) (. .))
