(S (NP (ADJP (NP (NNP Model)) (HYPH -) (JJ agnostic)) (NN meta) (HYPH -) (NN learning) (PRN (-LRB- -LRB-) (NP (NN MAML)) (-RRB- -RRB-))) (VP (VBZ is) (NP (DT a) (NML (NN meta) (HYPH -) (VBG learning)) (NN technique)) (S (VP (TO to) (VP (VB train) (NP (DT a) (NN model)) (PP (IN on) (NP (NP (DT a) (NN multitude)) (PP (IN of) (NP (VBG learning) (NNS tasks)))))))) (PP (IN in) (NP (NP (DT a) (NN way)) (SBAR (WHNP (WDT that)) (S (VP (VBZ primes) (NP (NP (DT the) (NN model)) (PP (IN for) (NP (NP (NML (JJ few) (HYPH -) (NN shot)) (NN learning)) (PP (IN of) (NP (JJ new) (NNS tasks)))))))))))) (. .))
(S (NP (DT The) (NNP MAML) (NN algorithm)) (VP (VP (VBZ performs) (ADVP (RB well) (PP (IN on) (NP (NML (JJ few) (HYPH -) (NN shot)) (NN learning) (NNS problems)))) (PP (IN in) (NP (NP (NML (NN classification) (, ,) (NN regression) (, ,) (CC and) (JJ fine)) (HYPH -) (NN tuning)) (PP (IN of) (NP (NP (NN policy) (NNS gradients)) (PP (IN in) (NP (NN reinforcement) (NN learning)))))))) (, ,) (CC but) (VP (VBZ comes) (PP (IN with) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NP (JJ costly) (NN hyperparameter) (NN tuning)) (PP (IN for) (NP (NN training) (NN stability))))))))) (. .))
(S (NP (PRP We)) (VP (VBP address) (NP (DT this) (NN shortcoming)) (PP (IN by) (S (VP (VBG introducing) (NP (DT an) (NN extension)) (PP (IN to) (NP (NNP MAML))) (, ,) (VP (VBN called) (S (NP (NNP Alpha) (NNP MAML))) (, ,) (S (VP (TO to) (VP (VB incorporate) (NP (NP (DT an) (JJ online) (NN hyperparameter) (NN adaptation) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (VBZ eliminates) (NP (DT the) (NN need) (S (VP (TO to) (VP (VB tune) (NP (NML (NML (NN meta) (HYPH -) (NN learning)) (CC and) (NML (NN learning))) (NNS rates)))))))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS results)) (PP (IN with) (NP (DT the) (NNP Omniglot) (NN database)))) (VP (VBP demonstrate) (NP (NP (DT a) (JJ substantial) (NN reduction)) (PP (IN in) (NP (DT the) (NN need)))) (S (VP (TO to) (VP (VB tune) (NP (NN MAML) (NN training) (NNS hyperparameters) (CC and) (NN improvement)) (PP (IN to) (NP (NN training) (NN stability))) (PP (IN with) (NP (NP (JJR less) (NN sensitivity)) (PP (IN to) (NP (NN hyperparameter) (NN choice))))))))) (. .))
