(S (NP (VBN Overparameterized) (JJ deep) (NNS networks)) (VP (VBP have) (NP (DT the) (NN capacity) (S (VP (TO to) (VP (VB memorize) (NP (NN training) (NNS data)) (PP (IN with) (NP (NML (CD zero) (NN training)) (NN error)))))))) (. .))
(S (PP (ADVP (RB Even)) (IN after) (NP (NN memorization))) (, ,) (S (NP (DT the) (NN training) (NN loss)) (VP (VBZ continues) (S (VP (TO to) (VP (VB approach) (NP (CD zero))))) (, ,) (S (VP (VBG making) (S (NP (DT the) (NN model)) (ADJP (JJ overconfident))))))) (CC and) (S (NP (DT the) (NN test) (NN performance)) (VP (VBN degraded))) (. .))
(S (SBAR (IN Since) (S (NP (VBG existing) (NNS regularizers)) (VP (VBP do) (RB not) (ADVP (RB directly)) (VP (VB aim) (S (VP (TO to) (VP (VB avoid) (NP (NML (CD zero) (NN training)) (NN loss))))))))) (, ,) (NP (PRP they)) (ADVP (RB often)) (VP (VBP fail) (S (VP (TO to) (VP (VB maintain) (NP (NP (DT a) (JJ moderate) (NN level)) (PP (IN of) (NP (NN training) (NN loss)))) (, ,) (S (VP (VBG ending) (PRT (RP up)) (PP (IN with) (NP (DT a) (ADJP (ADJP (RB too) (JJ small)) (CC or) (ADJP (RB too) (JJ large))) (NN loss))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ direct) (NN solution)) (VP (VBN called) (NP (NP (NN flooding)) (SBAR (WHNP (WDT that)) (S (ADVP (RB intentionally)) (VP (VBZ prevents) (NP (NP (JJ further) (NN reduction)) (PP (IN of) (NP (NP (DT the) (NN training) (NN loss)) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBZ reaches) (NP (NP (DT a) (ADJP (RB reasonably) (JJ small)) (NN value)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP call) (NP (DT the) (NN flooding) (NN level))))))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ makes) (NP (DT the) (NN loss) (NN float)) (PP (IN around) (NP (DT the) (NN flooding) (NN level))) (PP (IN by) (S (VP (VBG doing) (VP (VBN mini-batched) (NP (NN gradient) (NN descent)) (PP (IN as) (NP (NP (JJ usual)) (PP (CC but) (NP (NN gradient) (NN ascent))))) (SBAR (IN if) (S (NP (DT the) (NN training) (NN loss)) (VP (VBZ is) (PP (IN below) (NP (DT the) (NN flooding) (NN level))))))))))) (. .))
(S (NP (DT This)) (VP (VP (MD can) (VP (VB be) (VP (VBN implemented) (PP (IN with) (NP (NP (CD one) (NN line)) (PP (IN of) (NP (NN code)))))))) (, ,) (CC and) (VP (VBZ is) (ADJP (JJ compatible) (PP (IN with) (NP (NP (DT any) (JJ stochastic) (NN optimizer)) (CC and) (NP (JJ other) (NNS regularizers))))))) (. .))
(S (PP (IN With) (NP (NN flooding))) (, ,) (S (NP (DT the) (NN model)) (VP (MD will) (VP (VB continue) (PP (TO to) (NP (NP (`` ") (JJ random) (NN walk) ('' ")) (PP (IN with) (NP (DT the) (JJ same) (JJ non-zero) (NN training) (NN loss)))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP expect) (NP (PRP it)) (PP (IN to) (NP (NN drift))) (PP (IN into) (NP (NP (DT an) (NN area)) (PP (IN with) (NP (NP (DT a) (JJ flat) (NN loss) (NN landscape)) (SBAR (WHNP (WDT that)) (S (VP (VBZ leads) (PP (IN to) (NP (JJR better) (NN generalization)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB experimentally)) (VP (VBP show) (SBAR (IN that) (S (NP (NN flooding)) (VP (VP (VBZ improves) (NP (NN performance))) (CC and) (PP (IN as) (NP (DT a) (NN byproduct))) (, ,) (VP (VBZ induces) (NP (NP (DT a) (JJ double) (NN descent) (NN curve)) (PP (IN of) (NP (DT the) (NN test) (NN loss))))))))) (. .))
