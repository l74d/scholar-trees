(S (NP (NP (NNP Kronecker) (NNP Products)) (PRN (-LRB- -LRB-) (NP (NNP KP)) (-RRB- -RRB-))) (VP (VBP have) (VP (VBN been) (VP (VBN used) (S (VP (TO to) (VP (VB compress) (NP (NNP IoT) (NNP RNN) (NNP Applications)) (PP (IN by) (NP (JJ 15-38x) (NN compression) (NNS factors)))))) (, ,) (S (VP (VBG achieving) (NP (NP (JJR better) (NNS results)) (PP (IN than) (NP (JJ traditional) (NN compression) (NNS methods))))))))) (. .))
(S (ADVP (RB However)) (SBAR (WHADVP (WRB when)) (S (NP (NNP KP)) (VP (VBZ is) (VP (VBN applied) (PP (TO to) (NP (JJ large) (NNP Natural) (NNP Language) (NNP Processing) (NNS tasks))))))) (, ,) (NP (PRP it)) (VP (VBZ leads) (PP (TO to) (NP (NP (JJ significant) (NN accuracy) (NN loss)) (PRN (-LRB- -LRB-) (NP (QP (JJ approx) (CD 26)) (NN %)) (-RRB- -RRB-))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (NN way)) (SBAR (S (VP (TO to) (VP (VB recover) (NP (NP (NN accuracy)) (VP (ADVP (RB otherwise)) (VBD lost) (SBAR (WHADVP (WRB when)) (S (VP (VBG applying) (NP (NNP KP)) (PP (TO to) (NP (JJ large) (NNP NLP) (NNS tasks)))))))) (, ,) (PP (IN by) (S (VP (VBG allowing) (NP (NP (JJ additional) (NNS degrees)) (PP (IN of) (NP (NN freedom))) (PP (IN in) (NP (DT the) (NNP KP) (NN matrix))))))))))))) (. .))
(S (ADVP (RBR More) (RB formally)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (VBG doping)) (, ,) (NP (NP (DT a) (NN process)) (PP (IN of) (S (VP (VBG adding) (NP (DT an) (ADJP (RB extremely) (JJ sparse)) (NN overlay) (NN matrix)) (PP (IN on) (NP (NP (NN top)) (PP (IN of) (NP (DT the) (JJ pre-defined) (NNP KP) (NN structure))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP call) (S (NP (DT this) (NN compression) (NN method)) (NP (VBD doped) (JJR kronecker) (NN product) (NN compression)))) (. .))
(S (S (VP (TO To) (VP (VB train) (NP (DT these) (NNS models))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ new) (NN solution)) (PP (TO to) (NP (NP (DT the) (NN phenomenon)) (PP (IN of) (NP (NP (JJ co-matrix) (NN adaption)) (PRN (-LRB- -LRB-) (NP (NNP CMA)) (-RRB- -RRB-)))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NP (DT a) (JJ new) (NN regularization) (NN scheme)) (VP (VBN called) (S (NP (S (NP (NN co) (NN matrix) (NN dropout) (NN regularization))) (PRN (-LRB- -LRB-) (NP (NNP CMR)) (-RRB- -RRB-))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (JJ experimental) (NNS results)) (SBAR (WHNP (WDT that)) (S (VP (VBP demonstrate) (NP (NP (NN compression)) (PP (IN of) (NP (DT a) (JJ large) (NN language) (NN model))) (PP (IN with) (NP (NP (NNP LSTM) (NNS layers)) (PP (IN of) (NP (NP (NN size)) (NP (CD 25) (NNP MB)))))) (PP (IN by) (NP (CD 25x))) (PP (IN with) (NP (NP (ADJP (CD 1.4) (NN %)) (NN loss)) (PP (IN in) (NP (NN perplexity) (NN score))))))))))) (. .))
(S (PP (IN At) (NP (CD 25x) (NN compression))) (, ,) (NP (DT an) (NN equivalent) (VBD pruned) (NN network)) (VP (NNS leads) (PP (TO to) (NP (NP (ADJP (CD 7.9) (NN %)) (NN loss)) (PP (IN in) (NP (NN perplexity) (NN score))))) (, ,) (SBAR (IN while) (S (NP (NNP HMD) (CC and) (NNP LMF)) (VP (VBP lead) (PP (TO to) (NP (NP (NP (ADJP (QP (CD 15) (NN %) (CC and) (CD 27) (NN %))) (NN loss)) (PP (IN in) (NP (NN perplexity) (NN score)))) (ADVP (RB respectively)))))))) (. .))
