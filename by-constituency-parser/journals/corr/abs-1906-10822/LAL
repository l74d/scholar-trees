(S (S (NP (NP (NNP Large-batch) (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))) (VP (VBZ is) (VP (ADVP (RB widely)) (VBN used) (PP (IN for) (NP (NP (NN training)) (PP (IN in) (NP (JJ distributed) (JJ deep) (NN learning))))) (PP (IN because) (IN of) (NP (PRP$ its) (JJ training-time) (NN efficiency)))))) (, ,) (S (ADVP (RB however)) (, ,) (NP (ADJP (RB extremely) (JJ large-batch)) (NNP SGD)) (VP (VP (VBZ leads) (PP (TO to) (NP (JJ poor) (NN generalization)))) (CC and) (VP (VP (ADVP (RB easily)) (NNS converges) (PP (TO to) (NP (JJ sharp) (NN minima)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ prevents) (NP (NP (JJ naive) (JJ large-scale) (JJ data-parallel) (NNP SGD)) (PRN (-LRB- -LRB-) (NP (NNP DP-SGD)) (-RRB- -RRB-))) (PP (IN from) (S (VP (VBG converging) (PP (TO to) (NP (JJ good) (NN minima)))))))))))) (. .))
(S (S (VP (TO To) (VP (VB overcome) (NP (DT this) (NN difficulty))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ gradient) (NN noise) (NN convolution)) (PRN (-LRB- -LRB-) (NP (NNP GNC)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (ADVP (RB effectively)) (VBP smooths) (NP (NP (JJR sharper) (NN minima)) (PP (IN of) (NP (DT the) (NN loss) (NN function))))))))) (. .))
(S (PP (IN For) (NP (NNP DP-SGD))) (, ,) (NP (NNP GNC)) (VP (VBZ utilizes) (NP (NP (JJ so-called) (NN gradient) (NN noise)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VP (VBN induced) (PP (IN by) (NP (JJ stochastic) (NN gradient) (NN variation)))) (CC and) (VP (VBD convolved) (PP (TO to) (NP (DT the) (NN loss) (NN function))) (PP (IN as) (NP (DT a) (JJ smoothing) (NN effect)))))))))) (. .))
(S (NP (NNP GNC) (NN computation)) (VP (VP (MD can) (VP (VB be) (VP (VBN performed) (PP (IN by) (S (ADVP (RB simply)) (VP (VP (VBG computing) (NP (DT the) (JJ stochastic) (NN gradient)) (PP (IN on) (NP (DT each) (JJ parallel) (NN worker)))) (CC and) (VP (VBG merging) (NP (PRP them))))))))) (, ,) (CC and) (VP (VBZ is) (ADVP (RB therefore)) (ADJP (RB extremely) (JJ easy) (SBAR (S (VP (TO to) (VP (VB implement)))))))) (. .))
(S (PP (JJ Due) (TO to) (S (VP (VBG convolving) (PP (IN with) (NP (NP (DT the) (NN gradient) (NN noise)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ tends) (S (VP (TO to) (VP (VB spread) (PP (IN along) (NP (NP (DT a) (JJR sharper) (NN direction)) (PP (IN of) (NP (DT the) (NN loss) (NN function)))))))))))))))) (, ,) (NP (NNP GNC)) (VP (MD can) (VP (VP (ADVP (RB effectively)) (VB smooth) (NP (JJ sharp) (NN minima))) (CC and) (VP (VB achieve) (NP (JJR better) (NN generalization))) (, ,) (SBAR (WP whereas) (S (NP (NN isotropic) (NN random) (NN noise)) (VP (MD can) (RB not)))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (RB empirically)) (VBP show) (NP (DT this) (NN effect)) (PP (IN by) (S (VP (VBG comparing) (NP (NNP GNC)) (PP (IN with) (NP (JJ isotropic) (NN random) (NN noise))))))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ achieves) (NP (NP (JJ state-of-the-art) (NN generalization) (NN performance)) (PP (IN for) (NP (JJ large-scale) (JJ deep) (JJ neural) (NN network) (NN optimization))))))))) (. .))
