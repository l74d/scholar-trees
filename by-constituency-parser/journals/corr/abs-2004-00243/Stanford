(S (NP (NP (JJ Convolutional) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-)) (VP (VBP demonstrate) (S (VP (VBG promising) (NP (NN accuracy)) (PP (IN in) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNS applications)))))))) (. .))
(S (PP (IN Among) (NP (NP (DT all) (NNS layers)) (PP (IN in) (NP (NNS CNNs))))) (, ,) (NP (NN convolution) (NNS layers)) (VP (VP (VBP are) (NP (DT the) (ADJP (RBS most) (JJ computation) (HYPH -) (JJ intensive)))) (CC and) (VP (VBP consume) (ADVP (DT the) (RBS most)) (NP (NN energy)))) (. .))
(S (PP (IN As) (NP (NP (DT the) (NN maturity)) (PP (IN of) (NP (NML (NN device) (CC and) (NN fabrication)) (NN technology))))) (, ,) (NP (NP (JJ 3D) (JJ resistive) (NML (JJ random) (NN access)) (NN memory)) (-LRB- -LRB-) (NP (NN ReRAM)) (-RRB- -RRB-)) (VP (VBZ receives) (NP (JJ substantial) (NN attention)) (PP (IN for) (S (VP (VBG accelerating) (NP (NML (JJ large) (NN vector) (HYPH -) (NN matrix)) (NN multiplication) (CC and) (NN convolution)) (PP (IN due) (PP (IN to) (NP (PRP$ its) (NML (NML (JJ high) (NN parallelism)) (CC and) (NML (NN energy) (NN efficiency))) (NNS benefits)))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG implementing) (NP (JJ multi-channel) (NN convolution)) (ADVP (RB naively)) (PP (IN in) (NP (JJ 3D) (NN ReRAM))))) (VP (MD will) (VP (CC either) (VP (VB produce) (NP (JJ incorrect) (NNS results))) (CC or) (VP (VB exploit) (NP (NP (RB only) (JJ partial) (NN parallelism)) (PP (IN of) (NP (JJ 3D) (NN ReRAM))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (ADJP (NP (NN 3D) (NN ReRAM)) (HYPH -) (VBN based)) (NN convolution) (NN accelerator) (NN architecture)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB efficiently)) (VP (VBZ maps) (NP (ADJP (JJ multi-channel)) (NN convolution)) (PP (IN to) (NP (JJ monolithic) (NN 3D) (NN ReRAM)))))))) (. .))
(S (NP (PRP$ Our) (NN design)) (VP (VBZ has) (NP (CD two) (JJ key) (NNS principles))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP exploit) (NP (NP (DT the) (ADJP (JJ intertwined)) (NN structure)) (PP (IN of) (NP (JJ 3D) (NN ReRAM)))) (S (VP (TO to) (VP (VB implement) (NP (ADJP (JJ multi-channel)) (NN convolution)) (PP (IN by) (S (VP (VBG using) (NP (DT a) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN convolution) (NN algorithm))))))))) (. .))
(S (ADVP (RB Second)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (JJ new) (NN approach)) (S (VP (TO to) (ADVP (RB efficiently)) (VP (VB implement) (NP (JJ negative) (NNS weights)) (PP (IN by) (S (VP (VBG separating) (NP (PRP them)) (PP (IN from) (NP (NP (JJ non-negative) (NNS weights)) (VP (VBG using) (NP (JJ configurable) (NNS interconnects)))))))))))) (. .))
(S (NP (PRP$ Our) (NN evaluation)) (VP (VBZ demonstrates) (SBAR (IN that) (S (NP (NP (PRP$ our) (NN mapping) (NN scheme)) (PP (IN in) (NP (NML (CD 16) (HYPH -) (NN layer)) (NN 3D) (NN ReRAM)))) (VP (VBZ achieves) (NP (NP (DT a) (NN speedup)) (PP (IN of) (NP (NP (CD 5.79) (NN X)) (, ,) (NP (CD 927.81) (NN X)) (, ,) (CC and) (NP (CD 36.8) (NN X))))) (PP (VBN compared) (PP (IN with) (NP (NP (DT a) (NML (NN custom) (NN 2D)) (NN ReRAM) (NN baseline)) (CC and) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NN CPU) (CC and) (NN GPU))))))))) (. .))
(S (NP (PRP$ Our) (NN design)) (ADVP (RB also)) (VP (VBZ reduces) (NP (NN energy) (NN consumption)) (PP (IN by) (NP (NP (CD 2.12) (NN X)) (, ,) (NP (CD 1802.64) (NN X)) (, ,) (CC and) (NP (CD 114.1) (NN X)))) (PP (VBN compared) (PP (IN with) (NP (DT the) (JJ same) (NN baseline))))) (. .))
