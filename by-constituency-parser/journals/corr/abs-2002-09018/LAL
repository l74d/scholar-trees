(S (NP (NP (NN Optimization)) (PP (IN in) (NP (NN machine) (NN learning))) (, ,) (ADJP (DT both) (JJ theoretical) (CC and) (JJ applied)) (, ,)) (VP (VBZ is) (ADVP (RB presently)) (VP (VBN dominated) (PP (IN by) (NP (NP (JJ first-order) (NN gradient) (NNS methods)) (PP (JJ such) (IN as) (NP (JJ stochastic) (NN gradient) (NN descent))))))) (. .))
(S (NP (NP (JJ Second-order) (NN optimization) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP involve) (NP (NP (NN second-order) (NNS derivatives)) (VBP and/or) (NP (NP (JJ second-order) (NNS statistics)) (PP (IN of) (NP (DT the) (NNS data))))))))) (VP (VBP have) (VP (VBN become) (ADJP (ADVP (RB far) (RBR less)) (JJ prevalent)) (PP (IN despite) (NP (JJ strong) (JJ theoretical) (NNS properties))) (, ,) (PP (JJ due) (TO to) (NP (PRP$ their) (JJ prohibitive) (NN computation) (, ,) (NN memory) (CC and) (NN communication) (NNS costs))))) (. .))
(S (PP (IN In) (NP (DT an) (NN attempt) (S (VP (TO to) (VP (VB bridge) (NP (NP (DT this) (NN gap)) (PP (IN between) (NP (ADJP (JJ theoretical) (CC and) (JJ practical)) (NN optimization))))))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (NN proof-of-concept) (JJ distributed) (NN system) (NN implementation)) (PP (IN of) (NP (NP (DT a) (NN second-order) (VBN preconditioned) (NN method)) (PRN (-LRB- -LRB-) (ADVP (RB specifically)) (, ,) (NP (NP (DT a) (NN variant)) (PP (IN of) (NP (JJ full-matrix) (NNP Adagrad)))) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (IN that)) (S (ADVP (IN along) (PP (IN with) (NP (DT a) (JJ few) (ADJP (RB yet) (JJ critical)) (ADJP (NN algorithmic) (CC and) (JJ numerical)) (NNS improvements)))) (, ,) (VP (VP (VBZ provides) (NP (NP (JJ significant) (JJ practical) (NNS gains)) (PP (IN in) (NP (NP (NN convergence)) (PP (IN on) (NP (JJ state-of-the-art) (JJ deep) (NNS models))))))) (CC and) (VP (VBZ gives) (NP (NN rise)) (PP (TO to) (NP (NP (JJ actual) (JJ wall-time) (NNS improvements)) (PP (IN in) (NP (NN practice))) (PP (VBN compared) (PP (TO to) (NP (JJ conventional) (JJ first-order) (NNS methods)))))))))))))) (. .))
(S (NP (PRP$ Our) (NN design)) (VP (ADVP (RB effectively)) (VBZ utilizes) (NP (NP (DT the) (NN prevalent) (JJ heterogeneous) (NN hardware) (NN architecture))) (PP (IN for) (S (VP (VBG training) (NP (JJ deep) (NNS models))))) (SBAR (WHNP (WDT which)) (S (VP (VBZ consists) (PP (IN of) (NP (NP (DT a) (NN multicore) (NNP CPU)) (VP (VBD coupled) (PP (IN with) (NP (JJ multiple) (NN accelerator) (NNS units)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (JJ superior) (NN performance)) (PP (IN on) (NP (NP (ADJP (RB very) (JJ large)) (VBG learning) (NNS problems)) (PP (IN in) (NP (NN machine) (NN translation))) (SBAR (WHADVP (WRB where)) (S (NP (PRP$ our) (JJ distributed) (NN implementation)) (VP (VBZ runs) (ADVP (ADVP (RB considerably) (RBR faster)) (PP (IN than) (NP (VBG existing) (JJ gradient-based) (NNS methods))))))))))) (. .))
