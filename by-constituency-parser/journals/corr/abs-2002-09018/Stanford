(S (NP (NP (NML (NML (NN Optimization)) (PP (IN in) (NP (NN machine)))) (NN learning)) (, ,) (NP (NP (CC both) (NP (JJ theoretical)) (CC and)) (SBAR (S (VP (VBD applied))))) (, ,)) (VP (VBZ is) (ADVP (RB presently)) (VP (VBN dominated) (PP (IN by) (NP (NP (NML (JJ first) (HYPH -) (NN order)) (NN gradient) (NNS methods)) (PP (JJ such) (IN as) (NP (JJ stochastic) (NN gradient) (NN descent))))))) (. .))
(S (NP (NP (NML (JJ Second) (HYPH -) (NN order)) (NN optimization) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP involve) (NP (NP (NML (RB second) (HYPH -) (NN order)) (NNS derivatives)) (CONJP (CC and) (HYPH /) (CC or)) (NP (NP (NML (JJ second) (HYPH -) (NN order)) (NNS statistics)) (PP (IN of) (NP (DT the) (NNS data))))))))) (VP (VBP have) (VP (VBN become) (S (ADJP (RB far) (RBR less) (JJ prevalent))) (PP (IN despite) (NP (JJ strong) (JJ theoretical) (NNS properties))) (, ,) (PP (IN due) (PP (IN to) (NP (PRP$ their) (JJ prohibitive) (NML (NN computation) (, ,) (NN memory) (CC and) (NN communication)) (NNS costs)))))) (. .))
(S (PP (IN In) (NP (DT an) (NN attempt) (S (VP (TO to) (VP (VB bridge) (NP (NP (DT this) (NN gap)) (PP (IN between) (NP (ADJP (JJ theoretical) (CC and) (JJ practical)) (NN optimization))))))))) (, ,) (NP (PRP we)) (VP (VBP present) (S (NP (DT a) (NN proof) (HYPH -) (IN of) (HYPH -) (NN concept)) (VP (VBN distributed) (NP (NP (NN system) (NN implementation)) (PP (IN of) (NP (NP (NP (DT a) (NML (JJ second) (HYPH -) (NN order)) (JJ preconditioned) (NN method)) (-LRB- -LRB-) (NP (ADVP (RB specifically)) (, ,) (NP (DT a) (NN variant)) (PP (IN of) (NP (NML (JJ full) (HYPH -) (NN matrix)) (NNP Adagrad)))) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT that)) (S (ADVP (RB along)) (VP (VP (PP (IN with) (NP (NP (DT a) (ADJP (JJ few) (CC yet) (JJ critical)) (JJ algorithmic)) (CC and) (NP (JJ numerical) (NNS improvements)))) (, ,) (VBZ provides) (NP (NP (JJ significant) (JJ practical) (NNS gains)) (PP (IN in) (NP (NN convergence)))) (PP (IN on) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (JJ deep) (NNS models)))) (CC and) (VP (VBZ gives) (NP (NN rise)) (PP (IN to) (NP (JJ actual) (NML (NN wall) (HYPH -) (NN time)) (NNS improvements)))))))))) (PP (IN in) (NP (NN practice))) (PP (VBN compared) (PP (IN to) (NP (JJ conventional) (NML (JJ first) (HYPH -) (NN order)) (NNS methods))))))) (. .))
(S (NP (PRP$ Our) (NN design)) (ADVP (RB effectively)) (VP (VBZ utilizes) (NP (NP (NP (DT the) (JJ prevalent) (JJ heterogeneous) (NN hardware) (NN architecture)) (PP (IN for) (NP (NN training) (JJ deep) (NNS models)))) (SBAR (WHNP (WDT which)) (S (VP (VBZ consists) (PP (IN of) (NP (NP (DT a) (NN multicore) (NN CPU)) (VP (VBN coupled) (PP (IN with) (NP (JJ multiple) (NN accelerator) (NNS units))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (JJ superior) (NN performance)) (PP (IN on) (NP (NP (ADJP (RB very) (JJ large)) (NN learning) (NNS problems)) (PP (IN in) (NP (NN machine) (NN translation))))) (SBAR (WHADVP (WRB where)) (S (NP (PRP$ our) (VBN distributed) (NN implementation)) (VP (VBZ runs) (ADJP (ADJP (RB considerably) (JJR faster)) (PP (IN than) (NP (ADJP (NP (VBG existing) (NN gradient)) (HYPH -) (VBN based)) (NNS methods)))))))) (. .))
