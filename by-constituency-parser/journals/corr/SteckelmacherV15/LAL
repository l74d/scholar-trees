(S (NP (DT This) (NN paper)) (VP (VBZ explores) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ fitted) (JJ neural) (NNP Q) (NN iteration))) (PP (IN for) (NP (NN reinforcement) (NN learning))) (PP (IN in) (NP (JJ several) (ADJP (RB partially) (JJ observable)) (NNS environments)))) (, ,) (S (VP (VBG using) (NP (NP (CD three) (JJ recurrent) (JJ neural) (NN network) (NNS architectures)) (: :) (NP (NP (JJ Long) (JJ Short-Term) (NN Memory)) (, ,) (NP (NNP Gated) (NNP Recurrent) (NNP Unit)) (CC and) (NP (NP (NNP MUT1)) (, ,) (NP (NP (DT a) (JJ recurrent) (JJ neural) (NN architecture)) (VP (VBN evolved) (PP (IN from) (NP (NP (DT a) (NN pool)) (PP (IN of) (NP (QP (JJ several) (NNS thousands)) (JJ candidate) (NNS architectures))))))))))))) (. .))
(S (NP (NP (DT A) (NN variant)) (PP (IN of) (NP (JJ fitted) (NNP Q) (NN iteration))) (, ,) (PP (VBN based) (PP (IN on) (NP (NP (NNP Advantage) (NNS values)) (CONJP (RB instead) (IN of)) (NP (NNP Q) (NNS values))))) (, ,)) (VP (VBZ is) (ADVP (RB also)) (VP (VBN explored))) (. .))
(S (NP (DT The) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP GRU)) (VP (VBZ performs) (ADVP (ADVP (RB significantly) (JJR better)) (PP (IN than) (NP (NNP LSTM) (CC and) (NNP MUT1)))) (PP (IN for) (NP (NP (JJS most)) (PP (IN of) (NP (NP (DT the) (NNS problems)) (VP (VBN considered)))))) (, ,) (S (VP (VBG requiring) (NP (NP (RBR less) (VBG training) (NNS episodes)) (CC and) (NP (JJR less) (NNP CPU) (NN time))) (PP (IN before) (S (VP (VBG learning) (NP (DT a) (ADJP (RB very) (JJ good)) (NN policy))))))))))) (. .))
(S (NP (NN Advantage) (NN learning)) (ADVP (RB also)) (VP (VBZ tends) (S (VP (TO to) (VP (VB produce) (NP (JJR better) (NNS results)))))) (. .))
