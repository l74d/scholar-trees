(S (SBAR (IN While) (S (NP (JJ deep) (JJ neural) (NNS networks)) (VP (VBP are) (NP (DT a) (ADJP (RB highly) (JJ successful)) (NN model) (NN class))))) (, ,) (NP (PRP$ their) (JJ large) (NN memory) (NN footprint)) (VP (VBZ puts) (NP (JJ considerable) (NN strain)) (PP (IN on) (NP (NP (NN energy) (NN consumption)) (, ,) (NP (NN communication) (NN bandwidth)) (, ,) (CC and) (NP (NN storage) (NNS requirements))))) (. .))
(S (ADVP (RB Consequently)) (, ,) (NP (NN model) (NN size) (NN reduction)) (VP (VBZ has) (VP (VBN become) (NP (NP (DT an) (JJ utmost) (NN goal)) (PP (IN in) (NP (JJ deep) (NN learning)))))) (. .))
(S (NP (DT A) (JJ typical) (NN approach)) (VP (VBZ is) (S (VP (TO to) (VP (VB train) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ deterministic) (NNS weights)))) (, ,) (SBAR (IN while) (S (VP (VBG applying) (NP (NP (JJ certain) (NNS techniques)) (PP (JJ such) (IN as) (NP (NN pruning) (CC and) (NN quantization))))))) (, ,) (SBAR (IN in) (NN order) (IN that) (S (NP (DT the) (JJ empirical) (NN weight) (NN distribution)) (VP (VBZ becomes) (ADJP (JJ amenable) (PP (TO to) (NP (JJ Shannon-style) (NN coding) (NNS schemes))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (IN as) (S (VP (VBN shown) (PP (IN in) (NP (DT this) (NN paper)))))) (, ,) (S (VP (VP (VBG relaxing) (NP (JJ weight) (NN determinism))) (CC and) (VP (VBG using) (NP (NP (DT a) (JJ full) (JJ variational) (NN distribution)) (PP (IN over) (NP (NNS weights))))))) (VP (NNS allows) (PP (IN for) (NP (NP (ADJP (RBR more) (JJ efficient)) (VBG coding) (NNS schemes)) (CC and) (ADVP (RB consequently)) (NP (JJR higher) (NN compression) (NNS rates))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (S (VP (VBG following) (NP (DT the) (JJ classical) (NN bits-back) (NN argument)))) (, ,) (NP (PRP we)) (VP (VBP encode) (NP (DT the) (NN network) (NNS weights)) (S (VP (VBG using) (NP (DT a) (JJ random) (NN sample)))) (, ,) (S (VP (VBG requiring) (NP (NP (RB only) (DT a) (NN number)) (PP (IN of) (NP (NNS bits))) (VP (VBG corresponding) (PP (TO to) (NP (NP (DT the) (NNP Kullback-Leibler) (NN divergence)) (PP (IN between) (NP (NP (DT the) (JJ sampled) (JJ variational) (NN distribution)) (CC and) (NP (DT the) (VBG encoding) (NN distribution))))))))))) (. .))
(S (PP (IN By) (S (VP (VBG imposing) (NP (DT a) (NN constraint)) (PP (IN on) (NP (DT the) (NNP Kullback-Leibler) (NN divergence)))))) (, ,) (NP (PRP we)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (ADVP (RB explicitly)) (VB control) (NP (DT the) (NN compression) (NN rate)) (, ,) (SBAR (IN while) (S (VP (VBG optimizing) (NP (NP (DT the) (JJ expected) (NN loss)) (PP (IN on) (NP (DT the) (NN training) (NN set)))))))))))) (. .))
(S (NP (DT The) (JJ employed) (VBG encoding) (NN scheme)) (VP (MD can) (VP (VB be) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (RB close) (PP (TO to) (NP (DT the) (JJ optimal) (JJ information-theoretical) (JJR lower) (NN bound)))) (, ,) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (DT the) (VBN employed) (JJ variational) (NN family))))))))))) (. .))
(S (S (NP (PRP$ Our) (NN method)) (VP (VBZ sets) (NP (NP (JJ new) (NN state-of-the-art)) (PP (IN in) (NP (JJ neural) (NN network) (NN compression)))) (, ,) (SBAR (IN as) (S (NP (PRP it)) (VP (ADVP (RB strictly)) (VBZ dominates) (NP (JJ previous) (NNS approaches)) (PP (IN in) (NP (DT a) (NNP Pareto) (NN sense)))))))) (: :) (S (S (PP (IN On) (NP (NP (DT the) (NNS benchmarks)) (NP (NNP LeNet-5/MNIST) (CC and) (NNP VGG-16/CIFAR-10)))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ yields) (NP (NP (DT the) (JJS best) (NN test) (NN performance)) (PP (IN for) (NP (DT a) (JJ fixed) (NN memory) (NN budget)))))) (, ,) (CC and) (S (INTJ (NN vice) (NN versa)) (, ,) (NP (PRP it)) (VP (VBZ achieves) (NP (NP (DT the) (JJS highest) (NN compression) (NNS rates)) (PP (IN for) (NP (DT a) (JJ fixed) (NN test) (NN performance))))))) (. .))
