(S (PP (IN In) (NP (NML (JJ natural) (NN language)) (NN processing) (PRN (-LRB- -LRB-) (NP (NN NLP)) (-RRB- -RRB-)))) (, ,) (S (NP (DT the) (`` ") (NN Transformer) ('' ") (NN architecture)) (VP (VBD was) (VP (VBN proposed) (PP (IN as) (NP (NP (DT the) (JJ first) (NN transduction) (NN model)) (VP (VBG replying) (ADVP (RB entirely)) (PP (IN on) (NP (ADJP (NN self) (HYPH -) (NN attention)) (NNS mechanisms)))))) (PP (IN without) (S (VP (VBG using) (NP (NP (NP (ADJP (ADJP (NN sequence) (HYPH -) (VBN aligned)) (JJ recurrent)) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (CC or) (NP (NN convolution))))))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBD achieved) (NP (JJ significant) (NNS improvements)) (PP (IN for) (NP (NN sequence))) (PP (IN to) (NP (NN sequence) (NNS tasks))))) (. .))
(S (NP (NP (DT The) (VBN introduced) (JJ intensive) (NN computation)) (CC and) (NP (NP (NN storage)) (PP (IN of) (NP (DT these) (JJ pre-trained) (NN language) (NNS representations))))) (VP (VBZ has) (VP (VBN impeded) (NP (PRP$ their) (NN popularity)) (PP (IN into) (NP (NP (NN computation)) (CC and) (NP (ADJP (NN memory) (HYPH -) (VBN constrained)) (NNS devices)))))) (. .))
(S (NP (NP (NP (DT The) (NN field)) (HYPH -) (NP (JJ programmable) (NN gate) (NN array))) (-LRB- -LRB-) (NP (NN FPGA)) (-RRB- -RRB-)) (VP (VBZ is) (ADVP (RB widely)) (VP (VBN used) (S (VP (TO to) (VP (VB accelerate) (NP (JJ deep) (NN learning) (NNS algorithms)) (PP (IN for) (NP (NP (PRP$ its) (JJ high) (NN parallelism)) (CC and) (NP (JJ low) (NN latency))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT the) (VBN trained) (NNS models)) (VP (VBP are) (ADVP (RB still)) (ADJP (RB too) (JJ large) (S (VP (TO to) (VP (VB accommodate) (PP (IN to) (NP (DT an) (NNP FPGA) (NN fabric)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (DT an) (JJ efficient) (NN acceleration) (NN framework)) (, ,) (NP (NNPS Ftrans)) (, ,)) (PP (IN for) (NP (ADJP (NN transformer) (HYPH -) (VBN based)) (NML (JJ large) (NN scale) (NN language)) (NNS representations))))) (. .))
(S (NP (PRP$ Our) (NN framework)) (VP (VBZ includes) (NP (NP (NP (NP (VBN enhanced) (NML (NN block) (HYPH -) (NN circulant)) (NN matrix)) (-LRB- -LRB-) (NP (NN BCM)) (-RRB- -RRB-)) (HYPH -) (VP (VBN based) (NP (NN weight) (NN representation)) (S (VP (TO to) (VP (VB enable) (NP (NP (NN model) (NN compression)) (PP (IN on) (NP (NML (JJ large) (HYPH -) (NN scale)) (NN language) (NNS representations)))) (PP (IN at) (NP (DT the) (NN algorithm) (NN level))) (PP (IN with) (NP (JJ few) (NN accuracy) (NN degradation)))))))) (, ,) (CC and) (NP (NP (DT an) (NN acceleration) (NN design)) (PP (IN at) (NP (DT the) (NN architecture) (NN level)))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (VBN proposed) (NN framework)) (ADVP (RB significantly)) (VP (VBZ reduces) (NP (NP (DT the) (NN model) (NN size)) (PP (IN of) (NP (NN NLP) (NNS models)))) (PP (IN by) (NP (QP (RB up) (IN to) (CD 16)) (NNS times))))))) (. .))
(S (NP (PRP$ Our) (NNP FPGA) (NN design)) (VP (VP (VBZ achieves) (NP (NP (CD 27.07) (NML (NN x) (CC and) (NN 81x)) (NN improvement)) (PP (IN in) (NP (NML (NN performance) (CC and) (NN energy)) (NN efficiency)))) (PP (VBN compared) (PP (IN to) (NP (NN CPU))))) (, ,) (CC and) (VP (ADVP (RB up) (PP (IN to) (NP (CD 8.80) (SYM x) (NN improvement)))) (PP (IN in) (NP (NN energy) (NN efficiency))) (PP (VBN compared) (PP (IN to) (NP (NNP GPU)))))) (. .))
