(S (S (PP (IN In) (NP (NP (JJ natural) (NN language) (NN processing)) (PRN (-LRB- -LRB-) (NP (NNP NLP)) (-RRB- -RRB-)))) (, ,) (NP (DT the) (`` ``) (NNP Transformer) ('' '') (NN architecture)) (VP (VBD was) (VP (VBN proposed) (PP (IN as) (NP (NP (DT the) (JJ first) (NN transduction) (NN model)) (VP (VBG replying) (ADVP (RB entirely)) (PP (IN on) (NP (NN self-attention) (NNS mechanisms))) (PP (IN without) (S (VP (VBG using) (NP (NP (NP (JJ sequence-aligned) (JJ recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))) (CC or) (NP (NN convolution)))))))))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBD achieved) (NP (NP (JJ significant) (NNS improvements)) (PP (IN for) (NP (ADJP (NN sequence) (TO to) (VB sequence)) (NNS tasks)))))) (. .))
(S (NP (NP (DT The) (JJ introduced) (JJ intensive) (NN computation) (CC and) (NN storage)) (PP (IN of) (NP (DT these) (JJ pre-trained) (NN language) (NNS representations)))) (VP (VBZ has) (VP (VBN impeded) (NP (NP (PRP$ their) (NN popularity)) (PP (IN into) (NP (ADJP (NN computation) (CC and) (JJ memory-constrained)) (NNS devices)))))) (. .))
(S (NP (NP (DT The) (JJ field-programmable) (NN gate) (NN array)) (PRN (-LRB- -LRB-) (NP (NNP FPGA)) (-RRB- -RRB-))) (VP (VBZ is) (VP (ADVP (RB widely)) (VBN used) (S (VP (TO to) (VP (VB accelerate) (NP (JJ deep) (NN learning) (NN algorithms)) (PP (IN for) (NP (PRP$ its) (NX (NX (JJ high) (NN parallelism)) (CC and) (NX (JJ low) (NN latency)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT the) (JJ trained) (NNS models)) (VP (VBP are) (ADVP (RB still)) (ADJP (RB too) (JJ large) (S (VP (TO to) (VP (VB accommodate) (PP (TO to) (NP (DT an) (NNP FPGA) (NN fabric)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (JJ efficient) (NN acceleration) (NN framework)) (, ,) (NP (NNP Ftrans)) (, ,) (PP (IN for) (NP (JJ transformer-based) (JJ large) (NN scale) (NN language) (NNS representations))))) (. .))
(S (NP (PRP$ Our) (NN framework)) (VP (VBZ includes) (NP (NP (NP (JJ enhanced) (ADJP (JJ block-circulant) (NN matrix) (PRN (-LRB- -LRB-) (NNP BCM) (-RRB- -RRB-)) (VBD -based)) (JJ weight) (NN representation)) (SBAR (S (VP (TO to) (VP (VB enable) (NP (NP (NN model) (NN compression)) (PP (IN on) (NP (JJ large-scale) (NN language) (NNS representations)))) (PP (IN at) (NP (DT the) (JJ algorithm) (NN level))) (PP (IN with) (NP (JJ few) (NN accuracy) (NN degradation)))))))) (, ,) (CC and) (NP (NP (DT an) (NN acceleration) (NN design)) (PP (IN at) (NP (DT the) (NN architecture) (NN level)))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (VBN proposed) (NN framework)) (VP (ADVP (RB significantly)) (VBZ reduces) (NP (NP (DT the) (NN model) (NN size)) (PP (IN of) (NP (NNP NLP) (NNS models)))) (PP (IN by) (NP (QP (QP (IN up) (TO to) (CD 16)) (NNS times)))))))) (. .))
(S (NP (PRP$ Our) (NNP FPGA) (NN design)) (VP (VBZ achieves) (NP (NP (NP (QP (CD 27.07x) (CC and) (CD 81x)) (NN improvement)) (PP (IN in) (NP (NP (NN performance)) (CC and) (NP (NN energy) (NN efficiency)))) (PP (VBN compared) (PP (TO to) (NP (NNP CPU))))) (, ,) (CC and) (NP (NP (QP (RB up) (TO to) (CD 8.80x)) (NN improvement)) (PP (IN in) (NP (NN energy) (NN efficiency))) (PP (VBN compared) (PP (TO to) (NP (NNP GPU))))))) (. .))
