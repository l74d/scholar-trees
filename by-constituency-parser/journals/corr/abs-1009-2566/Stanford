(S (NP (DT This) (NN paper)) (VP (VBZ introduces) (NP (DT an) (NN approach)) (PP (IN to) (NP (NP (NN Reinforcement)) (VP (VBG Learning) (NP (NNP Algorithm)) (PP (IN by) (S (VP (VBG comparing) (NP (PRP$ their) (JJ immediate) (NNS rewards)) (S (VP (VBG using) (NP (NP (DT a) (NN variation)) (PP (IN of) (NP (NML (NN Q) (HYPH -) (VBG Learning)) (NN algorithm))))))))))))) (. .))
(S (PP (IN Unlike) (NP (DT the) (JJ conventional) (NN Q) (HYPH -) (NN Learning))) (, ,) (NP (DT the) (VBN proposed) (NN algorithm)) (VP (VBZ compares) (NP (JJ current) (NN reward)) (PP (IN with) (NP (NP (JJ immediate) (NN reward)) (PP (IN of) (NP (JJ past) (NN move) (CC and) (NN work))))) (ADVP (RB accordingly))) (. .))
(S (NP (ADJP (NP (JJ Relative) (NN reward)) (VBN based)) (NML (NNP Q) (HYPH -) (NN learning))) (VP (VBZ is) (NP (NP (DT an) (NN approach)) (PP (IN towards) (NP (JJ interactive) (NN learning))))) (. .))
(S (NP (NN Q) (HYPH -) (NN Learning)) (VP (VBZ is) (NP (NP (DT a) (NN model) (NML (JJ free) (NN reinforcement) (NN learning)) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBD used) (S (VP (TO to) (VP (VB learn) (NP (DT the) (NNS agents)))))))))) (. .))
(S (NP (PRP It)) (VP (VBZ is) (VP (VBN observed) (SBAR (IN that) (S (PP (IN under) (NP (JJ normal) (NNS circumstances))) (NP (NN algorithm)) (VP (VBP take) (NP (JJR more) (NNS episodes)) (S (VP (TO to) (VP (VB reach) (NP (JJ optimal) (NN Q) (HYPH -) (NN value)) (PP (IN due) (NP (UCP (PP (IN to) (NP (PRP$ its) (JJ normal) (NN reward))) (CC or) (ADVP (RB sometime))) (JJ negative) (NN reward))))))))))) (. .))
(S (PP (IN In) (NP (NP (DT this) (JJ new) (NN form)) (PP (IN of) (NP (NN algorithm))))) (NP (NNS agents)) (VP (VBP select) (NP (NP (RB only) (DT those) (NNS actions)) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (NP (NP (DT a) (JJR higher) (JJ immediate) (NN reward) (NN signal)) (PP (IN in) (NP (NN comparison)))) (PP (IN to) (NP (JJ previous) (CD one)))))))) (. .))
(S (NP (NP (DT The) (NN contribution)) (PP (IN of) (NP (DT this) (NN article)))) (VP (VBZ is) (NP (NP (DT the) (NN presentation)) (PP (IN of) (NP (NP (JJ new) (NML (NN Q) (HYPH -))) (VP (VBG Learning) (NP (NP (NNP Algorithm)) (PP (IN in) (NP (NN order)))) (S (VP (TO to) (VP (VP (VB maximize) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN algorithm))))) (CC and) (VP (VB reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NN episode)) (VP (VBN required) (S (VP (TO to) (VP (VB reach) (NP (JJ optimal) (NN Q) (HYPH -) (NN value)))))))))))))))))) (. .))
(S (S (NP (NP (NN Effectiveness)) (PP (IN of) (NP (VBN proposed) (NN algorithm)))) (VP (VBZ is) (VP (VBN simulated) (PP (IN in) (NP (DT a) (NML (CD 20) (NN x20)) (NML (NNP Grid) (NN world)) (JJ deterministic) (NN environment)))))) (CC and) (S (NP (NP (DT the) (NN result)) (PP (IN for) (NP (NP (DT the) (CD two) (NNS forms)) (PP (IN of) (NP (NML (NN Q) (HYPH -) (VBG Learning)) (NNS Algorithms)))))) (VP (VBZ is) (VP (VBN given)))) (. .))
