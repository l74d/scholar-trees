(S (NP (DT The) (NNP Adam) (NN algorithm)) (VP (VBZ has) (VP (VBN become) (ADJP (RB extremely) (JJ popular) (PP (IN for) (NP (JJ large-scale) (NN machine) (NN learning)))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (IN whether) (S (NP (JJ strong) (NN convexity)) (VP (MD can) (VP (VB be) (VP (VBN utilized) (S (VP (TO to) (ADVP (RBR further)) (VP (VB improve) (NP (DT the) (NN performance)))))))))) (VP (VBZ remains) (NP (DT an) (JJ open) (NN problem))) (. .))
(S (NP (DT The) (JJ essential) (NN idea)) (VP (VBZ is) (S (VP (TO to) (VP (VB maintain) (NP (DT a) (ADJP (ADJP (ADVP (RBR faster)) (VBG decaying)) (RB yet) (ADJP (IN under) (VBN controlled))) (NN step) (NN size)) (PP (IN for) (S (VP (VBG exploiting) (NP (JJ strong) (NN convexity))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (PP (IN under) (NP (NP (DT a) (JJ special) (NN configuration)) (PP (IN of) (NP (NNS hyperparameters))))) (, ,) (NP (PRP$ our) (NNP SAdam)) (VP (VBZ reduces) (PP (TO to) (NP (NP (NNP SC-RMSprop)) (, ,) (NP (NP (DT a) (ADJP (RB recently) (VBN proposed)) (NN variant)) (PP (IN of) (NP (NNP RMSprop))) (PP (IN for) (NP (ADJP (RB strongly) (JJ convex)) (NNS functions))) (, ,) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBP provide) (NP (DT the) (JJ first) (JJ data-dependent) (JJ logarithmic) (NN regret) (NN bound))))))))) (. .))
(S (NP (NP (JJ Empirical) (NNS results)) (PP (IN on) (S (VP (VP (VBG optimizing) (NP (ADJP (RB strongly) (JJ convex)) (NNS functions))) (CC and) (VP (VBG training) (NP (JJ deep) (NNS networks))))))) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (PRP$ our) (NN method))))) (. .))
