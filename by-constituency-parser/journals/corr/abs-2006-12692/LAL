(S (NP (NP (NNP Multi-step) (PRN (-LRB- -LRB-) (VP (ADVP (RB also)) (VBN called) (S (ADJP (NN n-step)))) (-RRB- -RRB-)) (NNS methods)) (PP (IN in) (NP (NP (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-))))) (VP (VBP have) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (ADJP (RBR more) (JJ efficient)) (PP (IN than) (NP (DT the) (JJ 1-step) (NN method)))) (PP (JJ due) (TO to) (NP (NP (VB faster) (NN propagation)) (PP (IN of) (NP (DT the) (JJ reward) (NN signal))))) (, ,) (ADVP (DT both) (RB theoretically) (CC and) (RB empirically)) (, ,) (PP (IN in) (NP (NP (NNS tasks)) (VP (VBG exploiting) (NP (NP (JJ tabular) (NN representation)) (PP (IN of) (NP (DT the) (NN value-function))))))))))))) (. .))
(S (ADVP (RB Recently)) (, ,) (NP (NP (NN research)) (PP (IN in) (NP (NP (NNP Deep) (NNP Reinforcement) (NNP Learning)) (PRN (-LRB- -LRB-) (NP (NNP DRL)) (-RRB- -RRB-))))) (ADVP (RB also)) (VP (VBZ shows) (SBAR (IN that) (S (NP (NN multi-step) (NNS methods)) (VP (VB improve) (NP (NP (VBG learning) (NN speed)) (CC and) (NP (JJ final) (NN performance))) (PP (IN in) (NP (NP (NNS applications)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN value-function) (CC and) (NN policy)) (VP (VBP are) (VP (VBN represented) (PP (IN with) (NP (JJ deep) (JJ neural) (NNS networks))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (NN lack)) (PP (IN of) (NP (NP (VBG understanding)) (PP (IN about) (SBAR (WHNP (WP what)) (S (VP (VBZ is) (ADVP (RB actually)) (VP (VBG contributing) (PP (TO to) (NP (NP (DT the) (NN boost)) (PP (IN of) (NP (NN performance)))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP analyze) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NN multi-step) (NNS methods))) (PP (IN on) (S (VP (VBG alleviating) (NP (NP (DT the) (NN overestimation) (NN problem)) (PP (IN in) (NP (NP (NNP DRL)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NN multi-step) (NNS experiences)) (VP (VBP are) (VP (VBN sampled) (PP (IN from) (NP (DT a) (NN replay) (NN buffer))))))))))))))) (. .))
(S (S (VP (ADVP (RB Specifically)) (VBG building) (PP (IN on) (NP (NP (NN top)) (PP (IN of) (NP (NP (NNP Deep) (NNP Deterministic) (NNP Policy) (NNP Gradient)) (PRN (-LRB- -LRB-) (NP (NNP DDPG)) (-RRB- -RRB-)))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (JJ Multi-step) (NNP DDPG)) (PRN (-LRB- -LRB-) (NP (NNP MDDPG)) (-RRB- -RRB-)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (JJ different) (NN step) (NNS sizes)) (VP (VBP are) (VP (ADVP (RB manually)) (VBN set)))))) (, ,) (CC and) (NP (NP (PRP$ its) (NN variant)) (VP (VBN called) (S (NP (NP (NNP Mixed) (NNP Multi-step) (NNP DDPG)) (PRN (-LRB- -LRB-) (NP (NNP MMDDPG)) (-RRB- -RRB-))))) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT an) (NN average)) (PP (IN over) (NP (JJ different) (JJ multi-step) (NN backups)))) (VP (VBZ is) (VP (VBN used) (PP (IN as) (NP (NP (JJ update) (NN target)) (PP (IN of) (NP (JJ Q-value) (NN function)))))))))))) (. .))
(S (ADVP (RB Empirically)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT both) (NNP MDDPG) (CC and) (NNP MMDDPG)) (VP (VBP are) (ADJP (ADJP (ADVP (RB significantly) (RBR less)) (JJ affected) (PP (IN by) (NP (DT the) (NN overestimation) (NN problem))) (PP (IN than) (NP (NP (NNP DDPG)) (PP (IN with) (NP (JJ 1-step) (NN backup)))))) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB consequently)) (VP (NNS results) (PP (IN in) (NP (JJR better) (NX (NX (JJ final) (NN performance)) (CC and) (NX (VBG learning) (NN speed))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP discuss) (NP (NP (DT the) (NNS advantages) (CC and) (NNS disadvantages)) (PP (IN of) (NP (NP (JJ different) (NNS ways)) (SBAR (S (VP (TO to) (VP (VB do) (NP (JJ multi-step) (NN expansion)) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB reduce) (NP (NN approximation) (NN error)))))))))))))) (, ,) (CC and) (VP (VB expose) (NP (NP (DT the) (NN tradeoff)) (PP (IN between) (NP (NN overestimation) (CC and) (NN underestimation))) (SBAR (WHNP (IN that)) (S (VP (VBZ underlies) (NP (JJ offline) (JJ multi-step) (NNS methods)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP compare) (NP (NP (DT the) (JJ computational) (NN resource) (NNS needs)) (PP (IN of) (NP (NP (NP (NNP Twin) (NNP Delayed) (NNP Deep) (NNP Deterministic) (NNP Policy) (NNP Gradient)) (PRN (-LRB- -LRB-) (NP (NNP TD3)) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (JJ state-of-art) (NN algorithm)) (VP (VBN proposed) (S (VP (TO to) (VP (VB address) (NP (NP (NN overestimation)) (PP (IN in) (NP (JJ actor-critic) (NNS methods)))))))))) (, ,) (CC and) (NP (PRP$ our) (VBN proposed) (NNS methods))))) (, ,) (SBAR (IN since) (S (NP (PRP they)) (VP (VBP show) (NP (JJ comparable) (NX (NX (JJ final) (NN performance)) (CC and) (NX (VBG learning) (NN speed)))))))) (. .))
