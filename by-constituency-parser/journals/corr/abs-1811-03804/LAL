(S (NP (JJ Gradient) (NN descent)) (VP (VBZ finds) (NP (DT a) (JJ global) (NN minimum)) (PP (IN in) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks))))) (PP (IN despite) (S (NP (DT the) (JJ objective) (NN function)) (VP (VBG being) (ADJP (JJ non-convex)))))) (. .))
(S (NP (DT The) (JJ current) (NN paper)) (VP (VBZ proves) (SBAR (S (NP (JJ gradient) (NN descent)) (VP (NNS achieves) (NP (CD zero) (NN training) (NN loss)) (PP (IN in) (NP (JJ polynomial) (NN time))) (PP (IN for) (NP (NP (NP (DT a) (JJ deep) (JJ over-parameterized) (JJ neural) (NN network)) (PP (IN with) (NP (JJ residual) (NNS connections)))) (PRN (-LRB- -LRB-) (NP (NNP ResNet)) (-RRB- -RRB-)))))))) (. .))
(S (NP (PRP$ Our) (NN analysis)) (VP (NNS relies) (PP (IN on) (NP (NP (DT the) (JJ particular) (NN structure)) (PP (IN of) (NP (DT the) (NNP Gram) (NN matrix))) (VP (VBN induced) (PP (IN by) (NP (DT the) (JJ neural) (NN network) (NN architecture))))))) (. .))
(S (S (NP (DT This) (NN structure)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB show) (SBAR (S (NP (DT the) (NNP Gram) (NN matrix)) (VP (VBZ is) (ADJP (JJ stable)) (PP (IN throughout) (NP (DT the) (NN training) (NN process))))))))))) (CC and) (S (NP (DT this) (NN stability)) (VP (VBZ implies) (NP (NP (DT the) (JJ global) (NN optimality)) (PP (IN of) (NP (DT the) (JJ gradient) (NN descent) (NN algorithm)))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (VBP further)) (VB extend) (NP (PRP$ our) (NN analysis)) (PP (TO to) (NP (VB deep) (JJ residual) (JJ convolutional) (JJ neural) (NNS networks)))) (CC and) (VP (VB obtain) (NP (DT a) (JJ similar) (NN convergence) (NN result)))) (. .))
