(S (NP (NP (JJ Neural) (NN network)) (VP (VBN based) (NP (JJ approximate) (NN computing)))) (VP (VBZ is) (NP (NP (DT a) (JJ universal) (NN architecture)) (VP (VBG promising) (S (VP (TO to) (VP (VB gain) (NP (JJ tremendous) (NN energy) (HYPH -) (NN efficiency)) (PP (IN for) (NP (JJ many) (ADJP (NN error) (JJ resilient)) (NNS applications))))))))) (. .))
(S (S (VP (TO To) (VP (VB guarantee) (NP (NP (DT the) (NN approximation) (NN quality)) (, ,) (NP (VBG existing) (NNS works)))))) (VP (VB deploy) (NP (NP (NP (CD two) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS NNs)) (-RRB- -RRB-)) (, ,) (NP (ADVP (FW e.g.)) (, ,) (NP (DT an) (NN approximator)) (CC and) (NP (DT a) (NN predictor))))) (. .))
(S (NP (DT The) (NN approximator)) (VP (VBZ provides) (NP (DT the) (JJ approximate) (NNS results)) (, ,) (SBAR (IN while) (S (NP (DT the) (NN predictor)) (VP (VBZ predicts) (SBAR (IN whether) (S (NP (DT the) (NN input) (NN data)) (VP (VBZ is) (ADJP (JJ safe) (S (VP (TO to) (VP (VB approximate) (PP (IN with) (NP (DT the) (VBN given) (NN quality) (NN requirement)))))))))))))) (. .))
(S (ADVP (RB However)) (PRN (, ,) (S (NP (PRP it)) (VP (VBZ is) (ADJP (ADJP (JJ non-trivial)) (CC and) (ADJP (NN time) (HYPH -) (VBG consuming))) (S (VP (TO to) (VP (VB make) (NP (DT these) (CD two) (NML (JJ neural) (NN network)) (NN coordinate))))))) (, ---)) (NP (PRP they)) (VP (VBP have) (NP (NP (JJ different) (NN optimization) (NNS objectives)) (NFP ---) (PP (IN by) (S (VP (VBG training) (NP (PRP them)) (ADVP (RB separately))))))) (. .))
(FRAG (S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (DT a) (JJ novel) (NML (JJ neural) (NN network)) (NN structure)))) (, ---) (FRAG (NP (NNP AXNet)) (, ---) (S (VP (TO to) (VP (VB fuse) (NP (CD two) (NNS NNs)) (PP (IN to) (NP (DT a) (JJ holistic) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (ADJP (NN end) (JJ trainable)))) (NNP NN))))))) (. .))
(S (S (VP (VBG Leveraging) (NP (NP (DT the) (NN philosophy)) (PP (IN of) (S (VP (VB multi-task) (NP (NN learning)))))))) (, ,) (NP (NNP AXNet)) (VP (MD can) (ADVP (RB tremendously)) (VP (VP (VB improve) (NP (DT the) (NN invocation)) (PRN (-LRB- -LRB-) (NP (NP (NN proportion)) (PP (IN of) (NP (ADJP (ADJP (JJ safe) (HYPH -) (PP (TO to))) (HYPH -) (JJ approximate)) (NNS samples)))) (-RRB- -RRB-))) (CC and) (VP (VB reduce) (NP (DT the) (NN approximation) (NN error))))) (. .))
(S (NP (DT The) (NN training) (NN effort)) (ADVP (RB also)) (VP (VBP decrease) (ADVP (RB significantly))) (. .))
(S (NP (NN Experiment) (NNS results)) (VP (VBP show) (NP (CD 50.7) (NN %)) (NP (NP (JJR more) (NN invocation)) (CC and) (NP (NP (JJ substantial) (NNS cuts)) (PP (IN of) (NP (NN training) (NN time))))) (SBAR (WHADVP (WRB when)) (S (VP (VBN compared) (PP (IN to) (NP (NP (VBG existing) (JJ neural) (NN network)) (VP (VBN based) (NP (JJ approximate) (NN computing) (NN framework))))))))) (. .))
