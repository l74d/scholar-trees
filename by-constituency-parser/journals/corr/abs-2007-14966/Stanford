(S (NP (JJ Neural) (NN text) (NN decoding)) (VP (VBZ is) (ADJP (JJ important) (PP (IN for) (S (VP (VBG generating) (NP (NML (JJ high) (HYPH -) (NN quality)) (NNS texts)) (S (VP (VBG using) (NP (NN language) (NNS models))))))))) (. .))
(S (S (VP (TO To) (VP (VB generate) (NP (NP (NML (JJ high) (HYPH -) (NN quality)) (NN text)) (, ,) (NP (NP (JJ popular) (NN decoding) (NNS algorithms)) (PP (IN like) (NP (JJ top) (HYPH -) (NN k)))) (, ,) (NP (JJ top) (HYPH -) (NN p) (PRN (-LRB- -LRB-) (NP (NN nucleus)) (-RRB- -RRB-))) (, ,) (CC and) (NP (ADJP (NN temperature) (HYPH -) (VBN based)) (NN sampling)))))) (VP (VBP truncate) (CC or) (VBP distort) (NP (NP (DT the) (ADJP (JJ unreliable) (JJ low)) (NN probability) (NN tail)) (PP (IN of) (NP (DT the) (NN language) (NN model))))) (. .))
(S (SBAR (IN Though) (S (NP (DT these) (NNS methods)) (VP (VBP generate) (NP (NML (JJ high) (HYPH -) (NN quality)) (NN text)) (PP (IN after) (NP (NN parameter) (NN tuning)))))) (, ,) (NP (PRP they)) (VP (VBP are) (ADJP (FW ad) (FW hoc))) (. .))
(S (ADVP (ADVP (RB Not) (RB much)) (SBAR (S (VP (VBZ is) (VP (VBN known) (PP (IN about) (NP (DT the) (NN control)))))))) (NP (PRP they)) (VP (VBP provide) (PP (IN over) (NP (NP (DT the) (NNS statistics)) (PP (IN of) (NP (NP (DT the) (NN output)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ important)) (SBAR (IN since) (S (NP (JJ recent) (NNS reports)) (VP (VBP show) (SBAR (S (NP (NN text) (NN quality)) (VP (VBZ is) (NP (NP (JJS highest)) (PP (IN for) (NP (NP (DT a) (JJ specific) (NN range)) (PP (IN of) (NP (NNS likelihoods)))))))))))))))))))) (. .))
(S (ADVP (RB Here)) (, ,) (ADVP (RB first)) (NP (PRP we)) (VP (VBP provide) (NP (NP (DT a) (JJ theoretical) (NN analysis)) (PP (IN of) (NP (NP (NN perplexity)) (PP (IN in) (NP (NML (NML (JJ top) (HYPH -) (NN k)) (, ,) (NML (JJ top) (HYPH -) (NN p)) (, ,) (CC and) (NML (NN temperature))) (NN sampling)))))) (, ,) (S (VP (VBG finding) (SBAR (IN that) (S (NP (NN cross-entropy)) (VP (VBZ behaves) (NP (RB approximately) (RB linearly)) (PP (IN as) (NP (NP (DT a) (NN function)) (PP (IN of) (NP (NP (NN p)) (PP (IN in) (NP (NML (JJ top) (HYPH -) (NN p)) (NN sampling))))))) (SBAR (IN whereas) (S (NP (PRP it)) (VP (VBZ is) (NP (NP (DT a) (JJ nonlinear) (NN function)) (PP (IN of) (NP (NP (NN k)) (PP (IN in) (NP (NML (JJ top) (HYPH -) (NN k)) (NN sampling)))))) (, ,) (PP (IN under) (NP (NNP Zipfian) (NNS statistics)))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP use) (NP (DT this) (NN analysis)) (S (VP (TO to) (VP (VB design) (NP (DT a) (ADJP (NP (NN feedback)) (HYPH -) (VBN based)) (JJ adaptive) (NML (JJ top) (HYPH -) (NN k)) (ADJP (NP (NN text) (NN decoding) (NN algorithm)) (VBN called)) (NN mirostat)) (SBAR (WHNP (WDT that)) (S (VP (VBZ generates) (NP (NP (NN text)) (-LRB- -LRB-) (PP (IN of) (NP (DT any) (NN length))) (-RRB- -RRB-)) (PP (IN with) (NP (NP (DT a) (VBN predetermined) (NN value)) (PP (IN of) (NP (NN perplexity)))))))))))) (, ,) (CC and) (ADVP (RB thereby)) (VP (NP (NML (JJ high) (HYPH -) (NN quality)) (NN text)) (PP (IN without) (NP (DT any) (NN tuning))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (PP (IN for) (NP (NP (JJ low) (NNS values)) (PP (IN of) (NP (NP (NN k) (CC and) (NN p)) (PP (IN in) (NP (NML (NML (JJ top) (HYPH -) (NN k)) (CC and) (NML (JJ top) (HYPH -) (NN p))) (NN sampling))))))) (, ,) (NP (NN perplexity)) (VP (VBZ drops) (ADVP (RB significantly)) (PP (IN with) (NP (NP (ADJP (VBN generated)) (NN text) (NN length)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADVP (RB also)) (VP (VBN correlated) (PP (IN with) (NP (NP (JJ excessive) (NNS repetitions)) (PP (IN in) (NP (NP (DT the) (NN text)) (-LRB- -LRB-) (NP (DT the) (NN boredom) (NN trap)) (-RRB- -RRB-))))))))))))))) (. .))
(S (PP (IN On) (NP (DT the) (JJ other) (NN hand))) (, ,) (PP (IN for) (NP (NP (JJ large) (NNS values)) (PP (IN of) (NP (NN k) (CC and) (NN p))))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (NP (NN perplexity) (NNS increases)) (PP (IN with))) (VP (VBN generated) (NP (NP (NN text) (NN length)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN correlated) (PP (IN with) (NP (NN incoherence))) (PP (IN in) (NP (DT the) (NN text)))))))) (PRN (-LRB- -LRB-) (NP (NN confusion) (NN trap)) (-RRB- -RRB-)))))) (. .))
(S (S (NP (NNP Mirostat)) (VP (VBZ avoids) (NP (DT both) (NNS traps)))) (: :) (S (NP (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NN cross-entropy)) (VP (VBZ has) (NP (NP (DT a) (NML (JJ near) (HYPH -) (JJ linear)) (NN relation)) (PP (IN with) (NP (NP (NN repetition)) (PP (IN in) (NP (ADJP (VBN generated)) (NN text))))))))))) (. .))
(S (NP (DT This) (NN relation)) (VP (VBZ is) (ADJP (ADJP (RB almost) (JJ independent) (PP (IN of) (NP (DT the) (NN sampling) (NN method)))) (CC but) (ADJP (RB slightly) (JJ dependent))) (PP (IN on) (NP (NP (DT the) (NN model)) (VP (VBN used))))) (. .))
(S (ADVP (RB Hence)) (, ,) (PP (IN for) (NP (DT a) (VBN given) (NN language) (NN model))) (, ,) (NP (NP (NN control)) (PP (IN over) (NP (NN perplexity)))) (ADVP (RB also)) (VP (VBZ gives) (NP (NP (NN control)) (PP (IN over) (NP (NNS repetitions))))) (. .))
