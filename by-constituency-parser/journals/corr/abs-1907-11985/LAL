(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NNP Wang-Landau) (NN algorithm)) (VP (MD can) (VP (VB be) (VP (VBN formulated) (PP (IN as) (NP (NP (DT a) (JJ stochastic) (NN gradient) (NN descent) (NN algorithm)) (VP (VBG minimizing) (NP (NP (DT a) (ADJP (JJ smooth) (CC and) (JJ convex)) (JJ objective) (NN function)) (, ,) (SBAR (WHPP (IN of) (WHNP (WDT which))) (S (NP (DT the) (NN gradient)) (VP (VBZ is) (VP (VBN estimated) (S (VP (VBG using) (NP (NNP Markov) (NN chain) (NNP Monte) (NNP Carlo) (NNS iterations)))))))))))))))))) (. .))
(S (NP (DT The) (NN optimization) (NN formulation)) (VP (VBZ provides) (NP (PRP us)) (NP (NP (DT a) (JJ new) (NN way)) (SBAR (S (VP (TO to) (VP (VB establish) (NP (NP (DT the) (NN convergence) (NN rate)) (PP (IN of) (NP (DT the) (NNP Wang-Landau) (NN algorithm)))) (, ,) (PP (IN by) (S (VP (VBG exploiting) (NP (DT the) (NN fact) (SBAR (IN that) (S (ADVP (RB almost) (RB surely)) (, ,) (NP (NP (DT the) (NN density) (NNS estimates)) (PRN (-LRB- -LRB-) (PP (IN on) (NP (DT the) (JJ logarithmic) (NN scale))) (-RRB- -RRB-))) (VP (VBP remain) (PP (IN in) (NP (NP (DT a) (JJ compact) (NN set)) (, ,) (SBAR (WHPP (IN upon) (WHNP (WDT which))) (S (NP (DT the) (NN objective) (NN function)) (VP (VBZ is) (ADJP (RB strongly) (JJ convex)))))))))))))))))))) (. .))
(S (NP (DT The) (NN optimization) (NN viewpoint)) (VP (VBZ motivates) (S (NP (PRP us)) (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN efficiency)) (PP (IN of) (NP (DT the) (NNP Wang-Landau) (NN algorithm)))) (S (VP (VBG using) (NP (NP (JJ popular) (NNS tools)) (PP (VBG including) (NP (NP (DT the) (NN momentum) (NN method)) (CC and) (NP (DT the) (JJ adaptive) (NN learning) (NN rate) (NN method))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (DT the) (JJ accelerated) (NNP Wang-Landau) (NN algorithm)) (PP (IN on) (NP (NP (DT a) (JJ two-dimensional) (NNP Ising) (NN model)) (CC and) (NP (DT a) (JJ two-dimensional) (JJ ten-state) (NNP Potts) (NN model))))) (. .))
