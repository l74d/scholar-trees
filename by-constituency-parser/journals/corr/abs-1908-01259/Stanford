(S (PP (IN In) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (JJ deep) (JJ neural) (NNS networks))) (, ,) (NP (NP (DT both) (NN feature) (NN normalization)) (CC and) (NP (NN feature) (NN attention))) (VP (VBP have) (VP (VBN become) (S (ADJP (JJ ubiquitous))) (PP (IN with) (NP (NP (JJ significant) (NN performance) (NN improvement)) (VP (VBN shown) (PP (IN in) (NP (NP (DT a) (JJ vast) (NN amount)) (PP (IN of) (NP (NNS tasks)))))))))) (. .))
(S (NP (PRP They)) (VP (VBP are) (ADVP (RB usually)) (VP (VBN studied) (PP (IN as) (NP (JJ separate) (NNS modules))) (, ,) (ADVP (RB however)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP propose) (NP (DT a) (NML (NN light) (HYPH -) (NN weight)) (NN integration)) (PP (IN between))) (, ,) (CC and) (ADVP (RB thus)) (VP (PP (NN harness) (PP (NP (DT the) (JJS best)) (IN of))) (, ,) (NP (DT the) (CD two) (NN schema)))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (NP (JJ Attentive) (NN Normalization)) (NP (-LRB- -LRB-) (DT AN) (-RRB- -RRB-))) (SBAR (WHNP (WDT which)) (S (VP (VBZ generalizes) (NP (NP (DT the) (JJ common) (NN affine) (NN transformation) (NN component)) (PP (IN in) (NP (DT the) (NML (NN vanilla) (NN feature)) (NN normalization))))))))) (. .))
(S (PP (RB Instead) (IN of) (S (VP (VBG learning) (NP (DT a) (JJ single) (NN affine) (NN transformation))))) (, ,) (NP (DT AN) (SBAR (S (VP (VP (VBZ learns) (NP (NP (DT a) (NN mixture)) (PP (IN of) (NP (JJ affine) (NNS transformations))))) (CC and) (VP (VBZ utilizes) (NP (PRP$ their) (JJ weighted) (HYPH -) (NN sum)) (PP (IN as) (NP (DT the) (JJ final) (JJ affine) (NN transformation)))))))) (VP (VBD applied) (PP (IN to) (NP (NN re-calibrate) (NNS features))) (PP (IN in) (NP (ADJP (NP (DT an) (NN instance)) (HYPH -) (JJ specific)) (NN way)))) (. .))
(S (NP (DT The) (NNS weights)) (VP (VBP are) (VP (VBN learned) (PP (IN by) (S (VP (VBG leveraging) (NP (NN feature) (NN attention))))))) (. .))
(S (NP (DT AN)) (VP (VBZ introduces) (NP (NP (JJ negligible) (JJ extra) (NNS parameters)) (CC and) (NP (JJ computational) (NN cost))) (PRN (-LRB- -LRB-) (ADVP (FW i.e.)) (, ,) (NP (NN light) (HYPH -) (NN weight)) (-RRB- -RRB-))) (. .))
(NP (NP (DT AN) (NML (S (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN as) (NP (NP (DT a) (NN drop)) (HYPH -) (PP (IN in) (NP (NN replacement))))) (PP (IN for) (NP (DT any) (NN feature) (NN normalization)))))))) (NN technique)) (SBAR (WHNP (WDT which)) (S (VP (VBZ includes) (NP (DT the) (JJ affine) (NN transformation) (NN component))))) (. .))
(S (PP (IN In) (NP (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP test) (NP (DT the) (VBN proposed)) (S (NP (NP (DT AN) (NML (S (VP (VBG using) (NP (NP (NP (CD three) (JJ representative) (JJ neural) (NNS architectures)) (-LRB- -LRB-) (NP (NP (NNPS ResNets)) (, ,) (NP (NP (NNPS MobileNets)) (HYPH -) (NP (NN v2) (CC and) (NNS AOGNets)))) (-RRB- -RRB-)) (PP (IN in) (NP (NP (DT the) (NML (NML (NNP ImageNet) (HYPH -) (CD 1000)) (NN classification)) (NN benchmark)) (CC and) (NP (DT the) (NML (NN MS) (HYPH -) (NN COCO)) (CD 2107) (NN object)))))))) (NN detection)) (CC and) (NP (NN instance) (NN segmentation) (NN benchmark))))) (. .))
(FRAG (NP (NP (DT AN) (NML (S (VP (VBZ obtains) (NP (NP (JJ consistent) (NN performance) (NN improvement)) (PP (IN for) (NP (NP (JJ different) (JJ neural) (NNS architectures)) (PP (IN in) (NP (NP (DT both) (NNS benchmarks)) (PP (IN with) (NP (NP (JJ absolute) (NN increase)) (PP (IN of) (NP (NML (JJ top) (HYPH -) (CD 1)) (NN accuracy)))))))))) (PP (IN in) (NP (NP (NNP ImageNet) (HYPH -) (CD 1000)) (PP (IN between) (NP (NP (QP (CD 0.5) (NN %) (CC and) (CD 2.0) (NN %))) (, ,) (CC and) (NP (NP (JJ absolute) (NN increase)) (PP (IN up) (NP (QP (IN to) (CD 1.8) (NN %) (CC and) (CD 2.2) (NN %))))))))) (PP (IN for) (S (VP (VBG bounding) (NP (NN box) (CC and) (NN mask)))))))) (NN AP)) (PP (IN in) (NP (NNP MS) (HYPH -) (NNP COCO)))) (ADVP (RB respectively)) (. .))
