(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT a) (ADJP (JJ simple) (CC and) (JJ generic)) (NN framework)) (SBAR (S (VP (TO to) (VP (VB tackle) (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (VBG learning) (NP (NN model) (NNS parameters)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT a) (NN fraction)) (PP (IN of) (NP (DT the) (NN training) (NNS samples)))) (VP (VBP are) (VP (VBN corrupted))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB first)) (VP (VB make) (NP (NP (DT a) (JJ simple) (NN observation)) (: :) (S (PP (IN in) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (JJ such) (NNS settings))))) (, ,) (NP (NP (DT the) (NN evolution)) (PP (IN of) (NP (VBG training) (NN accuracy))) (PRN (-LRB- -LRB-) (PP (IN as) (NP (NP (DT a) (NN function)) (PP (IN of) (NP (VBG training) (NN epochs))))) (-RRB- -RRB-))) (VP (VBZ is) (ADJP (JJ different)) (PP (IN for) (NP (ADJP (JJ clean) (CC and) (JJ bad)) (NNS samples))))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (DT this)))) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (ADVP (RB iteratively)) (VB minimize) (NP (DT the) (JJ trimmed) (NN loss)) (, ,) (PP (IN by) (S (VP (VBG alternating) (PP (IN between) (NP (S (VP (PRN (-LRB- -LRB-) (DT a) (-RRB- -RRB-)) (VP (NN selecting) (NP (NP (NNS samples)) (PP (IN with) (NP (JJ lowest) (JJ current) (NN loss))))))) (, ,) (CC and) (VP (PRN (-LRB- -LRB-) (NN b) (-RRB- -RRB-)) (VP (VBG retraining) (NP (DT a) (NN model)) (PP (IN on) (NP (JJ only) (DT these) (NNS samples)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (DT this) (NN process)) (VP (VBZ recovers) (NP (DT the) (NN ground) (NN truth)) (PRN (-LRB- -LRB-) (PP (IN with) (NP (JJ linear) (NN convergence) (NN rate))) (-RRB- -RRB-)) (PP (IN in) (NP (NP (VBN generalized) (JJ linear) (NNS models)) (PP (IN with) (NP (JJ standard) (JJ statistical) (NNS assumptions))))))))) (. .))
(S (ADVP (RB Experimentally)) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (PRP$ its) (NN effectiveness)) (PP (IN in) (NP (NP (CD three) (NNS settings)) (: :) (NP (NP (NP (LST (-LRB- -LRB-) (DT a) (-RRB- -RRB-)) (NP (JJ deep) (NN image) (NNS classifiers))) (PP (IN with) (NP (NP (NNS errors)) (PP (ADVP (RB only)) (IN in) (NP (NNS labels)))))) (, ,) (NP (NP (PRN (-LRB- -LRB-) (NN b) (-RRB- -RRB-)) (NP (VBP generative) (JJ adversarial) (NNS networks))) (PP (IN with) (NP (JJ bad) (NN training) (NNS images)))) (, ,) (CC and) (NP (LST (-LRB- -LRB-) (NN c) (-RRB- -RRB-)) (NP (NP (JJ deep) (NN image) (NNS classifiers)) (PP (IN with) (NP (NP (JJ adversarial) (-LRB- -LRB-) (NN image) (, ,) (NN label) (-RRB- -RRB-) (NN pairs)) (PRN (-LRB- -LRB-) (FW i.e.) (, ,) (NP (JJ backdoor) (NNS attacks)) (-RRB- -RRB-)))))))))) (. .))
(S (PP (IN For) (NP (NP (DT the) (JJ well-studied) (NN setting)) (PP (IN of) (NP (NN random) (NN label) (NN noise))))) (, ,) (NP (PRP$ our) (JJ algorithm)) (VP (NNS achieves) (NP (JJ state-of-the-art) (NN performance)) (PP (IN without) (S (VP (VBG having) (NP (NP (NN access)) (PP (TO to) (NP (DT any) (JJ a-priori) (JJ guaranteed) (JJ clean) (NNS samples)))))))) (. .))
