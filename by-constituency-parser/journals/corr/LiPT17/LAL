(S (NP (NP (NNP Sparse) (NNS methods)) (CC and) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NNP Winograd) (NNS convolutions))))) (VP (VBP are) (NP (NP (CD two) (JJ orthogonal) (NNS approaches)) (, ,) (SBAR (WHNP (NP (DT each)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (ADVP (RB significantly)) (VBZ accelerates) (NP (NP (NN convolution) (NNS computations)) (PP (IN in) (NP (JJ modern) (NNP CNNs))))))))) (. .))
(S (NP (NNP Sparse) (NNP Winograd)) (VP (VP (VBZ merges) (NP (DT these) (CD two))) (CC and) (VP (ADVP (RB thus)) (VBZ has) (NP (DT the) (JJ potential) (S (VP (TO to) (VP (VB offer) (NP (DT a) (JJ combined) (NN performance) (NN benefit)))))))) (. .))
(S (ADVP (RB Nevertheless)) (, ,) (S (VP (VBG training) (NP (NN convolution) (NNS layers)) (SBAR (RB so) (IN that) (S (NP (DT the) (VBG resulting) (NNP Winograd) (NNS kernels)) (VP (VBP are) (ADJP (NN sparse))))))) (VP (VBZ has) (RB not) (ADVP (VBN hitherto)) (VP (VBN been) (ADJP (RB very) (JJ successful)))) (. .))
(S (PP (IN By) (S (VP (VBG introducing) (NP (DT a) (NNP Winograd) (NN layer)) (PP (IN in) (NP (NP (NN place)) (PP (IN of) (NP (DT a) (JJ standard) (NN convolution) (NN layer)))))))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VP (VB learn) (CC and) (VB prune) (NP (NNP Winograd) (NNS coefficients)) (`` ``) (ADVP (RB natively)) ('' '')) (CC and) (VP (VP (VB obtain) (NP (NP (NN sparsity) (NN level)) (PP (IN beyond) (NP (CD 90) (NN %)))) (PP (IN with) (NP (ADJP (QP (RB only) (CD 0.1)) (NN %)) (NN accuracy) (NN loss)))) (PP (IN with) (NP (NP (NNP AlexNet)) (PP (IN on) (NP (NNP ImageNet) (NN dataset)))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (NN sparse) (NNP Winograd) (NN convolution) (NN algorithm) (CC and) (NN implementation)) (SBAR (WHNP (IN that)) (S (VP (VBZ exploits) (NP (DT the) (NN sparsity)) (, ,) (S (VP (VBG achieving) (NP (QP (RP up) (TO to) (CD 31.7)) (JJ effective) (NNP TFLOP/s)) (PP (IN in) (NP (JJ 32-bit) (NN precision))) (PP (IN on) (NP (DT a) (JJS latest) (NNP Intel) (NNP Xeon) (NNP CPU))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ corresponds) (PP (TO to) (NP (NP (DT a) (CD 5.4x) (NN speedup)) (PP (IN over) (NP (DT a) (JJ state-of-the-art) (NN dense) (NN convolution) (NN implementation))))))))))))))) (. .))
