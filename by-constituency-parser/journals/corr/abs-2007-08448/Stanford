(S (NP (PRP We)) (VP (VBP study) (NP (NP (NML (NN bandit) (NN convex)) (NN optimization) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP adapt) (PP (IN to) (NP (NP (DT the) (NN norm)) (PP (IN of) (NP (NP (DT the) (NN comparator)) (, ,) (NP (NP (DT a) (NN topic)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (ADVP (RB only)) (VP (VBN been) (VP (VBN studied) (PP (IN before) (PP (IN for) (NP (PRP$ its) (NML (JJ full) (HYPH -) (NN information)) (NN counterpart))))))))))))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NN convex) (NN bandit) (NNS algorithms)) (PP (IN with) (NP (NP (NN regret) (NNS bounds)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ small)) (SBAR (WHADVP (WRB whenever)) (S (NP (NP (DT the) (NN norm)) (PP (IN of) (NP (DT the) (NN comparator)))) (VP (VBZ is) (ADJP (JJ small))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB first)) (VP (VBP use) (NP (NNS techniques)) (PP (IN from) (NP (DT the) (NML (JJ full) (HYPH -) (NN information)) (NN setting))) (S (VP (TO to) (VP (VB develop) (NP (NP (NN comparator) (HYPH -) (JJ adaptive) (NNS algorithms)) (PP (IN for) (NP (JJ linear) (NNS bandits)))))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (PRP we)) (VP (VBP extend) (NP (DT the) (NNS ideas)) (PP (IN to) (NP (NP (NN convex) (NNS bandits)) (PP (IN with) (NP (NP (NNP Lipschitz)) (CC or) (NP (JJ smooth) (NN loss) (NNS functions)))))) (, ,) (S (VP (VBG using) (NP (NP (DT a) (JJ new) (NML (JJ single) (HYPH -) (NN point)) (NN gradient) (NN estimator)) (CC and) (NP (ADJP (RB carefully) (VBN designed)) (JJ surrogate) (NNS losses)))))) (. .))
