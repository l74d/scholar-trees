(S (PP (IN In) (S (VP (VBG seeking) (PP (IN for) (NP (ADJP (JJ sparse) (CC and) (JJ efficient)) (NML (JJ neural) (NN network)) (NNS models)))))) (, ,) (NP (JJ many) (JJ previous) (NNS works)) (VP (VBN investigated) (PP (IN on) (S (VP (VBG enforcing) (NP (NN L1) (CC or) (NN L0) (NNS regularizers)) (S (VP (TO to) (VP (VB encourage) (NP (NN weight) (NN sparsity)) (PP (IN during) (NP (NN training)))))))))) (. .))
(S (S (NP (DT The) (NN L0) (NN regularizer)) (VP (VP (VBZ measures) (NP (DT the) (NN parameter) (NN sparsity)) (ADVP (RB directly))) (CC and) (VP (VBZ is) (ADJP (JJ invariant) (PP (IN to) (NP (NP (DT the) (NN scaling)) (PP (IN of) (NP (NN parameter) (NNS values))))))))) (, ,) (CC but) (S (NP (PRP it)) (VP (VP (MD can) (RB not) (VP (VB provide) (NP (JJ useful) (NNS gradients)))) (, ,) (CC and) (ADVP (RB therefore)) (VP (VBZ requires) (NP (JJ complex) (NN optimization) (NNS techniques))))) (. .))
(S (NP (DT The) (NN L1) (NN regularizer)) (VP (VP (VBZ is) (ADVP (RB almost) (RB everywhere)) (ADJP (JJ differentiable))) (CC and) (VP (MD can) (VP (VB be) (ADVP (RB easily)) (VP (VBN optimized) (PP (IN with) (NP (NN gradient) (NN descent))))))) (. .))
(S (CC Yet) (NP (PRP it)) (VP (VBZ is) (RB not) (ADJP (NN scale) (HYPH -) (JJ invariant)) (, ,) (S (VP (VBG causing) (NP (DT the) (JJ same) (NN shrinking) (NN rate)) (PP (IN to) (NP (NP (DT all) (NNS parameters)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ inefficient) (PP (IN in) (NP (VBG increasing) (NN sparsity)))))))))))) (. .))
(S (S (VP (VBN Inspired) (PP (IN by) (NP (NP (NP (DT the) (NNP Hoyer) (NN measure)) (-LRB- -LRB-) (NP (NP (DT the) (NN ratio)) (PP (IN between) (NP (NN L1) (CC and) (NN L2) (NNS norms)))) (-RRB- -RRB-)) (VP (VBN used) (PP (IN in) (NP (JJ traditional) (ADJP (JJ compressed) (S (VP (VBG sensing)))) (NNS problems)))))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NNP DeepHoyer)) (, ,) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (ADJP (NN sparsity) (HYPH -) (VBG inducing)) (NNS regularizers)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (ADJP (NP (DT both) (JJ differentiable)) (ADVP (RB almost) (RB everywhere))) (CC and) (ADJP (NN scale) (HYPH -) (JJ invariant))))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG enforcing) (NP (NNP DeepHoyer) (NNS regularizers)))) (VP (MD can) (VP (VB produce) (NP (ADJP (RB even) (JJR sparser)) (JJ neural) (NN network) (NNS models)) (PP (IN than) (NP (JJ previous) (NNS works))) (, ,) (PP (IN under) (NP (DT the) (JJ same) (NN accuracy) (NN level)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP DeepHoyer)) (VP (MD can) (VP (VB be) (VP (VBN applied) (PP (IN to) (NP (NP (DT both) (NN element-wise)) (CC and) (NP (JJ structural) (NN pruning)))))))))) (. .))
