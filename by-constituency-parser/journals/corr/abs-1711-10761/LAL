(S (NP (JJ Previous) (NN work)) (VP (VBZ has) (VP (VBN shown) (SBAR (IN that) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (JJ possible)) (S (VP (TO to) (VP (VB train) (NP (JJ deep) (JJ neural) (NNS networks)) (PP (IN with) (NP (ADJP (JJ low) (NN precision)) (NNS weights) (CC and) (NNS activations))))))))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ extreme) (NN case))) (NP (NP (PRP it))) (VP (VBZ is) (ADVP (RB even)) (ADJP (JJ possible)) (S (VP (TO to) (VP (VB constrain) (NP (DT the) (NN network)) (PP (TO to) (NP (VB binary) (NNS values))))))) (. .))
(S (NP (DT The) (JJ costly) (VBG floating) (NN point) (NNS multiplications)) (VP (VBP are) (ADVP (RB then)) (VP (VBN reduced) (PP (TO to) (NP (VB fast) (JJ logical) (NNS operations))))) (. .))
(S (S (NP (NP (JJ High) (NN end) (JJ smart) (NNS phones)) (PP (JJ such) (IN as) (NP (NP (NP (NNP Google) (POS 's)) (NNP Pixel) (CD 2)) (CC and) (NP (NP (NNP Apple) (POS 's)) (NN iPhone) (NN X))))) (VP (VBP are) (ADVP (RB already)) (VP (VBN equipped) (PP (IN with) (NP (NP (JJ specialised) (NN hardware)) (PP (IN for) (NP (NN image) (NN processing)))))))) (CC and) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (RB very) (JJ likely)) (SBAR (IN that) (S (NP (JJ other) (JJ future) (NN consumer) (NN hardware)) (VP (MD will) (ADVP (RB also)) (VP (VB have) (NP (NP (VBN dedicated) (NNS accelerators)) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (JJ Binary) (JJ neural) (NNS networks)) (VP (VBP are) (ADJP (JJ attractive)) (PP (IN in) (NP (DT this) (NN case))) (SBAR (IN because) (S (NP (DT the) (JJ logical) (NNS operations)) (VP (VBP are) (ADJP (RB very) (RB fast) (CC and) (JJ efficient)) (SBAR (WHADVP (WRB when)) (S (VP (VBN implemented) (PP (IN in) (NP (NN hardware)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (ADJP (NN transfer) (NN learning) (VBN based)) (NN architecture)) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VP (ADVP (RB first)) (VBP train) (NP (DT a) (JJ binary) (NN network)) (PP (IN on) (NP (NNP Imagenet)))) (CC and) (VP (ADVP (RB then)) (VB retrain) (NP (NP (NN part)) (PP (IN of) (NP (DT the) (NN network)))) (PP (IN for) (NP (JJ different) (NNS tasks))) (SBAR (IN while) (S (VP (VBG keeping) (S (NP (NP (JJS most)) (PP (IN of) (NP (DT the) (NN network)))) (ADJP (VBN fixed)))))))))))) (. .))
(S (NP (DT The) (JJ fixed) (JJ binary) (NN part)) (VP (MD could) (VP (VB be) (VP (VBN implemented) (PP (IN in) (NP (DT a) (NN hardware) (NN accelerator))) (SBAR (IN while) (S (NP (NP (DT the) (JJ last) (NNS layers)) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBP are) (VP (VBN evaluated) (PP (IN in) (NP (NN software)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT a) (JJ single) (JJ binary) (JJ neural) (NN network)) (VP (VBN trained) (PP (IN on) (NP (DT the) (NNP Imagenet) (NN dataset))))) (VP (MD can) (ADVP (RB indeed)) (VP (VB be) (VP (VBN used) (PP (IN as) (NP (DT a) (NN feature) (NN extractor))) (PP (IN for) (NP (JJ other) (NNS datasets))))))))) (. .))
