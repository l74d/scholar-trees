(S (NP (NP (DT The) (NN learning) (NN speed)) (PP (IN of) (NP (NML (NN feed) (HYPH -) (JJ forward)) (JJ neural) (NNS networks)))) (VP (VP (VBZ is) (ADJP (RB notoriously) (JJ slow))) (CC and) (VP (VBZ has) (VP (VBN presented) (NP (NP (DT a) (NN bottleneck)) (PP (IN in) (NP (NML (JJ deep) (NN learning)) (NNS applications)))) (PP (IN for) (NP (JJ several) (NNS decades)))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (NP (NP (ADJP (NP (NN gradient)) (HYPH -) (VBN based)) (NN learning) (NNS algorithms)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN used) (ADVP (RB extensively)) (S (VP (TO to) (VP (VB train) (NP (JJ neural) (NNS networks))))))))) (, ,)) (VP (VBP tend) (S (VP (TO to) (VP (VB work) (ADVP (RB slowly)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT all)) (PP (IN of) (NP (DT the) (NN network) (NNS parameters)))) (VP (MD must) (VP (VB be) (ADJP (RB iteratively) (VBN tuned)))))))))) (. .))
(UCP (S (VP (TO To) (VP (VB counter) (NP (DT this))))) (, ,) (CC both) (S (NP (NNS researchers) (CC and) (NNS practitioners)) (VP (VBP have) (VP (VBN tried) (S (VP (VBG introducing) (NP (NN randomness)) (S (VP (TO to) (VP (VB reduce) (NP (DT the) (NN learning) (NN requirement)))))))))) (. .))
(S (S (PP (VBN Based) (PP (IN on) (NP (NP (DT the) (JJ original) (NN construction)) (PP (IN of) (NP (NNP Igelnik) (CC and) (NNP Pao)))))) (, ,) (NP (NP (NML (JJ single) (NN layer)) (NML (NML (NML (JJ neural) (HYPH -) (NNS networks)) (PP (IN with) (NP (JJ random) (NN input)))) (HYPH -) (SBAR (IN to) (HYPH -) (FRAG (VP (VBN hidden))))) (NN layer) (NNS weights)) (CC and) (NP (NNS biases))) (VP (VBP have) (VP (VBN seen) (NP (NN success)) (PP (IN in) (NP (NN practice)))))) (, ,) (CC but) (S (NP (DT the) (JJ necessary) (JJ theoretical) (NN justification)) (VP (VBZ is) (VP (VBG lacking)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP begin) (S (VP (TO to) (VP (VB fill) (NP (DT this) (JJ theoretical) (NN gap)))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VBP extend) (NP (DT this) (NN result)) (PP (IN to) (NP (DT the) (JJ non-asymptotic) (NN setting))) (, ,) (S (VP (VBG proving) (SBAR (IN that) (S (NP (PRP one)) (VP (MD can) (VP (VB achieve) (SBAR (S (NP (NP (DT any) (VBN desired) (NN approximation) (NN error)) (PP (IN with) (NP (JJ high) (NN probability)))) (VP (VBD provided) (NP (NP ($ $)) (SBAR (S (NP (NP (NN n)) (NP ($ $))) (VP (VBZ is) (ADJP (RB sufficiently) (JJ large)))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VBP adapt) (NP (DT this) (VBN randomized) (NML (JJ neural) (NN network)) (NN architecture) (S (VP (TO to) (VP (VB approximate) (NP (NNS functions)) (PP (IN on) (NP (NP (JJ smooth) (, ,) (JJ compact) (NNS submanifolds)) (PP (IN of) (NP (NNP Euclidean) (NN space))))))))) (, ,) (S (VP (VBG providing) (NP (JJ theoretical) (NNS guarantees)) (PP (IN in) (NP (CC both) (DT the) (ADJP (JJ asymptotic) (CC and) (JJ non-asymptotic)) (NNS forms)))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP illustrate) (NP (PRP$ our) (NNS results)) (PP (IN on) (NP (NP (NNS manifolds)) (PP (IN with) (NP (JJ numerical) (NNS experiments)))))) (. .))
