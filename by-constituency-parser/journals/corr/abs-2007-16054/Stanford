(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP present) (NP (DT an) (NML (NML (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN meta)))) (HYPH -) (VP (VBN learned) (NP (NN system)) (PP (IN for) (NP (NN image))))) (NN compression)))) (. .))
(S (NP (JJ Traditional) (NN machine) (NN learning)) (VP (VBN based) (NP (NNS approaches)) (PP (IN to) (NP (NP (NN image) (NN compression) (NN train) (CD one)) (CC or) (NP (JJR more) (JJ neural) (NN network)))) (PP (IN for) (NP (NN generalization) (NN performance)))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN at) (NP (NN inference) (NN time))) (, ,) (NP (NP (DT the) (NN encoder)) (CC or) (NP (NP (DT the) (JJ latent) (NN tensor) (NN output)) (PP (IN by) (NP (DT the) (NN encoder))))) (VP (MD can) (VP (VB be) (VP (VBN optimized) (PP (IN for) (NP (DT each) (NN test) (NN image)))))) (. .))
(S (NP (DT This) (NN optimization)) (VP (MD can) (VP (VB be) (VP (VBN regarded) (PP (IN as) (NP (NP (DT a) (NN form)) (PP (IN of) (NP (NP (NN adaptation)) (CC or) (NP (JJ benevolent) (NN overfitting)))))) (PP (IN to) (NP (DT the) (NN input) (NN content)))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN gap)) (PP (IN between) (NP (NML (NN training) (CC and) (NN inference)) (NNS conditions))))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (JJ new) (NN training) (NN paradigm)) (PP (IN for) (S (VP (VBN learned) (NP (NP (NN image) (NN compression)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (NN meta) (HYPH -) (NN learning)))))))))))) (. .))
(S (PP (IN In) (NP (DT a) (JJ first) (NN phase))) (, ,) (NP (DT the) (JJ neural) (NNS networks)) (VP (VBP are) (VP (VBN trained) (ADVP (RB normally)))) (. .))
(S (PP (IN In) (NP (DT a) (JJ second) (NN phase))) (, ,) (NP (DT the) (NML (NML (NP (NNP Model)) (PP (HYPH -) (NP (NNP Agnostic) (NNP Meta)))) (HYPH -) (NML (VBG learning))) (NN approach)) (VP (VBZ is) (VP (VBN adapted) (PP (IN to) (NP (NP (DT the) (JJ specific) (NN case)) (PP (IN of) (NP (NN image) (NN compression))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NML (JJ inner) (HYPH -) (NN loop))) (VP (VBZ performs) (NP (NP (NP (JJ latent) (NN tensor) (NN overfitting)) (, ,) (CC and) (NP (DT the) (JJ outer) (NN loop) (NNS updates))) (CC both) (NP (NML (NN encoder) (CC and) (NN decoder)) (JJ neural) (NNS networks))) (PP (VBN based) (PP (IN on) (NP (DT the) (NN overfitting) (NN performance))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (PP (IN after) (NP (NN meta) (HYPH -) (NN learning))) (, ,) (NP (PRP we)) (VP (VP (VBP propose) (PP (IN to) (NP (NN overfit)))) (CC and) (VP (VBP cluster) (NP (NP (DT the) (NN bias) (NNS terms)) (PP (IN of) (NP (NP (DT the) (NN decoder)) (PP (IN on) (NP (NN training) (NN image) (NNS patches))))))) (, ,) (SBAR (IN so) (IN that) (S (PP (IN at) (NP (NN inference) (NN time))) (NP (DT the) (JJ optimal) (ADJP (NN content) (HYPH -) (JJ specific)) (NN bias) (NNS terms)) (VP (MD can) (VP (VB be) (VP (VBN selected) (PP (IN at) (NP (NN encoder) (HYPH -) (NN side))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (JJ new) (NN probability) (NN model)) (PP (IN for) (NP (NP (JJ lossless) (NN compression)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ combines) (NP (NP (NNS concepts)) (PP (IN from) (NP (DT both) (ADJP (JJ multi-scale) (CC and) (JJ super-resolution)) (NML (NN probability) (NN model)) (NNS approaches)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (NP (NP (PDT all)) (NP (NP (PRP$ our) (VBN proposed) (NNS ideas)) (PP (IN via) (NP (ADJP (RB carefully) (VBN designed)) (NNS experiments)))))))) (. .))
