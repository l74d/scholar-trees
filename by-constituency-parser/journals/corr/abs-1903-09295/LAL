(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NP (JJ Deep) (NNP Q-Networks)) (PRN (-LRB- -LRB-) (NP (NNP DQN)) (-RRB- -RRB-)) (PP (IN with) (NP (JJ model-based) (NN exploration)))) (, ,) (NP (NP (DT an) (NN algorithm)) (VP (VBG combining) (NP (ADJP (DT both) (JJ model-free) (CC and) (JJ model-based)) (NNS approaches))) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ explores) (ADVP (JJR better))) (CC and) (VP (VBZ learns) (NP (NP (NNS environments)) (PP (IN with) (NP (JJ sparse) (NNS rewards)))) (ADVP (RBR more) (RB efficiently))))))))) (. .))
(S (NP (NNP DQN)) (VP (VP (VBZ is) (NP (DT a) (JJ general-purpose) (, ,) (JJ model-free) (NN algorithm))) (CC and) (VP (VBZ has) (VP (VBN been) (VP (VBN proven) (S (VP (TO to) (VP (VB perform) (ADVP (RB well)) (PP (IN in) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS tasks))) (PP (VBG including) (NP (NNP Atari) (CD 2600) (NNS games)))))))) (SBAR (IN since) (S (NP (PRP it)) (VP (VBZ 's) (ADVP (RB first)) (VP (VBN proposed) (PP (IN by) (NP (NNP Minh) (CC et) (NN el))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN like) (NP (JJ many) (JJ other) (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NNP RL) (-RRB- -RRB-)) (NN algorithms))) (, ,) (NP (NNP DQN)) (VP (NNS suffers) (PP (IN from) (NP (JJ poor) (NN sample) (NN efficiency))) (SBAR (WHADVP (WRB when)) (S (NP (NNS rewards)) (VP (VBP are) (ADJP (VBN sparse)) (PP (IN in) (NP (DT an) (NN environment))))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (NP (NP (JJS most)) (PP (IN of) (NP (NP (DT the) (NNS transitions)) (VP (VBN stored) (PP (IN in) (NP (DT the) (NN replay) (NN memory))))))) (VP (VP (VBP have) (NP (DT no) (JJ informative) (NN reward) (NN signal))) (, ,) (CC and) (VP (RB provide) (NP (VBD limited) (NN value)) (PP (TO to) (NP (NP (DT the) (NN convergence) (CC and) (NN training)) (PP (IN of) (NP (DT the) (NNP Q-Network))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (CD one) (NN insight)) (VP (VBZ is) (SBAR (IN that) (S (NP (DT these) (NNS transitions)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB learn) (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (DT the) (NN environment)))) (PP (IN as) (NP (DT a) (JJ supervised) (NN learning) (NN problem)))))))))))) (. .))
(S (NP (DT The) (NNS transitions)) (ADVP (RB also)) (VP (VBP provide) (NP (NP (NN information)) (PP (IN of) (NP (NP (DT the) (NN distribution)) (PP (IN of) (NP (JJ visited) (NNS states))))))) (. .))
(S (NP (PRP$ Our) (NN algorithm)) (VP (VBZ utilizes) (NP (DT these) (CD two) (NNS observations)) (S (VP (TO to) (VP (VB perform) (NP (DT a) (JJ one-step) (NN planning)) (PP (IN during) (NP (NN exploration))) (S (VP (TO to) (VP (VB pick) (NP (NP (DT an) (NN action)) (SBAR (WHNP (WDT that)) (S (VP (VBZ leads) (PP (TO to) (NP (NP (NNS states)) (ADJP (RBR least) (JJ likely) (S (VP (TO to) (VP (VB be) (VP (VBN seen))))))))))))))) (, ,) (S (ADVP (RB thus)) (VP (VBG improving) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN exploration)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (PRP$ our) (NN agent) (POS 's)) (NN performance)) (PP (IN in) (NP (NP (NP (CD two) (JJ classic) (NNS environments)) (PP (IN with) (NP (JJ sparse) (NNS rewards))) (PP (IN in) (NP (NNP OpenAI) (NN gym)))) (: :) (NP (NP (NN Mountain) (NNP Car)) (CC and) (NP (NNP Lunar) (NNP Lander)))))) (. .))
