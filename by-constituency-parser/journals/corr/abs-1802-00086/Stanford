(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT a) (NN class)) (PP (IN of) (NP (NP (NNS algorithms)) (ADJP (ADJP (JJ capable) (PP (IN of) (S (ADVP (RB directly)) (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks)) (PP (IN with) (NP (NN respect))) (PP (IN to) (NP (NP (NP (JJ large) (NNS families)) (PP (IN of) (NP (NP (ADJP (NN task) (HYPH -) (JJ specific)) (NN performance) (NNS measures)) (PP (JJ such) (IN as) (NP (NP (DT the) (NN F) (HYPH -) (NN measure)) (CC and) (NP (DT the) (NML (NNP Kullback) (HYPH -) (NNP Leibler)) (NN divergence))))))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (VBN structured))))))))))) (CC and) (ADJP (JJ non-decomposable))))))) (. .))
(S (NP (DT This)) (VP (VBZ presents) (NP (DT a) (NN departure)) (PP (IN from) (NP (NP (JJ standard) (NML (JJ deep) (NN learning)) (NNS techniques)) (SBAR (WHNP (WDT that)) (S (ADVP (RB typically)) (VP (VBP use) (S (NP (NP (ADJP (JJ squared) (CC or) (JJ cross-entropy)) (NN loss) (NNS functions)) (-LRB- -LRB-) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ decomposable))))) (-RRB- -RRB-)) (VP (TO to) (VP (VB train) (NP (JJ neural) (NNS networks))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (S (ADVP (RB directly)) (VP (VBG training) (PP (IN with) (NP (ADJP (NN task) (HYPH -) (JJ specific)) (NN loss))))) (VP (VBZ functions) (NP (NNS yields)) (ADVP (RB much) (RBR faster) (CC and) (RBR more)) (NP-TMP (NP (JJ stable) (NN convergence)) (PP (IN across) (NP (NNS problems) (CC and) (NNS datasets)))))))) (. .))
(S (NP (NP (PRP$ Our) (VBN proposed) (NNS algorithms)) (CC and) (NP (NNS implementations))) (VP (VBP have) (NP (NP (JJ several) (JJ novel) (NNS features)) (PP (VBG including) (NP (NP (LST (-LRB- -LRB-) (LS i) (-RRB- -RRB-)) (NP (NN convergence)) (PP (PP (IN to) (NP (JJ first) (NN order))) (PP (NP (JJ stationary) (NNS points)) (IN despite) (S (VP (VBG optimizing) (NP (JJ complex) (JJ objective) (NNS functions))))))) (: ;) (NP (LST (-LRB- -LRB-) (LS ii) (-RRB- -RRB-)) (NP (NN use)) (PP (IN of) (NP (JJR fewer) (NN training) (NNS samples))) (S (VP (TO to) (VP (VB achieve) (NP (NP (NP (DT a) (VBN desired) (NN level)) (PP (IN of) (NP (NN convergence)))) (, ,) (NP (LST (-LRB- -LRB-) (LS iii) (-RRB- -RRB-)) (NP (DT a) (JJ substantial) (NN reduction)) (PP (IN in) (NP (NN training) (NN time)))) (, ,) (CC and) (NP (NP (-LRB- -LRB-) (NN iv) (-RRB- -RRB-)) (NP (NP (DT a) (JJ seamless) (NN integration)) (PP (IN of) (NP (PRP$ our) (NN implementation)))))) (PP (IN into) (NP (VBG existing) (JJ symbolic) (NN gradient) (NNS frameworks))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP implement) (NP (PRP$ our) (NNS techniques)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NP (JJ deep) (NNS architectures)) (PP (VBG including) (NP (NP (JJ multi-layer) (NNS perceptrons)) (CC and) (NP (ADJP (JJ recurrent)) (JJ neural) (NNS networks))))))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (PP (IN on) (NP (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NN benchmark)))) (CC and) (NP (NML (JJ real) (NNS data)) (NNS sets)))) (, ,) (NP (PRP$ our) (NNS algorithms)) (VP (VBP outperform) (NP (NP (NP (JJ traditional) (NNS approaches)) (PP (IN to) (NP (NN training) (JJ deep) (NNS networks)))) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NP (DT some) (JJ recent) (NNS approaches)) (PP (IN to) (NP (NP (ADJP (NN task) (HYPH -) (JJ specific)) (NN training)) (PP (IN of) (NP (JJ neural) (NNS networks)))))))))))) (. .))
