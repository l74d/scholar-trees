(S (PP (VBG Following) (NP (NP (DT the) (JJ recent) (NN work)) (PP (IN on) (NP (NN capacity) (NN allocation))))) (, ,) (NP (PRP we)) (VP (VBP formulate) (NP (DT the) (NN conjecture)) (SBAR (IN that) (S (NP (NP (DT the) (VBG shattering) (NN problem)) (PP (IN in) (NP (JJ deep) (JJ neural) (NNS networks)))) (VP (MD can) (ADVP (RB only)) (VP (VB be) (VP (VBN avoided) (SBAR (IN if) (S (NP (NP (DT the) (NN capacity) (NN propagation)) (PP (IN through) (NP (NNS layers)))) (VP (VBZ has) (NP (NP (DT a) (JJ non-degenerate) (JJ continuous) (NN limit)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS layers)))) (VP (VBZ tends) (PP (TO to) (NP (NN infinity)))))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VP (VB study) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (ADJP (RB commonly) (VBN used)) (NNS architectures))))) (CC and) (VP (VB determine) (SBAR (WHNP (WDT which)) (S (NP (NN scaling) (NNS relations)) (VP (MD should) (VP (VB be) (VP (VBN enforced) (PP (IN in) (NP (NN practice))) (SBAR (IN as) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS layers)))) (VP (VBZ grows) (ADJP (JJ large))))))))))))))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (S (NP (PRP we)) (VP (VBP recover) (NP (NP (DT the) (NNS conditions)) (PP (IN of) (NP (NNP Xavier) (NN initialization)))) (PP (IN in) (NP (DT the) (JJ multi-channel) (NN case))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (NNS weights) (CC and) (NNS biases)) (VP (MD should) (VP (VB be) (VP (VBN scaled) (PRT (RP down)) (PP (PP (IN as) (NP (NP (DT the) (JJ inverse) (JJ square) (NN root)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS layers)) (PP (IN for) (NP (JJ deep) (JJ residual) (NNS networks))))))))) (CC and) (PP (IN as) (NP (NP (DT the) (JJ inverse) (JJ square) (NN root)) (PP (IN of) (NP (NP (DT the) (VBN desired) (NN memory) (NN length)) (PP (IN for) (NP (ADJP (JJ recurrent)) (NNS networks))))))))))))))) (. .))
