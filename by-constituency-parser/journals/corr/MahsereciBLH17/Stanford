(S (S (ADVP (RB Early)) (VP (VBG stopping))) (VP (VBZ is) (NP (DT a) (ADJP (RB widely) (VBN used)) (NN technique) (S (VP (TO to) (VP (VB prevent) (NP (JJ poor) (NN generalization) (NN performance)) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (DT an) (JJ over-expressive) (NN model)) (PP (IN by) (NP (ADJP (NP (NP (NNS means)) (PP (IN of) (NP (NN gradient)))) (HYPH -) (VBN based)) (NN optimization))))))))))) (. .))
(S (S (VP (TO To) (VP (VB find) (NP (DT a) (JJ good) (NN point)) (S (VP (TO to) (VP (VB halt) (NP (DT the) (NN optimizer)))))))) (, ,) (NP (DT a) (JJ common) (NN practice)) (VP (VBZ is) (S (VP (TO to) (VP (VB split) (NP (DT the) (NN dataset)) (PP (IN into) (NP (NP (DT a) (NN training)) (CC and) (NP (DT a) (JJR smaller) (NN validation) (NN set)))) (S (VP (TO to) (VP (VB obtain) (NP (NP (DT an) (JJ ongoing) (NN estimate)) (PP (IN of) (NP (DT the) (NN generalization) (NN performance))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP propose) (NP (DT a) (JJ novel) (JJ early)) (S (VP (VBG stopping) (NP (NN criterion)) (PP (VBN based) (PP (IN on) (ADJP (JJ fast)))) (S (VP (HYPH -) (TO to) (HYPH -) (VP (VB compute) (NP (NP (JJ local) (NNS statistics)) (PP (IN of) (NP (DT the) (VBN computed) (NNS gradients)))))))))) (CC and) (VP (ADVP (RB entirely)) (VBZ removes) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (DT a) (ADJP (VBN held) (HYPH -) (RP out)) (NN validation) (NN set)))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this)) (VP (VBZ is) (NP (NP (DT a) (JJ viable) (NN approach)) (PP (IN in) (NP (NP (DT the) (NN setting)) (PP (IN of) (NP (NP (NP (JJS least)) (HYPH -) (NP (NNS squares))) (CC and) (NP (NP (JJ logistic) (NN regression)) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (JJ neural) (NNS networks)))))))))))) (. .))
