(S (NP (NN Deconvolution)) (VP (VBZ has) (VP (VBN been) (ADJP (JJ widespread)) (PP (IN in) (NP (JJ neural) (NNS networks))))) (. .))
(S (PP (IN For) (NP (NN example))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ essential) (PP (IN for) (S (VP (VP (VBG performing) (NP (JJ unsupervised) (NN learning)) (PP (IN in) (NP (JJ generative) (JJ adversarial) (NNS networks)))) (CC or) (VP (VBG constructing) (NP (NP (ADJP (RB fully) (JJ convolutional)) (NNS networks)) (PP (IN for) (NP (JJ semantic) (NN segmentation)))))))))) (. .))
(S (NP (ADJP (NP (NP (JJ Resistive) (NN RAM)) (-LRB- -LRB-) (NP (NN ReRAM))) (-RRB- -RRB-) (HYPH -) (VBN based)) (NML (NN processing) (HYPH -) (IN in) (HYPH -) (NN memory)) (NN architecture)) (VP (VP (VBZ has) (VP (VBN been) (ADVP (RB widely)) (VP (VBN explored) (PP (IN in) (S (VP (VBG accelerating) (NP (JJ convolutional) (NN computation)))))))) (CC and) (VP (VBZ demonstrates) (NP (JJ good) (NN performance)))) (. .))
(S (S (VP (VBG Performing) (NP (NN deconvolution)) (PP (IN on) (NP (ADJP (NP (VBG existing) (NN ReRAM)) (HYPH -) (VBN based)) (NN accelerator) (NNS designs))))) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ suffers) (PP (IN from) (NP (NP (JJ long) (NN latency)) (CC and) (NP (NML (JJ high) (NN energy)) (NN consumption)))) (SBAR (IN because) (S (NP (JJ deconvolutional) (NN computation)) (VP (VBZ includes) (NP (CONJP (RB not) (RB only)) (NP (NN convolution)) (CONJP (CC but) (RB also)) (NP (JJ extra) (ADJP (VB add) (HYPH -) (RP on)) (NNS operations))))))) (. .))
(FRAG (S (VP (TO To) (VP (VB realize) (NP (DT the) (ADJP (RBR more) (JJ efficient)) (NN execution)) (PP (IN for) (NP (NN deconvolution)))))) (, ,) (S (NP (PRP we)) (VP (VP (VBP analyze) (NP (PRP$ its) (NN computation) (NN requirement))) (CC and) (VP (VB propose) (NP (ADJP (NP (DT a) (NN ReRAM)) (HYPH -) (VBN based)) (NN accelerator) (NN design))))) (, ,) (FRAG (ADVP (RB namely)) (, ,) (NP (NN RED))) (. .))
(S (S (ADJP (RBR More) (JJ specific))) (, ,) (NP (NN RED)) (VP (VBZ integrates) (NP (NP (CD two) (JJ orthogonal) (NNS methods)) (, ,) (NP (NP (DT the) (JJ pixel-wise) (NN mapping) (NN scheme)) (PP (IN for) (S (VP (VBG reducing) (NP (NP (NN redundancy)) (VP (VBN caused) (PP (IN by) (NP (ADJP (NP (CD zero)) (HYPH -) (VBG inserting)) (NNS operations))))))))) (CC and) (NP (NP (DT the) (NML (CD zero) (HYPH -) (NN skipping)) (NN data) (NN flow)) (PP (IN for) (S (VP (VP (VBG increasing) (NP (DT the) (NN computation) (NN parallelism))) (CC and) (ADVP (RB therefore)) (VP (VBG improving) (NP (NN performance))))))))) (. .))
(S (NP (JJ Experimental) (NNS evaluations)) (VP (VBP show) (SBAR (IN that) (S (PP (VBN compared) (PP (IN to) (NP (DT the) (ADJP (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN ReRAM)) (HYPH -) (VBN based)) (NN accelerator)))) (, ,) (NP (NN RED)) (VP (MD can) (VP (VP (VB speed) (PRT (RP up)) (NP (NP (NN operation) (CD 3.69) (NN x)) (PP (SYM ~) (NP (CD 1.15) (NN x))))) (CC and) (VP (VB reduce) (NP (NML (CD 8) (NN %)) (NML (QP (SYM ~) (CD 88.36)) (NN %)) (NN energy) (NN consumption)))))))) (. .))
