(S (NP (NNP Transformer) (NNS networks)) (VP (VBP have) (VP (VBN lead) (PP (TO to) (NP (NP (JJ important) (NN progress)) (PP (IN in) (NP (NP (NN language) (NN modeling)) (CC and) (NP (NN machine) (NN translation)))))))) (. .))
(S (NP (DT These) (NNS models)) (VP (VBP include) (NP (NP (CD two) (JJ consecutive) (NNS modules)) (, ,) (NP (NP (DT a) (JJ feed-forward) (NN layer)) (CC and) (NP (DT a) (NN self-attention) (NN layer))))) (. .))
(S (NP (DT The) (JJ latter)) (VP (VP (VBZ allows) (S (NP (DT the) (NN network)) (VP (TO to) (VP (VB capture) (NP (ADJP (JJ long) (NN term)) (NNS dependencies)))))) (CC and) (VP (VBP are) (ADVP (RB often)) (VP (VBN regarded) (PP (IN as) (NP (NP (DT the) (JJ key) (NN ingredient)) (PP (IN in) (NP (NP (DT the) (NN success)) (PP (IN of) (NP (NNS Transformers)))))))))) (. .))
(S (S (VP (VBG Building) (PP (IN upon) (NP (DT this) (NN intuition))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN model)) (SBAR (WHNP (WDT that)) (S (ADVP (RB solely)) (VP (VBZ consists) (PP (IN of) (NP (NN attention) (NNS layers)))))))) (. .))
(S (ADVP (RBR More) (RB precisely)) (, ,) (NP (PRP we)) (VP (VBP augment) (NP (DT the) (NN self-attention) (NNS layers)) (PP (IN with) (NP (NP (JJ persistent) (NN memory) (NNS vectors)) (SBAR (WHNP (WDT that)) (S (VP (VBP play) (NP (NP (DT a) (JJ similar) (NN role)) (PP (IN as) (NP (DT the) (JJ feed-forward) (NN layer)))))))))) (. .))
(S (NP (NP (NNS Thanks)) (PP (TO to) (NP (DT these) (NNS vectors)))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB remove) (NP (DT the) (JJ feed-forward) (NN layer)) (PP (IN without) (S (VP (VBG degrading) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT a) (NN transformer))))))))) (. .))
(S (NP (PRP$ Our) (NN evaluation)) (VP (VBZ shows) (NP (NP (DT the) (NNS benefits)) (VP (VBN brought) (PP (IN by) (NP (PRP$ our) (NN model))) (PP (IN on) (NP (JJ standard) (NN character) (CC and) (NN word) (NN level) (NN language) (VBG modeling) (NNS benchmarks)))))) (. .))
