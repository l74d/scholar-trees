(S (NP (NP (JJ Deep) (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP DRL)) (-RRB- -RRB-))) (VP (VBZ has) (VP (VBN shown) (NP (NP (JJ incredible) (NN performance)) (PP (IN in) (S (VP (VBG learning) (NP (JJ various) (NNS tasks)) (PP (TO to) (NP (DT the) (JJ human) (NN level))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN unlike) (NP (JJ human) (NN perception))) (, ,) (NP (JJ current) (NNP DRL) (NNS models)) (VP (VBP connect) (NP (DT the) (JJ entire) (JJ low-level) (NN sensory) (NN input)) (PP (TO to) (NP (DT the) (NN state-action) (NNS values))) (PP (RB rather) (IN than) (S (VP (VBG exploiting) (NP (NP (DT the) (NN relationship)) (PP (IN between) (CC and) (IN among) (NP (NP (NNS entities)) (SBAR (WHNP (WDT that)) (S (VP (VBP constitute) (NP (DT the) (JJ sensory) (NN input)))))))))))) (. .))
(S (PP (IN Because) (IN of) (NP (DT this) (NN difference))) (, ,) (NP (NNP DRL)) (VP (VBZ needs) (NP (NP (JJ vast) (NN amount)) (PP (IN of) (NP (NN experience) (NNS samples)))) (S (VP (TO to) (VP (VB learn))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NNP Multi-focus) (NNP Attention) (NNP Network)) (PRN (-LRB- -LRB-) (NP (NNP MANet)) (-RRB- -RRB-)) (SBAR (WHNP (WDT which)) (S (VP (VBZ mimics) (NP (JJ human) (NN ability) (S (VP (TO to) (VP (VP (ADVP (RB spatially)) (VB abstract) (NP (DT the) (JJ low-level) (NN sensory) (NN input)) (PP (IN into) (NP (JJ multiple) (NNS entities)))) (CC and) (VP (VBP attend) (PP (TO to) (NP (PRP them))) (ADVP (RB simultaneously)))))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN method)) (ADVP (RB first)) (VP (VBZ divides) (NP (DT the) (JJ low-level) (NN input)) (PP (IN into) (NP (NP (JJ several) (NNS segments)) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP refer) (PP (TO to)) (PP (IN as) (NP (JJ partial) (NNS states))))))))) (. .))
(S (PP (IN After) (NP (DT this) (NN segmentation))) (, ,) (NP (JJ parallel) (NN attention) (NNS layers)) (VP (VBP attend) (PP (TO to) (NP (NP (DT the) (JJ partial) (NNS states)) (ADJP (VBP relevant) (PP (TO to) (S (VP (VBG solving) (NP (DT the) (NN task))))))))) (. .))
(S (NP (PRP$ Our) (NN model)) (VP (VBZ estimates) (NP (JJ state-action) (NNS values)) (S (VP (VBG using) (NP (DT these) (VBN attended) (JJ partial) (NNS states))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (NNS experiments))) (, ,) (NP (NNP MANet)) (VP (VBZ attains) (NP (JJS highest) (NNS scores)) (PP (IN with) (NP (ADJP (RB significantly) (JJR less)) (NN experience) (NNS samples)))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (DT the) (NN model)) (VP (VBZ shows) (NP (JJR higher) (NN performance)) (PP (VBN compared) (PP (TO to) (NP (NP (NP (DT the) (NNP Deep) (NN Q-network)) (CC and) (NP (DT the) (JJ single) (NN attention) (NN model))) (PP (IN as) (NP (NNS benchmarks))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VBP extend) (NP (PRP$ our) (NN model)) (PP (TO to) (NP (NP (JJ attentive) (NN communication) (NN model)) (PP (IN for) (S (VP (VBG performing) (NP (JJ multi-agent) (JJ cooperative) (NNS tasks)))))))) (. .))
(S (PP (IN In) (NP (JJ multi-agent) (JJ cooperative) (NN task) (NNS experiments))) (, ,) (NP (PRP$ our) (NN model)) (VP (VBZ shows) (NP (NP (ADJP (NP (CD 20) (NN %)) (RBR faster)) (NN learning)) (PP (IN than) (NP (VBG existing) (JJ state-of-the-art) (NN model))))) (. .))
