(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (NP (NML (NML (NN reinforcement) (NN learning)) (PP (IN of) (NP (NNP Markov)))) (NN Decision) (NNS Processes) (PRN (-LRB- -LRB-) (NP (NN MDP)) (-RRB- -RRB-))) (PP (IN with) (NP (NN peak) (NNS constraints)))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT an) (NN agent)) (VP (VBZ chooses) (NP (DT a) (NN policy) (S (VP (TO to) (VP (VP (VB optimize) (NP (DT an) (NN objective))) (CC and) (ADVP (IN at) (NP (DT the) (JJ same) (NN time))) (VP (VB satisfy) (NP (JJ additional) (NNS constraints))))))))))) (. .))
(S (NP (DT The) (NN agent)) (VP (VBZ has) (S (VP (TO to) (VP (VB take) (NP (NNS actions)) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (VBN observed) (NNS states)) (, ,) (NP (NN reward) (NNS outputs)) (, ,) (CC and) (NP (NN constraint) (HYPH -) (NNS outputs))))) (, ,) (PP (IN without) (NP (NP (DT any) (NN knowledge)) (PP (IN about) (NP (NP (NP (DT the) (NNS dynamics)) (, ,) (NP (NN reward) (NNS functions))) (, ,) (CONJP (CC and) (HYPH /) (CC or)) (NP (NP (DT the) (NN knowledge)) (PP (IN of) (NP (DT the) (NN constraint) (HYPH -) (NNS functions)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (DT a) (NN game) (JJ theoretic) (NN approach)) (S (VP (TO to) (VP (VB construct) (S (VP (NN reinforcement) (VBG learning) (NP (NP (NNS algorithms)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN agent)) (VP (VBZ maximizes) (NP (NP (DT an) (ADJP (JJ unconstrained)) (NN objective)) (SBAR (WHNP (WDT that)) (S (VP (VBZ depends) (PP (IN on) (NP (NP (DT the) (JJ simulated) (NN action)) (PP (IN of) (NP (DT the) (NML (S (VP (VBG minimizing) (NP (NP (NN opponent)) (SBAR (WHNP (WDT which)) (S (VP (VBZ acts) (PP (IN on) (NP (NP (NP (DT a) (JJ finite) (NN set)) (PP (IN of) (NP (NNS actions)))) (CC and) (NP (NP (DT the) (NN output) (NNS data)) (PP (IN of) (NP (DT the) (NN constraint))))))))))))) (NNS functions))))) (PRN (-LRB- -LRB-) (NP (NNS rewards)) (-RRB- -RRB-)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NNS policies)) (VP (VBN obtained) (PP (IN from) (NP (NN maximin) (NML (NN Q) (HYPH -) (NN learning)))))) (VP (VBP converge) (PP (IN to) (NP (DT the) (JJ optimal) (NNS policies))))))) (. .))
(S (PP (IN To) (NP (NP (DT the) (JJS best)) (PP (IN of) (NP (PRP$ our) (NN knowledge))))) (, ,) (NP (DT this)) (VP (VBZ is) (NP (NP (DT the) (JJ first) (NN time)) (VP (VBG learning) (S (NP (NNS algorithms)) (VP (VB guarantee) (NP (NN convergence)) (PP (IN to) (NP (NP (JJ optimal) (JJ stationary) (NNS policies)) (PP (IN for) (NP (DT the) (NN MDP) (NN problem))))))) (PP (IN with) (NP (NP (NN peak) (NNS constraints)) (PP (IN for) (NP (NP (DT both)) (VP (VBN discounted) (CC and) (VBN expected) (NP (JJ average) (NNS rewards)))))))))) (. .))
