(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (NP (JJ reinforcement) (NN learning)) (PP (IN of) (NP (NP (NNP Markov) (NNP Decision) (NNP Processes)) (PRN (-LRB- -LRB-) (NP (NNP MDP)) (-RRB- -RRB-)) (PP (IN with) (NP (NN peak) (NNS constraints))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT an) (NN agent)) (VP (VBZ chooses) (NP (DT a) (NN policy)) (SBAR (S (VP (TO to) (VP (VP (VB optimize) (NP (DT an) (JJ objective))) (CC and) (VP (PP (IN at) (NP (DT the) (JJ same) (NN time))) (JJ satisfy) (NP (JJ additional) (NNS constraints)))))))))))))) (. .))
(S (NP (DT The) (NN agent)) (VP (VBZ has) (S (VP (TO to) (VP (VB take) (NP (NP (NNS actions)) (VP (VBN based) (PP (IN on) (NP (NP (DT the) (JJ observed) (NNS states)) (, ,) (NP (NN reward) (NNS outputs)) (, ,) (CC and) (NP (NNS constraint-outputs)))))) (, ,) (PP (IN without) (NP (NP (DT any) (NN knowledge)) (PP (IN about) (NP (NP (DT the) (NNS dynamics)) (, ,) (NP (NN reward) (NNS functions)) (, ,) (VBP and/or) (NP (NP (DT the) (NN knowledge)) (PP (IN of) (NP (DT the) (NNS constraint-functions)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (ADJP (NN game) (JJ theoretic)) (NN approach)) (SBAR (S (VP (TO to) (VP (VB construct) (NP (NP (NN reinforcement) (VBG learning) (NNS algorithms)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN agent)) (VP (VBZ maximizes) (NP (NP (DT an) (JJ unconstrained) (NN objective)) (SBAR (WHNP (WDT that)) (S (VP (VBZ depends) (PP (IN on) (NP (NP (NP (DT the) (JJ simulated) (NN action)) (PP (IN of) (NP (NP (DT the) (NN minimizing) (NN opponent)) (SBAR (WHNP (WDT which)) (S (VP (VBZ acts) (PP (IN on) (NP (NP (DT a) (JJ finite) (NN set)) (PP (IN of) (NP (NNS actions))))))))))) (CC and) (NP (NP (DT the) (NN output) (NNS data)) (PP (IN of) (NP (DT the) (NN constraint) (NNS functions))) (PRN (-LRB- -LRB-) (NP (NNS rewards)) (-RRB- -RRB-))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NNS policies)) (VP (VBN obtained) (PP (IN from) (NP (JJ maximin) (JJ Q-learning))))) (VP (NN converge) (PP (TO to) (NP (DT the) (JJ optimal) (NNS policies))))))) (. .))
(S (PP (TO To) (NP (NP (DT the) (JJS best)) (PP (IN of) (NP (PRP$ our) (NN knowledge))))) (, ,) (NP (DT this)) (VP (VBZ is) (NP (NP (DT the) (JJ first) (NN time)) (SBAR (S (NP (VBG learning) (JJ algorithms)) (VP (NN guarantee) (NP (NP (NN convergence)) (PP (TO to) (NP (VB optimal) (JJ stationary) (NNS policies))) (PP (IN for) (NP (DT the) (NNP MDP) (NN problem))) (PP (IN with) (NP (NP (NN peak) (NNS constraints)) (PP (IN for) (NP (UCP (DT both) (VBN discounted) (CC and) (VBN expected)) (JJ average) (NNS rewards))))))))))) (. .))
