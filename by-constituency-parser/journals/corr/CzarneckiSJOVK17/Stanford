(S (SBAR (WHADVP (WRB When)) (S (VP (VBG training) (NP (JJ neural) (NNS networks))))) (, ,) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ Synthetic) (NNS Gradients))) (PRN (-LRB- -LRB-) (NP (NN SG)) (-RRB- -RRB-))) (VP (VBZ allows) (NP (NNS layers) (CC or) (NNS modules)) (S (VP (TO to) (VP (VB be) (VP (VBN trained) (PP (IN without) (NP (NP (NN update) (NN locking)) (HYPH -) (PP (IN without) (S (VP (VBG waiting) (PP (IN for) (NP (NP (DT a) (ADJP (ADJP (JJ true) (NP (NP (NN error) (NN gradient)) (SBAR (S (VP (TO to) (VP (VB be) (VP (VBN backpropagated)))))))) (HYPH -) (ADJP (VBG resulting)))) (PP (IN in) (NP (VBN Decoupled) (JJ Neural) (NNS Interfaces)))))))))) (PRN (-LRB- -LRB-) (NP (NNS DNIs)) (-RRB- -RRB-))))))) (. .))
(S (NP (NP (DT This) (VBN unlocked) (NN ability)) (PP (IN of) (S (VP (VBG being) (ADJP (JJ able) (S (VP (TO to) (VP (VB update) (NP (NP (NNS parts)) (PP (IN of) (NP (DT a) (JJ neural) (NN network)))) (UCP (ADVP (RB asynchronously)) (CC and) (PP (IN with) (NP (JJ only) (JJ local) (NN information)))))))))))) (VP (VBD was) (VP (VBN demonstrated) (PP (IN to) (NP (NN work))) (PP (ADVP (RB empirically)) (IN in) (NP (NP (NNP Jaderberg)) (ADVP (FW et) (FW al)))) (PRN (-LRB- -LRB-) (NP (CD 2016)) (-RRB- -RRB-)))) (. .))
(S (ADVP (RB However)) (, ,) (NP (EX there)) (VP (VBZ has) (VP (VBN been) (NP (NP (ADJP (RB very) (JJ little)) (NN demonstration)) (PP (IN of) (SBAR (WHNP (WP what)) (S (VP (VBZ changes) (S (NP (NNS DNIs) (CC and) (NNS SGs)) (VP (VB impose) (PP (IN from) (NP (NP (DT a) (NML (NML (NP (JJ functional)) (, ,) (NP (JJ representational)) (, ,)) (CC and) (NML (VBG learning) (NNS dynamics))) (NN point)) (PP (IN of) (NP (NN view)))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NNS DNIs)) (PP (IN through) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (JJ synthetic) (NNS gradients)) (PP (IN on) (NP (NML (NN feed) (HYPH -) (JJ forward)) (NNS networks))))))) (S (VP (TO to) (ADVP (RBR better)) (VP (VP (VB understand) (NP (PRP$ their) (NN behaviour))) (CC and) (VP (VB elucidate) (NP (PRP$ their) (NN effect)) (PP (IN on) (NP (NN optimisation)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN incorporation)) (PP (IN of) (NP (NNP SGs)))) (VP (VBZ does) (RB not) (VP (VP (VB affect) (NP (NP (DT the) (JJ representational) (NN strength)) (PP (IN of) (NP (DT the) (NN learning) (NN system)))) (PP (IN for) (NP (DT a) (JJ neural) (NN network)))) (, ,) (CC and) (VP (VB prove) (NP (NP (DT the) (NN convergence)) (PP (IN of) (NP (NP (DT the) (NN learning) (NN system)) (PP (IN for) (NP (ADJP (JJ linear) (CC and) (JJ deep)) (JJ linear) (NNS models)))))))))))) (. .))
(S (PP (IN On) (NP (JJ practical) (NNS problems))) (NP (PRP we)) (VP (VBP investigate) (NP (DT the) (NN mechanism)) (SBAR (SBAR (WHPP (IN by) (WHNP (WDT which))) (S (NP (JJ synthetic) (NN gradient) (NNS estimators)) (VP (VBP approximate) (NP (DT the) (JJ true) (NN loss))))) (, ,) (CC and) (, ,) (ADVP (RB surprisingly)) (, ,) (SBAR (WHADVP (WRB how)) (S (NP (DT that)) (VP (VBZ leads) (PP (IN to) (NP (ADJP (RB drastically) (JJ different)) (JJ layer-wise) (NNS representations)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VP (VB expose) (NP (NP (DT the) (NN relationship)) (PP (IN of) (S (VP (VBG using) (NP (JJ synthetic) (NNS gradients)) (PP (IN to) (NP (JJ other) (NN error) (NN approximation) (NNS techniques)))))))) (CC and) (VP (VB find) (NP (DT a) (ADJP (JJ unifying)) (NN language)) (PP (IN for) (NP (NN discussion) (CC and) (NN comparison))))) (. .))
