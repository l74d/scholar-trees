(S (S (ADJP (RB Phenomenally) (JJ successful) (PP (IN in) (NP (JJ practical) (NN inference) (NNS problems))))) (, ,) (NP (NP (JJ convolutional) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNP CNN)) (-RRB- -RRB-)) (VP (VBP are) (ADVP (RB widely)) (VP (VBN deployed) (PP (IN in) (NP (NP (JJ mobile) (NNS devices)) (, ,) (NP (NNS data) (NNS centers)) (, ,) (CC and) (NP (RB even) (NNS supercomputers)))))) (. .))
(S (NP (NP (DT The) (NN number)) (PP (IN of) (NP (NP (NNS parameters)) (VP (VBN needed) (PP (IN in) (NP (NNS CNNs))))))) (, ,) (ADVP (RB however)) (, ,) (VP (VBP are) (ADVP (RB often)) (ADJP (JJ large) (CC and) (JJ undesirable))) (. .))
(S (ADVP (RB Consequently)) (, ,) (NP (JJ various) (NNS methods)) (VP (VBP have) (VP (VBN been) (VP (VBN developed) (PP (IN to) (S (VP (VB prune) (NP (DT a) (NNP CNN)) (SBAR (IN once) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN trained))))))))))) (. .))
(S (ADVP (RB Nevertheless)) (, ,) (NP (DT the) (VBG resulting) (NNS CNNs)) (VP (VBP offer) (NP (JJ limited) (NNS benefits))) (. .))
(S (SBAR (IN While) (S (NP (NP (NN pruning)) (NP (DT the) (ADJP (RB fully) (JJ connected)) (NNS layers))) (VP (VBZ reduces) (NP (NP (DT a) (NNP CNN) (POS 's)) (NN size)) (ADVP (RB considerably))))) (, ,) (NP (PRP it)) (VP (VBZ does) (RB not) (VP (VB improve) (NP (NN inference) (NN speed)) (ADVP (RB noticeably)) (SBAR (IN as) (S (NP (DT the) (NML (S (VP (VB compute) (NP (JJ heavy) (NNS parts)))))) (VP (VBP lie) (PP (IN in) (NP (NNS convolutions)))))))) (. .))
(S (S (VP (VBG Pruning) (NP (NNS CNNs)) (PP (IN in) (NP (NP (DT a) (NN way)) (SBAR (WHNP (WDT that)) (S (VP (VBP increase) (SBAR (S (NP (NN inference) (NN speed)) (ADVP (RB often)) (VP (VBZ imposes) (NP (JJ specific) (NN sparsity) (NNS structures)))))))))))) (, ,) (S (ADVP (RB thus)) (VP (VBG limiting) (NP (DT the) (ADJP (JJ achievable)) (NN sparsity) (NNS levels)))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (DT a) (NN method)) (S (VP (TO to) (VP (VB realize) (ADVP (RB simultaneously)) (NP (NP (NN size) (NN economy)) (CC and) (NP (NN speed) (NN improvement))) (PP (IN while) (NP (NN pruning) (NNS CNNs))))))) (. .))
(S (NP (NP (NNP Paramount)) (PP (IN to) (NP (PRP$ our) (NN success)))) (VP (VBZ is) (NP (NP (DT an) (JJ efficient) (NML (NML (JJ general) (JJ sparse)) (HYPH -) (PP (IN with) (HYPH -) (NP (JJ dense) (NN matrix)))) (NN multiplication) (NN implementation)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ applicable) (PP (IN to) (NP (NP (NN convolution)) (PP (IN of) (NP (NP (NN feature)) (SBAR (S (VP (VBZ maps) (PP (IN with) (NP (NP (NNS kernels)) (PP (IN of) (NP (JJ arbitrary) (NN sparsity) (NNS patterns)))))))))))))))))) (. .))
(S (S (VP (VBG Complementing) (NP (DT this)))) (, ,) (NP (PRP we)) (VP (VBD developed) (NP (NP (DT a) (NN performance) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (VBZ predicts) (NP (NP (JJ sweet) (NNS spots)) (PP (IN of) (NP (NN sparsity) (NNS levels)))) (PP (PP (IN for) (NP (JJ different) (NNS layers))) (CC and) (PP (IN on) (NP (JJ different) (NN computer) (NNS architectures))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (NP (NP (JJ open) (NN source)) (NP (NP (PRP$ our) (NN project)) (PP (IN at) (NP (DT this))))) (VP (VBZ https) (NP (NN URL))))
