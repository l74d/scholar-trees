(S (NP (NP (DT An) (JJ important) (NN problem)) (PP (IN in) (S (VP (VBG training) (NP (NP (JJ deep) (NNS networks)) (PP (IN with) (NP (JJ high) (NN capacity)))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB ensure) (SBAR (IN that) (S (NP (DT the) (JJ trained) (NN network)) (VP (NNS works) (ADVP (RB well)) (SBAR (WHADVP (WRB when)) (S (VP (VBN presented) (PP (IN with) (NP (NP (JJ new) (NNS inputs)) (PP (IN outside) (NP (DT the) (NN training) (NN dataset))))))))))))))) (. .))
(S (NP (NNP Dropout)) (VP (VBZ is) (NP (NP (DT an) (JJ effective) (NN regularization) (NN technique)) (SBAR (S (VP (TO to) (VP (VB boost) (NP (DT the) (NN network) (NN generalization)))))) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (NP (DT a) (NN random) (NN subset)) (PP (IN of) (NP (NP (DT the) (NNS elements)) (PP (IN of) (NP (DT the) (VBN given) (NNS data)))))) (CC and) (NP (DT the) (JJ extracted) (NNS features))) (VP (VBP are) (VP (VBN set) (PP (TO to) (NP (CD zero))) (PP (IN during) (NP (DT the) (NN training) (NN process))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (NP (DT a) (JJ new) (JJ randomized) (NN regularization) (NN technique)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBD withhold) (NP (NP (DT a) (JJ random) (NN part)) (PP (IN of) (NP (DT the) (NNS data)))) (PP (IN without) (S (VP (ADVP (RB necessarily)) (VBG turning) (PRT (RP off)) (NP (DT the) (NNS neurons/data-elements))))))))) (VP (VBZ is) (VP (VBN proposed))) (. .))
(S (PP (IN In) (NP (NP (DT the) (VBN proposed) (NN method)) (, ,) (SBAR (WHPP (IN of) (WHNP (WDT which))) (S (NP (DT the) (JJ conventional) (NN dropout)) (VP (VBZ is) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (NP (DT a) (JJ special) (NN case))))))))))) (, ,) (NP (NN random) (NNS data) (NN dropout)) (VP (VBZ is) (VP (VBN performed) (PP (IN in) (NP (DT an) (JJ arbitrary) (NN basis))) (, ,) (ADVP (RB hence)) (NP (NP (DT the) (NN designation)) (NP (NNP Generalized) (NNP Dropout))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBD present) (NP (NP (DT a) (NN framework)) (SBAR (WHADVP (WRB whereby)) (S (NP (DT the) (VBN proposed) (NN technique)) (VP (MD can) (VP (VB be) (VP (VBN applied) (ADVP (RB efficiently)) (PP (TO to) (NP (JJ convolutional) (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (DT The) (JJ presented) (JJ numerical) (NNS experiments)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN technique)) (VP (NNS yields) (NP (JJ notable) (NN performance) (NN gain)))))) (. .))
(S (NP (VBN Generalized) (NNP Dropout)) (VP (VP (VBZ provides) (NP (NP (JJ new) (NN insight)) (PP (IN into) (NP (NP (DT the) (NN idea)) (PP (IN of) (NP (NN dropout))))))) (, ,) (VP (VBZ shows) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VB achieve) (NP (JJ different) (NN performance) (NNS gains)) (PP (IN by) (S (VP (VBG using) (NP (JJ different) (NNS bases) (NNS matrices)))))))))) (, ,) (CC and) (VP (VBZ opens) (PRT (RP up)) (NP (NP (DT a) (JJ new) (NN research) (NN question)) (PP (IN as) (PP (IN of) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB choose) (NP (NP (JJ optimal) (NNS bases) (NNS matrices)) (SBAR (WHNP (WDT that)) (S (VP (VBP achieve) (NP (JJ maximal) (NN performance) (NN gain))))))))))))))) (. .))
