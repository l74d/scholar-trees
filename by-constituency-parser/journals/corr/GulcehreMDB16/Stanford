(S (NP (NP (JJ Common) (JJ nonlinear) (NN activation) (NNS functions)) (VP (VBN used) (PP (IN in) (NP (JJ neural) (NNS networks))))) (VP (MD can) (VP (VB cause) (NP (NN training) (NNS difficulties)) (PP (IN due) (IN to) (NP (NP (NP (DT the) (NN saturation) (NN behavior)) (PP (IN of) (NP (DT the) (NN activation) (NN function)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD may) (VP (VB hide) (NP (NP (NNS dependencies)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (RB not) (ADJP (JJ visible)) (PP (IN to) (NP (NN vanilla) (HYPH -) (NN SGD))) (PRN (-LRB- -LRB-) (S (VP (VBG using) (NP (JJ first) (NN order) (NNS gradients)) (ADVP (RB only)))) (-RRB- -RRB-)))))))))))))) (. .))
(S (NP (NP (VBG Gating) (NNS mechanisms)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (ADVP (RB softly)) (NP (NP (VBG saturating) (NN activation) (NNS functions)) (PP (IN to) (NP (NML (S (VP (VB emulate) (NP (NP (DT the) (JJ discrete) (NN switching)) (PP (IN of) (NP (JJ digital) (NN logic))))))) (NNS circuits)))))))) (VP (VBP are) (NP (NP (JJ good) (NNS examples)) (PP (IN of) (NP (DT this))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (VP (TO to) (VP (VB exploit) (NP (NP (DT the) (NN injection)) (PP (IN of) (NP (JJ appropriate) (NN noise)))) (SBAR (IN so) (IN that) (S (NP (DT the) (NNS gradients)) (VP (MD may) (VP (VB flow) (ADVP (RB easily)))))) (, ,) (SBAR (RB even) (IN if) (S (NP (NP (DT the) (JJ noiseless) (NN application)) (PP (IN of) (NP (DT the) (NN activation) (NN function)))) (VP (MD would) (VP (VB yield) (NP (CD zero) (NN gradient)))))))))) (. .))
(S (NP (JJ Large) (NN noise)) (VP (MD will) (VP (VP (VB dominate) (NP (ADJP (NP (DT the) (NN noise)) (HYPH -) (JJ free)) (NN gradient))) (CC and) (VP (VB allow) (NP (JJ stochastic) (NN gradient) (NN descent) (NN toexplore)) (ADVP (RBR more))))) (. .))
(S (PP (IN By) (S (VP (VBG adding) (NP (NN noise)) (ADVP (RB only)) (PP (IN to) (NP (NP (DT the) (JJ problematic) (NNS parts)) (PP (IN of) (NP (DT the) (NN activation) (NN function)))))))) (, ,) (NP (PRP we)) (VP (VBP allow) (NP (DT the) (NN optimization) (NN procedure)) (S (VP (TO to) (VP (VB explore) (NP (NP (NP (DT the) (NN boundary)) (PP (IN between) (NP (DT the) (JJ degenerate))) (PRN (-LRB- -LRB-) (ADJP (VBG saturating)) (-RRB- -RRB-))) (CC and) (NP (NP (DT the) (ADJP (RB well) (HYPH -) (VBN behaved)) (NNS parts)) (PP (IN of) (NP (DT the) (NN activation) (NN function))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP establish) (NP (NNS connections)) (PP (IN to) (NP (NP (JJ simulated) (NN annealing)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NN noise)))) (VP (VBZ is) (VP (VBN annealed) (PRT (RP down)))))))) (, ,) (S (VP (VBG making) (S (NP (PRP it)) (ADJP (JJR easier)) (S (VP (TO to) (VP (VB optimize) (NP (JJ hard) (JJ objective) (NNS functions))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (ADVP (RB experimentally)) (SBAR (IN that) (S (S (VP (VBG replacing) (NP (JJ such) (VBG saturating) (NN activation) (NNS functions)) (PP (IN by) (NP (JJ noisy) (NNS variants))))) (VP (VBZ helps) (NP (NP (NN training)) (PP (IN in) (NP (JJ many) (NNS contexts)))) (, ,) (S (VP (VBG yielding) (NP (UCP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (CC or) (ADJP (JJ competitive))) (NNS results)) (PP (IN on) (NP (NP (JJ different) (NNS datasets)) (CC and) (NP (NN task))))))))) (, ,) (SBAR (WHADVP (RB especially) (WRB when)) (S (NP (VBG training)) (VP (VBZ seems) (S (VP (TO to) (VP (VB be) (ADJP (DT the) (RBS most) (JJ difficult)))))))) (, ,) (SBAR (ADVP (FW e.g.)) (, ,) (WHADVP (WRB when)) (S (NP (NN curriculum) (NN learning)) (VP (VBZ is) (ADJP (JJ necessary) (S (VP (TO to) (VP (VB obtain) (NP (JJ good) (NNS results))))))))))) (. .))
