(S (NP (PRP We)) (VP (VBP provide) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (NP (NNS results)) (PP (IN for) (NP (JJ unsupervised) (NN learning)))))) (PP (IN with) (NP (NNS autoencoders)))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP study) (NP (JJ shallow) (NML (CD two) (HYPH -) (NN layer)) (NN autoencoder) (NNS architectures)) (PP (IN with) (NP (VBN shared) (NNS weights)))) (. .))
(S (NP (PRP We)) (VP (VBP focus) (PP (IN on) (NP (NP (CD three) (JJ generative) (NNS models)) (PP (IN for) (NP (NP (NNS data)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ common) (PP (IN in) (NP (NP (NP (NP (JJ statistical) (NML (NN machine) (NN learning))) (: :) (LST (-LRB- -LRB-) (LS i) (-RRB- -RRB-))) (NP (DT the) (NML (NML (NN mixture)) (HYPH -) (PP (IN of) (HYPH -) (NP (NNS gaussians)))) (NN model))) (, ,) (NP (LST (-LRB- -LRB-) (LS ii) (-RRB- -RRB-)) (NP (DT the) (JJ sparse) (NN coding) (NN model))) (, ,) (CC and) (NP (LST (-LRB- -LRB-) (LS iii) (-RRB- -RRB-)) (NP (DT the) (NN sparsity) (NN model)) (PP (IN with) (NP (JJ non-negative) (NNS coefficients))))))))))))))) (. .))
(S (PP (IN For) (NP (NP (DT each)) (PP (IN of) (NP (DT these) (NNS models))))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (PP (IN under) (NP (NP (JJ suitable) (NNS choices)) (PP (IN of) (NP (NNS hyperparameters) (, ,) (NNS architectures) (, ,) (CC and) (NN initialization))))) (, ,) (NP (NP (NNS autoencoders)) (VP (VBN learned) (PP (IN by) (NP (NN gradient) (NN descent))))) (VP (MD can) (ADVP (RB successfully)) (VP (VB recover) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT the) (VBG corresponding) (NN model))))))))) (. .))
(S (PP (IN To) (NP (PRP$ our) (NN knowledge))) (, ,) (NP (DT this)) (VP (VBZ is) (NP (NP (DT the) (JJ first) (NN result)) (SBAR (WHNP (WDT that)) (S (ADVP (RB rigorously)) (VP (VBZ studies) (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (NP (NN gradient) (NN descent)) (PP (IN for) (NP (ADJP (NP (NN weight)) (HYPH -) (VBG sharing)) (NNS autoencoders))))))))))) (. .))
(S (NP (PRP$ Our) (NN analysis)) (VP (MD can) (VP (VB be) (VP (VBN viewed) (PP (IN as) (NP (JJ theoretical) (NN evidence))) (SBAR (IN that) (S (NP (JJ shallow) (NN autoencoder) (NNS modules)) (ADVP (RB indeed)) (VP (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN as) (NP (NN feature) (NN learning) (NNS mechanisms))) (PP (IN for) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS data) (NNS models)))))))) (, ,) (CC and) (VP (MD may) (VP (VB shed) (NP (NN insight)) (PP (IN on) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB train) (NP (NP (JJR larger)) (VP (VBN stacked) (NP (NNS architectures)) (PP (IN with) (NP (NP (NNS autoencoders)) (PP (IN as) (NP (JJ basic) (NN building) (NNS blocks)))))))))))))))))))) (. .))
