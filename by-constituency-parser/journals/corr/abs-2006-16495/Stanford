(S (NP (NP (NNP Learning)) (SBAR (S (VP (HYPH -) (TO to) (HYPH -) (VP (VB learn) (S (-LRB- -LRB-) (VP (VBG using) (NP (NN optimization) (NNS algorithms)) (S (VP (TO to) (VP (VB learn) (NP (DT a) (JJ new) (NN optimizer)))))) (-RRB- -RRB-))))))) (VP (VBZ has) (ADVP (RB successfully)) (VP (VBN trained) (NP (JJ efficient) (NNS optimizers)) (PP (IN in) (NP (NN practice))))) (. .))
(S (NP (DT This) (NN approach)) (VP (VBZ relies) (PP (IN on) (NP (NN meta) (HYPH -) (NN gradient) (NN descent))) (PP (IN on) (NP (NP (DT a) (NN meta) (HYPH -) (NN objective)) (VP (VBN based) (PP (IN on) (NP (DT the) (NN trajectory))) (SBAR (IN that) (S (NP (DT the) (NN optimizer)) (VP (VBZ generates)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (EX there)) (VP (VBD were) (NP (NP (JJ few) (JJ theoretical) (NNS guarantees)) (PP (IN on) (SBAR (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB avoid) (S (NP (NN meta) (HYPH -) (NN gradient)) (NP (NP (NN explosion) (HYPH /) (VBG vanishing)) (NP (NNS problems)))))))) (, ,) (CC or) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB train) (NP (DT an) (NN optimizer)) (PP (IN with) (NP (JJ good) (NN generalization) (NN performance))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT the) (NML (NML (NN learning)) (HYPH -) (SBAR (IN to) (HYPH -) (FRAG (S (VP (VB learn) (NP (NN approach)) (PP (IN on) (NP (NP (DT a) (JJ simple) (NN problem)) (PP (IN of) (S (VP (VBG tuning) (NP (DT the) (NN step)))))))))))) (NN size)) (PP (IN for) (NP (JJ quadratic) (NN loss))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (SBAR (IN although) (S (NP (EX there)) (VP (VBZ is) (NP (DT a) (NN way) (S (VP (TO to) (VP (VB design) (NP (DT the) (NN meta) (HYPH -) (NN objective)) (SBAR (IN so) (IN that) (S (NP (DT the) (NN meta) (HYPH -) (NN gradient)) (VP (VBP remain) (ADVP (RB polynomially)) (VP (VBN bounded)))))))))))) (, ,) (S (VP (VBG computing) (NP (DT the) (NN meta) (HYPH -) (NN gradient)) (S (ADVP (RB directly)) (VP (VBG using) (NP (NN backpropagation)))))) (VP (VBZ leads) (PP (IN to) (NP (NP (JJ numerical) (NNS issues)) (SBAR (WHNP (WDT that)) (S (VP (VBP look) (ADJP (JJ similar) (PP (IN to) (NP (ADJP (NP (NN gradient) (NN explosion)) (HYPH /) (VBG vanishing)) (NNS problems))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP characterize) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ necessary) (S (VP (TO to) (VP (VB compute) (NP (DT the) (NN meta) (HYPH -) (NN objective)) (PP (IN on) (NP (NP (DT a) (JJ separate) (NN validation)) (VP (VBN set) (PP (RB instead) (IN of) (NP (DT the) (JJ original) (NN training) (NN set)))))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VP (VBP verify) (NP (PRP$ our) (NNS results)) (ADVP (RB empirically))) (CC and) (VP (VB show) (SBAR (IN that) (S (NP (DT a) (JJ similar) (NN phenomenon)) (VP (VBZ appears) (ADVP (RB even)) (PP (IN for) (NP (NP (ADJP (RBR more) (JJ complicated))) (VP (VBN learned) (NP (NP (NNS optimizers)) (VP (VBN parametrized) (PP (IN by) (NP (JJ neural) (NNS networks))))))))))))) (. .))
