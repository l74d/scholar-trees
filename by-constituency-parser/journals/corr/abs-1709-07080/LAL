(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP design) (CC and) (VBP evaluate) (NP (NP (DT a) (JJ Deep-Reinforcement) (NNP Learning) (NN agent)) (SBAR (WHNP (WDT that)) (S (VP (VBZ optimizes) (NP (NN routing))))))) (. .))
(S (NP (PRP$ Our) (NN agent)) (VP (VP (VBZ adapts) (ADVP (RB automatically)) (PP (TO to) (NP (JJ current) (NN traffic) (NNS conditions)))) (CC and) (VP (NNS proposes) (NP (NP (VBD tailored) (NNS configurations)) (SBAR (WHNP (WDT that)) (S (VP (VBP attempt) (S (VP (TO to) (VP (VB minimize) (NP (DT the) (NN network) (NN delay))))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (NP (ADJP (RB very) (JJ promising)) (NN performance))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (DT this) (NN approach)) (VP (VBZ provides) (NP (JJ important) (JJ operational) (NNS advantages)) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (JJ traditional) (NN optimization) (NN algorithms)))))) (. .))
