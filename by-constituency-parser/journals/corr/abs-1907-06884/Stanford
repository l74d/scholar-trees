(NP (NP (JJ Deep) (NML (NN reinforcement) (VBG learning)) (NNS trains)) (NP (NP (JJ neural) (NNS networks)) (VP (VBG using) (NP (NP (NNS experiences)) (VP (VBN sampled) (PP (IN from) (NP (NP (DT the) (NN replay) (NN buffer)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADVP (RB commonly)) (VP (VBN updated) (PP (IN at) (NP (DT each) (NN time) (NN step))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (NN method)) (S (VP (VP (TO to) (VP (VB update) (NP (DT the) (NN replay) (NN buffer)) (ADVP (RB adaptively)))) (CC and) (ADVP (RB selectively)) (VP (TO to) (VP (VB train) (NP (DT a) (NN robot) (NN arm)) (S (VP (TO to) (VP (VB accomplish) (NP (DT a) (NN suction) (NN task)) (PP (IN in) (NP (NN simulation))))))))))) (. .))
(S (NP (NP (DT The) (NN response) (NN time)) (PP (IN of) (NP (DT the) (NN agent)))) (VP (VBZ is) (ADVP (RB thoroughly)) (VP (VBN taken) (PP (IN into) (NP (NN account))))) (. .))
(S (NP (NP (DT The) (NN state) (NNS transitions)) (SBAR (WHNP (WDT that)) (S (VP (VBP remain) (ADJP (JJ stuck) (PP (IN at) (NP (NP (DT the) (NN boundary)) (PP (IN of) (NP (NN constraint)))))))))) (VP (VBP are) (RB not) (VP (VBN stored))) (. .))
(S (NP (NP (DT The) (NN policy)) (VP (VBN trained) (PP (IN with) (NP (PRP$ our) (NN method))))) (VP (VBZ works) (ADVP (RBR better)) (PP (IN than) (NP (NP (DT the) (CD one)) (PP (IN with) (NP (DT the) (JJ common) (NN replay) (NN buffer) (NN update) (NN method)))))) (. .))
(S (NP (DT The) (NN result)) (VP (VBZ is) (VP (VBN demonstrated) (PP (CC both) (PP (IN by) (NP (NN simulation))) (CC and) (PP (IN by) (NP (NN experiment)))) (PP (IN with) (NP (DT a) (JJ real) (NN robot) (NN arm))))) (. .))
