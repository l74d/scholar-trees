(S (NP (DT This) (NN paper)) (VP (VBZ presents) (NP (NP (NP (DT a) (JJ novel) (NML (NN network) (NN compression)) (NN framework)) (NP (NNP Kernel) (NNP Quantization) (-LRB- -LRB-) (NNP KQ) (-RRB- -RRB-))) (, ,) (VP (VBG targeting) (S (VP (TO to) (ADVP (RB efficiently)) (VP (VB convert) (NP (DT any) (ADJP (JJ pre-trained) (JJ full)) (HYPH -) (NN precision) (JJ convolutional) (NML (NML (JJ neural) (NN network)) (-LRB- -LRB-) (NML (NP (NNP CNN))) (-RRB- -RRB-)) (NN model)) (PP (IN into) (NP (DT a) (NML (JJ low) (HYPH -) (NN precision)) (NN version))) (PP (IN without) (NP (JJ significant) (NN performance) (NN loss))))))))) (. .))
(S (PP (IN Unlike) (NP (NP (VBG existing) (NNS methods)) (VP (VBG struggling) (PP (IN with) (NP (NN weight) (NML (NN bit) (HYPH -) (NN length))))))) (, ,) (NP (NN KQ)) (VP (VBZ has) (NP (NP (DT the) (NN potential)) (PP (IN in) (S (VP (VBG improving) (NP (DT the) (NN compression) (NN ratio)) (PP (IN by) (S (VP (VBG considering) (NP (DT the) (NN convolution) (NN kernel)) (PP (IN as) (NP (DT the) (NN quantization) (NN unit))))))))))) (. .))
(S (S (VP (VBN Inspired) (PP (IN by) (NP (DT the) (NN evolution))) (PP (IN from) (NP (NN weight) (NN pruning))) (PP (IN to) (NP (NN filter) (NN pruning))))) (, ,) (NP (PRP we)) (VP (VBP propose) (PP (IN to) (NP (NN quantize))) (PP (IN in) (NP (NP (DT both) (NN kernel)) (CC and) (NP (NN weight) (NN level))))) (. .))
(S (PP (RB Instead) (IN of) (S (VP (VBG representing) (NP (DT each) (NN weight) (NN parameter)) (PP (IN with) (NP (DT a) (NML (JJ low) (HYPH -) (NN bit)) (NN index)))))) (, ,) (NP (PRP we)) (VP (VP (VBP learn) (NP (DT a) (NN kernel) (NN codebook))) (CC and) (VP (VB replace) (NP (NP (DT all) (NNS kernels)) (PP (IN in) (NP (DT the) (NN convolution) (NN layer)))) (PP (IN with) (NP (VBG corresponding) (NML (JJ low) (HYPH -) (NN bit)) (NNS indexes))))) (. .))
(S (ADVP (RB Thus)) (, ,) (NP (NNP KQ)) (VP (MD can) (VP (VB represent) (NP (DT the) (NN weight) (NN tensor)) (PP (IN in) (NP (NP (NP (NP (DT the) (NN convolution) (NN layer)) (PP (IN with) (NP (NML (JJ low) (HYPH -) (NN bit)) (NNS indexes)))) (CC and) (NP (NP (DT a) (NN kernel) (NN codebook)) (PP (IN with) (NP (JJ limited) (NN size))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ enables) (NP (NN KQ)) (S (VP (TO to) (VP (VB achieve) (NP (JJ significant) (NN compression) (NN ratio)))))))))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (PRP we)) (VP (VBP conduct) (NP (NP (DT a) (NML (CD 6) (HYPH -) (NN bit)) (NN parameter) (NN quantization)) (PP (IN on) (NP (DT the) (NN kernel) (NN codebook)))) (S (VP (TO to) (ADVP (RB further)) (VP (VB reduce) (NP (NN redundancy)))))) (. .))
(S (NP (NP (JJ Extensive) (NNS experiments)) (PP (IN on) (NP (DT the) (NML (NNP ImageNet) (NN classification)) (NN task)))) (VP (VB prove) (SBAR (IN that) (S (NP (NNP KQ)) (VP (VP (VBZ needs) (NP (QP (CD 1.05) (CC and) (CD 1.62)) (NNS bits)) (PP (IN on) (NP (NP (JJ average)) (PP (IN in) (NP (NN VGG) (CC and) (NN ResNet18)))) (, ,) (ADVP (RB respectively))) (, ,) (S (VP (TO to) (VP (VB represent) (NP (DT each) (NN parameter)) (PP (IN in) (NP (DT the) (NN convolution) (NN layer))))))) (CC and) (VP (VBZ achieves) (NP (DT the) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN compression) (NN ratio)) (PP (IN with) (NP (JJ little) (NN accuracy) (NN loss)))))))) (. .))
