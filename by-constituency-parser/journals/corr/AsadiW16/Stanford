(S (S (VP (VBG Representing) (NP (DT a) (NN dialog) (NN policy)) (PP (IN as) (NP (DT a) (ADJP (JJ recurrent)) (JJ neural) (NN network) (PRN (-LRB- -LRB-) (NP (NN RNN)) (-RRB- -RRB-)))))) (VP (VBZ is) (ADJP (JJ attractive)) (SBAR (IN because) (S (NP (PRP it)) (VP (VP (VBZ handles) (NP (JJ partial) (NN observability))) (, ,) (VP (VBZ infers) (NP (NP (DT a) (NN latent) (NN representation)) (PP (IN of) (NP (NN state))))) (, ,) (CC and) (VP (MD can) (VP (VB be) (VP (VBN optimized) (PP (IN with) (NP (NP (JJ supervised) (NN learning) (PRN (-LRB- -LRB-) (NP (NNP SL)) (-RRB- -RRB-))) (CC or) (NP (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-)))))))))))) (. .))
(S (S (PP (IN For) (NP (NN RL))) (, ,) (NP (DT a) (NML (NN policy) (NN gradient)) (NN approach)) (VP (VBZ is) (ADJP (JJ natural)))) (, ,) (CC but) (SQ (VBZ is) (NP (NN sample)) (ADJP (JJ inefficient))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (CD 3) (NNS methods)) (PP (IN for) (S (VP (VBG reducing) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS dialogs)) (VP (VBN required) (S (VP (TO to) (VP (VB optimize) (NP (ADJP (NP (DT an) (NN RNN)) (HYPH -) (VBN based)) (NN dialog) (NN policy)) (PP (IN with) (NP (NN RL)))))))))))))) (. .))
(S (NP (DT The) (JJ key) (NN idea)) (VP (VBZ is) (S (VP (VP (TO to) (VP (VB maintain) (NP (NP (DT a) (JJ second) (NN RNN)) (SBAR (WHNP (WDT which)) (S (VP (VBZ predicts) (NP (NP (DT the) (NN value)) (PP (IN of) (NP (DT the) (JJ current) (NN policy)))))))))) (, ,) (CC and) (VP (TO to) (VP (VB apply) (NP (NN experience) (NN replay)) (PP (IN to) (NP (DT both) (NNS networks)))))))) (. .))
(S (PP (IN On) (NP (CD two) (NNS tasks))) (, ,) (NP (DT these) (NNS methods)) (VP (VBP reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS dialogs)) (, /) (NP (NP (NNS episodes)) (VP (VBN required) (PP (IN by) (PP (IN about) (NP (NP (DT a) (JJ third)) (, ,) (FW vs.) (NP (JJ standard) (NML (NN policy) (NN gradient)) (NNS methods))))))))))) (. .))
