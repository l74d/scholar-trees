(S (NP (DT This) (NN paper)) (VP (VBZ presents) (NP (NP (DT a) (NN reinforcement)) (VP (VBG learning) (NP (NN approach)) (PP (IN to) (S (VP (VBG synthesizing) (NP (ADJP (NN task) (HYPH -) (VBN driven)) (NN control) (NNS policies)) (PP (IN for) (NP (NP (JJ robotic) (NNS systems)) (VP (VBN equipped) (PP (IN with) (NP (JJ rich) (JJ sensory) (NNS modalities)))))) (PRN (-LRB- -LRB-) (NP (ADVP (FW e.g.)) (, ,) (NN vision) (CC or) (NN depth)) (-RRB- -RRB-)))))))) (. .))
(S (NP (JJ Standard) (NML (NN reinforcement) (VBG learning)) (NNS algorithms)) (ADVP (RB typically)) (VP (VBP produce) (NP (NP (NNS policies)) (SBAR (WHNP (WDT that)) (S (ADVP (RB tightly)) (VP (VBP couple) (NP (NN control) (NNS actions)) (PP (IN to) (NP (NP (DT the) (NN entirety)) (PP (IN of) (NP (NP (DT the) (NN system) (POS 's)) (ADJP (NN state) (CC and) (JJ rich)) (NN sensor) (NNS observations)))))))))) (. .))
(S (PP (IN As) (NP (DT a) (NN consequence))) (, ,) (NP (DT the) (VBG resulting) (NNS policies)) (VP (MD can) (ADVP (RB often)) (VP (VB be) (ADJP (JJ sensitive) (PP (IN to) (NP (NP (NP (NNS changes)) (PP (IN in) (NP (NP (ADJP (NN task) (HYPH -) (JJ irrelevant)) (NNS portions)) (PP (IN of) (NP (NP (DT the) (NN state)) (CC or) (NP (NNS observations)))) (-LRB- -LRB-) (ADVP (FW e.g.))))) (, ,) (VP (VBG changing) (NP (NN background) (NNS colors))) (-RRB- -RRB-)))))) (. .))
(S (PP (IN In) (NP (NN contrast))) (, ,) (NP (NP (DT the) (NN approach)) (SBAR (S (NP (PRP we)) (VP (VBP present) (ADVP (RB here)))))) (VP (VBZ learns) (S (VP (TO to) (VP (VB create) (NP (NP (DT a) (ADJP (NN task) (HYPH -) (VBN driven)) (NN representation)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBN used) (S (VP (TO to) (VP (VB compute) (NP (NN control) (NNS actions)))))))))))))) (. .))
(S (S (ADVP (RB Formally)) (, ,) (NP (DT this)) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (S (VP (VBG deriving) (NP (NP (DT a) (NN policy) (NML (NN gradient) (HYPH -) (NN style)) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ creates) (NP (NP (DT an) (NN information) (NN bottleneck)) (PP (IN between) (NP (NP (DT the) (NNS states)) (CC and) (NP (DT the) (ADJP (NN task) (HYPH -) (VBN driven)) (NN representation))))))))))))))) (: ;) (S (NP (DT this)) (VP (VBZ constrains) (NP (NNS actions)) (S (VP (TO to) (ADVP (RB only)) (VP (VB depend) (PP (IN on) (NP (ADJP (NN task) (HYPH -) (JJ relevant)) (NN information)))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (PRP$ our) (NN approach)) (PP (IN in) (NP (NP (DT a) (JJ thorough) (NN set)) (PP (IN of) (NP (NN simulation) (NNS results))))) (PP (IN on) (NP (NP (JJ multiple) (NNS examples)) (PP (VBG including) (NP (NP (DT a) (VBG grasping) (NN task)) (SBAR (WHNP (WDT that)) (S (VP (VBZ utilizes) (NP (NP (NN depth) (NNS images)) (CC and) (NP (NP (DT a) (ADJP (NP (NN ball)) (HYPH -) (VBG catching)) (NN task)) (SBAR (WHNP (WDT that)) (S (VP (VBZ utilizes) (NP (NN RGB) (NNS images))))))))))))))) (. .))
(S (NP (NP (NNS Comparisons)) (PP (IN with) (NP (DT a) (JJ standard) (NML (NN policy) (NN gradient)) (NN approach)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT the) (ADJP (NN task) (HYPH -) (VBN driven)) (NNS policies)) (VP (VBN produced) (PP (IN by) (NP (PRP$ our) (NN algorithm))))) (VP (VBP are) (ADVP (RB often)) (ADJP (ADJP (RB significantly) (RBR more) (JJ robust)) (PP (IN to) (NP (NP (NN sensor) (NN noise)) (CC and) (NP (ADJP (NN task) (HYPH -) (JJ irrelevant)) (NNS changes))))) (PP (IN in) (NP (DT the) (NN environment))))))) (. .))
