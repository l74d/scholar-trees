(S (NP (DT The) (NNP Transformer) (NN translation) (NN model)) (VP (VBZ employs) (NP (NP (JJ residual) (NN connection)) (CC and) (NP (NN layer) (NN normalization))) (S (VP (TO to) (VP (VB ease) (NP (NP (DT the) (NN optimization) (NNS difficulties)) (VP (VBN caused) (PP (IN by) (NP (PRP$ its) (JJ multi-layer) (NN encoder/decoder) (NN structure))))))))) (. .))
(S (NP (JJ Previous) (NN research)) (VP (VBZ shows) (SBAR (IN that) (S (S (PP (ADVP (RB even)) (IN with) (NP (NP (JJ residual) (NN connection)) (CC and) (NP (NN layer) (NN normalization)))) (, ,) (NP (JJ deep) (NNPS Transformers)) (ADVP (RB still)) (VP (VBP have) (NP (NP (NN difficulty)) (PP (IN in) (S (VP (NN training))))))) (, ,) (CC and) (S (NP (NP (ADVP (RB particularly)) (NNP Transformer) (NNS models)) (PP (IN with) (NP (QP (JJR more) (IN than) (CD 12)) (NN encoder/decoder) (NNS layers)))) (VP (VBP fail) (S (VP (TO to) (VP (VB converge))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (ADVP (RB first)) (VP (ADVP (RB empirically)) (VB demonstrate) (SBAR (IN that) (S (NP (NP (DT a) (JJ simple) (NN modification)) (VP (VBN made) (PP (IN in) (NP (DT the) (JJ official) (NN implementation)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ changes) (NP (NP (DT the) (NN computation) (NN order)) (PP (IN of) (NP (NP (JJ residual) (NN connection)) (CC and) (NP (NN layer) (NN normalization)))))))) (, ,)) (VP (MD can) (VP (ADVP (RB significantly)) (VB ease) (NP (NP (DT the) (NN optimization)) (PP (IN of) (NP (JJ deep) (NNS Transformers))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VP (VBP compare) (NP (NP (DT the) (JJ subtle) (NNS differences)) (PP (IN in) (NP (NN computation) (NN order)))) (PP (IN in) (NP (JJ considerable) (NN detail)))) (, ,) (CC and) (VP (VB present) (NP (NP (DT a) (NN parameter) (NN initialization) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ leverages) (NP (NP (NP (DT the) (NNP Lipschitz) (NN constraint)) (PP (IN on) (NP (NP (DT the) (NN initialization)) (PP (IN of) (NP (NNP Transformer) (NNS parameters)))))) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB effectively)) (VBZ ensures) (NP (VBG training) (NN convergence)))))))))))) (. .))
(S (PP (IN In) (NP (NP (NN contrast)) (PP (TO to) (NP (NP (NNS findings)) (PP (IN in) (NP (JJ previous) (NN research))))))) (NP (PRP we)) (ADVP (VBP further)) (VP (VB demonstrate) (SBAR (IN that) (S (PP (IN with) (NP (NNP Lipschitz) (NN parameter) (NN initialization))) (, ,) (NP (NP (JJ deep) (NNS Transformers)) (PP (IN with) (NP (DT the) (JJ original) (NN computation) (NN order)))) (VP (MD can) (VP (VP (VB converge)) (, ,) (CC and) (VP (VB obtain) (NP (JJ significant) (NNP BLEU) (NNS improvements)) (PP (IN with) (NP (QP (IN up) (TO to) (CD 24)) (NNS layers))))))))) (. .))
(S (PP (IN In) (NP (NP (NN contrast)) (PP (TO to) (NP (NP (JJ previous) (NN research)) (SBAR (WHNP (WDT which)) (S (VP (VBZ focuses) (PP (IN on) (NP (JJ deep) (NNS encoders)))))))))) (, ,) (NP (PRP$ our) (NN approach)) (VP (ADVP (RB additionally)) (VBZ enables) (S (NP (NNS Transformers)) (VP (TO to) (ADVP (RB also)) (VP (VB benefit) (PP (IN from) (NP (JJ deep) (NNS decoders))))))) (. .))
