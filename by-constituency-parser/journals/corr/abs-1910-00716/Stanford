(S (NP (NN Self) (HYPH -) (NN attention)) (VP (VBZ has) (VP (VBN been) (NP (NP (DT a) (JJ huge) (NN success)) (PP (IN for) (NP (NP (NP (JJ many) (JJ downstream) (NNS tasks)) (PP (IN in) (NP (NN NLP)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD led) (PP (IN to) (NP (NP (NN exploration)) (PP (IN of) (S (VP (VBG applying) (NP (NP (NN self) (HYPH -) (NN attention)) (PP (IN to) (NP (NN speech) (NNS problems)))) (CONJP (RB as) (RB well))))))))))))))) (. .))
(S (NP (NP (DT The) (NN efficacy)) (PP (IN of) (NP (NP (NN self) (HYPH -) (NN attention)) (PP (IN in) (NP (NN speech) (NNS applications)))))) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ seems) (RB not) (ADJP (ADJP (RB fully) (VBN blown)) (SBAR (ADVP (RB yet)) (IN since) (S (NP (PRP it)) (VP (VBZ is) (VP (VBG challenging) (S (VP (TO to) (VP (VB handle) (NP (ADJP (RB highly) (VBN correlated)) (NN speech) (NNS frames)) (PP (IN in) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (NN self) (HYPH -) (NN attention)))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP propose) (S (NP (NP (DT a) (JJ new) (NML (JJ neural) (NN network)) (NN model) (NN architecture)) (, ,) (RRC (ADVP (RB namely)) (ADJP (JJ multi-stream) (NP (NN self) (HYPH -) (NN attention)))) (, ,)) (VP (TO to) (VP (VB address) (S (NP (DT the) (NN issue)) (ADVP (RB thus)) (VP (VB make) (NP (NP (DT the) (ADJP (NN self) (HYPH -) (NN attention)) (NN mechanism)) (ADJP (RBR more) (JJ effective))) (PP (IN for) (NP (NN speech) (NN recognition))))))))) (. .))
(S (S (NP (DT The) (VBN proposed) (NN model) (NN architecture)) (VP (VBZ consists) (PP (IN of) (NP (NP (JJ parallel) (NNS streams)) (PP (IN of) (NP (ADJP (NN self) (HYPH -) (NN attention)) (NNS encoders))))))) (, ,) (CC and) (S (NP (DT each) (NN stream)) (VP (VBZ has) (NP (NP (NNS layers)) (PP (IN of) (NP (NP (NN 1D) (NNS convolutions)) (PP (IN with) (NP (NP (ADJP (VBN dilated)) (NNS kernels)) (SBAR (WHNP (WP$ whose) (NN dilation)) (S (NP (NNS rates)) (VP (VBP are) (NP (NP (JJ unique) (VBN given) (NN stream)) (, ,) (VP (VBN followed) (PP (IN by) (NP (DT a) (ADJP (NN self) (HYPH -) (NN attention)) (NN layer))))))))))))))) (. .))
(S (S (NP (NP (DT The) (ADJP (NN self) (HYPH -) (NN attention)) (NN mechanism)) (PP (IN in) (NP (DT each) (NN stream)))) (VP (VBZ pays) (NP (NN attention)) (PP (IN to) (NP (NP (RB only) (CD one) (NN resolution)) (PP (IN of) (NP (NN input) (NN speech) (NNS frames))))))) (CC and) (S (NP (DT the) (ADJP (JJ attentive)) (NN computation)) (VP (MD can) (VP (VB be) (ADJP (RBR more) (JJ efficient))))) (. .))
(S (PP (IN In) (NP (DT a) (JJ later) (NN stage))) (, ,) (NP (NP (NNS outputs)) (PP (IN from) (NP (PDT all) (DT the) (NNS streams)))) (VP (VBP are) (VP (VP (VBN concatenated) (ADVP (RB then))) (ADVP (RB linearly)) (VP (VBN projected) (PP (IN to) (NP (DT the) (JJ final) (NN embedding)))))) (. .))
(S (PP (IN By) (S (VP (VP (VBG stacking) (NP (NP (DT the) (VBN proposed) (NN multi-stream) (NN self) (HYPH -) (NN attention)) (NP (NN encoder) (NNS blocks)))) (CC and) (VP (VBG rescoring) (NP (NP (DT the) (JJ resultant) (NNS lattices)) (PP (IN with) (NP (NML (JJ neural) (NN network) (NN language)) (NNS models)))))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (DT the) (NN word) (NN error) (NN rate)) (PP (IN of) (NP (CD 2.2) (NN %)))) (PP (IN on) (NP (NP (NP (DT the) (ADJP (NP (NN test)) (HYPH -) (JJ clean)) (NN dataset)) (PP (IN of) (NP (DT the) (NNP LibriSpeech) (NN corpus)))) (, ,) (NP (NP (DT the) (JJS best) (NN number)) (VP (VBN reported) (ADVP (RB thus) (RB far)) (PP (IN on) (NP (DT the) (NN dataset)))))))) (. .))
