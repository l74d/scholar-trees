(S (NP (NP (JJ Classical) (JJ stochastic) (NN gradient) (NNS methods)) (PP (IN for) (NP (NN optimization)))) (VP (RB rely) (PP (IN on) (NP (NP (JJ noisy) (NN gradient) (NNS approximations)) (SBAR (WHNP (IN that)) (S (VP (VBP become) (ADJP (RB progressively) (JJ less) (JJ accurate)) (SBAR (IN as) (S (NP (NNS iterates)) (VP (VBP approach) (NP (DT a) (NN solution))))))))))) (. .))
(S (NP (NP (DT The) (NX (NX (JJ large) (NN noise)) (CC and) (NX (JJ small) (NN signal)))) (PP (IN in) (NP (DT the) (JJ resulting) (NNS gradients)))) (VP (VBZ makes) (S (NP (NP (PRP it))) (ADJP (JJ difficult)) (S (VP (TO to) (VP (VB use) (NP (PRP them)) (PP (IN for) (NP (NP (JJ adaptive) (NN stepsize) (NN selection)) (CC and) (NP (JJ automatic) (NN stopping))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (JJ alternative) (`` ``) (JJ big) (NN batch) ('' '') (NNP SGD) (VBZ schemes)) (SBAR (WHNP (IN that)) (S (VP (ADVP (RB adaptively)) (VB grow) (NP (DT the) (NN batch) (NN size)) (PP (IN over) (NP (NN time))) (S (VP (TO to) (VP (VB maintain) (NP (NP (DT a) (ADJP (RB nearly) (JJ constant)) (NN signal-to-noise) (NN ratio)) (PP (IN in) (NP (DT the) (JJ gradient) (NN approximation)))))))))))) (. .))
(S (NP (DT The) (VBG resulting) (NNS methods)) (VP (VP (VBP have) (NP (NP (JJ similar) (NN convergence) (NNS rates)) (PP (TO to) (NP (JJ classical) (NNP SGD))))) (, ,) (CC and) (VP (VBP do) (RB not) (VP (VB require) (NP (NP (NN convexity)) (PP (IN of) (NP (DT the) (NN objective))))))) (. .))
(S (NP (DT The) (JJ high) (NN fidelity) (NNS gradients)) (VP (VP (JJ enable) (NP (VBD automated) (VBG learning) (NN rate) (NN selection))) (CC and) (VP (VBP do) (RB not) (VP (VB require) (NP (JJ stepsize) (NN decay))))) (. .))
(S (NP (JJ Big) (NN batch) (NNS methods)) (VP (VP (VBP are) (ADVP (RB thus)) (VP (ADVP (RB easily)) (VBN automated))) (CC and) (VP (MD can) (VP (VB run) (PP (IN with) (NP (ADJP (JJ little) (CC or) (DT no)) (NN oversight)))))) (. .))
