(S (NP (JJ Model-free) (JJ deep) (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)) (NNS methods)) (VP (VBP have) (VP (VBN been) (ADJP (JJ successful)) (PP (IN in) (NP (NP (DT a) (JJ wide) (NN variety)) (PP (IN of) (NP (JJ simulated) (NNS domains))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT a) (JJ major) (NN obstacle)) (VP (VBG facing) (NP (JJ deep) (NNP RL)) (PP (IN in) (NP (DT the) (JJ real) (NN world))))) (VP (VBZ is) (NP (PRP$ their) (JJ high) (NN sample) (NN complexity))) (. .))
(S (NP (NN Batch) (NN policy) (NN gradient) (NNS methods)) (VP (VBP offer) (NP (JJ stable) (NN learning)) (, ,) (PP (CC but) (PP (IN at) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (NP (JJ high) (NN variance)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB often)) (VP (VBZ requires) (NP (JJ large) (NNS batches))))))))))) (. .))
(S (NP (NP (JJ TD-style) (NNS methods)) (, ,) (PP (JJ such) (IN as) (NP (NP (JJ off-policy) (JJ actor-critic)) (CC and) (NP (JJ Q-learning)))) (, ,)) (VP (VP (VBP are) (ADJP (RBR more) (JJ sample-efficient) (CC but) (ADJP (JJ biased)))) (, ,) (CC and) (VP (ADVP (RB often)) (VBP require) (NP (JJ costly) (JJR hyperparameter) (NNS sweeps)) (S (VP (TO to) (VP (VB stabilize)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP aim) (S (VP (TO to) (VP (VB develop) (NP (NP (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP combine) (NP (NP (DT the) (NN stability)) (PP (IN of) (NP (NN policy) (NNS gradients)))) (PP (IN with) (NP (NP (DT the) (NN efficiency)) (PP (IN of) (NP (JJ off-policy) (NNP RL))))))))))))) (. .))
(S (NP (PRP We)) (VP (JJ present) (NP (NP (NNP Q-Prop)) (, ,) (NP (NP (DT a) (NN policy) (NN gradient) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (NP (DT a) (NNP Taylor) (NN expansion)) (PP (IN of) (NP (DT the) (JJ off-policy) (NN critic)))) (PP (IN as) (NP (DT a) (NN control) (NN variate))))))))) (. .))
(S (NP (NN Q-Prop)) (VP (VP (VBZ is) (ADJP (DT both) (ADJP (JJ sample) (NN efficient)) (CC and) (ADJP (JJ stable)))) (, ,) (CC and) (VP (ADVP (RB effectively)) (VBZ combines) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (NP (NN on-policy) (CC and) (NN off-policy) (NNS methods)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP analyze) (NP (NP (DT the) (NN connection)) (PP (IN between) (NP (NP (NNP Q-Prop)) (CC and) (NP (VBG existing) (JJ model-free) (NN algorithms)))))) (, ,) (CC and) (VP (VB use) (NP (NN control) (NN variate) (NN theory)) (S (VP (TO to) (VP (VB derive) (NP (NP (CD two) (NNS variants)) (PP (IN of) (NP (NNP Q-Prop))) (PP (IN with) (NP (ADJP (JJ conservative) (CC and) (JJ aggressive)) (NN adaptation))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ conservative) (NNP Q-Prop)) (VP (VP (VBZ provides) (NP (NP (JJ substantial) (NNS gains)) (PP (IN in) (NP (JJ sample) (NN efficiency))) (PP (IN over) (NP (NP (JJ trust) (NN region) (NN policy) (NN optimization)) (PRN (-LRB- -LRB-) (NP (NNP TRPO)) (-RRB- -RRB-)))) (PP (IN with) (NP (NP (VBN generalized) (NN advantage) (NN estimation)) (PRN (-LRB- -LRB-) (NP (NNP GAE)) (-RRB- -RRB-)))))) (, ,) (CC and) (VP (VBZ improves) (NP (NN stability)) (PP (IN over) (NP (NP (NP (NP (JJ deep) (JJ deterministic) (NN policy) (NN gradient)) (PRN (-LRB- -LRB-) (NP (NNP DDPG)) (-RRB- -RRB-))) (, ,) (NP (DT the) (JJ state-of-the-art) (UCP (NN on-policy) (CC and) (NN off-policy)) (NNS methods))) (, ,))) (PP (IN on) (NP (NP (NNP OpenAI) (NNP Gym) (POS 's)) (NNP MuJoCo) (JJ continuous) (NN control) (NNS environments)))))))) (. .))
