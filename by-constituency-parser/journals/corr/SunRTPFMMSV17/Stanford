(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (NN max) (HYPH -)) (S (VP (VBG pooling) (PP (VBN based) (NP (NP (NN loss) (NN function)) (PP (IN for) (NP (NP (NN training) (NML (JJ Long) (JJ Short)) (HYPH -) (NN Term) (NN Memory) (PRN (-LRB- -LRB-) (NP (NN LSTM)) (-RRB- -RRB-))) (NP (NP (NNS networks)) (PP (IN for) (NP (NML (JJ small) (HYPH -) (NN footprint)) (NN keyword) (NN spotting) (PRN (-LRB- -LRB-) (NP (NN KWS)) (-RRB- -RRB-))))) (, ,) (PP (IN with) (NP (NP (JJ low) (NN CPU)) (, ,) (NP (NN memory)) (, ,) (CC and) (NP (NN latency) (NNS requirements))))))))))) (. .))
(S (NP (DT The) (ADJP (NN max) (HYPH -) (VBG pooling)) (NN loss) (NN training)) (VP (MD can) (VP (VB be) (NP (JJ further) (ADJP (VBN guided) (PP (IN by) (S (VP (VBG initializing) (PP (IN with) (NP (NP (DT a) (JJ cross-entropy) (NN loss)) (VP (VBN trained)))))))) (NN network)))) (. .))
(S (NP (DT A) (ADJP (NP (JJ posterior) (NN smoothing)) (VBN based)) (NN evaluation) (NN approach)) (VP (VBZ is) (VP (VBN employed) (S (VP (TO to) (VP (VB measure) (NP (JJ keyword) (NN spotting) (NN performance))))))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NNP LSTM) (NNS models)) (VP (VBN trained) (S (VP (VP (VBG using) (NP (JJ cross-entropy) (NN loss))) (CC or) (VP (NN max) (HYPH -) (VBG pooling) (NP (NN loss))))))) (VP (VBP outperform) (NP (NP (DT a) (JJ cross-entropy) (NN loss)) (VP (VBN trained) (NP (NP (ADJP (NP (NN baseline) (NN feed)) (HYPH -) (JJ forward)) (JJ Deep) (JJ Neural) (NN Network)) (-LRB- -LRB-) (NP (NN DNN)) (-RRB- -RRB-)))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (NP (NP (ADJP (NN max) (HYPH -) (VBG pooling)) (NN loss)) (VP (VBN trained) (NP (NNP LSTM)) (PP (IN with) (ADVP (RB randomly))))) (VP (VBN initialized) (NP (NN network)))) (VP (VBZ performs) (NP (JJR better)) (PP (VBN compared) (PP (IN to) (NP (JJ cross-entropy) (ADJP (NN loss) (VBN trained)) (NNP LSTM))))) (. .))
