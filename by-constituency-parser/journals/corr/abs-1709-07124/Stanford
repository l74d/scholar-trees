(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (ADJP (JJ novel) (JJ recurrent)) (NML (JJ neural) (NN network)) (NN architecture)) (PP (IN for) (NP (NN speech) (NN separation))))) (. .))
(S (NP (DT This) (NN architecture)) (VP (VBZ is) (VP (VBN constructed) (PP (IN by) (S (VP (VBG unfolding) (NP (NP (DT the) (NNS iterations)) (PP (IN of) (NP (NP (NP (DT a) (JJ sequential) (JJ iterative) (NML (JJ soft) (HYPH -)) (VBG thresholding) (NN algorithm)) (-LRB- -LRB-) (NP (NNP ISTA)) (-RRB- -RRB-)) (SBAR (WHNP (WDT that)) (S (VP (VBZ solves) (NP (NP (DT the) (NN optimization) (NN problem)) (PP (IN for) (NP (NP (NP (JJ sparse) (JJ nonnegative) (NN matrix) (NN factorization)) (-LRB- -LRB-) (NP (NN NMF)) (-RRB- -RRB-)) (PP (IN of) (NP (NNS spectrograms))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP name) (NP (DT this) (NML (NN network) (NN architecture)) (ADJP (JJ deep) (JJ recurrent)) (NN NMF)) (PRN (-LRB- -LRB-) (NP (NNP DR) (HYPH -) (NNP NMF)) (-RRB- -RRB-))) (. .))
(S (NP (DT The) (VBN proposed) (NML (NNP DR) (HYPH -) (NNP NMF)) (NN network)) (VP (VBZ has) (NP (CD three) (JJ distinct) (NNS advantages))) (. .))
(S (ADVP (RB First)) (, ,) (NP (NNP DR) (HYPH -) (NNP NMF)) (VP (VBZ provides) (NP (JJR better) (NN interpretability)) (PP (IN than) (NP (JJ other) (JJ deep) (NNS architectures))) (, ,) (SBAR (IN since) (S (NP (DT the) (NNS weights)) (VP (VBP correspond) (PP (PP (IN to) (NP (NN NMF) (NN model) (NNS parameters))) (, ,) (RB even) (PP (IN after) (NP (NN training)))))))) (. .))
(S (NP (DT This) (NN interpretability)) (ADVP (RB also)) (VP (VBZ provides) (NP (NP (JJ principled) (NNS initializations)) (SBAR (WHNP (WDT that)) (S (VP (VBP enable) (ADVP (RBR faster)) (NP (NP (NN training) (CC and) (NN convergence)) (PP (TO to) (NP (NP (ADVP (RBR better)) (NNS solutions)) (PP (VBN compared) (PP (IN to) (NP (JJ conventional) (JJ random) (NN initialization)))))))))))) (. .))
(S (ADVP (RB Second)) (, ,) (PP (IN like) (NP (JJ many) (JJ deep) (NNS networks))) (, ,) (NP (NNP DR) (HYPH -) (NNP NMF)) (VP (VBZ is) (NP (NP (DT an) (NN order)) (PP (IN of) (NP (NN magnitude)))) (PP (ADVP (RBR faster)) (IN at) (NP (NP (NN test) (NN time)) (PP (IN than) (NP (NN NMF))))) (, ,) (SBAR (IN since) (S (NP (NP (NN computation)) (PP (IN of) (NP (DT the) (NN network) (NN output)))) (ADVP (RB only)) (VP (VBZ requires) (S (VP (VBG evaluating) (NP (DT a) (JJ few) (NNS layers)) (PP (IN at) (NP (DT each) (NN time) (NN step))))))))) (. .))
(S (LST (JJ Third)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT a) (JJ limited) (NN amount)) (PP (IN of) (NP (NN training) (NNS data)))) (VP (VBZ is) (ADJP (JJ available))))) (, ,) (NP (NNP DR) (HYPH -) (NNP NMF)) (VP (VBZ exhibits) (NP (JJR stronger) (NML (NN generalization) (CC and) (NN separation)) (NN performance)) (PP (VBN compared) (PP (IN to) (NP (JJ sparse) (NML (NML (NN NMF) (CC and) (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (ADJP (JJ long) (HYPH -) (JJ short)) (NML (NML (NN term) (NN memory)) (-LRB- -LRB-) (NML (NN LSTM)) (-RRB- -RRB-)) (NNS networks))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (NP (NP (DT a) (JJ large) (NN amount)) (PP (IN of) (NP (NN training) (NNS data)))) (VP (VBZ is) (ADJP (JJ available))))) (, ,) (NP (NNP DR) (HYPH -) (NNP NMF)) (VP (VBZ achieves) (NP (ADJP (ADJP (JJR lower)) (CC yet) (ADJP (JJ competitive))) (NN separation) (NN performance)) (PP (VBN compared) (PP (IN to) (NP (NNP LSTM) (NNS networks))))) (. .))
