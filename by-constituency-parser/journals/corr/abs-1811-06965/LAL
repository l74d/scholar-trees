(S (S (VP (VBG Scaling) (PRT (RP up)) (NP (JJ deep) (JJ neural) (NN network) (NN capacity)))) (VP (VBZ has) (VP (VBN been) (VP (VBN known) (PP (IN as) (NP (NP (DT an) (JJ effective) (NN approach)) (PP (TO to) (S (VP (VBG improving) (NP (NN model) (NN quality)) (PP (IN for) (NP (JJ several) (JJ different) (NN machine) (NN learning) (NNS tasks))))))))))) (. .))
(S (PP (IN In) (NP (JJ many) (NNS cases))) (, ,) (S (VP (VBG increasing) (NP (NN model) (NN capacity)) (PP (IN beyond) (NP (NP (DT the) (NN memory) (NN limit)) (PP (IN of) (NP (DT a) (JJ single) (NN accelerator))))))) (VP (VBZ has) (VP (VBN required) (S (VP (VBG developing) (NP (JJ special) (NN algorithms) (CC or) (NN infrastructure)))))) (. .))
(S (NP (DT These) (NNS solutions)) (VP (VP (VBP are) (ADVP (RB often)) (ADJP (JJ architecture-specific))) (CC and) (VP (VB do) (RB not) (VP (VB transfer) (PP (TO to) (NP (JJ other) (NNS tasks)))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (ADJP (JJ efficient) (CC and) (JJ task-independent)) (NN model) (NN parallelism))))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (NNP GPipe)) (, ,) (NP (NP (DT a) (NN pipeline) (NN parallelism) (VBP library)) (SBAR (WHNP (WDT that)) (S (VP (VBZ allows) (S (VP (VBG scaling) (NP (NP (DT any) (NN network)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN expressed) (PP (IN as) (NP (NP (DT a) (NN sequence)) (PP (IN of) (NP (NNS layers))))))))))))))))))) (. .))
(S (PP (IN By) (S (VP (VBG pipelining) (NP (NP (JJ different) (NNS sub-sequences)) (PP (IN of) (NP (NNS layers)))) (PP (IN on) (NP (JJ separate) (NNS accelerators)))))) (, ,) (NP (NNP GPipe)) (VP (VBZ provides) (NP (NP (DT the) (NN flexibility)) (PP (IN of) (S (VP (VBG scaling) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (JJ different) (NNS networks)))) (PP (TO to) (NP (JJ gigantic) (NNS sizes))) (ADVP (RB efficiently))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NNP GPipe)) (VP (VBZ utilizes) (NP (DT a) (JJ novel) (JJ batch-splitting) (NN pipelining) (NN algorithm)) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (ADJP (RB almost) (JJ linear)) (NN speedup))) (SBAR (WHADVP (WRB when)) (S (NP (DT a) (NN model)) (VP (VBZ is) (VP (VBN partitioned) (PP (IN across) (NP (JJ multiple) (NNS accelerators)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (NP (NNP GPipe)))) (PP (IN by) (S (VP (VBG training) (NP (JJ large-scale) (JJ neural) (NNS networks)) (PP (IN on) (NP (NP (NP (CD two) (JJ different) (NNS tasks)) (PP (IN with) (NP (JJ distinct) (NN network) (NNS architectures)))) (: :) (NP (PRN (-LRB- -LRB-) (NN i) (-RRB- -RRB-)) (NP (NP (NN Image) (NN Classification)) (: :) (S (NP (PRP We)) (VP (VP (VBP train) (NP (DT a) (JJ 557-million-parameter) (NNP AmoebaNet) (NN model))) (CC and) (VP (VB attain) (NP (NP (DT a) (JJ top-1) (NN accuracy)) (PP (IN of) (NP (CD 84.4) (NN %)))) (PP (IN on) (NP (NNP ImageNet-2012))))))) (, ,) (NP (NP (PRN (-LRB- -LRB-) (NN ii) (-RRB- -RRB-)) (NP (NNP Multilingual) (NNP Neural) (NNP Machine) (NN Translation))) (: :) (S (NP (PRP We)) (VP (VP (VBP train) (NP (DT a) (JJ single) (JJ 6-billion-parameter) (, ,) (JJ 128-layer) (NNP Transformer) (NN model)) (PP (IN on) (NP (NP (DT a) (NN corpus)) (VP (VBG spanning) (NP (QP (IN over) (CD 100)) (NNS languages)))))) (CC and) (VP (VBP achieve) (NP (NP (JJR better) (NN quality)) (PP (IN than) (NP (DT all) (JJ bilingual) (NNS models))))))))))))))) (. .))
