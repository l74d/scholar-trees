(S (S (NP (NN Machine) (NN learning)) (VP (VBZ is) (VP (VBN predicated) (PP (IN on) (NP (NP (DT the) (NN concept)) (PP (IN of) (NP (NN generalization)))))))) (: :) (S (NP (NP (DT a) (NN model)) (VP (VBG achieving) (NP (JJ low) (NN error)) (PP (IN on) (NP (DT a) (ADJP (RB sufficiently) (JJ large)) (VBG training) (NN set))))) (VP (MD should) (ADVP (RB also)) (VP (VB perform) (ADVP (RB well)) (PP (IN on) (NP (NP (JJ novel) (NNS samples)) (PP (IN from) (NP (DT the) (JJ same) (NN distribution)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT both) (NP (NNS data) (NN whitening)) (CC and) (NP (JJ second) (NN order) (NN optimization))) (VP (MD can) (VP (VP (VB harm)) (CC or) (VP (ADVP (RB entirely)) (JJ prevent)) (NP (NN generalization))))))) (. .))
(S (PP (IN In) (ADJP (JJ general))) (, ,) (NP (NN model) (NN training)) (VP (VBZ harnesses) (NP (NP (NN information)) (VP (VBN contained) (PP (IN in) (NP (NP (DT the) (JJ sample-sample) (JJ second) (NN moment) (NN matrix)) (PP (IN of) (NP (DT a) (NN dataset)))))))) (. .))
(S (PP (IN For) (NP (NP (NP (DT a) (JJ general) (NN class)) (PP (IN of) (NP (NNS models)))) (, ,) (ADVP (RB namely)) (NP (NP (NNS models)) (PP (IN with) (NP (DT a) (ADJP (RB fully) (VBN connected)) (JJ first) (NN layer)))) (, ,))) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (NP (DT the) (NN information)) (VP (VBN contained) (PP (IN in) (NP (DT this) (NN matrix))))) (VP (VBZ is) (NP (NP (DT the) (JJ only) (NN information)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB generalize)))))))))))))) (. .))
(S (S (NP (NP (NNS Models)) (VP (VBN trained) (UCP (PP (VBG using) (NP (VBN whitened) (NNS data))) (, ,) (CC or) (PP (IN with) (NP (JJ certain) (JJ second) (NN order) (NN optimization) (NNS schemes))) (, ,)))) (VP (VBP have) (NP (NP (JJR less) (NN access)) (PP (TO to) (NP (DT this) (NN information)))))) (: ;) (S (PP (IN in) (NP (DT the) (JJ high) (JJ dimensional) (NN regime))) (NP (PRP they)) (VP (VBP have) (NP (DT no) (NN access)) (ADVP (IN at) (DT all)) (, ,) (S (VP (VBG producing) (NP (NP (NNS models)) (SBAR (WHNP (IN that)) (S (VP (VBP generalize) (ADVP (ADVP (RB poorly)) (CC or) (ADVP (RB not) (IN at) (DT all))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (RB experimentally)) (VB verify) (NP (DT these) (NNS predictions)) (PP (IN for) (NP (JJ several) (NNS architectures)))) (, ,) (CC and) (VP (ADVP (RB further)) (VB demonstrate) (SBAR (DT that) (S (NP (NN generalization)) (VP (VBZ continues) (S (VP (TO to) (VP (VB be) (VP (VBN harmed))))) (SBAR (WHADVP (RB even) (WRB when)) (S (NP (JJ theoretical) (NNS requirements)) (VP (VBP are) (VP (VBN relaxed)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VBP show) (ADVP (RB experimentally)) (SBAR (IN that) (S (NP (VBN regularized) (JJ second) (NN order) (NN optimization)) (VP (MD can) (VP (VB provide) (NP (DT a) (JJ practical) (NN tradeoff)) (, ,) (SBAR (SBAR (WHADVP (WRB where)) (S (S (NP (NN training)) (VP (VBZ is) (ADVP (RB still)) (VP (VBN accelerated)))) (CC but) (S (NP (JJR less) (NN information)) (VP (VBZ is) (VP (VBN lost)))))) (, ,) (CC and) (S (NP (NN generalization)) (VP (MD can) (PP (IN in) (NP (DT some) (NNS circumstances))) (ADVP (RB even)) (VP (VB improve)))))))))) (. .))
