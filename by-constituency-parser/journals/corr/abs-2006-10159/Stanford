(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT the) (NNP QKeras) (NN library)) (, ,) (NP (NP (DT an) (NN extension)) (PP (IN of) (NP (DT the) (NNP Keras) (NN library))))) (S (VP (VBG allowing) (PP (IN for) (NP (NP (DT the) (NN creation)) (PP (IN of) (ADVP (RB heterogeneously))))) (NP (NP (VBN quantized) (NNS versions)) (PP (IN of) (NP (JJ deep) (NML (JJ neural) (NN network)) (NNS models)))))) (, ,) (PP (IN through) (NP (NP (NN drop)) (HYPH -) (PP (IN in) (NP (NP (NN replacement)) (PP (IN of) (NP (NNP Keras) (NNS layers)))))))) (. .))
(S (NP (DT These) (NNS models)) (VP (VBP are) (VP (VBN trained) (NP (ADJP (NP (NN quantization)) (HYPH -) (JJ aware))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN user)) (VP (MD can) (VP (VB trade) (PRT (RP off)) (NP (NP (NN model) (NN area)) (CC or) (NP (NN energy) (NN consumption))) (PP (IN by) (NP (NN accuracy))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (WHADVP (WRB how)) (S (NP (NP (DT the) (NN reduction)) (PP (IN of) (NP (JJ numerical) (NN precision)))) (, ,) (PP (IN through) (NP (ADJP (NP (NN quantization)) (HYPH -) (JJ aware)) (NN training))) (, ,) (ADVP (RB significantly)) (VP (VBZ reduces) (NP (NN resource) (NN consumption)) (PP (IN while) (S (VP (VBG retaining) (NP (JJ high) (NN accuracy)) (SBAR (WHADVP (WRB when)) (S (VP (VBN implemented) (PP (IN on) (NP (NNP FPGA) (NN hardware))))))))))))) (. .))
(S (PP (ADVP (RB Together)) (IN with) (NP (DT the) (NN hls4ml) (NN library))) (, ,) (NP (DT this)) (VP (VBZ allows) (PP (IN for) (NP (NP (DT a) (RB fully) (VBN automated) (NN deployment)) (PP (IN of) (NP (VBN quantized) (NNP Keras) (NNS models))))) (PP (IN on) (NP (NN chip))) (, ,) (ADJP (JJ crucial) (PP (IN for) (NP (NN ultra) (NML (JJ low) (HYPH -) (NN latency)) (NN inference))))) (. .))
