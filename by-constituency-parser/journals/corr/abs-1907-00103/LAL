(S (NP (PRP We)) (VP (VBP consider) (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (VBG learning) (NP (NP (DT a) (NN loss) (NN function)) (SBAR (WHNP (WDT which)) (S (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBN minimized) (PP (IN over) (NP (DT a) (NN training) (NN dataset)))))) (, ,) (VP (VBZ yields) (NP (NP (DT a) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB approximately)) (VBZ minimizes) (NP (DT a) (NN validation) (NN error) (JJ metric))))))))))))))) (. .))
(S (SBAR (IN Though) (S (S (VP (VBG learning) (NP (DT an) (JJ optimal) (NN loss) (NN function)))) (VP (VBZ is) (ADJP (NNP NP-hard))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT an) (NN anytime) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ is) (ADJP (RB asymptotically) (JJ optimal)) (PP (IN in) (NP (DT the) (JJS worst) (NN case)))) (, ,) (CC and) (VP (VBZ is) (ADJP (RB provably) (JJ efficient)) (PP (IN in) (NP (DT an) (JJ idealized) (`` ``) (JJ easy) ('' '') (NN case))))))))) (. .))
(S (ADVP (RB Experimentally)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this) (NN algorithm)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB tune) (NP (NN loss) (NN function) (NNS hyperparameters)) (ADVP (ADVP (NP (NP (NNS orders)) (PP (IN of) (NP (NN magnitude)))) (RBR faster)) (PP (IN than) (NP (JJ state-of-the-art) (NNS alternatives))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN algorithm)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB learn) (NP (ADJP (JJ novel) (CC and) (JJ effective)) (NN loss) (NNS functions)) (ADVP (VBP on-the-fly)) (PP (IN during) (NP (NN training)))))))))))) (. .))
