(S (NP (NP (NP (JJ Stochastic) (NN Gradient) (NN Descent)) (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)) (CC and) (NP (PRP$ its) (NNS variants))) (VP (VBP are) (NP (NP (JJ mainstream) (NNS methods)) (PP (IN for) (S (VP (VBG training) (NP (JJ deep) (NNS networks)) (PP (IN in) (NP (NN practice)))))))) (. .))
(S (NP (NNP SGD)) (VP (VBZ is) (VP (VBN known) (S (VP (TO to) (VP (VB find) (NP (DT a) (JJ flat) (NN minimum)) (PP (IN with) (NP (NP (DT a) (JJ large) (NN neighboring) (NN region)) (PP (IN in) (NP (NP (DT the) (NN parameter) (NN space)) (SBAR (WHPP (IN from) (WHNP (WDT which))) (S (NP (DT each) (NN weight) (NN vector)) (VP (VBZ has) (NP (JJ similar) (JJ small) (NN error)))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP it)) (VP (VBZ is) (ADVP (RB mathematically)) (ADJP (JJ unclear)) (SBAR (WHADJP (WRB how) (JJ deep)) (S (NP (NN learning)) (VP (MD can) (VP (VB select) (NP (DT a) (JJ flat) (NN minimum)) (PP (IN among) (NP (ADJP (RB so) (JJ many)) (NN minima)))))))) (. .))
(S (S (VP (TO To) (VP (VB answer) (NP (DT the) (NN question)) (ADVP (RB quantitatively))))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (DT a) (NN density) (NN diffusion) (NN theory) (PRN (-LRB- -LRB-) (NP (NN DDT)) (-RRB- -RRB-))) (S (VP (TO to) (VP (VB reveal) (SBAR (WHADVP (WRB how)) (S (NP (NN minima) (NN selection)) (ADVP (RB quantitatively)) (VP (VBZ depends) (PP (IN on) (NP (NP (DT the) (NN minima) (NN sharpness)) (, ,) (NP (NN gradient) (NN noise)) (CC and) (NP (NNS hyperparameters))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP verify) (NP (DT an) (JJ interesting) (NN fact)) (SBAR (IN that) (S (NP (DT the) (JJ stochastic) (NN gradient) (NN noise) (NN covariance)) (VP (VBZ is) (ADJP (RB nearly) (JJ proportional) (PP (IN to) (NP (DT the) (JJ Hessian) (CC and) (JJ inverse)))) (PP (IN to) (NP (NP (DT the) (NN batch) (NN size)) (PP (IN near) (NP (NN minima))))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (PRN (, ,) (SINV (VP (VBD benefited) (PP (IN from) (NP (JJ stochastic) (NN gradient)))) (NP (NN noise))) (, ,)) (S (NP (NNP SGD)) (VP (VBZ favors) (NP (JJ flat) (NN minima)) (S (ADVP (RB exponentially)) (ADJP (ADJP (JJR more)) (PP (IN than) (NP (JJ sharp) (NN minima))))) (, ,) (SBAR (IN while) (S (NP (NP (NNP Gradient) (NNP Descent)) (PP (IN with) (NP (ADJP (VBN injected) (JJ white)) (NN noise)))) (VP (VBZ favors) (NP (JJ flat) (NN minima)) (S (ADVP (RB only)) (ADJP (ADJP (RB polynomially) (JJR more)) (PP (IN than) (NP (JJ sharp) (NN minima)))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (RB also)) (VBP prove) (SBAR (IN that) (S (NP (CC either) (NP (DT a) (NML (JJ small) (NN learning)) (NN rate)) (CC or) (NP (NML (JJ large) (HYPH -) (NN batch)) (NN training))) (VP (VBZ requires) (ADVP (RB exponentially)) (NP (JJ many) (NNS iterations))))) (S (VP (TO to) (VP (VB escape) (PP (IN from) (NP (NN minima))) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (DT the) (NN ratio)) (PP (IN of) (NP (NN batch) (NML (NN size) (CC and) (NN learning)) (NN rate))))))))))) (, ,) (CC and) (ADVP (RB thus)) (VP (MD can) (RB not) (VP (VB search) (NP (JJ flat) (NN minima)) (ADVP (RB efficiently) (PP (IN in) (NP (DT a) (JJ realistic) (JJ computational) (NN time))))))) (. .))
