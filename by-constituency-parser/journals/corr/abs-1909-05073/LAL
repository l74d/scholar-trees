(S (S (NP (NP (NNP Model) (NN compression) (NNS techniques)) (PP (IN on) (NP (NP (NNP Deep) (NNP Neural) (NNP Network)) (PRN (-LRB- -LRB-) (NP (NNP DNN)) (-RRB- -RRB-))))) (VP (VBP have) (VP (VBN been) (VP (ADVP (RB widely)) (VBN acknowledged) (PP (IN as) (NP (NP (DT an) (JJ effective) (NN way)) (SBAR (S (VP (TO to) (VP (VB achieve) (NP (NN acceleration)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS platforms))))))))))))))) (, ,) (CC and) (S (NP (NNP DNN) (VBD weight) (NN pruning)) (VP (VBZ is) (NP (DT a) (ADJP (NN straightforward) (CC and) (JJ effective)) (NN method)))) (. .))
(S (NP (EX There)) (VP (VBP are) (ADVP (RB currently)) (NP (NP (NP (CD two) (NNS mainstreams)) (PP (IN of) (NP (VBG pruning) (NNS methods))) (VP (VBG representing) (NP (NP (CD two) (NNS extremes)) (PP (IN of) (NP (VBG pruning) (NN regularity)))))) (: :) (S (S (NP (ADJP (JJ non-structured) (, ,) (JJ fine-grained)) (NN pruning)) (VP (VP (MD can) (VP (VB achieve) (NP (JJ high) (NN sparsity) (CC and) (NN accuracy)))) (, ,) (CC but) (VP (VBZ is) (RB not) (ADJP (JJ hardware) (RB friendly))))) (: ;) (S (NP (ADJP (VBN structured) (, ,) (JJ coarse-grained)) (VBG pruning)) (VP (VP (NNS exploits) (NP (NP (JJ hardware-efficient) (NNS structures)) (PP (IN in) (NP (NN pruning))))) (, ,) (CC but) (VP (NNS suffers) (PP (IN from) (NP (NN accuracy) (NN drop))) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN pruning) (NN rate)) (VP (VBZ is) (ADJP (JJ high))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (NNP PCONV)) (, ,) (VP (VBG comprising) (NP (NP (DT a) (JJ new) (NN sparsity) (NN dimension)) (, ,) (: â€”) (NP (NP (JJ fine-grained) (NN pruning) (NNS patterns)) (PP (IN inside) (NP (DT the) (JJ coarse-grained) (NNS structures)))))))) (. .))
(S (NP (NNP PCONV)) (VP (VBZ comprises) (NP (NP (NP (CD two) (NNS types)) (PP (IN of) (NP (NNS sparsities)))) (, ,) (NP (NP (NP (NNP Sparse) (NNP Convolution) (NNP Patterns)) (PRN (-LRB- -LRB-) (NP (NNP SCP)) (-RRB- -RRB-)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN generated) (PP (IN from) (NP (JJ intra-convolution) (NNS kernel) (VBG pruning)))))))) (CC and) (NP (NP (NN connectivity) (NN sparsity)) (VP (VBN generated) (PP (IN from) (NP (JJ inter-convolution) (NNS kernel) (VBG pruning)))))))) (. .))
(S (ADVP (RB Essentially)) (, ,) (S (NP (NNP SCP)) (VP (VBZ enhances) (NP (NN accuracy)) (ADVP (JJ due) (PP (TO to) (NP (PRP$ its) (JJ special) (NN vision) (NNS properties)))))) (, ,) (CC and) (S (NP (NN connectivity) (NN sparsity)) (VP (VBZ increases) (NP (VBG pruning) (NN rate)) (SBAR (IN while) (S (VP (VBG maintaining) (NP (NP (VBN balanced) (NN workload)) (PP (IN on) (NP (NN filter) (NN computation))))))))) (. .))
(S (S (VP (TO To) (VP (VB deploy) (NP (NNP PCONV))))) (, ,) (NP (PRP we)) (VP (VP (VBP develop) (NP (DT a) (JJ novel) (JJ compiler-assisted) (NNP DNN) (NN inference) (NN framework))) (CC and) (VP (VP (VB execute) (NP (NNP PCONV) (NNS models)) (PP (IN in) (NP (NN real-time))) (PP (IN without) (NP (NN accuracy) (NN compromise)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (RB not) (VP (VB be) (VP (VBN achieved) (PP (IN in) (NP (JJ prior) (NN work)))))))))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (, ,) (S (NP (NNP PCONV)) (VP (VBZ outperforms) (NP (NP (CD three) (JJ state-of-art) (JJ end-to-end) (NNP DNN) (NNS frameworks)) (, ,) (NP (NP (NNP TensorFlow-Lite)) (, ,) (NP (NNP TVM)) (, ,) (CC and) (NP (NNP Alibaba) (NNP Mobile) (NNP Neural) (NNP Network)))) (PP (IN with) (NP (NP (NN speedup)) (PP (RB up) (PP (TO to) (NP (NP (CD 39.2x) (, ,) (CD 11.4x) (, ,) (CC and) (CD 6.3x)) (, ,) (ADVP (RB respectively))))))) (, ,) (PP (IN with) (NP (DT no) (NN accuracy) (NN loss))))))) (. .))
(S (NP (JJ Mobile) (NNS devices)) (VP (MD can) (VP (VB achieve) (NP (NP (JJ real-time) (NN inference)) (PP (IN on) (NP (JJ large-scale) (NNP DNNs)))))) (. .))
