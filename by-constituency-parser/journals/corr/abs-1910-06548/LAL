(S (NP (PRP We)) (VP (VB reduce) (NP (NP (VBG training) (NN time)) (PP (IN in) (NP (NP (JJ convolutional) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP CNNs)) (-RRB- -RRB-))))) (PP (IN with) (NP (NP (DT a) (NN method)) (SBAR (WHNP (WDT that)) (, ,) (S (PP (IN for) (NP (NP (DT some)) (PP (IN of) (NP (DT the) (NNS mini-batches))))) (: :) (VP (VP (ADVP (DT a) (-RRB- -RRB-)) (VP (VBZ scales) (PRT (RP down)) (NP (NP (DT the) (NN resolution)) (PP (IN of) (NP (NN input) (NNS images)))) (PP (IN via) (NP (NN downsampling))))) (, ,) (CC and) (VP (LST (NN b) (-RRB- -RRB-)) (VP (VBZ reduces) (NP (DT the) (NN forward) (NN pass) (NNS operations)) (PP (IN via) (NP (NP (VBG pooling)) (PP (IN on) (NP (DT the) (NN convolution) (NNS filters))))))))))))) (. .))
(S (S (NP (NN Training)) (VP (VBZ is) (VP (VBN performed) (PP (IN in) (NP (DT an) (JJ interleaved) (NN fashion)))))) (: ;) (S (NP (DT some) (NNS batches)) (VP (VBP undergo) (NP (NP (DT the) (JJ regular) (NN forward) (CC and) (NN backpropagation) (NNS passes)) (PP (IN with) (NP (JJ original) (NN network) (NNS parameters)))) (, ,) (SBAR (IN whereas) (S (NP (NNS others)) (VP (VBP undergo) (NP (NP (DT a) (JJ forward) (NN pass)) (PP (IN with) (NP (NP (JJ pooled) (NNS filters)) (CC and) (NP (VBD downsampled) (NNS inputs)))))))))) (. .))
(S (SBAR (IN Since) (S (NP (NN pooling)) (VP (VBZ is) (ADJP (JJ differentiable))))) (, ,) (NP (NP (DT the) (NNS gradients)) (PP (IN of) (NP (DT the) (JJ pooled) (NNS filters)))) (VP (VBP propagate) (PP (TO to) (NP (DT the) (JJ original) (NN network) (NNS parameters))) (PP (IN for) (NP (DT a) (JJ standard) (NN parameter) (NN update)))) (. .))
(S (NP (DT The) (JJ latter) (NN phase)) (VP (VBZ requires) (NP (NP (JJR fewer) (VBG floating) (NN point) (NNS operations)) (CC and) (NP (JJR less) (NN storage))) (PP (JJ due) (TO to) (NP (NP (DT the) (VBN reduced) (JJ spatial) (NNS dimensions)) (PP (IN in) (NP (NP (NN feature) (NNS maps)) (CC and) (NP (NNS filters))))))) (. .))
(S (NP (DT The) (JJ key) (NN idea)) (VP (VBZ is) (SBAR (IN that) (S (NP (DT this) (NN phase)) (VP (VBZ leads) (PP (TO to) (NP (NP (NP (ADJP (JJR smaller) (CC and) (VB approximate)) (NNS updates)) (CC and) (RB thus) (NP (JJR slower) (NN learning))) (, ,) (CC but) (PP (IN at) (NP (ADJP (RB significantly) (VBN reduced)) (NN cost))) (, ,) (VP (VBN followed) (PP (IN by) (NP (NP (NNS passes)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (DT the) (JJ original) (NN network) (NNS parameters)) (PP (IN as) (NP (DT a) (NN refinement) (NN stage))))))))))))))) (. .))
(S (S (VP (VBG Deciding) (SBAR (WHADVP (WHADVP (WRB how) (RB often)) (CC and) (WHPP (IN for) (WHNP (WDT which) (VBZ batches)))) (S (NP (DT the) (NN downsmapling)) (VP (VBZ occurs)))))) (VP (VP (MD can) (VP (VB be) (VP (VBN done) (ADVP (DT either) (RB stochastically) (CC or) (RB deterministically))))) (, ,) (CC and) (VP (MD can) (VP (VB be) (VP (VBN defined) (PP (IN as) (NP (NP (DT a) (NN training) (NN hyperparameter)) (NP (PRP itself)))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (JJ residual) (NNS architectures)))) (VP (VBP show) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VB achieve) (NP (NP (ADJP (QP (RB up) (TO to) (CD 23)) (NN %)) (NN reduction)) (PP (IN in) (NP (NN training) (NN time)))) (PP (IN with) (NP (NP (JJ minimal) (NN loss)) (PP (IN in) (NP (NN validation) (NN accuracy)))))))))) (. .))
