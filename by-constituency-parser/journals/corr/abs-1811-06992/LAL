(S (S (NP (JJ Deep) (NN learning)) (VP (VBZ is) (ADJP (RB extremely) (RB computationally) (JJ intensive)))) (, ,) (CC and) (S (NP (NN hardware) (NNS vendors)) (VP (VBP have) (VP (VBN responded) (PP (IN by) (S (VP (VBG building) (NP (JJR faster) (NNS accelerators)) (PP (IN in) (NP (JJ large) (NNS clusters))))))))) (. .))
(S (S (VP (VBG Training) (NP (JJ deep) (NN learning) (NNS models)) (PP (IN at) (NP (JJ petaFLOPS) (NN scale))))) (VP (VBZ requires) (S (VP (VBG overcoming) (NP (DT both) (JJ algorithmic) (CC and) (NNS systems) (NN software) (VBZ challenges))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP discuss) (NP (NP (CD three) (JJ systems-related) (NNS optimizations)) (: :) (NP (NP (NP (ADJP (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (VBN distributed) (NN batch) (NN normalization)) (SBAR (S (VP (TO to) (VP (VB control) (NP (JJ per-replica) (NN batch) (NNS sizes))))))) (, ,) (NP (NP (PRN (-LRB- -LRB-) (CD 2) (-RRB- -RRB-)) (NN input) (NN pipeline) (NNS optimizations)) (SBAR (S (VP (TO to) (VP (VB sustain) (NP (NN model) (NN throughput))))))) (, ,) (CC and) (NP (LST (-LRB- -LRB-) (CD 3) (-RRB- -RRB-)) (NP (NP (JJ 2-D) (NN torus) (NN all-reduce)) (SBAR (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (JJ gradient) (NN summation))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP combine) (NP (DT these) (NNS optimizations)) (S (VP (TO to) (VP (VB train) (NP (NNP ResNet-50)) (PP (IN on) (NP (NNP ImageNet))) (PP (TO to) (NP (ADJP (CD 76.3) (NN %)) (NN accuracy))) (PP (IN in) (NP (CD 2.2) (NNS minutes))) (PP (IN on) (NP (DT a) (JJ 1024-chip) (NNP TPU) (NN v3) (NNP Pod))) (PP (IN with) (NP (NP (NP (DT a) (NN training) (NN throughput)) (PP (IN of) (NP (QP (IN over) (CD 1.05) (CD million)) (NN images/second)))) (CC and) (NP (DT no) (NN accuracy) (NN drop)))))))) (. .))
