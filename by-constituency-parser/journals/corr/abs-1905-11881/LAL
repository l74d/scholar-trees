(S (NP (PRP We)) (VP (VBP provide) (NP (NP (DT a) (JJ theoretical) (NN explanation)) (PP (IN for) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NN gradient) (NN clipping))) (PP (IN in) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks))))))))) (. .))
(S (NP (DT The) (JJ key) (NN ingredient)) (VP (VBZ is) (NP (NP (DT a) (JJ new) (JJ smoothness) (NN condition)) (VP (VBN derived) (PP (IN from) (NP (JJ practical) (JJ neural) (NN network) (NN training) (NNS examples)))))) (. .))
(S (NP (PRP We)) (VP (VBP observe) (SBAR (DT that) (S (NP (NP (NN gradient) (NN smoothness)) (, ,) (NP (NP (DT a) (JJ concept)) (ADJP (JJ central) (PP (TO to) (NP (NP (DT the) (NN analysis)) (PP (IN of) (NP (JJ first-order) (NN optimization) (NN algorithms)))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADVP (RB often)) (VP (VBN assumed) (S (VP (TO to) (VP (VB be) (NP (DT a) (JJ constant)))))))))) (, ,)) (VP (VBZ demonstrates) (NP (NP (JJ significant) (NN variability)) (PP (IN along) (NP (NP (DT the) (NN training) (NN trajectory)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))))))))) (. .))
(S (ADVP (RB Further)) (, ,) (S (NP (DT this) (NN smoothness)) (VP (ADVP (RB positively)) (VBZ correlates) (PP (IN with) (NP (DT the) (NN gradient) (NN norm))))) (, ,) (CC and) (S (ADVP (JJ contrary) (PP (TO to) (NP (NP (JJ standard) (NNS assumptions)) (PP (IN in) (NP (DT the) (NN literature)))))) (, ,) (NP (PRP it)) (VP (MD can) (VP (VB grow) (PP (IN with) (NP (NP (DT the) (NN norm)) (PP (IN of) (NP (DT the) (NN gradient)))))))) (. .))
(S (NP (DT These) (JJ empirical) (NNS observations)) (VP (VBP limit) (NP (NP (DT the) (NN applicability)) (PP (IN of) (NP (NP (VBG existing) (JJ theoretical) (NNS analyses)) (PP (IN of) (NP (NP (NN algorithms)) (SBAR (WHNP (WDT that)) (S (VP (VBP rely) (PP (IN on) (NP (NP (DT a) (VBN fixed) (NN bound)) (PP (IN on) (NP (NN smoothness)))))))))))))) (. .))
(S (NP (DT These) (NNS observations)) (VP (VBP motivate) (S (NP (PRP us)) (VP (TO to) (VP (VB introduce) (NP (NP (DT a) (JJ novel) (NN relaxation)) (PP (IN of) (NP (NN gradient) (NN smoothness))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (ADJP (JJR weaker)) (PP (IN than) (NP (DT the) (ADJP (NN commonly) (VBN used)) (NNP Lipschitz) (JJ smoothness) (NN assumption)))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (VBP further)) (VB explain) (SBAR (WHADVP (WRB why)) (S (NP (JJ such) (ADJP (RB adaptively) (VBD scaled)) (JJ gradient) (NNS methods)) (VP (MD can) (VP (VB accelerate) (NP (JJ empirical) (NN convergence))))))) (CC and) (VP (VB verify) (NP (PRP$ our) (NNS results)) (ADVP (RB empirically)) (PP (IN in) (NP (JJ popular) (JJ neural) (NN network) (NN training) (NNS settings))))) (. .))
