(S (NP (DT This) (NN paper)) (VP (VBZ explores) (NP (NP (DT a) (JJ simple) (NN regularizer)) (PP (IN for) (NP (NN reinforcement) (NN learning)))) (PP (IN by) (S (VP (VBG proposing) (NP (NP (NNP Generative) (NNP Adversarial) (NML (NNP Self) (HYPH -) (NNP Imitation)) (NNP Learning)) (-LRB- -LRB-) (NP (NNP GASIL)) (-RRB- -RRB-) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ encourages) (NP (DT the) (NN agent) (S (VP (TO to) (VP (VB imitate) (NP (NP (JJ past) (JJ good) (NNS trajectories)) (PP (IN via) (NP (NP (JJ generative) (JJ adversarial) (NN imitation)) (VP (VBG learning) (NP (NN framework)))))))))))))))))) (. .))
(S (PP (RB Instead) (PP (IN of) (NP (ADJP (RB directly) (VBG maximizing)) (NNS rewards)))) (, ,) (NP (NN GASIL)) (VP (VBZ focuses) (PP (IN on) (S (VP (VBG reproducing) (NP (NP (JJ past) (JJ good) (NNS trajectories)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (ADVP (RB potentially)) (VP (VB make) (NP (NML (JJ long) (HYPH -) (NN term)) (NN credit) (NN assignment)) (S (ADJP (JJR easier))) (SBAR (WHADVP (WRB when)) (S (NP (NNS rewards)) (VP (VBP are) (ADJP (JJ sparse) (CC and) (VBN delayed)))))))))))))) (. .))
(S (NP (NN GASIL)) (VP (MD can) (VP (VB be) (ADVP (RB easily)) (VP (VBN combined) (PP (IN with) (NP (DT any) (NN policy) (NN gradient) (NN objective))) (PP (IN by) (S (VP (VBG using) (NP (NN GASIL)) (PP (IN as) (NP (NP (DT a)) (VP (VBN learned) (NP (VBN shaped) (NN reward) (NN function))))))))))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NN GASIL)) (VP (VBZ improves) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NP (JJ proximal) (NN policy) (NN optimization)) (PP (IN on) (NP (NP (NN 2D) (NN Point) (NML (NNP Mass) (CC and) (NNP MuJoCo)) (NNS environments)) (PP (IN with) (NP (NP (VBN delayed) (NN reward)) (CC and) (NP (JJ stochastic) (NNS dynamics))))))))))))) (. .))
