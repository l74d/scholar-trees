(S (NP (NP (DT The) (JJ learning) (NN capability)) (PP (IN of) (NP (DT a) (JJ neural) (NN network)))) (VP (VBZ improves) (PP (IN with) (NP (VBG increasing) (NN depth))) (PP (IN at) (NP (JJR higher) (NN computational) (NNS costs)))) (. .))
(S (NP (NP (JJR Wider) (NNS layers)) (PP (PP (IN with) (NP (JJ dense) (NNS kernel) (NN connectivity) (VBP patterns))) (ADVP (JJ furhter)))) (VP (VP (NN increase) (NP (DT this) (NN cost))) (CC and) (VP (MD may) (VP (VB hinder) (NP (JJ real-time) (NN inference))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (JJ feature) (NN map) (CC and) (VB kernel) (NN level) (VBG pruning)) (PP (IN for) (S (VP (VBG reducing) (NP (NP (DT the) (JJ computational) (NN complexity)) (PP (IN of) (NP (DT a) (JJ deep) (JJ convolutional) (JJ neural) (NN network)))))))) (. .))
(S (NP (VBG Pruning) (NP (NN feature) (NNS maps))) (VP (VP (VBZ reduces) (NP (NP (DT the) (NN width)) (PP (IN of) (NP (DT a) (NN layer))))) (CC and) (ADVP (NN hence)) (VP (VBZ does) (RB not) (VP (VB need) (NP (DT any) (JJ sparse) (NN representation))))) (. .))
(S (ADVP (RB Further)) (, ,) (NP (NNS kernel) (VBG pruning)) (VP (NNS converts) (NP (DT the) (NN dense) (NN connectivity) (NN pattern)) (PP (IN into) (NP (DT a) (JJ sparse) (CD one)))) (. .))
(S (PP (JJ Due) (TO to) (NP (VB coarse) (NN nature))) (, ,) (NP (DT these) (VBG pruning) (NNS granularities)) (VP (MD can) (VP (VB be) (VP (VBN exploited) (PP (IN by) (NP (NP (NNP GPUs)) (CC and) (NP (ADJP (NNP VLSI) (VBN based)) (NNS implementations))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (ADJP (JJ simple) (CC and) (JJ generic)) (NN strategy)) (SBAR (S (VP (TO to) (VP (VB choose) (NP (DT the) (ADJP (JJS least) (JJ adversarial)) (NN pruning) (NNS masks)) (PP (IN for) (NP (DT both) (NNS granularities))))))))) (. .))
(S (NP (DT The) (JJ pruned) (NNS networks)) (VP (VBP are) (VP (VBN retrained) (SBAR (WHNP (WDT which)) (S (VP (VBZ compensates) (NP (NP (DT the) (NN loss)) (PP (IN in) (NP (NN accuracy))))))))) (. .))
(S (NP (PRP We)) (VP (VB obtain) (NP (DT the) (JJS best) (NN pruning) (NNS ratios)) (SBAR (WHADVP (WRB when)) (S (NP (PRP we)) (VP (VBP prune) (NP (NP (DT a) (NN network)) (PP (IN with) (NP (DT both) (NNS granularities)))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN with) (NP (DT the) (NNP CIFAR-10) (NN dataset)))) (VP (NN show) (SBAR (IN that) (S (NP (ADJP (QP (JJR more) (IN than) (CD 85)) (NN %)) (NN sparsity)) (VP (MD can) (VP (VB be) (VP (VBN induced) (PP (IN in) (NP (DT the) (NN convolution) (NNS layers))) (PP (IN with) (NP (NP (ADJP (QP (JJR less) (IN than) (CD 1)) (NN %)) (NN increase)) (PP (IN in) (NP (NP (DT the) (NN missclassification) (NN rate)) (PP (IN of) (NP (DT the) (NN baseline) (NN network))))))))))))) (. .))
