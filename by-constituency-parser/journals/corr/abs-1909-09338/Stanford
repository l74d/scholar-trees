(S (ADVP (RB Recently)) (NP (JJ deep) (JJ neural) (NNS networks)) (VP (VBP have) (VP (VBN shown) (NP (PRP$ their) (NN capacity)) (S (VP (TO to) (VP (VB memorize) (NP (NN training) (NNS data))))) (, ,) (PP (ADVP (RB even)) (IN with) (NP (NP (JJ noisy) (NNS labels)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ hurts) (NP (NN generalization) (NN performance))))))))) (. .))
(S (S (VP (TO To) (VP (VB mitigate) (NP (DT this) (NN issue))))) (, ,) (NP (PRP we)) (VP (VBP provide) (NP (NP (DT a) (ADJP (JJ simple) (CC but) (JJ effective)) (NN baseline) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ robust) (PP (IN to) (NP (JJ noisy) (NNS labels)))) (, ,) (ADVP (RB even)) (PP (IN with) (NP (JJ severe) (NN noise)))))))) (. .))
(S (NP (PRP$ Our) (JJ objective)) (VP (VBZ involves) (NP (NP (DT a) (NN variance) (NN regularization) (NN term)) (SBAR (WHNP (WDT that)) (S (ADVP (RB implicitly)) (VP (VBZ penalizes) (NP (NP (DT the) (JJ Jacobian) (NN norm)) (PP (IN of) (NP (NP (NP (DT the) (JJ neural) (NN network)) (PP (IN on) (NP (DT the) (JJ whole) (NN training) (NN set))) (PRN (-LRB- -LRB-) (PP (VBG including) (NP (DT the) (ADJP (JJ noisy) (HYPH -) (VBN labeled)) (NNS data))) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ encourages) (NP (NN generalization))) (CC and) (VP (VBZ prevents) (S (VP (VBG overfitting) (PP (IN to) (NP (DT the) (JJ corrupted) (NNS labels))))))))))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NP (DT both) (ADJP (RB synthetically) (VBN generated)) (JJ incorrect) (NNS labels)) (CC and) (NP (JJ realistic) (NML (JJ large) (HYPH -) (NN scale)) (JJ noisy) (NNS datasets))))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (VBZ achieves) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NN performance)) (PP (IN with) (NP (NP (DT a) (JJ high) (NN tolerance)) (PP (IN to) (NP (JJ severe) (NN noise))))))))) (. .))
