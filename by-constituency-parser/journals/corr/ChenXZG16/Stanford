(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (JJ systematic) (NN approach)) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN memory) (NN consumption)) (PP (IN of) (NP (JJ deep) (NML (JJ neural) (NN network)) (NN training)))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP design) (NP (NP (DT an) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ costs) (NP (NML (NML (NN O)) (-LRB- -LRB-) (NML (NN sqrt) (PRN (-LRB- -LRB-) (NP (NN n)) (-RRB- -RRB-))) (-RRB- -RRB-)) (NN memory)) (S (VP (TO to) (VP (VB train) (NP (DT a) (NN n) (NN layer) (NN network))))) (, ,) (PP (IN with) (NP (NP (RB only) (DT the) (JJ computational) (NN cost)) (PP (IN of) (NP (NP (DT an) (JJ extra) (JJ forward) (NN pass)) (PP (IN per) (NP (NN mini-batch)))))))))))) (. .))
(S (SBAR (IN As) (S (NP (JJ many) (NML (PP (IN of) (NP (DT the) (NN state))) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS models)) (VP (VBD hit) (NP (NP (DT the) (JJ upper) (VBN bound)) (PP (IN of) (NP (DT the) (NNP GPU) (NN memory))))))) (, ,) (NP (PRP$ our) (NN algorithm)) (VP (VP (VBZ allows) (NP (ADJP (ADJP (JJR deeper)) (CC and) (ADJP (RBR more) (JJ complex))) (NNS models)) (S (VP (TO to) (VP (VB be) (VP (VBN explored)))))) (, ,) (CC and) (VP (VBZ helps) (S (VP (VB advance) (NP (DT the) (NNS innovations)) (PP (IN in) (NP (NML (JJ deep) (NN learning)) (NN research))))))) (. .))
(S (NP (PRP We)) (VP (VBP focus) (PP (IN on) (S (VP (VBG reducing) (NP (DT the) (NN memory) (NN cost)) (S (VP (TO to) (VP (VB store) (NP (NP (DT the) (JJ intermediate) (NN feature) (NNS maps) (CC and) (NNS gradients)) (PP (IN during) (NP (NN training))))))))))) (. .))
(S (NP (JJ Computation) (NN graph) (NN analysis)) (VP (VBZ is) (VP (VBN used) (PP (IN for) (NP (NML (NML (NML (JJ automatic)) (PP (IN in) (HYPH -) (NP (NN place) (NN operation)))) (CC and) (NML (NN memory) (NN sharing))) (NNS optimizations))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ possible) (S (VP (TO to) (VP (VB trade) (NP (NP (NN computation)) (PP (IN for) (NP (ADJP (NN memory) (HYPH -) (VBG giving)) (ADJP (NP (QP (DT a) (JJR more)) (NN memory)) (JJ efficient)) (NN training) (NN algorithm)))) (PP (IN with) (NP (DT a) (JJ little) (JJ extra) (NN computation) (NN cost))))))))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ extreme) (NN case))) (, ,) (NP (PRP$ our) (NN analysis)) (ADVP (RB also)) (VP (VBZ shows) (SBAR (IN that) (S (NP (DT the) (NN memory) (NN consumption)) (VP (MD can) (VP (VB be) (VP (VBN reduced) (PP (IN to) (NP (NP (NN O) (PRN (-LRB- -LRB-) (NP (NN log) (NN n)) (-RRB- -RRB-))) (PP (IN with) (NP (NP (ADJP (RB as) (JJ little) (PP (IN as) (NP (NN O) (PRN (-LRB- -LRB-) (NP (NN n) (NN log) (NN n)) (-RRB- -RRB-))))) (JJ extra) (NN cost)) (PP (IN for) (NP (JJ forward) (NN computation))))))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VB reduce) (NP (NP (DT the) (NN memory) (NN cost)) (PP (IN of) (NP (DT a) (NML (CD 1,000) (HYPH -) (NN layer)) (JJ deep) (JJ residual) (NN network)))) (PP (IN from) (NP (NN 48G))) (PP (IN to) (NP (NP (NML (NML (NN 7G)) (PP (IN with) (NP (RB only) (CD 30) (NN percent)))) (JJ additional) (NN running) (NN time) (NN cost)) (PP (IN on) (NP (NNP ImageNet) (NNS problems)))))))))) (. .))
(S (ADVP (RB Similarly)) (, ,) (NP (JJ significant) (NML (NN memory) (NN cost)) (NN reduction)) (VP (VBZ is) (VP (VBN observed) (PP (IN in) (NP (NN training))) (NP (NP (ADJP (JJ complex) (JJ recurrent)) (JJ neural) (NNS networks)) (PP (IN on) (NP (ADJP (RB very) (JJ long)) (NNS sequences)))))) (. .))
