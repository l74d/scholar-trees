(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ systematic) (NN approach)) (SBAR (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN memory) (NN consumption)) (PP (IN of) (NP (JJ deep) (JJ neural) (NN network) (NN training)))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP design) (NP (NP (DT an) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ costs) (NP (NNP O) (PRN (-LRB- -LRB-) (NN sqrt) (PRN (PRN (-LRB- -LRB-) (JJ n) (-RRB- -RRB-)) (-RRB- -RRB-))) (NN memory)) (S (VP (TO to) (VP (VB train) (NP (DT a) (NN n) (NN layer) (NN network))))) (, ,) (PP (IN with) (NP (NP (RB only) (DT the) (JJ computational) (NN cost)) (PP (IN of) (NP (NP (DT an) (JJ extra) (NN forward) (NN pass)) (PP (IN per) (NP (NN mini-batch)))))))))))) (. .))
(S (SBAR (IN As) (S (NP (NP (JJ many)) (PP (IN of) (NP (DT the) (JJ state-of-the-art) (NNS models)))) (VP (VBP hit) (NP (NP (DT the) (JJ upper) (NN bound)) (PP (IN of) (NP (DT the) (NNP GPU) (NN memory))))))) (, ,) (NP (PRP$ our) (NN algorithm)) (VP (VP (VBZ allows) (S (NP (ADJP (ADJP (JJR deeper)) (CC and) (ADJP (RBR more) (JJ complex))) (NNS models)) (VP (TO to) (VP (VB be) (VP (VBN explored)))))) (, ,) (CC and) (VP (VBZ helps) (S (VP (VB advance) (NP (NP (DT the) (NNS innovations)) (PP (IN in) (NP (JJ deep) (NN learning) (NN research)))))))) (. .))
(S (NP (PRP We)) (VP (VBP focus) (PP (IN on) (S (VP (VBG reducing) (NP (NP (DT the) (NN memory) (NN cost)) (SBAR (S (VP (TO to) (VP (VB store) (NP (DT the) (JJ intermediate) (NX (NX (NN feature) (NNS maps)) (CC and) (NX (NNS gradients)))) (PP (IN during) (NP (NN training)))))))))))) (. .))
(S (NP (NNP Computation) (NN graph) (NN analysis)) (VP (VBZ is) (VP (VBN used) (PP (IN for) (NP (NP (JJ automatic) (NN in-place) (NN operation)) (CC and) (NP (NN memory) (NN sharing) (NNS optimizations)))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (JJ possible)) (S (VP (TO to) (VP (VB trade) (NP (NN computation)) (PP (IN for) (NP (NN memory))) (: -) (S (VP (VBG giving) (NP (NP (DT a) (ADJP (RBR more) (JJ memory) (JJ efficient)) (VBG training) (NN algorithm)) (PP (IN with) (NP (DT a) (JJ little) (JJ extra) (NN computation) (NN cost))))))))))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ extreme) (NN case))) (, ,) (NP (PRP$ our) (NN analysis)) (ADVP (RB also)) (VP (VBZ shows) (SBAR (IN that) (S (NP (DT the) (NN memory) (NN consumption)) (VP (MD can) (VP (VB be) (VP (VBN reduced) (PP (TO to) (NP (NP (NNP O)) (PRN (-LRB- -LRB-) (NP (JJ log) (NN n)) (-RRB- -RRB-)))) (PP (IN with) (NP (NP (ADJP (QP (RB as) (JJ little) (IN as) (NNP O)) (PRN (-LRB- -LRB-) (NP (JJ n) (NN log) (NN n)) (-RRB- -RRB-))) (VBZ extra) (NN cost)) (PP (IN for) (NP (JJ forward) (NN computation))))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VB reduce) (NP (NP (DT the) (NN memory) (NN cost)) (PP (IN of) (NP (DT a) (JJ 1,000-layer) (JJ deep) (JJ residual) (NN network)))) (PP (IN from) (NP (CD 48G))) (PP (TO to) (NP (CD 7G))) (PP (IN with) (NP (NP (ADJP (RB only) (CD 30) (JJ percent)) (JJ additional) (NN running) (NN time) (NN cost)) (PP (IN on) (NP (NNP ImageNet) (NNS problems)))))))))) (. .))
(S (ADVP (RB Similarly)) (, ,) (NP (JJ significant) (NN memory) (NN cost) (NN reduction)) (VP (VBZ is) (VP (VBN observed) (PP (IN in) (S (VP (NN training) (NP (JJ complex) (NN recurrent) (JJ neural) (NNS networks)) (PP (IN on) (NP (ADJP (RB very) (JJ long)) (NNS sequences)))))))) (. .))
