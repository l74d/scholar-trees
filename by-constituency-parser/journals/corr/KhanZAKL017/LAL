(S (NP (PRP We)) (VP (VBP investigate) (SBAR (WHADVP (WRB how)) (S (NP (DT a) (JJ neural) (NN network)) (VP (MD can) (VP (VB learn) (NP (NP (NN perception) (NNS actions) (VBP loops)) (PP (IN for) (NP (NP (NN navigation)) (PP (IN in) (NP (JJ unknown) (NNS environments))))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP consider) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB learn) (S (VP (TO to) (VP (VB navigate) (PP (IN in) (NP (NP (NNS environments)) (VP (VBN populated) (PP (IN with) (NP (NP (NN cul-de-sacs)) (SBAR (WHNP (WDT that)) (S (VP (VBP represent) (NP (NP (VB convex) (JJ local) (NN minima)) (SBAR (WHNP (IN that)) (S (NP (DT the) (NN robot)) (VP (MD could) (VP (VB fall) (PP (IN into))))))))))))))) (PP (RB instead) (IN of) (S (VP (VBG finding) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (JJ feasible) (NNS actions)) (SBAR (WHNP (WDT that)) (S (VP (VBP take) (NP (PRP it)) (PP (TO to) (NP (DT the) (NN goal)))))))))))))))))))) (. .))
(S (NP (JJ Traditional) (NNS methods)) (VP (RB rely) (PP (IN on) (S (VP (VBG maintaining) (NP (DT a) (JJ global) (NN map))))) (S (VP (TO to) (VP (VB solve) (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (ADVP (IN over)) (VBG coming) (NP (DT a) (JJ long) (NN cul-de-sac)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (JJ due) (TO to) (NP (NP (NNS errors)) (VP (VBN induced) (PP (IN from) (NP (ADJP (JJ local) (CC and) (JJ global)) (NN drift)))))) (, ,) (NP (NP (PRP it))) (VP (VBZ is) (ADJP (RB highly) (VBG challenging)) (S (VP (TO to) (VP (VB maintain) (NP (JJ such) (DT a) (NN map)) (PP (IN for) (NP (NP (JJ long) (NNS periods)) (PP (IN of) (NP (NN time))))))))) (. .))
(S (NP (NP (CD One) (NN way)) (SBAR (S (VP (TO to) (VP (VB mitigate) (NP (DT this) (NN problem))))))) (VP (VBZ is) (PP (IN by) (S (VP (VBG using) (NP (NP (VBG learning) (NNS techniques)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP do) (RB not) (VP (VB rely) (PP (IN on) (NP (ADJP (NN hand) (VBN engineered)) (NN map) (NNS representations))))) (CC and) (VP (ADVP (RB instead)) (NN output) (NP (JJ appropriate) (NN control) (NNS policies)) (ADVP (RB directly)) (PP (IN from) (NP (PRP$ their) (JJ sensory) (NN input)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB first)) (VP (VB demonstrate) (SBAR (IN that) (S (NP (PDT such) (DT a) (NN problem)) (VP (MD can) (RB not) (VP (VB be) (VP (VBN solved) (ADVP (RB directly)) (PP (IN by) (NP (JJ deep) (NN reinforcement) (VBG learning))) (PP (JJ due) (PP (TO to) (NP (NP (DT the) (JJ sparse) (NN reward) (NN structure)) (PP (IN of) (NP (DT the) (NN environment)))))))))))) (. .))
(S (ADVP (RB Further)) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NN deep) (VBD supervised) (VBG learning)) (ADVP (RB also)) (VP (MD can) (RB not) (VP (VB be) (VP (VBN used) (ADVP (RB directly)) (S (VP (TO to) (VP (VB solve) (NP (DT this) (NN problem))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VP (VB investigate) (NP (NP (NN network) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP offer) (NP (NP (DT a) (NN combination)) (PP (IN of) (NP (NP (NN reinforcement) (NN learning)) (CC and) (NP (VBD supervised) (NN learning)))))))))) (CC and) (VP (VBD highlight) (NP (NP (DT the) (NN significance)) (PP (IN of) (S (VP (VBG adding) (NP (ADJP (RB fully) (JJ differentiable)) (NN memory) (NNS units)) (PP (TO to) (NP (JJ such) (NNS networks))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (PRP$ our) (NNS networks)) (PP (IN on) (NP (PRP$ their) (NN ability) (S (VP (TO to) (VP (VB generalize) (PP (TO to) (NP (JJ new) (NNS environments))))))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG adding) (NP (NN memory)) (PP (TO to) (NP (JJ such) (NNS networks))))) (VP (NNS offers) (NP (NP (JJ huge) (NNS jumps)) (PP (IN in) (NP (NN performance))))))))))
