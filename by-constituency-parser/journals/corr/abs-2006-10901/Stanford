(S (NP (JJ Scientific) (NNS workloads)) (VP (VBP have) (ADVP (RB traditionally)) (VP (VBN exploited) (NP (NP (JJ high) (NNS levels)) (PP (IN of) (NP (NN sparsity)))) (S (VP (TO to) (VP (VP (VB accelerate) (NP (NN computation))) (CC and) (VP (VB reduce) (NP (NN memory) (NNS requirements)))))))) (. .))
(S (SBAR (IN While) (S (NP (JJ deep) (JJ neural) (NNS networks)) (VP (MD can) (VP (VB be) (VP (VBN made) (S (ADJP (JJ sparse))) (, ,) (S (VP (VBG achieving) (NP (JJ practical) (NNS speedups)) (PP (IN on) (NP (NNS GPUs)))))))))) (VP (VBZ is) (ADJP (JJ difficult)) (SBAR (IN because) (S (NP (DT these) (NNS applications)) (VP (VBP have) (NP (NP (ADJP (RB relatively) (JJ moderate)) (NNS levels)) (PP (IN of) (NP (NP (NN sparsity)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (RB not) (ADJP (JJ sufficient) (PP (IN for) (NP (VBG existing) (JJ sparse) (NNS kernels))))))))) (S (VP (TO to) (VP (VB outperform) (NP (PRP$ their) (JJ dense) (NNS counterparts)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VP (VBP study) (NP (JJ sparse) (NNS matrices)) (PP (IN from) (NP (NML (JJ deep) (NN learning)) (NNS applications)))) (CC and) (VP (VB identify) (NP (NP (JJ favorable) (NNS properties)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN exploited) (S (VP (TO to) (VP (VB accelerate) (NP (NN computation))))))))))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (DT these) (NNS insights)))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (NP (NML (JJ high) (HYPH -) (NN performance)) (NN GPU) (NNS kernels)) (PP (IN for) (NP (NP (NP (CD two) (JJ sparse) (NN matrix) (NNS operations)) (ADJP (RB widely) (JJ applicable))) (PP (IN in) (NP (JJ neural) (NNS networks)))))) (: :) (NP (JJ sparse) (NML (NML (ADJP (NN matrix) (HYPH -) (JJ dense)) (NN matrix) (NN multiplication)) (CC and) (NML (VBN sampled) (ADJP (JJ dense) (HYPH -) (JJ dense)) (NN matrix))) (NN multiplication)))) (. .))
(S (NP (PRP$ Our) (NNS kernels)) (VP (VBP reach) (NP (NP (CD 27) (NN %)) (PP (IN of) (NP (NML (JJ single) (HYPH -) (NN precision)) (NN peak)))) (PP (IN on) (NP (NNP Nvidia) (NNP V100) (NNS GPUs)))) (. .))
(S (S (VP (VBG Using) (NP (PRP$ our) (NNS kernels)))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (NP (JJ sparse) (NML (NN Transformer) (CC and) (NN MobileNet)) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP achieve) (NP (NP (NP (QP (CD 1.2) (HYPH -) (CD 2.1))) (PP (SYM x) (NP (NNS speedups)))) (CC and) (NP (NP (QP (IN up) (IN to) (CD 12.8))) (PP (SYM x) (NP (NN memory) (NNS savings))))) (PP (IN without) (S (VP (VBG sacrificing) (NP (NN accuracy)))))))))) (. .))
