(S (NP (NNP Scientific) (NNS workloads)) (VP (VBP have) (ADVP (RB traditionally)) (VP (VBN exploited) (NP (NP (JJ high) (NNS levels)) (PP (IN of) (NP (NN sparsity)))) (S (VP (TO to) (VP (VP (VB accelerate) (NP (NN computation))) (CC and) (VP (VB reduce) (NP (NN memory) (NNS requirements)))))))) (. .))
(S (SBAR (IN While) (S (NP (JJ deep) (JJ neural) (NNS networks)) (VP (MD can) (VP (VB be) (VP (VBN made) (S (ADJP (NN sparse)))))))) (, ,) (S (VP (VBG achieving) (NP (NP (JJ practical) (NNS speedups)) (PP (IN on) (NP (NNP GPUs)))))) (VP (VBZ is) (ADJP (JJ difficult)) (SBAR (IN because) (S (NP (DT these) (NNS applications)) (VP (VBP have) (NP (NP (ADJP (RB relatively) (JJ moderate)) (NNS levels)) (PP (IN of) (NP (NN sparsity))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (RB not) (ADJP (JJ sufficient) (SBAR (IN for) (S (NP (VBG existing) (NN sparse) (NNS kernels)) (VP (TO to) (VP (VB outperform) (NP (PRP$ their) (NN dense) (NNS counterparts))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VP (VBP study) (NP (NP (JJ sparse) (NNS matrices)) (PP (IN from) (NP (JJ deep) (NN learning) (NNS applications))))) (CC and) (VP (VB identify) (NP (NP (JJ favorable) (NNS properties)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN exploited) (S (VP (TO to) (VP (VB accelerate) (NP (NN computation))))))))))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (DT these) (NNS insights)))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (JJ high-performance) (NNP GPU) (NNS kernels)) (PP (IN for) (NP (NP (NP (CD two) (JJ sparse) (NN matrix) (NNS operations)) (ADJP (RB widely) (JJ applicable) (PP (IN in) (NP (JJ neural) (NNS networks))))) (: :) (NP (NP (JJ sparse) (JJ matrix-dense) (NN matrix) (NN multiplication)) (CC and) (NP (VBD sampled) (JJ dense-dense) (NN matrix) (NN multiplication))))))) (. .))
(S (NP (PRP$ Our) (NNS kernels)) (VP (VBP reach) (NP (NP (CD 27) (NN %)) (PP (IN of) (NP (NN single-precision) (NN peak)))) (PP (IN on) (NP (NNP Nvidia) (NNP V100) (NNP GPUs)))) (. .))
(S (S (VP (VBG Using) (NP (PRP$ our) (NNS kernels)))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (NP (JJ sparse) (NNP Transformer) (CC and) (NNP MobileNet) (NNS models)) (SBAR (WHNP (IN that)) (S (VP (VBP achieve) (NP (NP (JJ 1.2-2.1x) (NNS speedups)) (CC and) (NP (QP (RB up) (TO to) (CD 12.8x)) (NN memory) (NNS savings))) (PP (IN without) (S (VP (VBG sacrificing) (NP (NN accuracy)))))))))) (. .))
