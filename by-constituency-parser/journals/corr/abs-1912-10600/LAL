(S (NP (NN Reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)) (NN algorithms)) (VP (VBP have) (VP (VBN been) (VP (ADVP (RB successfully)) (VBN applied) (PP (TO to) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (VBG challenging) (JJ sequential) (NN decision) (NN making) (CC and) (NN control) (NNS tasks)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP classify) (NP (NNP RL)) (PP (IN into) (NP (ADJP (JJ direct) (CC and) (JJ indirect)) (NNS methods))) (PP (VBG according) (PP (TO to) (SBAR (WHADVP (WRB how)) (S (NP (PRP they)) (VP (VBP seek) (NP (NP (JJ optimal) (NN policy)) (PP (IN of) (NP (DT the) (NNP Markov) (NNP Decision) (NNP Process) (PRN (-LRB- -LRB-) (NP (NNP MDP)) (-RRB- -RRB-)) (NN problem)))))))))) (. .))
(S (NP (DT The) (JJ former)) (VP (NNS solves) (NP (JJ optimal) (NN policy)) (PP (IN by) (S (VP (ADVP (RB directly)) (VBG maximizing) (NP (DT an) (JJ objective) (NN function)) (S (VP (VBG using) (NP (NP (JJ gradient) (NN descent) (NN method)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT the) (NN objective) (NN function)) (VP (VBZ is) (ADVP (RB usually)) (NP (NP (DT the) (NN expectation)) (PP (IN of) (NP (JJ accumulative) (NN future) (NNS rewards)))))))))))))) (. .))
(S (NP (DT The) (JJ latter)) (VP (ADVP (RB indirectly)) (VBZ finds) (NP (DT the) (JJ optimal) (NN policy)) (PP (IN by) (S (VP (VBG solving) (NP (NP (DT the) (NNP Bellman) (NN equation)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (DT the) (ADJP (JJ sufficient) (CC and) (JJ necessary)) (NN condition)) (PP (IN from) (NP (NP (NP (NNP Bellman) (POS 's)) (NN principle)) (PP (IN of) (NP (NN optimality)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP take) (NP (NP (NN vanilla) (NN policy) (NN gradient)) (CC and) (NP (NN approximate) (NN policy) (NN iteration))) (S (VP (TO to) (VP (VB study) (NP (PRP$ their) (JJ internal) (NN relationship)))))) (, ,) (CC and) (VP (NN reveal) (SBAR (IN that) (S (NP (UCP (DT both) (JJ direct) (CC and) (JJ indirect)) (NNS methods)) (VP (VP (MD can) (VP (VB be) (VP (VBN unified) (PP (IN in) (NP (JJ actor-critic) (NN architecture)))))) (CC and) (VP (VBP are) (ADJP (JJ equivalent)) (SBAR (IN if) (S (NP (PRP we)) (ADVP (RB always)) (VP (VBP choose) (NP (NP (JJ stationary) (NN state) (NN distribution)) (PP (IN of) (NP (JJ current) (NN policy)))) (PP (IN as) (NP (NP (JJ initial) (NN state) (NN distribution)) (PP (IN of) (NP (NNP MDP)))))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VP (VBP classify) (NP (DT the) (JJ current) (NN mainstream) (NNP RL) (NN algorithms))) (CC and) (VP (VB compare) (NP (NP (DT the) (NNS differences)) (PP (IN between) (NP (NP (JJ other) (NNS criteria)) (PP (VBG including) (ADJP (JJ value-based) (CC and) (JJ policy-based) (, ,) (JJ model-based) (CC and) (JJ model-free)))))))) (. .))
