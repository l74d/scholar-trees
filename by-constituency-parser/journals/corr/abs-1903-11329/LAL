(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN objective)) (, ,) (NP (DT the) (JJ counterfactual) (NN objective)) (, ,) (VP (VBG unifying) (NP (NP (VBG existing) (NNS objectives)) (PP (IN for) (NP (NN off-policy) (NN policy) (NN gradient) (NN algorithms))) (PP (IN in) (NP (DT the) (VBG continuing) (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NNP RL) (-RRB- -RRB-)) (NN setting))))))) (. .))
(S (PP (VBN Compared) (PP (TO to) (NP (NP (DT the) (ADJP (RB commonly) (VBN used)) (NN excursion) (NN objective)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (ADJP (VBG misleading) (PP (IN about) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (NN target) (NN policy))) (SBAR (WHADVP (WRB when)) (S (VP (NN deployed))))))))))) (, ,)))) (NP (PRP$ our) (JJ new) (JJ objective)) (VP (ADVP (JJR better)) (NNS predicts) (NP (JJ such) (NN performance))) (. .))
(S (NP (PRP We)) (VP (VP (VBP prove) (NP (DT the) (NNP Generalized) (NN Off-Policy) (NNP Policy) (NNP Gradient) (NNP Theorem)) (S (VP (TO to) (VP (VB compute) (NP (NP (DT the) (NN policy) (NN gradient)) (PP (IN of) (NP (DT the) (JJ counterfactual) (NN objective)))))))) (CC and) (VP (VB use) (NP (DT an) (JJ emphatic) (NN approach)) (S (VP (TO to) (VP (VB get) (NP (DT an) (JJ unbiased) (NN sample)) (PP (IN from) (NP (DT this) (NN policy) (NN gradient))))))) (, ,) (S (VP (VBG yielding) (NP (DT the) (NNP Generalized) (NNP Off-Policy) (NNP Actor-Critic) (PRN (-LRB- -LRB-) (NP (NNP Geoff-PAC)) (-RRB- -RRB-)) (NN algorithm))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (NP (DT the) (NNS merits)) (PP (IN of) (NP (NNP Geoff-PAC))) (PP (IN over) (NP (VBG existing) (NN algorithms))) (PP (IN in) (NP (NNP Mujoco) (VBP robot) (NN simulation) (NNS tasks)))) (, ,) (NP (NP (DT the) (JJ first) (JJ empirical) (NN success)) (PP (IN of) (NP (JJ emphatic) (NN algorithms))) (PP (IN in) (NP (VBG prevailing) (JJ deep) (NNP RL) (NNS benchmarks)))))) (. .))
