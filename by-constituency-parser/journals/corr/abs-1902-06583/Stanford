(S (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (NN policy) (NN gradient) (NNS methods)))) (VP (VBZ is) (ADJP (JJ sensitive) (PP (IN to) (NP (NP (NN hyperparameter) (NNS settings)) (SBAR (WHNP (WDT that)) (S (VP (MD must) (VP (VB be) (VP (VBN tuned) (PP (IN for) (NP (DT any) (JJ new) (NN application)))))))))))) (. .))
(S (ADVP (RB Widely)) (NP (NP (VBN used) (NN grid) (NN search) (NNS methods)) (PP (IN for) (NP (NN tuning) (NNS hyperparameters)))) (VP (VBP are) (ADJP (ADJP (JJ sample) (JJ inefficient)) (CC and) (ADJP (ADVP (RB computationally)) (JJ expensive)))) (. .))
(S (NP (NP (ADJP (RBR More) (JJ advanced)) (NNS methods)) (PP (IN like) (NP (NP (NNP Population) (NNP Based) (NNP Training)) (SBAR (WHNP (WDT that)) (S (VP (VBP learn) (NP (JJ optimal) (NNS schedules)) (PP (IN for) (NP (NP (NNS hyperparameters)) (PP (RB instead) (IN of) (NP (VBN fixed) (NNS settings))))))))))) (VP (VP (MD can) (VP (VB yield) (NP (JJR better) (NNS results)))) (, ,) (CC but) (VP (VBP are) (ADVP (RB also)) (ADJP (ADJP (NP (NN sample)) (JJ inefficient)) (CC and) (ADJP (ADVP (RB computationally)) (JJ expensive))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NNP Hyperparameter) (NNP Optimisation)) (PP (IN on) (NP (NP (DT the) (NML (S (VP (VB Fly) (NP (NP (-LRB- -LRB-) (NN HOOF) (-RRB- -RRB-)) (, ,) (ADJP (NP (DT a) (NN gradient)) (HYPH -) (JJ free)))))) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ requires) (NP (DT no) (NML (QP (JJR more) (IN than) (CD one))) (NN training) (NN run) (S (VP (TO to) (ADVP (RB automatically)) (VP (VB adapt) (NP (NP (DT the) (NN hyperparameter)) (SBAR (WHNP (WDT that)) (S (VP (VBP affect) (NP (DT the) (NN policy) (NN update)) (ADVP (RB directly)) (PP (IN through) (NP (DT the) (NN gradient)))))))))))))))))) (. .))
(S (NP (DT The) (JJ main) (NN idea)) (VP (VBZ is) (S (VP (TO to) (VP (VB use) (NP (NP (NP (VBG existing) (NNS trajectories)) (VP (VBN sampled) (PP (IN by) (NP (DT the) (NN policy) (NN gradient) (NN method))) (S (VP (TO to) (VP (VB optimise) (NP (DT a) (NML (CD one) (HYPH -) (NN step)) (NN improvement) (NN objective)) (, ,) (S (VP (VBG yielding) (NP (NP (DT a) (NN sample)) (CC and) (ADVP (RB computationally)) (NP (JJ efficient) (NN algorithm)))))))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ easy) (S (VP (TO to) (VP (VB implement))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (JJ experimental) (NNS results)) (PP (IN across) (NP (JJ multiple) (NNS domains) (CC and) (NNS algorithms)))) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG using) (NP (NN HOOF)) (S (VP (TO to) (VP (VB learn) (NP (DT these) (NN hyperparameter) (NNS schedules))))))) (VP (VBZ leads) (PP (IN to) (S (ADVP (RBR faster)) (VP (VBG learning) (PP (IN with) (NP (VBN improved) (NN performance)))))))))) (. .))
