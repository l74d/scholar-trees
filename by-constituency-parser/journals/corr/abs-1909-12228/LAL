(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NP (CD two) (NNS approaches)) (PP (IN of) (NP (ADJP (RB locally) (JJ adaptive)) (NN activation) (NNS functions)))) (ADVP (RB namely)) (, ,) (NP (NP (ADJP (JJ layer-wise) (CC and) (JJ neuron-wise)) (VP (VP (RB locally) (JJ adaptive))) (NN activation) (NNS functions)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (ADJP (JJ deep) (CC and) (JJ physics-informed)) (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (NP (DT The) (JJ local) (NN adaptation)) (PP (IN of) (NP (NN activation) (NN function)))) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (S (VP (VP (VBG introducing) (NP (DT a) (JJ scalable) (NN parameter)) (PP (PP (IN in) (NP (NP (DT each) (NN layer)) (PRN (-LRB- -LRB-) (ADJP (NN layer-wise)) (-RRB- -RRB-)))) (CC and) (PP (IN for) (NP (NP (DT every) (NN neuron)) (PRN (-LRB- -LRB-) (ADJP (JJ neuron-wise)) (-RRB- -RRB-))))) (ADVP (RB separately))) (, ,) (CC and) (ADVP (RB then)) (VP (VBG optimizing) (NP (PRP it)) (S (VP (VBG using) (NP (NP (DT a) (NN variant)) (PP (IN of) (NP (JJ stochastic) (NN gradient) (NN descent) (NN algorithm)))))))))))) (. .))
(S (SBAR (IN In) (NN order) (S (VP (TO to) (ADVP (JJ further)) (VP (VB increase) (NP (DT the) (NN training) (NN speed)))))) (, ,) (NP (DT an) (ADJP (NN activation) (NN slope) (VBN based)) (JJ slope) (NN recovery) (NN term)) (VP (VBZ is) (VP (VBN added) (PP (IN in) (NP (DT the) (NN loss) (NN function))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (ADVP (RB further)) (VBZ accelerates) (NP (NN convergence)) (, ,) (S (ADVP (RB thereby)) (VP (VBG reducing) (NP (DT the) (NN training) (NN cost))))))))) (. .))
(S (PP (IN On) (NP (DT the) (JJ theoretical) (NN side))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (SBAR (IN that) (S (PP (IN in) (NP (DT the) (VBN proposed) (NN method))) (, ,) (NP (DT the) (JJ gradient) (NN descent) (NNS algorithms)) (VP (VBP are) (RB not) (VP (VBN attracted) (PP (TO to) (NP (NP (JJ sub-optimal) (JJ critical) (NNS points)) (CC or) (NP (JJ local) (NN minima)))) (PP (IN under) (NP (NP (JJ practical) (NNS conditions)) (PP (IN on) (NP (DT the) (NN initialization) (CC and) (VBG learning) (NN rate))))))))) (, ,) (CC and) (SBAR (IN that) (S (NP (NP (DT the) (NN gradient) (NNS dynamics)) (PP (IN of) (NP (DT the) (VBN proposed) (NN method)))) (VP (VBZ is) (RB not) (ADJP (JJ achievable) (PP (IN by) (NP (NP (NN base) (NNS methods)) (PP (IN with) (NP (DT any) (PRN (-LRB- -LRB-) (JJ adaptive) (-RRB- -RRB-)) (VBG learning) (NNS rates))))))))))) (. .))
(S (NP (PRP We)) (ADVP (VBP further)) (VP (VB show) (SBAR (IN that) (S (NP (DT the) (JJ adaptive) (NN activation) (NNS methods)) (VP (VBP accelerate) (NP (DT the) (NN convergence)) (PP (IN by) (S (VP (ADVP (RB implicitly)) (VBG multiplying) (NP (VBG conditioning) (NNS matrices)) (PP (TO to) (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (DT the) (NN base) (NN method))))) (PP (IN without) (NP (NP (DT any) (JJ explicit) (NN computation)) (PP (IN of) (NP (NP (DT the) (NN conditioning) (NN matrix)) (CC and) (NP (DT the) (JJ matrix-vector) (NN product))))))))))))) (. .))
(S (NP (DT The) (JJ different) (JJ adaptive) (NN activation) (NNS functions)) (VP (VBP are) (VP (VBN shown) (S (VP (TO to) (VP (VB induce) (NP (JJ different) (JJ implicit) (NN conditioning) (NNS matrices))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (NP (DT the) (VBN proposed) (NNS methods)) (PP (IN with) (NP (DT the) (NN slope) (NN recovery)))) (VP (VBP are) (VP (VBN shown) (S (VP (TO to) (VP (VB accelerate) (NP (DT the) (NN training) (NN process))))))) (. .))
