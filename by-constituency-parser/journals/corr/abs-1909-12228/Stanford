(S (NP (PRP We)) (VP (VBP propose) (SBAR (S (NP (NP (CD two) (NNS approaches)) (PP (IN of) (NP (ADVP (RB locally)) (JJ adaptive) (NN activation)))) (VP (VBZ functions) (NP (NP (NP (ADVP (RB namely)) (, ,) (NN layer-wise)) (CC and) (NP (ADJP (JJ neuron-wise) (RB locally)) (JJ adaptive) (NN activation) (NNS functions))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (ADJP (UCP (ADJP (JJ deep)) (CC and) (NML (NN physics))) (HYPH -) (VBN informed)) (JJ neural) (NNS networks)))))))))))) (. .))
(S (NP (NP (DT The) (JJ local) (NN adaptation)) (PP (IN of) (NP (NN activation) (NN function)))) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (S (VP (VP (VBG introducing) (NP (DT a) (JJ scalable) (NN parameter)) (PP (PP (IN in) (NP (DT each) (NN layer))) (PRN (-LRB- -LRB-) (NP (NN layer-wise)) (-RRB- -RRB-)) (CC and) (PP (IN for) (NP (DT every) (NN neuron) (-LRB- -LRB-) (NN neuron-wise) (-RRB- -RRB-))) (ADVP (RB separately)))) (, ,) (CC and) (ADVP (RB then)) (VP (VBG optimizing) (NP (PRP it)) (S (VP (VBG using) (NP (NP (DT a) (NN variant)) (PP (IN of) (NP (JJ stochastic) (NN gradient) (NN descent) (NN algorithm)))))))))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (ADVP (RBR further)) (VP (VB increase) (NP (DT the) (NN training) (NN speed))))))) (, ,) (NP (DT an) (ADJP (NP (NN activation) (NN slope)) (VBN based)) (NML (NN slope) (NN recovery)) (NN term)) (VP (VBZ is) (VP (VBN added) (PP (IN in) (NP (NP (DT the) (NN loss) (NN function)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB further)) (VP (VBZ accelerates) (NP (NN convergence))))))) (, ,) (S (ADVP (RB thereby)) (VP (VBG reducing) (NP (DT the) (NN training) (NN cost)))))) (. .))
(S (PP (IN On) (NP (DT the) (JJ theoretical) (NN side))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (SBAR (IN that) (S (PP (IN in) (NP (DT the) (JJ proposed) (NN method))) (, ,) (NP (DT the) (NN gradient) (NN descent) (NNS algorithms)) (VP (VBP are) (RB not) (VP (VBN attracted) (PP (IN to) (NP (NP (JJ sub-optimal) (JJ critical) (NNS points)) (CC or) (NP (JJ local) (NN minima)))) (PP (IN under) (NP (NP (JJ practical) (NNS conditions)) (PP (IN on) (NP (DT the) (NML (NN initialization) (CC and) (NN learning)) (NN rate))))))))) (, ,) (CC and) (SBAR (IN that) (S (NP (NP (DT the) (NN gradient) (NNS dynamics)) (PP (IN of) (NP (DT the) (JJ proposed) (NN method)))) (VP (VBZ is) (RB not) (ADJP (JJ achievable) (PP (IN by) (NP (NP (NN base) (NNS methods)) (PP (IN with) (NP (DT any) (-LRB- -LRB-) (JJ adaptive) (-RRB- -RRB-) (NN learning) (NNS rates))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (JJ adaptive) (NN activation) (NNS methods)) (VP (VB accelerate) (NP (DT the) (NN convergence)) (PP (IN by) (S (ADVP (RB implicitly)) (VP (VBG multiplying) (NP (NN conditioning) (NNS matrices)) (PP (IN to) (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (DT the) (NN base) (NN method))))) (PP (IN without) (NP (NP (DT any) (JJ explicit) (NN computation)) (PP (IN of) (NP (NP (DT the) (NML (NN conditioning) (NN matrix))) (CC and) (NP (DT the) (NML (NN matrix) (HYPH -) (NN vector)) (NN product))))))))))))) (. .))
(S (NP (DT The) (JJ different) (JJ adaptive) (NN activation) (NNS functions)) (VP (VBP are) (VP (VBN shown) (S (VP (TO to) (VP (VB induce) (NP (JJ different) (JJ implicit) (NN conditioning) (NNS matrices))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (NP (DT the) (VBN proposed) (NNS methods)) (PP (IN with) (NP (DT the) (NN slope) (NN recovery)))) (VP (VBP are) (VP (VBN shown) (S (VP (TO to) (VP (VB accelerate) (NP (DT the) (NN training) (NN process))))))) (. .))
