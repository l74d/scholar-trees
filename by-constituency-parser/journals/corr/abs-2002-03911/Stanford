(S (S (VP (VBG Training) (NP (JJ deep) (JJ neural) (NNS networks)) (PP (IN on) (NP (NML (JJ large) (HYPH -) (NN scale)) (NNS datasets))))) (VP (VBZ requires) (NP (NP (JJ significant) (NN hardware) (NNS resources)) (SBAR (WHNP (WHNP (WP$ whose) (NNS costs)) (-LRB- -LRB-) (PP (ADVP (RB even)) (IN on) (NP (NN cloud) (NNS platforms))) (-RRB- -RRB-)) (S (VP (VBD put) (NP (PRP them)) (PP (IN out) (PP (IN of) (NP (NP (NN reach)) (PP (IN of) (NP (NP (JJR smaller) (NNS organizations)) (, ,) (NP (NNS groups)) (, ,) (CC and) (NP (NNS individuals)))))))))))) (. .))
(S (NP (NP (NNP Backpropagation) (-LRB- -LRB-) (NN backprop) (-RRB- -RRB-)) (, ,) (NP (NP (DT the) (NN workhorse)) (PP (IN for) (S (VP (VBG training) (NP (DT these) (NNS networks)))))) (, ,)) (VP (VBZ is) (NP (NP (DT an) (ADJP (RB inherently) (JJ sequential)) (NN process)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB parallelize)))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP it)) (VP (VBZ requires) (NP (NNS researchers)) (S (VP (TO to) (ADVP (RB continually)) (VP (VB develop) (NP (NP (JJ various) (NNS tricks)) (, ,) (PP (JJ such) (IN as) (NP (NP (JJ specialized) (NN weight) (NNS initializations)) (CC and) (NP (NN activation) (NNS functions)))) (, ,) (PP (IN in) (NP (NN order) (S (VP (TO to) (VP (VB ensure) (NP (DT a) (JJ stable) (NN parameter) (NN optimization)))))))))))) (. .))
(S (NP (PRP$ Our) (NN goal)) (VP (VBZ is) (S (VP (TO to) (VP (VB seek) (NP (DT an) (JJ effective) (, ,) (JJ parallelizable) (NN alternative)) (PP (IN to) (NP (NP (NN backprop)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB train) (NP (JJ deep) (NNS networks)))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NML (NML (NN gradient)) (HYPH -) (NML (JJ free) (NN learning))) (NN procedure)) (, ,) (NP (JJ recursive) (JJ local) (NN representation) (NN alignment)) (, ,)) (PP (IN for) (S (VP (VBG training) (NP (NML (JJ large) (HYPH -) (NN scale)) (JJ neural) (NNS architectures)))))) (. .))
(S (NP (NP (NP (NNS Experiments)) (PP (IN with) (NP (NP (JJ deep) (JJ residual) (NNS networks)) (PP (IN on) (NP (NP (NN CIFAR) (HYPH -) (CD 10)) (CC and) (NP (DT the) (NML (JJ large) (HYPH -) (NN scale)) (NN benchmark))))))) (, ,) (NP (NNP ImageNet)) (, ,)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN algorithm)) (VP (VBZ generalizes) (PP (CONJP (RB as) (RB well)) (PP (IN as) (NP (NN backprop))) (IN while) (NP (VBG converging))) (ADVP (RB sooner) (PP (IN due) (PP (IN to) (NP (NP (NN weight) (NNS updates)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (ADJP (JJ parallelizable)) (CC and) (ADJP (ADVP (RB computationally)) (RBR less) (JJ demanding)))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (NP (JJ empirical) (NN evidence)) (SBAR (IN that) (S (NP (DT a) (NML (NN backprop) (HYPH -) (JJ free)) (NN algorithm)) (VP (MD can) (VP (VB scale) (PRT (RP up)) (PP (IN to) (NP (JJR larger) (NNS datasets)))))))) (. .))
(S (NP (DT Another) (NN contribution)) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP we)) (ADVP (RB also)) (VP (ADVP (RB significantly)) (VB reduce) (NP (NP (JJ total) (NN parameter) (NN count)) (PP (IN of) (NP (PRP$ our) (NNS networks))))))) (PP (IN by) (S (VP (VBG utilizing) (ADVP (RB fast)) (, ,) (NP (NP (VBN fixed) (NN noise) (NNS maps)) (PP (IN in) (NP (NP (NN place)) (PP (IN of) (NP (NP (JJ convolutional) (NNS operations)) (PP (IN without) (S (VP (VBG compromising) (NP (NN generalization)))))))))))))) (. .))
