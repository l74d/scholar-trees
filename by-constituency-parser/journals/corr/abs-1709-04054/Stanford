(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (JJ simple) (NN extension)) (PP (IN to) (NP (NP (DT the) (NN ReLU) (HYPH -) (NN family)) (PP (IN of) (NP (NP (NN activation) (NNS functions)) (SBAR (WHNP (WDT that)) (S (VP (VBZ allows) (S (NP (PRP them)) (VP (TO to) (VP (VB shift) (NP (DT the) (NN mean) (NN activation)) (PP (IN across) (NP (NP (DT a) (NN layer)) (PP (IN towards) (NP (CD zero)))))))))))))))) (. .))
(S (PP (VBN Combined) (PP (IN with) (NP (JJ proper) (NN weight) (NN initialization)))) (, ,) (NP (DT this)) (VP (VBZ alleviates) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NN normalization) (NNS layers))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP explore) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (NP (ADJP (NML (JJ deep) (NN vanilla)) (JJ recurrent)) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)))) (PP (IN with) (NP (QP (RB up) (IN to) (CD 144)) (NNS layers)))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (JJ bipolar) (NN activation)) (VP (VBZ functions) (NP (NP (NN help)) (VP (VBG learning) (PP (IN in) (NP (DT this) (NN setting)))))))))) (. .))
(S (PP (IN On) (NP (DT the) (NNP Penn) (NNP Treebank) (CC and) (NNP Text8) (NN language) (NN modeling) (NNS tasks))) (NP (PRP we)) (VP (VBP obtain) (NP (JJ competitive) (NNS results)) (, ,) (S (VP (VBG improving) (PP (IN on) (NP (NP (DT the) (JJS best) (VBN reported) (NNS results)) (PP (IN for) (NP (JJ non-gated) (NNS networks)))))))) (. .))
(S (PP (IN In) (NP (NP (NNS experiments)) (PP (IN with) (NP (NP (JJ convolutional) (JJ neural) (NNS networks)) (PP (IN without) (NP (NN batch) (NN normalization))))))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (JJ bipolar) (NNS activations)) (VP (VBP produce) (NP (NP (NP (DT a) (JJR faster) (NN drop)) (PP (IN in) (NP (NN training) (NN error)))) (, ,) (CC and) (NP (NP (NNS results)) (PP (IN in) (NP (NP (DT a) (JJR lower) (NN test) (NN error)) (PP (IN on) (NP (DT the) (NML (NML (NN CIFAR) (HYPH -) (CD 10)) (NN classification)) (NN task))))))))))) (. .))
