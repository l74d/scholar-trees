(S (NP (VBG Vanishing) (JJ long-term) (NNS gradients)) (VP (VBP are) (NP (NP (DT a) (JJ major) (NN issue)) (PP (IN in) (S (VP (VBG training) (NP (NP (JJ standard) (JJ recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-)))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN alleviated) (PP (IN by) (NP (NP (ADJP (JJ long) (JJ short-term)) (NN memory) (PRN (-LRB- -LRB-) (NNP LSTM) (-RRB- -RRB-)) (NNS models)) (PP (IN with) (NP (NN memory) (NNS cells)))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (JJ extra) (NNS parameters)) (VP (VBN associated) (PP (IN with) (NP (DT the) (NN memory) (NNS cells))))) (VP (VBP mean) (SBAR (S (NP (DT an) (NNP LSTM) (NN layer)) (VP (VBZ has) (NP (NP (QP (QP (CD four) (NNS times)) (IN as) (JJ many)) (NNS parameters)) (PP (IN as) (NP (NP (DT an) (NNP RNN)) (PP (IN with) (NP (DT the) (JJ same) (JJ hidden) (NN vector) (NN size)))))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ addresses) (NP (DT the) (VBG vanishing) (NN gradient) (NN problem)) (S (VP (VBG using) (NP (NP (DT a) (JJ high) (NN order) (NNP RNN)) (PRN (-LRB- -LRB-) (NP (NNP HORNN)) (-RRB- -RRB-)) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (NP (NP (JJ additional) (NNS connections)) (PP (IN from) (NP (JJ multiple) (JJ previous) (NN time) (NNS steps))))))))))) (. .))
(S (NP (NP (NNP Speech) (NN recognition) (NNS experiments)) (VP (VBG using) (NP (JJ British) (JJ English) (NN multi-genre) (NN broadcast) (PRN (-LRB- -LRB-) (NNP MGB3) (-RRB- -RRB-)) (NN data)))) (VP (VBD showed) (SBAR (IN that) (S (NP (NP (DT the) (VBN proposed) (NNP HORNN) (VBZ architectures)) (PP (IN for) (NP (JJ rectified) (JJ linear) (NN unit) (CC and) (JJ sigmoid) (NN activation) (NNS functions)))) (VP (VP (VBD reduced) (NP (NP (NN word) (NN error) (NNS rates)) (PRN (-LRB- -LRB-) (NP (NNP WER)) (-RRB- -RRB-))) (PP (IN by) (NP (NP (CD 4.2) (NN %)) (CC and) (NP (CD 6.3) (NN %)))) (PP (IN over) (NP (DT the) (JJ corresponding) (NNP RNNs)))) (, ,) (CC and) (VP (VBD gave) (NP (JJ similar) (NNP WERs)) (PP (TO to) (NP (DT a) (PRN (-LRB- -LRB-) (VBN projected) (-RRB- -RRB-)) (NNP LSTM))) (SBAR (IN while) (S (VP (VBG using) (NP (NP (QP (RB only) (CD 20) (NN %) (: â€”) (CD 50) (NN %))) (PP (IN of) (NP (NP (DT the) (NN recurrent) (NN layer) (NNS parameters)) (CC and) (NP (NN computation))))))))))))) (. .))
