(S (NP (NNP Tucker) (NN decomposition)) (VP (VBZ is) (NP (NP (NP (DT the) (NN cornerstone)) (PP (IN of) (NP (NP (JJ modern) (NML (NML (NN machine) (NN learning)) (PP (IN on) (NP (JJ tensorial) (NNS data)))) (NN analysis)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (VP (VBN attracted) (NP (JJ considerable) (NN attention)) (PP (IN for) (NP (JJ multiway) (NN feature) (NN extraction)))))))))) (, ,) (NP (NP (JJ compressive)) (VP (VBG sensing))) (, ,) (CC and) (NP (NN tensor) (NN completion)))) (. .))
(S (NP (DT The) (ADJP (RBS most) (JJ challenging)) (NN problem)) (VP (VBZ is) (VP (VBN related) (PP (IN to) (NP (NP (NN determination)) (PP (IN of) (NP (NP (NN model) (NN complexity)) (-LRB- -LRB-) (NP (ADVP (FW i.e.)) (, ,) (JJ multilinear) (NN rank)) (-RRB- -RRB-))))) (, ,) (SBAR (WHADVP (RB especially) (WRB when)) (S (NP (NP (NN noise)) (CC and) (NP (VBG missing) (NNS data))) (VP (VBP are) (ADJP (JJ present))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (VBG existing) (NNS methods)) (VP (MD can) (RB not) (VP (VB take) (PP (IN into) (NP (NP (NN account) (NN uncertainty) (NN information)) (PP (IN of) (NP (JJ latent) (NNS factors))))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (NML (JJ low) (NN generalization)) (NN performance))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS issues))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (NN class)) (PP (IN of) (NP (NML (JJ probabilistic) (NN generative)) (NNP Tucker) (NNS models)))) (PP (IN for) (NP (NN tensor) (NN decomposition) (CC and) (NN completion))) (PP (IN with) (NP (NP (JJ structural) (NN sparsity)) (PP (IN over) (NP (JJ multilinear) (NN latent) (NN space)))))) (. .))
(S (S (VP (TO To) (VP (VB exploit) (NP (JJ structural) (JJ sparse) (NN modeling))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (CD two) (NN group) (NN sparsity)) (S (VP (VBG inducing) (NP (NNS priors)) (PP (IN by) (NP (NP (NP (JJ hierarchial) (NN representation)) (PP (IN of) (NP (NML (NML (NNP Laplace) (CC and) (NNP Student)) (HYPH -) (NN t)) (NNS distributions)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ facilitates) (NP (ADJP (RB fully) (JJ posterior)) (NN inference)))))))))) (. .))
(S (PP (IN For) (NP (NN model) (NN learning))) (, ,) (NP (PRP we)) (VP (VP (VBD derived) (NP (JJ variational) (JJ Bayesian) (NNS inferences)) (PP (IN over) (NP (DT all) (NML (NN model) (PRN (-LRB- -LRB-) (ADJP (JJ hyper)) (-RRB- -RRB-))) (NNS parameters)))) (, ,) (CC and) (VP (VBD developed) (NP (ADJP (JJ efficient) (CC and) (JJ scalable)) (NNS algorithms)) (PP (VBN based) (PP (IN on) (NP (JJ multilinear) (NNS operations)))))) (. .))
(S (NP (PRP$ Our) (NNS methods)) (VP (VP (MD can) (ADVP (RB automatically)) (VP (VB adapt) (NP (NN model) (NN complexity)))) (CC and) (VP (VBP infer) (NP (DT an) (JJ optimal) (NN multilinear) (NN rank)) (PP (IN by) (NP (NP (DT the) (NN principle)) (PP (IN of) (NP (NP (NN maximum)) (VP (ADVP (JJR lower)) (VBN bound) (PP (IN of) (NP (NN model) (NN evidence)))))))))) (. .))
(S (NP (NP (JJ Experimental) (NNS results) (CC and) (NNS comparisons)) (PP (IN on) (NP (NP (JJ synthetic)) (, ,) (NP (NNS chemometrics)) (CC and) (NP (NN neuroimaging) (NNS data))))) (VP (VBP demonstrate) (NP (NP (JJ remarkable) (NN performance)) (PP (IN of) (NP (PRP$ our) (NNS models)))) (PP (IN for) (S (VP (VP (VBG recovering) (NP (NP (NN ground) (HYPH -) (NN truth)) (PP (IN of) (NP (JJ multilinear) (NN rank))))) (CC and) (VP (VBG missing) (NP (NNS entries))))))) (. .))
