(S (NP (NP (DT A) (JJ recent) (NN line)) (PP (IN of) (NP (NN work)))) (VP (NNS shows) (SBAR (IN that) (S (NP (NP (DT a) (JJ deep) (JJ neural) (NN network)) (PP (IN with) (NP (NNP ReLU) (NNS nonlinearities)))) (VP (VBZ arises) (PP (IN from) (NP (NP (DT a) (JJ finite) (NN sequence)) (PP (IN of) (NP (NP (JJ cascaded) (NN sparse) (NN coding) (NNS models)) (, ,) (SBAR (WHNP (WHNP (DT the) (NNS outputs)) (WHPP (IN of) (WHNP (WDT which)))) (S (, ,) (PP (IN except) (PP (IN for) (NP (NP (DT the) (JJ last) (NN element)) (PP (IN in) (NP (DT the) (NN cascade)))))) (, ,) (VP (VBP are) (ADJP (JJ sparse) (CC and) (JJ unobservable))))))))))))) (. .))
(S (S (NP (DT That)) (VP (VBZ is))) (, ,) (NP (NP (JJ intermediate) (NNS outputs)) (ADVP (RB deep) (PP (IN in) (NP (DT the) (NN cascade))))) (VP (VP (VBP are) (ADJP (JJ sparse))) (, ,) (S (ADVP (RB hence)) (NP (NP (DT the) (NN title)) (PP (IN of) (NP (DT this) (NN manuscript)))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (ADVP (RB here)) (, ,) (S (VP (VBG using) (NP (NP (NNS techniques)) (PP (IN from) (NP (DT the) (JJ dictionary) (NN learning) (NN literature)))))) (SBAR (IN that) (, ,) (S (SBAR (IN if) (S (S (NP (NP (DT the) (NN measurement) (NNS matrices)) (PP (IN in) (NP (DT the) (JJ cascaded) (NN sparse) (VBG coding) (NN model)))) (S (PRN (-LRB- -LRB-) (DT a) (-RRB- -RRB-)) (VP (NN satisfy) (NP (NNP RIP))))) (CC and) (S (PRN (-LRB- -LRB-) (NN b) (-RRB- -RRB-)) (NP (DT all)) (VP (VBP have) (NP (VBN sparse) (NNS columns)) (PP (IN except) (PP (IN for) (NP (DT the) (JJ last)))))))) (, ,) (NP (PRP they)) (VP (MD can) (VP (VB be) (VP (VBN recovered) (PP (IN with) (NP (JJ high) (NN probability))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NP (CD two) (NN algorithms)) (PP (IN for) (NP (DT this) (NN purpose)))) (: :) (NP (NP (NP (NN one)) (SBAR (WHNP (WDT that)) (S (VP (VBZ recovers) (NP (DT the) (NNS matrices)) (PP (IN in) (NP (DT a) (NN forward) (NN sequence))))))) (, ,) (CC and) (NP (NP (DT another)) (SBAR (WHNP (WDT that)) (S (VP (VBZ recovers) (NP (PRP them)) (PP (IN in) (NP (DT a) (NN backward) (NN sequence)))))))))) (. .))
(S (NP (NP (DT The) (NN method)) (PP (IN of) (NP (NN choice))) (PP (IN in) (NP (JJ deep) (NN learning))) (SBAR (S (VP (TO to) (VP (VB solve) (NP (DT this) (NN problem))))))) (VP (VBZ is) (PP (IN by) (S (VP (VBG training) (NP (DT an) (NN auto-encoder)))))) (. .))
(S (NP (PRP$ Our) (NNS algorithms)) (VP (VBP provide) (NP (DT a) (NN sound) (JJ alternative)) (, ,) (PP (IN with) (NP (NP (JJ theoretical) (NNS guarantees)) (, ,) (CONJP (RB as) (RB well)) (NP (NP (JJ upper) (NNS bounds)) (PP (IN on) (NP (JJ sample) (NN complexity))))))) (. .))
(S (NP (DT The) (NN theory)) (VP (VBZ shows) (SBAR (IN that) (S (NP (NP (DT the) (JJ learning) (NN complexity)) (PP (IN of) (NP (DT the) (NN forward) (NN algorithm)))) (VP (VBZ depends) (PP (IN on) (NP (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ hidden) (NNS units))) (PP (IN at) (NP (DT the) (JJS deepest) (NN layer)))) (CC and) (NP (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ active) (NNS neurons))) (PP (IN at) (NP (DT that) (NN layer)))) (PRN (-LRB- -LRB-) (NP (NN sparsity)) (-RRB- -RRB-))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (DT the) (NN theory)) (VP (VBZ relates) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ hidden) (NNS units))) (PP (IN in) (NP (JJ successive) (NNS layers)))) (, ,) (S (ADVP (RB thus)) (VP (VBG giving) (NP (NP (DT a) (JJ practical) (NN prescription)) (PP (IN for) (S (VP (VBG designing) (NP (JJ deep) (NNP ReLU) (JJ neural) (NNS networks))))))))) (. .))
(S (SBAR (IN Because) (S (NP (PRP it)) (VP (VBZ puts) (NP (JJR fewer) (NNS restrictions)) (PP (IN on) (NP (DT the) (NN architecture)))))) (, ,) (NP (DT the) (NN backward) (NN algorithm)) (VP (VBZ requires) (NP (JJR more) (NNS data))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (DT the) (JJ deep) (NN dictionary) (VBG learning) (JJ algorithm)) (PP (IN via) (NP (NNS simulations)))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP use) (NP (DT a) (NN coupon-collection) (NN argument)) (S (VP (TO to) (VP (VB conjecture) (NP (NP (DT a) (JJR lower) (NN bound)) (PP (IN on) (NP (JJ sample) (NN complexity))) (SBAR (WHNP (WDT that)) (S (VP (VBZ gives) (NP (NP (DT some) (NN insight)) (PP (IN as) (PP (TO to) (SBAR (WHADVP (WRB why)) (S (NP (JJ deep) (NNS networks)) (VP (VBP require) (NP (NP (JJR more) (NNS data))) (S (VP (TO to) (VP (VB train)))) (PP (IN than) (NP (JJ shallow) (NNS ones))))))))))))))))) (. .))
