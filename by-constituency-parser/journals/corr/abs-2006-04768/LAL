(S (NP (JJ Large) (NN transformer) (NNS models)) (VP (VBP have) (VP (VBN shown) (NP (JJ extraordinary) (NN success)) (PP (IN in) (S (VP (VBG achieving) (NP (JJ state-of-the-art) (NNS results)) (PP (IN in) (NP (JJ many) (JJ natural) (NN language) (NN processing) (NNS applications)))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG training) (CC and) (VBG deploying) (NP (DT these) (NNS models)))) (VP (MD can) (VP (VB be) (ADJP (RB prohibitively) (JJ costly)) (PP (IN for) (NP (JJ long) (NNS sequences))) (, ,) (SBAR (IN as) (S (NP (NP (DT the) (JJ standard) (NN self-attention) (NN mechanism)) (PP (IN of) (NP (DT the) (NNP Transformer)))) (VP (VBZ uses) (NP ($ $) (NNP O) (PRN (PRN (-LRB- -LRB-) (NN n^2) (-RRB- -RRB-)) ($ $)) (NN time) (CC and) (NN space)) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (VB sequence) (NN length)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (NN self-attention) (NN mechanism)) (VP (MD can) (VP (VB be) (VP (VBN approximated) (PP (IN by) (NP (DT a) (JJ low-rank) (NN matrix))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VBP exploit) (NP (DT this) (NN finding)) (S (VP (TO to) (VP (VB propose) (NP (NP (DT a) (JJ new) (NN self-attention) (NN mechanism)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ reduces) (NP (DT the) (JJ overall) (NN self-attention) (NN complexity)) (PP (IN from) (NP ($ $) (NNP O) (PRN (-LRB- -LRB-) (NN n^2) (-RRB- -RRB-)) ($ $))) (PP (TO to) (NP ($ $) (NNP O) (PRN (-LRB- -LRB-) (FW n) (-RRB- -RRB-)) ($ $))) (PP (IN in) (NP (DT both) (NN time) (CC and) (NN space))))))))))) (. .))
