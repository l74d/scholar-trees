(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (JJ greedy) (NN strategy)) (S (VP (TO to) (VP (VB train) (NP (DT a) (JJ deep) (NN network)) (PP (IN for) (NP (NN multi-class) (NN classification)))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT each) (NN layer)) (VP (VBZ is) (VP (VBN defined) (PP (IN as) (NP (NP (DT a) (NN composition)) (PP (IN of) (NP (NP (DT a) (JJ linear) (NN projection)) (CC and) (NP (DT a) (JJ nonlinear) (NN mapping))))))))))) (. .))
(S (S (NP (DT This) (JJ nonlinear) (NN mapping)) (VP (VBZ is) (VP (VBN defined) (PP (IN as) (NP (NP (DT the) (NN feature) (NN map)) (PP (IN of) (NP (DT a) (JJ Gaussian) (NN kernel)))))))) (, ,) (CC and) (S (NP (DT the) (JJ linear) (NN projection)) (VP (VBZ is) (VP (VBN learned) (PP (IN by) (S (VP (VBG maximizing) (NP (NP (DT the) (NN dependence)) (PP (IN between) (NP (NP (DT the) (NN layer) (NN output)) (CC and) (NP (DT the) (NNS labels)))))))) (, ,) (S (VP (VBG using) (NP (DT the) (NNP Hilbert) (NNP Schmidt) (NNP Independence) (NNP Criterion) (PRN (-LRB- -LRB-) (NP (NNP HSIC)) (-RRB- -RRB-))) (PP (IN as) (NP (DT the) (NN dependence) (NN measure)))))))) (. .))
(S (S (SBAR (IN Since) (S (NP (DT each) (NN layer)) (VP (VBZ is) (VP (VBN trained) (ADVP (RB greedily)) (PP (IN in) (NP (NN sequence))))))) (, ,) (NP (DT all) (NN learning)) (VP (VBZ is) (ADJP (JJ local)))) (, ,) (CC and) (S (NP (CC neither) (NP (NN backpropagation)) (CC nor) (NP (RB even) (NN gradient) (NN descent))) (VP (VBZ is) (VP (VBN needed)))) (. .))
(S (S (NP (NP (DT The) (NN depth) (CC and) (NN width)) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBP are) (VP (VBN determined) (PP (IN via) (NP (JJ natural) (NNS guidelines)))))) (, ,) (CC and) (S (NP (DT the) (NN procedure)) (VP (VBZ regularizes) (NP (PRP$ its) (NNS weights)) (PP (IN in) (NP (DT the) (JJ linear) (NN layer))))) (. .))
(S (PP (IN As) (NP (DT the) (JJ key) (JJ theoretical) (NN result))) (, ,) (NP (NP (DT the) (NN function) (NN class)) (VP (VBN represented) (PP (IN by) (NP (DT the) (NN network))))) (VP (VBZ is) (VP (VBN proved) (S (VP (TO to) (VP (VB be) (ADJP (RB sufficiently) (JJ rich) (S (VP (TO to) (VP (VB learn) (NP (DT any) (NN dataset) (NN labeling)) (S (VP (VBG using) (NP (NP (DT a) (JJ finite) (NN number)) (PP (IN of) (NP (NNS layers))))))))))))) (, ,) (PP (IN in) (NP (NP (DT the) (NN sense)) (PP (IN of) (S (VP (VBG reaching) (NP (NP (JJ minimum) (ADJP (JJ mean) (HYPH -) (JJ squared)) (NN error)) (CC or) (NP (NN cross-entropy))) (, ,) (ADVP (ADVP (RB as) (RB long)) (SBAR (IN as) (S (NP (DT no) (CD two) (NNS data)) (VP (VBZ points) (SBAR (IN with) (S (NP (JJ different) (NNS labels)) (VP (VBP coincide))))))))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP demonstrate) (NP (NP (JJ good) (NN generalization) (NN performance)) (PP (IN of) (NP (NP (DT the) (JJ greedy) (NN approach)) (PP (IN across) (NP (JJ multiple) (NNS benchmarks)))))) (PP (IN while) (S (VP (VBG showing) (NP (DT a) (JJ significant) (JJ computational) (NN advantage)) (PP (IN against) (NP (NP (DT a) (JJ multilayer) (NN perceptron)) (PP (IN of) (NP (NP (DT the) (JJ same) (NN complexity)) (VP (VBN trained) (ADVP (RB globally)) (PP (IN by) (NP (NN backpropagation)))))))))))) (. .))
