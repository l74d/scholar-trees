(S (NP (PRP We)) (VP (VBP consider) (NP (NP (DT a) (NN problem)) (PP (IN of) (S (VP (VBG learning) (NP (NP (DT the) (NN reward) (CC and) (NN policy)) (PP (IN from) (NP (NN expert) (NNS examples)))) (PP (IN under) (NP (JJ unknown) (NNS dynamics)))))))) (. .))
(S (NP (PRP$ Our) (JJ proposed) (NN method)) (VP (VP (VBZ builds) (PP (IN on) (NP (NP (DT the) (NN framework)) (PP (IN of) (NP (JJ generative) (JJ adversarial) (NNS networks)))))) (CC and) (VP (VBZ introduces) (NP (NP (NP (DT the) (NN empowerment)) (HYPH -) (VP (VBN regularized) (NP (NML (NN maximum) (HYPH -) (NN entropy)) (NN inverse) (NN reinforcement)))) (VP (VBG learning) (S (VP (TO to) (VP (VB learn) (PP (IN near) (HYPH -) (NP (JJ optimal) (NNS rewards) (CC and) (NNS policies)))))))))) (. .))
(S (NP (ADJP (NN Empowerment) (HYPH -) (VBN based)) (NN regularization)) (VP (VBZ prevents) (NP (DT the) (NN policy)) (PP (IN from) (S (VP (VBG overfitting) (PP (IN to) (NP (NP (JJ expert) (NNS demonstrations)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB advantageously)) (VP (VBZ leads) (PP (IN to) (NP (NP (JJR more)) (VP (VBN generalized) (NP (NP (NNS behaviors)) (SBAR (WHNP (WDT that)) (S (VP (VBP result) (PP (IN in) (NP (NP (NN learning)) (PP (IN near) (HYPH -) (NP (JJ optimal) (NNS rewards))))))))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (ADVP (RB simultaneously)) (VP (VBZ learns) (NP (NN empowerment)) (PP (IN through) (NP (NP (JJ variational) (NN information) (NN maximization)) (ADVP (IN along) (PP (IN with) (NP (NP (DT the) (NN reward) (CC and) (NN policy)) (PP (IN under) (NP (DT the) (JJ adversarial) (NN learning) (NN formulation))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (PRP$ our) (NN approach)) (PP (IN on) (NP (JJ various) (ADJP (JJ high) (HYPH -) (JJ dimensional)) (JJ complex) (NN control) (NNS tasks)))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP test) (NP (NP (PRP$ our)) (VP (VBN learned) (NP (NP (NNS rewards)) (PP (IN in) (NP (JJ challenging) (NML (NN transfer) (NN learning)) (NNS problems)))) (SBAR (WHADVP (WRB where)) (S (NP (NML (NN training) (CC and) (NN testing)) (NNS environments)) (VP (VBP are) (VP (VBN made) (S (VP (TO to) (VP (VB be) (ADJP (JJ different) (PP (IN from) (NP (NP (DT each) (JJ other)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NNS dynamics) (CC or) (NN structure)))))))))))))))))) (. .))
(S (NP (DT The) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (JJ proposed) (NN method)) (VP (CONJP (RB not) (RB only)) (VP (VBZ learns) (PP (IN near) (HYPH -) (NP (JJ optimal) (NNS rewards) (CC and) (NNS policies))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (VBG matching) (NP (JJ expert) (NN behavior))))))) (CC but) (ADVP (RB also)) (VP (VBZ performs) (NP (ADJP (ADJP (RB significantly) (JJR better)) (PP (IN than) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN inverse) (NN reinforcement)))) (VBG learning) (NNS algorithms))))))) (. .))
