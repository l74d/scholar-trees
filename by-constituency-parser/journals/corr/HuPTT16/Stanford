(S (NP (ADJP (NN State) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (JJ neural) (NNS networks)) (VP (VBP are) (VP (VBG getting) (NP (JJR deeper) (CC and) (JJR wider)))) (. .))
(S (SBAR (IN While) (S (NP (PRP$ their) (NN performance)) (VP (VBZ increases) (PP (IN with) (NP (NP (DT the) (VBG increasing) (NN number)) (PP (IN of) (NP (NNS layers) (CC and) (NNS neurons)))))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ crucial) (S (VP (TO to) (VP (VB design) (NP (NP (DT an) (JJ efficient) (JJ deep) (NN architecture)) (PP (IN in) (NP (NN order)))) (S (VP (TO to) (VP (VB reduce) (NP (UCP (ADJP (JJ computational)) (CC and) (NML (NN memory))) (NNS costs)))))))))) (. .))
(S (NP (NP (NNP Designing)) (NP (DT an) (JJ efficient) (JJ neural) (NN network))) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ is) (ADJP (NN labor) (JJ intensive)) (S (VP (VBG requiring) (NP (JJ many) (NNS experiments) (, ,) (CC and) (JJ fine) (HYPH -) (NNS tunings))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (NN network) (NN trimming)) (SBAR (WHNP (WDT which)) (S (ADVP (RB iteratively)) (VP (VBZ optimizes) (NP (DT the) (NN network)) (PP (IN by) (NP (NP (ADJP (NP (NN pruning)) (JJ unimportant)) (NNS neurons)) (VP (VBN based) (PP (IN on) (NP (NP (NN analysis)) (PP (IN of) (NP (PRP$ their) (NNS outputs))))) (PP (IN on) (NP (DT a) (JJ large) (NN dataset))))))))))) (. .))
(S (NP (PRP$ Our) (NN algorithm)) (VP (VBZ is) (VP (VBN inspired) (PP (IN by) (NP (DT an) (NN observation))) (SBAR (IN that) (S (NP (NP (DT the) (NNS outputs)) (PP (IN of) (NP (NP (DT a) (JJ significant) (NN portion)) (PP (IN of) (NP (NP (NNS neurons)) (PP (IN in) (NP (DT a) (JJ large) (NN network)))))))) (VP (VBP are) (NP (RB mostly) (CD zero)) (, ,) (ADVP (RB regardless) (PP (IN of) (SBAR (WHNP (WDT what)) (S (NP (NP (NNS inputs)) (NP (DT the) (NN network))) (VP (VBD received))))))))))) (. .))
(S (NP (DT These) (NML (CD zero) (NN activation)) (NNS neurons)) (VP (VP (VBP are) (ADJP (JJ redundant))) (, ,) (CC and) (VP (MD can) (VP (VB be) (VP (VBN removed) (PP (IN without) (S (VP (VBG affecting) (NP (NP (DT the) (JJ overall) (NN accuracy)) (PP (IN of) (NP (DT the) (NN network))))))))))) (. .))
(S (PP (IN After) (NP (NP (NN pruning)) (NP (DT the) (CD zero) (NN activation) (NNS neurons)))) (, ,) (NP (PRP we)) (VP (VBP retrain) (NP (DT the) (NN network)) (S (VP (VBG using) (NP (DT the) (NNS weights)) (PP (IN before) (NP (NP (NN pruning)) (PP (IN as) (NP (NN initialization)))))))) (. .))
(S (NP (PRP We)) (VP (FRAG (ADJP (JJ alternate)) (SBAR (S (NP (NP (DT the) (NN pruning)) (CC and) (NP (VBG retraining))) (VP (TO to) (ADVP (RB further)) (VP (VB reduce) (NP (NP (CD zero) (NNS activations)) (PP (IN in) (NP (DT a) (NN network)))))))))) (. .))
(NP (NP (PRP$ Our) (NNS experiments)) (PP (IN on) (NP (NP (DT the) (NML (NML (NNP LeNet)) (CC and) (NML (NNP VGG) (HYPH -) (CD 16))) (NN show)) (SBAR (WHNP (WDT that)) (S (NP (PRP we)) (VP (MD can) (VP (VB achieve) (NP (NP (NML (JJ high) (NN compression)) (NN ratio)) (PP (IN of) (NP (NNS parameters)))) (PP (IN without) (S (VP (VP (VBG losing)) (CC or) (ADVP (RB even)) (VP (VBG achieving) (NP (JJR higher) (NN accuracy)) (PP (IN than) (NP (DT the) (JJ original) (NN network))))))))))))) (. .))
