(S (NP (JJ State-of-the-art) (JJ neural) (NNS networks)) (VP (VBP are) (VP (VBG getting) (ADJP (JJR deeper) (CC and) (JJR wider)))) (. .))
(S (SBAR (IN While) (S (NP (PRP$ their) (NN performance)) (VP (NNS increases) (PP (IN with) (NP (NP (DT the) (VBG increasing) (NN number)) (PP (IN of) (NP (NNS layers) (CC and) (NNS neurons)))))))) (, ,) (NP (NP (PRP it))) (VP (VBZ is) (ADJP (JJ crucial)) (S (VP (TO to) (VP (VB design) (NP (DT an) (JJ efficient) (JJ deep) (NN architecture)) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB reduce) (NP (UCP (JJ computational) (CC and) (NN memory)) (NNS costs)))))))))) (. .))
(S (S (VP (VBG Designing) (NP (DT an) (JJ efficient) (JJ neural) (NN network)))) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ is) (ADJP (NN labor) (JJ intensive)) (S (VP (VBG requiring) (NP (JJ many) (NNS experiments) (, ,) (CC and) (NNS fine-tunings))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (NN network) (VBG trimming)) (SBAR (WHNP (WDT which)) (S (VP (ADVP (RB iteratively)) (VBZ optimizes) (NP (DT the) (NN network)) (PP (IN by) (S (VP (VBG pruning) (NP (JJ unimportant) (NNS neurons))))) (PP (VBN based) (PP (IN on) (NP (NP (NN analysis)) (PP (IN of) (NP (PRP$ their) (NNS outputs))) (PP (IN on) (NP (DT a) (JJ large) (NN dataset))))))))))) (. .))
(S (NP (PRP$ Our) (NN algorithm)) (VP (VBZ is) (VP (VBN inspired) (PP (IN by) (NP (DT an) (NN observation) (SBAR (IN that) (S (NP (NP (DT the) (NNS outputs)) (PP (IN of) (NP (NP (DT a) (JJ significant) (NN portion)) (PP (IN of) (NP (NP (NNS neurons)) (PP (IN in) (NP (DT a) (JJ large) (NN network)))))))) (VP (VBP are) (ADJP (RB mostly) (CD zero)) (, ,) (ADVP (RB regardless) (PP (IN of) (SBAR (WHNP (WP what) (VBZ inputs)) (S (NP (DT the) (NN network)) (VP (VBD received))))))))))))) (. .))
(S (NP (DT These) (CD zero) (NN activation) (NNS neurons)) (VP (VP (VBP are) (ADJP (JJ redundant))) (, ,) (CC and) (VP (MD can) (VP (VB be) (VP (VBN removed) (PP (IN without) (S (VP (VBG affecting) (NP (NP (DT the) (JJ overall) (NN accuracy)) (PP (IN of) (NP (DT the) (NN network))))))))))) (. .))
(S (PP (IN After) (S (VP (VBG pruning) (NP (DT the) (CD zero) (NN activation) (NNS neurons))))) (, ,) (NP (PRP we)) (VP (VBP retrain) (NP (DT the) (NN network)) (S (VP (VBG using) (NP (NP (DT the) (NNS weights)) (PP (RB before) (NP (VBG pruning)))) (PP (IN as) (NP (NN initialization)))))) (. .))
(S (NP (PRP We)) (VP (VBP alternate) (NP (DT the) (NN pruning) (CC and) (VBG retraining)) (S (VP (TO to) (VP (ADVP (JJ further)) (VB reduce) (NP (NP (CD zero) (NNS activations)) (PP (IN in) (NP (DT a) (NN network)))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (PP (IN on) (NP (DT the) (NNP LeNet) (CC and) (NNP VGG-16)))) (VP (VBP show) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VB achieve) (NP (NP (JJ high) (NN compression) (NN ratio)) (PP (IN of) (NP (NNS parameters)))) (PP (IN without) (S (VP (VP (VBG losing)) (CC or) (VP (ADVP (RB even)) (VBG achieving)) (NP (NP (JJR higher) (NN accuracy)) (PP (IN than) (NP (DT the) (JJ original) (NN network)))))))))))) (. .))
