(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ direct-to-word) (NN sequence) (NN model)) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (DT a) (NN word) (NN network)) (S (VP (TO to) (VP (VB learn) (NP (NN word) (NNS embeddings)) (PP (IN from) (NP (NNS letters))))))))))) (. .))
(S (NP (DT The) (NN word) (NN network)) (VP (MD can) (VP (VB be) (VP (VBN integrated) (ADVP (RB seamlessly)) (PP (IN with) (NP (NP (JJ arbitrary) (NN sequence) (NNS models)) (PP (VBG including) (NP (NP (NP (JJ Connectionist) (NNP Temporal) (NNP Classification)) (CC and) (NP (JJ encoder-decoder) (NNS models))) (PP (IN with) (NP (NN attention)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (S (NP (PRP$ our) (JJ direct-to-word) (NN model)) (VP (MD can) (VP (VB achieve) (NP (NP (NN word) (NN error) (NN rate) (NNS gains)) (PP (IN over) (NP (NP (JJ sub-word) (NN level) (NNS models)) (PP (IN for) (NP (JJ speech) (NN recognition))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (JJ direct-to-word) (NN approach)) (VP (VBZ retains) (NP (DT the) (NN ability) (S (VP (TO to) (VP (VB predict) (NP (NP (NNS words)) (VP (RB not) (VBN seen) (PP (IN at) (NP (NN training) (NN time))))) (PP (IN without) (NP (DT any) (NN retraining))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT a) (JJ word-level) (NN model)) (VP (MD can) (VP (VB use) (NP (NP (DT a) (JJR larger) (NN stride)) (PP (IN than) (NP (DT a) (JJ sub-word) (NN level) (NN model)))) (SBAR (IN while) (S (VP (VBG maintaining) (NP (NN accuracy)))))))))) (. .))
(S (NP (DT This)) (VP (VBZ makes) (S (NP (DT the) (NN model)) (ADJP (ADJP (RBR more) (JJ efficient)) (PP (DT both) (IN for) (NP (NN training) (CC and) (NN inference)))))) (. .))
