(S (NP (NP (JJ Convolutional) (NML (NML (JJ neural) (NN network)) (-LRB- -LRB-) (NML (NP (NNP CNN))) (-RRB- -RRB-)) (NN inference)) (PP (IN on) (NP (JJ mobile) (NNS devices)))) (VP (VBZ demands) (NP (NP (JJ efficient) (NN hardware) (NN acceleration)) (PP (IN of) (NP (NML (JJ low) (HYPH -) (NN precision)) (PRN (-LRB- -LRB-) (NP (NN INT8)) (-RRB- -RRB-)) (JJ general) (NN matrix) (NN multiplication)))) (PRN (-LRB- -LRB-) (NP (NNP GEMM)) (-RRB- -RRB-))) (. .))
(S (NP (NP (DT The) (JJ systolic) (NN array)) (-LRB- -LRB-) (NP (NNP SA)) (-RRB- -RRB-)) (VP (VBZ is) (NP (NP (DT a) (ADJP (JJ pipelined)) (NN 2D) (NN array)) (PP (IN of) (NP (NP (NN processing) (NNS elements)) (-LRB- -LRB-) (NP (NNS PEs)) (-RRB- -RRB-))) (, ,) (UCP (PP (IN with) (NP (NP (ADJP (RB very) (JJ efficient)) (NML (JJ local) (NNS data)) (NN movement)) (, ,) (ADJP (RB well) (JJ suited) (PP (IN to) (S (VP (VBG accelerating) (NP (NNP GEMM)))))) (, ,))) (CC and) (VP (ADVP (RB widely)) (VBN deployed) (PP (IN in) (NP (NN industry))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP describe) (NP (CD two) (JJ significant) (NNS improvements)) (PP (IN to) (NP (DT the) (JJ traditional) (NNP SA) (NN architecture))) (, ,) (S (VP (TO to) (ADVP (RB specifically)) (VP (VB optimize) (PP (IN for) (NP (NNP CNN) (NN inference))))))) (. .))
(S (ADVP (RB Firstly)) (, ,) (NP (PRP we)) (VP (VBP generalize) (NP (DT the) (JJ traditional) (JJ scalar) (NN PE)) (, ,) (PP (IN into) (NP (NP (DT a) (NML (NNP Tensor) (HYPH -) (NN PE))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ gives) (NP (NN rise)) (PP (IN to) (NP (NP (DT a) (NN family)) (PP (IN of) (NP (JJ new) (JJ Systolic) (NML (NML (NNP Tensor) (NN Array)) (-LRB- -LRB-) (NML (NN STA)) (-RRB- -RRB-)) (NNS microarchitectures))))))))))) (. .))
(S (NP (DT The) (NN STA) (NN family)) (VP (VBZ increases) (S (NP (JJ intra-PE) (NN operand)) (VP (VB reuse) (CC and) (VB datapath) (NP (NN efficiency)) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (NP (NML (NN circuit) (NN area) (CC and) (NN power)) (NN dissipation) (NN reduction)) (PP (IN of) (NP (NP (QP (RB as) (JJ much) (IN as) (CD 2.08)) (NN x)) (CC and) (NP (CD 1.36) (SYM x)))))) (ADVP (RB respectively)) (, ,) (PP (VBN compared) (PP (IN to) (NP (NP (DT the) (JJ conventional) (NML (NML (NP (NNP SA)) (PP (IN at) (NP (NNP iso)))) (HYPH -) (NN throughput))) (PP (IN with) (NP (NN INT8) (NNS operands))))))))))) (. .))
(S (ADVP (RB Secondly)) (, ,) (NP (PRP we)) (VP (VBP extend) (NP (DT this) (NN design) (S (VP (TO to) (VP (VB support) (NP (DT a) (ADJP (NP (NP (JJ novel) (NN block)) (HYPH -) (NP (JJ sparse) (NNS data) (NN format))) (VBN called)) (ADJP (NP (NN density)) (HYPH -) (VBN bound)) (NN block)))))) (PRN (-LRB- -LRB-) (NP (NN DBB)) (-RRB- -RRB-))) (. .))
(S (NP (NP (DT This) (NN variant)) (-LRB- -LRB-) (NP (NN STA) (HYPH -) (NN DBB)) (-RRB- -RRB-)) (VP (VBZ achieves) (NP (NP (DT a) (CD 3.14) (NN x)) (CC and) (NP (NP (CD 1.97) (SYM x) (NN improvement)) (PP (IN over) (NP (NP (DT the) (NNP SA) (NN baseline)) (PP (IN at) (NP (NP (NN iso) (HYPH -) (NN throughput)) (PP (IN in) (NP (NN area) (CC and) (NN power))))))))) (ADVP (RB respectively)) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBG processing) (NP (NP (ADJP (RB specially) (HYPH -) (VBN trained)) (NML (NN DBB) (HYPH -) (JJ sparse)) (NNS models)) (, ,) (SBAR (IN while) (S (VP (VBG remaining) (ADJP (ADVP (RB fully) (RB backwards)) (JJ compatible)) (PP (IN with) (NP (JJ dense) (NNS models))))))))))) (. .))
