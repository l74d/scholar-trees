(S (PP (IN Due) (PP (IN to) (NP (NP (PRP$ their) (VBG growing) (NN popularity)) (CC and) (NP (JJ computational) (NN cost))))) (, ,) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-)) (VP (VBP are) (VP (VBG being) (VP (VBN targeted) (PP (IN for) (NP (NN hardware) (NN acceleration)))))) (. .))
(S (NP (NP (NP (DT A) (JJ popular) (NN architecture)) (PP (IN for) (NP (NN DNN) (NN acceleration)))) (, ,) (VP (VBN adopted) (PP (IN by) (NP (DT the) (NNP Google) (NNP Tensor) (NNP Processing) (NNP Unit))) (PRN (-LRB- -LRB-) (NP (NN TPU)) (-RRB- -RRB-))) (, ,)) (VP (VBZ utilizes) (NP (NP (DT a) (JJ systolic) (NN array)) (VP (VBN based) (NP (NML (NN matrix) (NN multiplication)) (NN unit)) (PP (IN at) (NP (PRP$ its) (NN core)))))) (. .))
(NP (NP (DT This) (ADJP (NP (NP (NN paper) (NNS deals)) (PP (IN with) (NP (NP (DT the) (NN design)) (PP (IN of) (NP (NN fault)))))) (HYPH -) (JJ tolerant)) (, ,) (JJ systolic) (NN array)) (VP (VBN based) (NP (NNP DNN) (NNS accelerators)) (PP (IN for) (NP (NML (JJ high) (NN defect)) (NN rate) (NNS technologies)))) (. .))
(S (S (NP (DT The) (NN FAP+T)) (VP (VBZ does) (VP (VB introduce) (NP (NP (DT a) (NML (CD one) (HYPH -) (NN time)) (VBG retraining) (NN penalty)) (PP (IN per) (NP (NN TPU) (NN chip)))) (SBAR (IN before) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN deployed)))))))) (, ,) (CC but) (S (NP (PRP we)) (VP (VBP propose) (NP (NP (NNS optimizations)) (SBAR (WHNP (WDT that)) (S (VP (VBP reduce) (NP (DT this) (NML (CD one) (HYPH -) (NN time)) (NN penalty)) (PP (IN to) (PP (IN under) (NP (CD 12) (NNS minutes)))))))))) (. .))
(S (NP (DT The) (NN penalty)) (VP (VBZ is) (ADVP (RB then)) (VP (VBN amortized) (PP (IN over) (NP (NP (DT the) (JJ entire) (NN lifetime)) (PP (IN of) (NP (NP (DT the) (NNP TPU) (POS 's)) (NN operation))))))) (. .))
