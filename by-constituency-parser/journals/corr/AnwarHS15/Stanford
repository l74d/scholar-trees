(S (S (NP (NP (JJ Real) (NN time) (NN application)) (PP (IN of) (NP (NML (JJ deep) (NN learning)) (NNS algorithms)))) (VP (VBZ is) (ADVP (RB often)) (VP (VBN hindered) (PP (IN by) (NP (JJ high) (JJ computational) (NN complexity)))))) (CC and) (S (NP (JJ frequent) (NN memory)) (VP (VBZ accesses))) (. .))
(S (NP (NNP Network) (NN pruning)) (VP (VBZ is) (NP (DT a) (JJ promising) (NN technique) (S (VP (TO to) (VP (VB solve) (NP (DT this) (NN problem))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NN pruning)) (ADVP (RB usually)) (VP (VBZ results) (PP (IN in) (NP (NP (JJ irregular) (NN network) (NNS connections)) (SBAR (WHNP (WDT that)) (S (CONJP (RB not) (RB only)) (S (VP (VB demand) (NP (JJ extra) (NN representation) (NNS efforts)))) (CONJP (CC but) (RB also)) (S (VP (VBP do) (RB not) (VP (VB fit) (ADVP (RB well)) (PP (IN on) (NP (JJ parallel) (NN computation))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (JJ structured) (NN sparsity)) (PP (IN at) (NP (NP (NP (JJ various) (NNS scales)) (PP (IN for) (NP (NP (JJ convolutional) (JJ neural) (NNS networks)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADJP (NP (NN channel)) (JJ wise)) (, ,) (S (NP (NN kernel)) (ADJP (JJ wise))))))))) (CC and) (NP (ADJP (AFX intra) (NN kernel)) (VBN strided) (NN sparsity))))) (. .))
(S (NP (DT This) (JJ structured) (NN sparsity)) (VP (VBZ is) (ADJP (RB very) (JJ advantageous) (PP (IN for) (NP (JJ direct) (JJ computational) (NML (NML (NML (NN resource) (NNS savings)) (PP (IN on) (NP (VBN embedded) (NNS computers) (, ,) (JJ parallel) (NN computing) (NNS environments)))) (CC and) (NML (NML (NN hardware)) (VP (VBN based)))) (NNS systems))))) (. .))
(S (S (VP (TO To) (VP (VB decide) (NP (NP (DT the) (NN importance)) (PP (IN of) (NP (NN network) (NNS connections) (CC and) (NNS paths))))))) (, ,) (NP (DT the) (JJ proposed) (NN method)) (VP (VBZ uses) (NP (DT a) (NN particle) (VBG filtering) (NN approach))) (. .))
(S (NP (NP (DT The) (NN importance) (NN weight)) (PP (IN of) (NP (DT each) (NN particle)))) (VP (VBZ is) (VP (VBN assigned) (PP (IN by) (S (VP (VBG computing) (NP (DT the) (NN misclassification) (NN rate)) (PP (IN with) (NP (VBG corresponding) (NN connectivity) (NN pattern)))))))) (. .))
(S (NP (DT The) (VBN pruned) (NN network)) (VP (VBZ is) (VP (VBN re-trained) (S (VP (TO to) (VP (VB compensate) (PP (IN for) (NP (DT the) (NNS losses))) (PP (IN due) (PP (IN to) (NP (NN pruning))))))))) (. .))
(S (SBAR (IN While) (S (VP (VBG implementing) (NP (NNS convolutions)) (PP (IN as) (NP (NN matrix) (NNS products)))))) (, ,) (NP (PRP we)) (ADVP (RB particularly)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (ADJP (AFX intra) (NN kernel)) (VBN strided) (NN sparsity)) (PP (IN with) (NP (DT a) (JJ simple) (NN constraint)))) (VP (MD can) (ADVP (RB significantly)) (VP (VB reduce) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (NP (NN kernel)) (CC and) (NP (NN feature) (NN map) (NNS matrices)))))))))) (. .))
(S (NP (DT The) (VBN pruned) (NN network)) (VP (VBZ is) (ADVP (RB finally)) (NP (NP (VBN fixed) (NN point)) (VP (VBN optimized) (PP (IN with) (NP (JJ reduced) (NML (NN word) (NN length)) (NN precision)))))) (. .))
(S (NP (DT This)) (VP (VBZ results) (PP (IN in) (NP (NP (JJ significant) (NN reduction)) (PP (IN in) (NP (NP (DT the) (JJ total) (NN storage) (NN size)) (VP (VBG providing) (NP (NNS advantages)) (PP (IN for) (NP (NP (NML (IN on) (HYPH -) (NN chip)) (ADJP (NN memory) (VBN based)) (NNS implementations)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks))))))))))) (. .))
