(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (NN novel) (NN hardware) (CC and) (NN software) (NN co-exploration) (NN framework)) (PP (IN for) (NP (NP (JJ efficient) (JJ neural) (NN architecture) (NN search)) (PRN (-LRB- -LRB-) (NP (NNP NAS)) (-RRB- -RRB-)))))) (. .))
(S (S (ADJP (NN Different) (PP (IN from) (NP (NP (VBG existing) (NN hardware-aware) (NNP NAS)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ assumes) (NP (DT a) (JJ fixed) (NN hardware) (NN design))) (CC and) (VP (VBZ explores) (NP (DT the) (JJ neural) (NN architecture) (NN search) (NN space)) (ADVP (RB only)))))))))) (, ,) (NP (PRP$ our) (NN framework)) (VP (ADVP (RB simultaneously)) (VBZ explores) (NP (CC both) (NP (DT the) (NN architecture) (NN search) (NN space)) (CC and) (NP (DT the) (NN hardware) (NN design) (NN space))) (S (VP (TO to) (VP (VB identify) (NP (NP (DT the) (JJS best) (JJ neural) (NN architecture) (CC and) (NN hardware) (NNS pairs)) (SBAR (WHNP (WDT that)) (S (VP (VBP maximize) (NP (DT both) (NP (NN test) (NN accuracy)) (CC and) (NP (NN hardware) (NN efficiency))))))))))) (. .))
(S (NP (JJ Such) (DT a) (NN practice)) (VP (VP (ADVP (RB greatly)) (VBZ opens) (PRT (RP up)) (NP (DT the) (NN design) (NN freedom))) (CC and) (VP (NNS pushes) (ADVP (VBP forward)) (NP (NP (DT the) (NNP Pareto) (NN frontier)) (PP (IN between) (NP (NP (NN hardware) (NN efficiency)) (CC and) (NP (NN test) (NN accuracy))))) (PP (IN for) (NP (JJR better) (NN design) (NNS tradeoffs))))) (. .))
(S (NP (DT The) (NN framework)) (VP (ADVP (RB iteratively)) (VBZ performs) (NP (DT a) (JJ two-level) (PRN (-LRB- -LRB-) (ADJP (JJ fast) (CC and) (JJ slow)) (-RRB- -RRB-)) (NN exploration))) (. .))
(S (PP (IN Without) (NP (JJ lengthy) (NN training))) (, ,) (NP (DT the) (JJ fast) (NN exploration)) (VP (MD can) (VP (VP (ADVP (RB effectively)) (JJ fine-tune) (NP (NNS hyperparameters))) (CC and) (VP (JJ prune) (NP (JJ inferior) (NNS architectures)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NN hardware) (NNS specifications)))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (ADVP (RB significantly)) (VBZ accelerates) (NP (DT the) (NNP NAS) (NN process))))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (DT the) (JJ slow) (NN exploration)) (VP (VP (NNS trains) (NP (NNS candidates)) (PP (IN on) (NP (DT a) (NN validation) (NN set)))) (CC and) (VP (VBZ updates) (NP (DT a) (NN controller))) (S (VP (VBG using) (NP (DT the) (NN reinforcement) (VBG learning)) (S (VP (TO to) (VP (VB maximize) (NP (NP (DT the) (JJ expected) (NN accuracy)) (PP (RB together) (PP (IN with) (NP (DT the) (NN hardware) (NN efficiency))))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NNP ImageNet)))) (VP (NN show) (SBAR (IN that) (S (NP (PRP$ our) (NN co-exploration) (NNP NAS)) (VP (MD can) (VP (VB find) (NP (NP (DT the) (JJ neural) (NNS architectures)) (CC and) (NX (VBN associated) (NN hardware) (NN design))) (PP (IN with) (NP (NP (DT the) (JJ same) (NN accuracy)) (, ,) (NP (ADJP (NP (CD 35.24) (NN %)) (JJR higher)) (NN throughput)) (, ,) (NP (ADJP (NP (CD 54.05) (NN %)) (JJR higher)) (NN energy) (NN efficiency)) (CC and) (NP (QP (CD 136x)) (VBN reduced) (NN search) (NN time)))) (, ,) (PP (VBN compared) (PP (IN with) (NP (DT the) (JJ state-of-the-art) (JJ hardware-aware) (NNP NAS))))))))) (. .))
