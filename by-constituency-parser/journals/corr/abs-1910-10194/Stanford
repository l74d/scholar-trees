(S (NP (NP (NNP Controlling)) (SBAR (S (NP (DT a) (NN biped) (NN robot)) (VP (TO to) (VP (VB walk) (ADVP (RB stably))))))) (VP (VBZ is) (NP (NP (DT a) (JJ challenging) (NN task)) (PP (VBG considering) (NP (NP (PRP$ its) (NN nonlinearity)) (CC and) (NP (NN hybrid) (NNS dynamics)))))) (. .))
(S (NP (NN Reinforcement) (NN learning)) (VP (MD can) (VP (VB address) (NP (DT these) (NNS issues)) (PP (IN by) (S (ADVP (RB directly)) (VP (VBG mapping) (NP (DT the) (VBN observed) (NNS states)) (PP (IN to) (NP (NP (JJ optimal) (NNS actions)) (SBAR (WHNP (WDT that)) (S (VP (VBP maximize) (NP (DT the) (JJ cumulative) (NN reward)))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (JJ local) (NN minima)) (VP (VBN caused) (PP (IN by) (NP (NP (ADJP (JJ unsuitable)) (NNS rewards)) (CC and) (NP (NP (DT the) (NN overestimation)) (PP (IN of) (NP (DT the) (JJ cumulative) (NN reward)))))))) (VP (VBP impede) (NP (NP (DT the) (NN maximization)) (PP (IN of) (NP (DT the) (JJ cumulative) (NN reward))))) (. .))
(S (S (VP (TO To) (VP (VB increase) (NP (DT the) (JJ cumulative) (NN reward))))) (, ,) (NP (DT this) (NN paper)) (VP (VBZ designs) (NP (DT a) (NN gait) (NN reward)) (PP (VBN based) (PP (IN on) (NP (NP (VBG walking) (NNS principles)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ compensates) (NP (NP (DT the) (JJ local) (NN minima)) (PP (IN for) (NP (JJ unnatural) (NNS motions))))))))))) (. .))
(S (ADVP (RB Besides)) (, ,) (NP (NP (DT an) (JJ Adversarial) (NN Twin)) (NP (NP (VBN Delayed) (NML (NML (NML (NML (NNP Deep)) (ADJP (JJ Deterministic))) (-LRB- -LRB-) (NML (NN ATD3)) (-RRB- -RRB-)) (NN policy) (NN gradient)) (NN algorithm)) (PP (IN with) (NP (DT a) (ADJP (JJ recurrent)) (JJ neural) (NN network))) (PRN (-LRB- -LRB-) (NP (NN RNN)) (-RRB- -RRB-)))) (VP (VBZ is) (VP (VBN proposed) (S (VP (TO to) (ADVP (RB further)) (VP (VB boost) (NP (DT the) (JJ cumulative) (NN reward)) (PP (IN by) (S (VP (VBG mitigating) (NP (NP (DT the) (NN overestimation)) (PP (IN of) (NP (DT the) (JJ cumulative) (NN reward)))))))))))) (. .))
(S (NP (NP (NP (JJ Experimental) (NNS results)) (PP (IN in) (NP (DT the) (NNP Roboschool) (NN Walker2d)))) (CC and) (NP (NML (NNP Webots) (NNP Atlas)) (NNS simulators))) (VP (VBP indicate) (SBAR (IN that) (S (NP (DT the) (NN test) (NNS rewards)) (VP (VBP increase) (PP (IN by) (NP (QP (CD 23.50) (NN %) (CC and) (CD 9.63) (NN %)))) (PP (IN after) (S (VP (VBG adding) (NP (DT the) (NN gait) (NN reward))))))))) (. .))
(S (S (NP (DT The) (NN test) (NNS rewards)) (ADVP (RBR further)) (VP (VB increase) (PP (IN by) (NP (QP (CD 15.96) (NN %) (CC and) (CD 12.68) (NN %)))) (PP (IN after) (S (VP (VBG using) (NP (DT the) (NN ATD3_RNN))))))) (, ,) (CC and) (S (NP (DT the) (NN reason)) (VP (MD may) (VP (VB be) (SBAR (IN that) (S (NP (DT the) (NN ATD3_RNN)) (VP (VBZ decreases) (NP (NP (DT the) (NN error)) (PP (IN of) (S (VP (VBG estimating) (NP (JJ cumulative) (NN reward)) (PP (IN from) (NP (QP (CD 19.86) (NN %) (IN to) (CD 3.35) (NN %)))))))))))))) (. .))
(S (ADVP (RB Besides)) (, ,) (NP (NP (DT the) (NN cosine) (JJ kinetic) (NN similarity)) (PP (IN between) (NP (NP (DT the) (JJ human)) (CC and) (NP (DT the) (NN biped) (NN robot))))) (VP (VP (VBN trained) (PP (IN by) (NP (DT the) (NN gait) (NN reward)))) (CC and) (VP (NP (NN ATD3_RNN) (NNS increases)) (PP (IN by) (NP (QP (IN over) (CD 69.23)) (NN %))))) (. .))
(S (ADVP (RB Consequently)) (, ,) (NP (NP (DT the) (VBN designed) (NN gait) (NN reward)) (CC and) (NP (NN ATD3_RNN))) (VP (VP (VBP boost) (NP (DT the) (JJ cumulative) (NN reward))) (CC and) (VP (VB teach) (NP (NN biped) (NNS robots)) (S (VP (TO to) (VP (VB walk) (NP (JJR better))))))) (. .))
