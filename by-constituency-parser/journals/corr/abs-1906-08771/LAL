(S (NP (ADJP (JJ Mini-batch) (NN gradient) (NN descent) (VBN based)) (NNS methods)) (VP (VBP are) (NP (NP (DT the) (FW de) (FW facto) (NN algorithms)) (PP (IN for) (S (VP (VBG training) (NP (JJ neural) (NN network) (NNS architectures)))))) (NP (NN today))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (JJ mini-batch) (NN selection) (NN strategy)) (VP (VBN based) (PP (IN on) (NP (JJ submodular) (NN function) (NN maximization)))))) (. .))
(S (NP (PRP$ Our) (JJ novel) (JJ submodular) (NN formulation)) (VP (VBZ captures) (NP (NP (NP (DT the) (NN informativeness)) (PP (IN of) (NP (DT each) (NN sample)))) (CC and) (NP (NP (NN diversity)) (PP (IN of) (NP (DT the) (JJ whole) (NN subset)))))) (. .))
(S (NP (PRP We)) (VP (VBP design) (NP (NP (DT an) (NN efficient) (, ,) (NN greedy) (NN algorithm)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB give) (NP (NP (JJ high-quality) (NNS solutions)) (PP (TO to) (NP (DT this) (NNP NP-hard) (JJ combinatorial) (NN optimization) (NN problem)))))))))) (. .))
(S (NP (NP (PRP$ Our) (JJ extensive) (NNS experiments)) (PP (IN on) (NP (JJ standard) (NNS datasets)))) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (JJ deep) (NNS models)) (VP (VBN trained) (S (VP (VBG using) (NP (DT the) (VBN proposed) (NN batch) (NN selection) (NN strategy)))))) (VP (VBP provide) (NP (NP (NP (JJR better) (NN generalization)) (PP (IN than) (NP (JJ Stochastic) (NNP Gradient) (NNP Descent)))) (CONJP (RB as) (RB well) (IN as)) (NP (NP (DT a) (JJ popular) (NN baseline) (VBG sampling) (NN strategy)) (PP (IN across) (NP (JJ different) (NX (NX (VBG learning) (NNS rates)) (, ,) (NX (NN batch) (NNS sizes)) (, ,) (CC and) (NX (NN distance) (NNS metrics))))))))))) (. .))
