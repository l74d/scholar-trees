(S (NP (DT This) (NN paper)) (VP (VBZ presents) (NP (NP (DT the) (NN design) (, ,) (NN implementation) (, ,) (CC and) (NN evaluation)) (PP (IN of) (NP (DT the) (NNP PyTorch) (VBD distributed) (NNS data) (JJ parallel) (NN module))))) (. .))
(S (NP (NNP PyTorch)) (VP (VBZ is) (NP (NP (DT a) (JJ widely-adopted) (JJ scientific) (NN computing) (NN package)) (VP (VBN used) (PP (IN in) (NP (JJ deep) (NN learning) (NN research) (CC and) (NNS applications)))))) (. .))
(S (NP (NP (JJ Recent) (NNS advances)) (PP (IN in) (NP (JJ deep) (NN learning)))) (VP (NN argue) (PP (IN for) (NP (NP (DT the) (NN value)) (PP (IN of) (NP (NP (JJ large) (NNS datasets)) (CC and) (NP (JJ large) (NNS models)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ necessitates) (NP (DT the) (NN ability) (S (VP (TO to) (VP (VB scale) (PRT (RP out)) (NP (NN model) (VBG training)) (PP (TO to) (NP (RBR more) (JJ computational) (NNS resources))))))))))))) (. .))
(S (NP (NNP Data) (NN parallelism)) (VP (VBZ has) (VP (VBN emerged) (PP (IN as) (NP (NP (DT a) (JJ popular) (NN solution)) (PP (IN for) (NP (JJ distributed) (NN training))))) (ADVP (NNS thanks) (PP (TO to) (NP (PRP$ its) (NX (NN straightforward) (NN principle) (CC and) (NP (JJ broad) (NN applicability)))))))) (. .))
(S (PP (IN In) (ADJP (JJ general))) (, ,) (NP (NP (DT the) (NN technique)) (PP (IN of) (NP (VBN distributed) (NNS data) (NN parallelism)))) (VP (VP (VBZ replicates) (NP (DT the) (NN model)) (PP (IN on) (NP (DT every) (JJ computational) (NN resource))) (S (VP (TO to) (VP (VB generate) (NP (NNS gradients)) (ADVP (RB independently)))))) (CC and) (RB then) (VP (NNS communicates) (NP (DT those) (NNS gradients)) (PP (IN at) (NP (DT each) (NN iteration))) (S (VP (TO to) (VP (VB keep) (S (NP (NN model) (JJ replicas)) (ADJP (NN consistent)))))))) (. .))
(S (PP (IN Despite) (NP (NP (DT the) (JJ conceptual) (NN simplicity)) (PP (IN of) (NP (DT the) (NN technique))))) (, ,) (NP (NP (DT the) (JJ subtle) (NNS dependencies)) (PP (IN between) (NP (NN computation) (CC and) (NN communication)))) (VP (VBP make) (S (NP (NP (PRP it))) (ADJP (JJ non-trivial)) (S (VP (TO to) (VP (VB optimize) (NP (DT the) (JJ distributed) (NN training) (NN efficiency))))))) (. .))
(S (PP (IN As) (PP (IN of) (NP (NN v1.5)))) (, ,) (NP (NNP PyTorch)) (VP (ADVP (RB natively)) (VBZ provides) (NP (NP (JJ several) (NNS techniques)) (SBAR (S (VP (TO to) (VP (VB accelerate) (NP (VBN distributed) (NNS data) (NNS parallel)))))) (, ,) (PP (VBG including) (S (VP (VP (VBG bucketing) (NP (NNS gradients))) (, ,) (VP (VBG overlapping) (NP (NN computation)) (PP (IN with) (NP (NN communication)))) (, ,) (CC and) (VP (VBG skipping) (NP (JJ gradient) (NN synchronization)))))))) (. .))
(S (NP (NNS Evaluations)) (VP (VBP show) (SBAR (IN that) (, ,) (S (SBAR (WHADVP (WRB when)) (S (VP (VBN configured) (ADVP (RB appropriately))))) (, ,) (NP (DT the) (NNP PyTorch) (VBD distributed) (NNS data) (JJ parallel) (NN module)) (VP (VBZ attains) (NP (JJ near-linear) (NN scalability)) (S (VP (VBG using) (NP (CD 256) (NNP GPUs)))))))) (. .))
