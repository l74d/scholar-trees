(S (PP (IN As) (S (VP (VBG enjoying) (NP (DT the) (NML (JJ closed) (NN form)) (NN solution))))) (, ,) (NP (JJS least) (NNS squares)) (VP (VBP support) (SBAR (S (NP (NN vector) (NN machine) (PRN (-LRB- -LRB-) (NP (NN LSSVM)) (-RRB- -RRB-))) (VP (VBZ has) (VP (VBN been) (ADVP (RB widely)) (VP (VBN used) (PP (IN for) (NP (NML (NN classification) (CC and) (NN regression)) (NNS problems))) (S (VP (VBG having) (NP (DT the) (JJ comparable) (NN performance)) (PP (IN with) (NP (NP (JJ other) (NNS types)) (PP (IN of) (NP (NNS SVMs))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NNP LSSVM)) (VP (VBZ has) (NP (NP (CD two) (NNS drawbacks)) (: :) (UCP (ADJP (JJ sensitive) (PP (IN to) (NP (NNS outliers)))) (CC and) (VP (VBG lacking) (NP (NN sparseness)))))) (. .))
(S (S (NP (JJ Robust) (NN LSSVM) (PRN (-LRB- -LRB-) (NP (NN R) (HYPH -) (NN LSSVM)) (-RRB- -RRB-))) (VP (VBZ overcomes) (NP (DT the) (ADJP (JJ first) (PP (RB partly) (IN via) (NP (JJ nonconvex) (VBN truncated) (NN loss)))) (NN function)))) (, ,) (CC but) (S (NP (NP (DT the) (JJ current) (NNS algorithms)) (PP (IN for) (NP (NP (NN R) (HYPH -) (NN LSSVM)) (PP (IN with) (NP (DT the) (JJ dense) (NN solution)))))) (VP (VP (VBP are) (VP (VBN faced) (PP (IN with) (NP (DT the) (JJ second) (NN drawback))))) (CC and) (VP (VBP are) (ADJP (JJ inefficient) (PP (IN for) (S (VP (VBG training) (NP (NML (JJ large) (HYPH -) (NN scale)) (NNS problems))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP interpret) (NP (NP (DT the) (NN robustness)) (PP (IN of) (NP (NN R) (HYPH -) (NN LSSVM)))) (PP (IN from) (NP (DT a) (JJ re-weighted) (NN viewpoint)))) (CC and) (VP (VB give) (NP (DT a) (JJ primal) (NML (NN R) (HYPH -) (NN LSSVM))) (PP (IN by) (NP (DT the) (NN representer) (NN theorem))))) (. .))
(S (NP (DT The) (JJ new) (NN model)) (VP (MD may) (VP (VB have) (NP (JJ sparse) (NN solution)) (SBAR (IN if) (S (NP (DT the) (VBG corresponding) (NN kernel) (NN matrix)) (VP (VBZ has) (NP (JJ low) (NN rank))))))) (. .))
(S (S (ADVP (RB Then)) (VP (VP (VBG approximating) (NP (DT the) (NN kernel) (NN matrix)) (PP (IN by) (NP (DT a) (NML (JJ low) (HYPH -) (NN rank)) (NN matrix)))) (CC and) (VP (VBG smoothing) (NP (DT the) (NN loss) (NN function)) (PP (IN by) (NP (NN entropy) (NN penalty) (NN function)))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (JJ convergent) (JJ sparse) (NML (NN R) (HYPH -) (NN LSSVM) (PRN (-LRB- -LRB-) (NP (NNP SR) (HYPH -) (NNP LSSVM)) (-RRB- -RRB-))) (NN algorithm)) (S (VP (TO to) (VP (VB achieve) (NP (NP (DT the) (JJ sparse) (NN solution)) (PP (IN of) (NP (NP (JJ primal) (NML (NN R) (HYPH -) (NN LSSVM))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ overcomes) (NP (NP (CD two) (NNS drawbacks)) (PP (IN of) (NP (NNP LSSVM)))) (ADVP (RB simultaneously)))))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN algorithm)) (VP (VP (VBZ has) (NP (NP (JJR lower) (NN complexity)) (PP (IN than) (NP (DT the) (VBG existing) (NNS algorithms))))) (CC and) (VP (VBZ is) (ADJP (RB very) (JJ efficient) (PP (IN for) (S (VP (VBG training) (NP (NML (JJ large) (HYPH -) (NN scale)) (NNS problems)))))))) (. .))
(S (NP (JJ Many) (JJ experimental) (NNS results)) (VP (VBP illustrate) (SBAR (IN that) (S (NP (NNP SR) (HYPH -) (NNP LSSVM)) (VP (MD can) (VP (VB achieve) (NP (ADJP (ADJP (JJR better)) (CC or) (ADJP (JJ comparable))) (NN performance)) (PP (PP (IN with) (NP (NP (JJR less) (NN training) (NN time)) (PP (IN than) (NP (JJ related) (NNS algorithms))))) (, ,) (RB especially) (PP (IN for) (NP (VBG training) (NML (JJ large) (NN scale)) (NNS problems))))))))) (. .))
