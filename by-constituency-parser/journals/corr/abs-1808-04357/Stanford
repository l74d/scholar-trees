(S (NP (NNS Data) (NN parallelism)) (VP (VBZ has) (VP (VBN become) (NP (DT a) (JJ dominant) (NN method)) (S (VP (TO to) (VP (VB scale) (NP (JJ Deep) (JJ Neural) (NML (NN Network) (-LRB- -LRB-) (NN DNN) (-RRB- -RRB-)) (NN training)) (PP (IN across) (NP (JJ multiple) (NNS nodes)))))))) (. .))
(S (PP (IN Since) (S (VP (VBG synchronizing) (SBAR (S (NP (NP (DT a) (JJ large) (NN number)) (PP (IN of) (NP (NP (NNS gradients)) (PP (IN of) (NP (DT the) (JJ local) (NN model)))))) (VP (MD can) (VP (VB be) (NP (NP (DT a) (NN bottleneck)) (PP (IN for) (NP (NML (JJ large) (HYPH -) (NN scale)) (VBN distributed) (NN training))))))))))) (, ,) (S (VP (VBG compressing) (NP (NN communication) (NNS data)))) (VP (VBZ has) (VP (VBN gained) (NP (JJ widespread) (NN attention)) (ADVP (RB recently)))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN literature)) (PP (IN on) (S (VP (VBG compressing) (NP (JJ deep) (NNS networks)))))) (VP (VBZ focuses) (ADVP (RB almost) (RB exclusively)) (PP (IN on) (S (VP (VBG achieving) (NP (JJ good) (NML (JJ theoretical) (NN compression)) (NN rate))))) (, ,) (SBAR (IN while) (S (NP (NP (DT the) (NN efficiency)) (PP (IN of) (NP (NP (NNP RGC)) (PP (IN in) (NP (JJ real) (VBN distributed) (NN implementation)))))) (VP (VBZ has) (VP (VBN been) (ADVP (RBR less)) (VP (VBN investigated))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (DT an) (ADJP (NP (NN RGC)) (HYPH -) (VBN based)) (NN system)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN training)))) (NN time)) (PP (IN on) (NP (NML (JJ real) (HYPH -) (NN world)) (NN multi-GPU) (NNS systems))))))))))))) (. .))
(NP (NP (NP (PRP$ Our) (VBN proposed) (NN design)) (VP (VBN called) (NP (NP (NNP RedSync)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ introduces) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NNS optimizations)))))))))) (S (VP (TO to) (VP (VB reduce) (NP (NN communication) (NN bandwidth) (NN requirement)) (PP (IN while) (S (VP (VBG introducing) (NP (JJ limited) (NN overhead)))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NNP RedSync))) (PP (IN on) (NP (CD two) (JJ different) (JJ multiple) (NN GPU) (NNS platforms))) (, ,) (PP (VBG including) (NP (NP (CD 128) (NNS GPUs)) (PP (IN of) (NP (NP (DT a) (NN supercomputer)) (CC and) (NP (DT an) (NML (CD 8) (HYPH -) (NN GPU)) (NN server)))))))) (. .))
(S (NP (PRP$ Our) (NN test) (NNS cases)) (VP (VBP include) (NP (NP (NP (NML (NN image) (NN classification)) (NNS tasks)) (PP (IN on) (NP (NP (NN Cifar10)) (CC and) (NP (NNP ImageNet))))) (, ,) (CC and) (NP (NP (NML (NN language) (NN modeling)) (NNS tasks)) (PP (IN on) (NP (NP (NNP Penn) (NNP Treebank)) (CC and) (NP (NN Wiki2) (NNS datasets))))))) (. .))
(S (PP (IN For) (NP (NP (NNS DNNs)) (VP (VBN featured) (PP (IN with) (NP (JJ high) (NN communication))) (PP (IN to) (NP (NP (JJ computation) (NN ratio)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (ADVP (RB long)) (VP (VBN been) (VP (VBN considered) (PP (IN with) (NP (JJ poor) (NN scalability))))))))))))) (, ,) (NP (NN RedSync)) (VP (VBZ brings) (NP (JJ significant) (NN performance) (NNS improvements))) (. .))
