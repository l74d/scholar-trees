(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP present) (NP (DT an) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN speech)))) (NN recognition) (NN model)) (PP (IN with) (NP (NP (NN Transformer) (NNS encoders)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN in) (NP (DT a) (NN streaming) (NN speech) (NN recognition) (NN system))))))))))) (. .))
(S (NP (NP (NN Transformer) (NN computation) (NNS blocks)) (PP (VBN based) (PP (IN on) (NP (NN self) (HYPH -) (NN attention))))) (VP (VBP are) (VP (VBN used) (S (VP (TO to) (VP (VB encode) (NP (NP (DT both) (NN audio)) (CC and) (NP (NN label) (NNS sequences))) (ADVP (RB independently))))))) (. .))
(S (NP (NP (DT The) (NNS activations)) (PP (IN from) (NP (NP (DT both) (NN audio)) (CC and) (NP (NN label) (NNS encoders))))) (VP (VBP are) (VP (VBN combined) (PP (IN with) (NP (DT a) (NML (NN feed) (HYPH -) (JJ forward)) (NN layer))) (PP (IN to) (NP (NML (S (VP (VB compute) (NP (DT a) (NN probability) (NN distribution)) (PP (IN over) (NP (NP (DT the) (NN label) (NN space)) (PP (IN for) (NP (NP (DT every) (NN combination)) (PP (IN of) (NP (JJ acoustic) (NN frame) (NN position) (CC and) (NN label)))))))))) (NN history))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (ADJP (JJ similar) (PP (IN to) (NP (NP (DT the) (JJ Recurrent) (JJ Neural) (NML (NML (NN Network) (NN Transducer)) (-LRB- -LRB-) (NML (NN RNN) (HYPH -) (NN T)) (-RRB- -RRB-)) (NN model)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NP (NNS RNNs)) (PP (IN for) (NP (NP (NN information)) (VP (VBG encoding) (ADVP (RB instead)) (PP (IN of) (NP (NNP Transformer) (NNS encoders)))))))))))))) (. .))
(S (NP (DT The) (NN model)) (VP (VBZ is) (VP (VBN trained) (PP (IN with) (NP (NP (DT the) (NML (NN RNN) (HYPH -) (NN T)) (NN loss)) (ADJP (RB well) (HYPH -) (VBN suited)))) (PP (IN to) (NP (VBG streaming) (NN decoding))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (NNS results)) (PP (IN on) (NP (DT the) (NNP LibriSpeech) (NN dataset)))) (S (VP (VBG showing) (SBAR (IN that) (S (S (VP (VBG limiting) (NP (DT the) (JJ left) (NN context)) (PP (IN for) (NP (NP (NN self) (HYPH -) (NN attention)) (PP (IN in) (NP (DT the) (NN Transformer) (NNS layers))))))) (VP (VBZ makes) (NP (NN decoding)) (S (ADVP (RB computationally)) (ADJP (JJ tractable) (PP (IN for) (NP (NN streaming))))) (, ,) (PP (IN with) (NP (NP (RB only) (DT a) (JJ slight) (NN degradation)) (PP (IN in) (NP (NN accuracy))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (JJ full) (NN attention) (NN version)) (PP (IN of) (NP (PRP$ our) (NN model)))) (VP (VBZ beats) (NP (NP (NML (NML (DT the) (HYPH -) (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (NN art)))) (NN accuracy)) (PP (IN on) (NP (DT the) (NNP LibriSpeech) (NNS benchmarks)))))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VB bridge) (NP (NP (NP (DT the) (NN gap)) (PP (IN between) (NP (JJ full) (NN attention)))) (CC and) (NP (NP (JJ limited) (NN attention) (NNS versions)) (PP (IN of) (NP (PRP$ our) (NN model))))) (PP (IN by) (S (VP (VBG attending) (PP (IN to) (NP (NP (DT a) (JJ limited) (NN number)) (PP (IN of) (NP (JJ future) (NNS frames))))))))))))) (. .))
