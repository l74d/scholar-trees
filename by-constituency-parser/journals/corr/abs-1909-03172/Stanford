(S (NP (JJ Numerous) (JJ empirical) (NN evidence)) (VP (VBZ has) (VP (VBN corroborated) (SBAR (IN that) (S (NP (DT the) (NN noise)) (VP (VBZ plays) (NP (NP (DT a) (JJ crucial) (NN rule)) (PP (IN in) (NP (NP (ADJP (JJ effective) (CC and) (JJ efficient)) (NN training)) (PP (IN of) (NP (JJ neural) (NNS networks))))))))))) (. .))
(S (PP (NP (DT The) (NN theory)) (IN behind)) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ is) (ADVP (RB still)) (ADJP (RB largely) (JJ unknown))) (. .))
(FRAG (NP (NP (DT This) (NN paper) (NNS studies)) (NP (DT this) (JJ fundamental) (NN problem))) (PP (IN through) (S (VP (VBG training) (NP (DT a) (JJ simple) (NML (CD two) (HYPH -) (NN layer)) (JJ convolutional) (JJ neural) (NN network) (NN model))))) (. .))
(S (SBAR (IN Although) (S (S (VP (VBG training) (NP (PDT such) (DT a) (NN network)))) (VP (VBZ requires) (S (VP (VBG solving) (NP (NP (NP (DT a) (JJ nonconvex) (NN optimization) (NN problem)) (PP (IN with) (NP (DT a) (JJ spurious) (JJ local) (JJ optimum)))) (CC and) (NP (DT a) (JJ global) (JJ optimum)))))))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (S (VP (VP (VBN perturbed) (NP (NN gradient) (NN descent))) (CC and) (VP (VBD perturbed) (NP (NP (NN mini-batch) (JJ stochastic) (NN gradient) (NNS algorithms)) (PP (IN in) (NP (NN conjunction)))) (PP (IN with) (NP (NN noise) (VBG annealing)))))) (VP (VBZ is) (VP (VBN guaranteed) (S (VP (TO to) (VP (VB converge) (PP (IN to) (NP (NP (DT a) (JJ global) (ADJP (JJ optimum) (PP (IN in) (ADJP (JJ polynomial)))) (NN time)) (PP (IN with) (NP (JJ arbitrary) (NN initialization))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ implies) (SBAR (IN that) (S (NP (DT the) (NN noise)) (VP (VBZ enables) (NP (DT the) (NN algorithm) (S (VP (TO to) (ADVP (RB efficiently)) (VP (VB escape) (PP (IN from) (NP (DT the) (JJ spurious) (JJ local) (JJ optimum))))))))))) (. .))
(S (NP (NNP Numerical) (NNS experiments)) (VP (VBP are) (VP (VBN provided) (S (VP (TO to) (VP (VB support) (NP (PRP$ our) (NN theory))))))) (. .))
