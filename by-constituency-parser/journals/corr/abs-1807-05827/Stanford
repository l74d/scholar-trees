(S (NP (NN Experience) (NN replay) (PRN (-LRB- -LRB-) (NP (NN ER)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (DT a) (JJ fundamental) (NN component)) (PP (IN of) (NP (NML (RB off) (HYPH -) (NN policy)) (NML (JJ deep) (NN reinforcement)) (NN learning) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-)))))) (. .))
(S (NP (NN ER)) (VP (VBZ recalls) (NP (NNS experiences)) (PP (IN from) (NP (JJ past) (NNS iterations))) (PP (IN to) (S (S (VP (VB compute) (NP (NN gradient) (NNS estimates)) (PP (IN for) (NP (DT the) (JJ current) (NN policy))))) (, ,) (S (VP (VBG increasing) (NP (NN data) (HYPH -) (NN efficiency))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN accuracy)) (PP (IN of) (NP (JJ such) (NNS updates)))) (VP (MD may) (VP (VB deteriorate) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN policy)) (VP (VP (VBZ diverges) (PP (IN from) (NP (JJ past) (NNS behaviors)))) (CC and) (VP (MD can) (VP (VB undermine) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN ER))))))))))) (. .))
(S (NP (JJ Many) (NNS algorithms)) (VP (VB mitigate) (NP (DT this) (NN issue)) (PP (IN by) (S (VP (VBG tuning) (NP (ADJP (JJ hyper) (HYPH -)) (NNS parameters)) (S (VP (TO to) (VP (VB slow) (PRT (RP down)) (NP (NN policy) (NNS changes))))))))) (. .))
(S (NP (DT An) (NN alternative)) (VP (VBZ is) (S (VP (TO to) (ADVP (RB actively)) (VP (VB enforce) (NP (NP (NP (DT the) (NN similarity)) (PP (IN between) (NP (NN policy)))) (CC and) (NP (NP (DT the) (NNS experiences)) (PP (IN in) (NP (DT the) (NN replay) (NN memory))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (VP (VB Remember) (CC and) (VB Forget) (NP (NP (NML (NNP Experience) (NNP Replay)) (-LRB- -LRB-) (NML (NN ReF) (HYPH -) (NN ER)) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (JJ novel) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB enhance) (NP (NNP RL) (NNS algorithms)) (PP (IN with) (NP (JJ parameterized) (NNS policies))))))))))) (. .))
(S (NP (NN ReF) (HYPH -) (NN ER) (PRN (-LRB- -LRB-) (NP (CD 1)) (-RRB- -RRB-))) (VP (VBZ skips) (NP (NP (NNS gradients)) (VP (VBN computed) (PP (IN from) (NP (NP (NNS experiences)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP are) (ADJP (RB too) (JJ unlikely) (PP (IN with) (NP (DT the) (JJ current) (NN policy))))) (CC and) (VP (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (VBZ regulates) (NP (NP (NN policy) (NNS changes)) (PP (IN within) (NP (NP (DT a) (NN trust) (NN region)) (PP (IN of) (NP (DT the) (VBN replayed) (NNS behaviors))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP couple) (NP (NP (NN ReF) (HYPH -) (NN ER)) (PP (IN with) (NP (NML (NN Q) (HYPH -) (NN learning)) (, ,) (NML (UCP (NP (JJ deterministic) (NN policy) (NN gradient)) (CC and) (ADVP (IN off))) (HYPH -) (NN policy)) (NN gradient) (NNS methods))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NN ReF) (HYPH -) (NN ER)) (ADVP (RB consistently)) (VP (VBZ improves) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NML (JJ continuous) (HYPH -) (NN action)) (, ,) (ADJP (IN off) (HYPH -) (NN policy)) (NN RL)))) (PP (IN on) (NP (NP (ADJP (RB fully) (JJ observable)) (NNS benchmarks)) (CC and) (NP (ADJP (RB partially) (JJ observable)) (NML (NN flow) (NN control)) (NNS problems)))))))) (. .))
