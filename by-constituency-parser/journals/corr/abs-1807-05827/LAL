(S (NP (NP (NN Experience) (NN replay)) (PRN (-LRB- -LRB-) (NP (NNP ER)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (DT a) (JJ fundamental) (NN component)) (PP (IN of) (NP (NP (JJ off-policy) (JJ deep) (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)))))) (. .))
(S (NP (NNP ER)) (VP (VBZ recalls) (NP (NP (NNS experiences)) (PP (IN from) (NP (JJ past) (NNS iterations)))) (S (VP (TO to) (VP (VB compute) (NP (NP (NN gradient) (NNS estimates)) (PP (IN for) (NP (DT the) (JJ current) (NN policy)))) (, ,) (S (VP (VBG increasing) (NP (NN data-efficiency)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN accuracy)) (PP (IN of) (NP (JJ such) (NNS updates)))) (VP (VP (MD may) (VP (VB deteriorate) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN policy)) (VP (VBZ diverges) (PP (IN from) (NP (JJ past) (NNS behaviors)))))))) (CC and) (VP (MD can) (VP (VB undermine) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NNP ER))))))) (. .))
(S (NP (JJ Many) (RB algorithms)) (VP (VBP mitigate) (NP (DT this) (NN issue)) (PP (IN by) (S (VP (VBG tuning) (NP (NNS hyper-parameters)) (S (VP (TO to) (VP (VB slow) (PRT (RP down)) (NP (NN policy) (NNS changes))))))))) (. .))
(S (NP (DT An) (NN alternative)) (VP (VBZ is) (S (VP (TO to) (VP (ADVP (RB actively)) (VB enforce) (NP (NP (DT the) (NN similarity)) (PP (IN between) (NP (NP (NN policy)) (CC and) (NP (NP (DT the) (NNS experiences)) (PP (IN in) (NP (DT the) (NN replay) (NN memory))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (NP (NNP Remember) (CC and) (NNP Forget) (NNP Experience) (NNP Replay)) (PRN (-LRB- -LRB-) (NP (NNP ReF-ER)) (-RRB- -RRB-))) (, ,) (NP (NP (DT a) (JJ novel) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB enhance) (NP (NNP RL) (NN algorithms)) (PP (IN with) (NP (JJ parameterized) (NNS policies)))))))))) (. .))
(S (NP (NNP ReF-ER)) (VP (PRN (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (VP (NNS skips) (NP (NP (NNS gradients)) (VP (VBD computed) (PP (IN from) (NP (NP (NNS experiences)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RB too) (JJ unlikely)) (PP (IN with) (NP (DT the) (JJ current) (NN policy)))))))))))) (CC and) (VP (PRN (-LRB- -LRB-) (CD 2) (-RRB- -RRB-)) (VP (VBZ regulates) (NP (NN policy) (NNS changes)) (PP (IN within) (NP (NP (DT a) (JJ trust) (NN region)) (PP (IN of) (NP (DT the) (JJ replayed) (NNS behaviors))))))) (. .))
(S (NP (PRP We)) (VP (VBP couple) (NP (JJ ReF-ER)) (PP (IN with) (NP (NP (NNP Q-learning)) (, ,) (NP (JJ deterministic) (NN policy) (NN gradient) (CC and) (JJ off-policy) (NN gradient) (NNS methods))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NNP ReF-ER)) (VP (ADVP (RB consistently)) (VBZ improves) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN continuous-action) (, ,) (JJ off-policy) (NNP RL)))) (PP (IN on) (NP (NP (ADJP (RB fully) (JJ observable)) (NNS benchmarks)) (CC and) (NP (ADJP (RB partially) (JJ observable)) (NN flow) (NN control) (NNS problems)))))))) (. .))
