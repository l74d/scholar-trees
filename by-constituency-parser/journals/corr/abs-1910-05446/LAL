(S (S (VP (VBG Selecting) (NP (DT an) (NN optimizer)))) (VP (VBZ is) (NP (NP (DT a) (JJ central) (NN step)) (PP (IN in) (NP (DT the) (JJ contemporary) (JJ deep) (NN learning) (NN pipeline))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (NP (DT the) (NN sensitivity)) (PP (IN of) (NP (JJ optimizer) (NNS comparisons))) (PP (TO to) (NP (DT the) (NN hyperparameter) (VBG tuning) (NN protocol))))) (. .))
(S (NP (PRP$ Our) (NNS findings)) (VP (VBP suggest) (SBAR (IN that) (S (NP (DT the) (NN hyperparameter) (NN search) (NN space)) (VP (MD may) (VP (VB be) (NP (NP (DT the) (ADJP (JJ single) (RBS most) (JJ important)) (NN factor)) (VP (VBG explaining) (NP (NP (DT the) (NNS rankings)) (VP (VBN obtained) (PP (IN by) (NP (NP (JJ recent) (JJ empirical) (NNS comparisons)) (PP (IN in) (NP (DT the) (NN literature)))))))))))))) (. .))
(S (PP (IN In) (NP (NN fact))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT these) (NNS results)) (VP (MD can) (VP (VB be) (VP (VBN contradicted) (SBAR (WHADVP (WRB when)) (S (NP (NN hyperparameter) (NN search) (NNS spaces)) (VP (VBP are) (VP (VBN changed))))))))))) (. .))
(S (S (SBAR (IN As) (S (NP (VBG tuning) (NN effort)) (VP (NNS grows) (PP (IN without) (NP (NN bound)))))) (, ,) (NP (ADJP (JJR more) (JJ general)) (NNS optimizers)) (VP (VP (MD should) (ADVP (RB never)) (VP (VB underperform) (NP (NP (DT the) (NNS ones)) (SBAR (S (NP (PRP they)) (VP (MD can) (VP (VB approximate)))))))) (PRN (-LRB- -LRB-) (S (INTJ (FW i.e.)) (, ,) (NP (NNP Adam)) (VP (MD should) (ADVP (RB never)) (VP (VB perform) (ADVP (ADVP (JJR worse)) (PP (IN than) (NP (NN momentum))))))) (-RRB- -RRB-)))) (, ,) (CC but) (S (NP (JJ recent) (NNS attempts) (S (VP (TO to) (VP (VB compare) (NP (NNS optimizers)))))) (VP (CC either) (VP (VP (VB assume) (SBAR (S (NP (DT these) (NN inclusion) (NNS relationships)) (VP (VBP are) (RB not) (ADJP (RB practically) (JJ relevant)))))) (CC or) (VP (VB restrict) (NP (DT the) (NNS hyperparameters)) (PP (IN in) (NP (NP (NNS ways)) (SBAR (WHNP (WDT that)) (S (VP (VBP break) (NP (DT the) (NNS inclusions))))))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (DT that) (S (NP (NP (NN inclusion) (VBZ relationships)) (PP (IN between) (NP (NNS optimizers)))) (VP (VP (RBR matter) (PP (IN in) (NP (NN practice)))) (CC and) (VP (ADVP (RB always)) (VBP predict) (NP (JJ optimizer) (NNS comparisons))))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (DT the) (JJ popular) (JJ adaptive) (NN gradient) (NNS methods)) (ADVP (RB never)) (VP (VBP underperform) (NP (NP (NN momentum)) (CC or) (NP (JJ gradient) (NN descent))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP report) (NP (NP (JJ practical) (NNS tips)) (PP (IN around) (S (VP (VBG tuning) (NP (NP (ADJP (RB often) (VBN ignored)) (NNS hyperparameters)) (PP (IN of) (NP (JJ adaptive) (NN gradient) (NNS methods))))))))) (CC and) (VP (VB raise) (NP (NP (NNS concerns)) (PP (IN about) (S (VP (ADVP (RB fairly)) (VBG benchmarking) (NP (NNS optimizers)) (PP (IN for) (NP (JJ neural) (NN network) (NN training))))))))) (. .))
