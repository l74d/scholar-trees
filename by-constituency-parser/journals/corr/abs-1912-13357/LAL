(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ stochastic) (NN optimization) (NN method)) (PP (IN for) (S (VP (VBG minimizing) (NP (NP (NN loss) (NNS functions)) (, ,) (VP (VBD expressed) (PP (IN as) (NP (DT an) (JJ expected) (NN value)))) (, ,))))) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB adaptively)) (VBZ controls) (NP (NP (NP (DT the) (NN batch) (NN size)) (VP (VBN used) (PP (IN in) (NP (NP (DT the) (NN computation)) (PP (IN of) (NP (JJ gradient) (NNS approximations))))))) (CC and) (NP (NP (DT the) (NN step) (NN size)) (VP (VBN used) (S (VP (TO to) (VP (VB move) (PP (RB along) (NP (JJ such) (NNS directions))))))))) (, ,) (S (VP (VBG eliminating) (NP (DT the) (NN need) (SBAR (IN for) (S (NP (DT the) (NN user)) (VP (TO to) (VP (VB tune) (NP (DT the) (NN learning) (NN rate)))))))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN method)) (VP (VP (VP (VBZ exploits) (NP (JJ local) (NN curvature) (NN information))) (CC and) (VP (VBZ ensures) (SBAR (IN that) (S (NP (NN search) (NNS directions)) (VP (VBP are) (NP (NP (JJ descent) (NNS directions)) (PP (IN with) (NP (JJ high) (NN probability)))))))) (S (VP (VBG using) (NP (DT an) (JJ acute-angle) (NN test))))) (CC and) (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN as) (NP (NP (DT a) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (NP (NP (DT a) (JJ global) (JJ linear) (NN rate)) (PP (IN of) (NP (NN convergence))) (PP (IN on) (NP (NP (JJ self-concordant) (NNS functions)) (PP (IN with) (NP (JJ high) (NN probability))))))))))))))) (. .))
(S (NP (JJ Numerical) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this) (NN method)) (VP (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB choose) (NP (DT the) (JJS best) (NN learning) (NNS rates))))))) (CC and) (VP (VBZ compares) (ADVP (RB favorably)) (PP (TO to) (NP (JJ fine-tuned) (NNP SGD))) (PP (IN for) (S (VP (VBG training) (NP (NP (JJ logistic) (NN regression)) (CC and) (NP (NNP DNNs))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP propose) (NP (NP (DT an) (JJ adaptive) (NN version)) (PP (IN of) (NP (NNP ADAM))) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ eliminates) (NP (DT the) (NN need) (S (VP (TO to) (VP (VB tune) (NP (DT the) (NN base) (NN learning) (NN rate))))))) (CC and) (VP (VBZ compares) (ADVP (RB favorably)) (PP (TO to) (NP (NP (JJ fine-tuned) (NNP ADAM)) (PP (IN on) (NP (VBG training) (NNP DNNs))))))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (NNP DNN) (NNS experiments))) (, ,) (NP (PRP we)) (VP (ADVP (RB rarely)) (VBD encountered) (NP (JJ negative) (NN curvature)) (PP (IN at) (NP (NP (DT the) (JJ current) (NN point)) (PP (IN along) (NP (NP (DT the) (NN step) (NN direction)) (PP (IN in) (NP (NNP DNNs)))))))) (. .))
