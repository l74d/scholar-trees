(S (NP (PRP$ Our) (NN community)) (VP (VBZ has) (VP (ADVP (RB greatly)) (VBN improved) (NP (NP (DT the) (NN efficiency)) (PP (IN of) (NP (JJ deep) (NN learning) (NNS applications)))) (, ,) (PP (VBG including) (PP (IN by) (S (VP (VBG exploiting) (NP (NP (NN sparsity)) (PP (IN in) (NP (NNS inputs)))))))))) (. .))
(S (NP (NP (JJS Most)) (PP (IN of) (NP (DT that) (NN work)))) (, ,) (ADVP (IN though)) (, ,) (VP (VBZ is) (PP (PP (IN for) (NP (NP (NN inference)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NN weight) (NN sparsity)) (VP (VBZ is) (VP (VBN known) (ADVP (RB statically)))))))) (, ,) (NN and/or) (PP (IN for) (NP (JJ specialized) (NN hardware))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (NN scheme)) (SBAR (S (VP (TO to) (VP (VB leverage) (NP (JJ dynamic) (NN sparsity)) (PP (IN during) (NP (NN training))))))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (NP (PRP we)) (VP (VBP exploit) (NP (NP (NNS zeros)) (VP (VBN introduced) (PP (IN by) (NP (DT the) (NNP ReLU) (NN activation) (NN function))))) (PP (TO to) (NP (DT both) (NP (NN feature) (NNS maps)) (CC and) (NP (PRP$ their) (NNS gradients))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (ADJP (VBG challenging)) (SBAR (IN because) (S (S (NP (DT the) (NN sparsity) (NN degree)) (VP (VBZ is) (ADJP (JJ moderate)))) (CC and) (S (NP (NP (DT the) (NNS locations)) (PP (IN of) (NP (NNS zeros)))) (VP (VBP change) (PP (IN over) (NP (NN time)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP rely) (ADVP (RB purely)) (PP (IN on) (NP (NN software)))) (. .))
(S (NP (PRP We)) (VP (VP (VBP identify) (NP (NNS zeros)) (PP (IN in) (NP (DT a) (NN dense) (NN data) (NN representation))) (PP (IN without) (S (VP (VBG transforming) (NP (DT the) (NN data)))))) (CC and) (VP (NNS performs) (NP (JJ conventional) (JJ vectorized) (NN computation)))) (. .))
(S (NP (NP (NNS Variations)) (PP (IN of) (NP (DT the) (NN scheme)))) (VP (VBP are) (ADJP (JJ applicable) (PP (TO to) (NP (NP (NP (DT all) (JJ major) (NNS components)) (PP (IN of) (NP (NN training)))) (: :) (NP (NP (NN forward) (NN propagation)) (, ,) (NP (NP (JJ backward) (NN propagation)) (PP (IN by) (NP (NNS inputs)))) (, ,) (CC and) (NP (NP (JJ backward) (NN propagation)) (PP (IN by) (NP (NNS weights))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (ADVP (RB significantly)) (VBZ outperforms) (NP (NP (DT a) (JJ highly-optimized) (NN dense) (JJ direct) (NN convolution)) (PP (IN on) (NP (JJ several) (JJ popular) (JJ deep) (JJ neural) (NNS networks))))) (. .))
(S (PP (IN At) (NP (JJ realistic) (NN sparsity))) (, ,) (NP (PRP we)) (VP (VBP speed) (PRT (RP up)) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (NP (DT the) (JJ non-initial) (JJ convolutional) (NNS layers)) (PP (IN in) (NP (NP (NNP VGG16)) (, ,) (NP (NNP ResNet-34)) (, ,) (NP (NNP ResNet-50)) (, ,) (CC and) (NP (NNP Fixup) (NNP ResNet-50))))))) (PP (IN by) (NP (NP (NP (CD 2.19x)) (, ,) (NP (CD 1.37x)) (, ,) (NP (CD 1.31x)) (, ,) (CC and) (NP (CD 1.51x))) (ADVP (RB respectively)))) (PP (IN on) (NP (DT an) (NNP Intel) (NNP Skylake-X) (NNP CPU)))) (. .))
