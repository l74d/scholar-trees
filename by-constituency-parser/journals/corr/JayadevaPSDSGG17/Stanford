(S (NP (NP (JJ Modern) (JJ neural) (NN network) (NNS architectures)) (PP (IN for) (NP (NML (JJ large) (HYPH -) (NN scale)) (NN learning) (NNS tasks)))) (VP (VBP have) (NP (NP (ADJP (RB substantially) (JJR higher)) (NN model) (NNS complexities)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (NP (NN understanding)) (, ,) (S (VP (VP (VBG visualizing)) (CC and) (VP (VBG training) (S (NP (DT these) (NNS architectures)) (ADJP (JJ difficult))))))))))) (. .))
(S (NP (NP (JJ Recent) (NNS contributions)) (PP (IN to) (NP (NML (JJ deep) (NN learning)) (NNS techniques)))) (VP (VBP have) (VP (VBN focused) (PP (IN on) (NP (JJ architectural) (NNS modifications))) (S (VP (TO to) (VP (VB improve) (NP (NN parameter) (NN efficiency) (CC and) (NN performance))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP derive) (NP (NP (NP (NP (DT a) (ADJP (JJ continuous) (CC and) (JJ differentiable)) (NN error)) (ADJP (JJ functional) (PP (IN for) (NP (DT a) (JJ neural) (NN network))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ minimizes) (NP (PRP$ its) (JJ empirical) (NN error)))))) (CONJP (RB as) (RB well) (IN as)) (NP (NP (DT a) (NN measure)) (PP (IN of) (NP (DT the) (NN model) (NN complexity)))))) (. .))
(S (NP (DT The) (JJ latter) (NN measure)) (VP (VBZ is) (VP (VBN obtained) (PP (IN by) (S (VP (VBG deriving) (NP (NP (DT a) (JJ differentiable) (JJ upper) (ADJP (VBN bound) (PP (IN on) (NP (DT the) (NNP Vapnik) (HYPH -) (NNP Chervonenkis) (-LRB- -LRB-) (NNP VC) (-RRB- -RRB-)))) (NN dimension)) (PP (IN of) (NP (NP (DT the) (NN classifier) (NN layer)) (PP (IN of) (NP (NP (DT a) (NN class)) (PP (IN of) (NP (JJ deep) (NNS networks))))))))))))) (. .))
(S (S (VP (VBG Using) (NP (JJ standard) (NN backpropagation)))) (, ,) (NP (PRP we)) (VP (VBP realize) (NP (NP (DT a) (NN training) (NN rule)) (SBAR (WHNP (WDT that)) (S (VP (VBZ tries) (S (VP (TO to) (VP (VB minimize) (NP (DT the) (NN error)) (PP (IN on) (NP (NN training) (NNS samples))) (, ,) (PP (IN while) (S (VP (VBG improving) (NP (NN generalization)) (PP (IN by) (S (VP (VBG keeping) (S (NP (DT the) (NN model) (NN complexity)) (ADJP (JJ low))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NP (PRP$ our) (NN formulation)) (-LRB- -LRB-) (NP (NP (DT the) (JJ Low) (NN Complexity)) (NP (JJ Neural) (NML (NN Network) (HYPH -) (NN LCNN)))) (-RRB- -RRB-)))) (PP (IN across) (NP (NP (JJ several) (NML (JJ deep) (NN learning)) (NNS algorithms)) (, ,) (CC and) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (JJ large) (NN benchmark) (NNS datasets))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (JJ hidden) (NN layer) (NNS neurons)) (PP (IN in) (NP (DT the) (JJ resultant) (NNS networks)))) (VP (VBP learn) (NP (NP (NNS features)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP are) (ADJP (JJ crisp))) (, ,) (CC and) (VP (PP (IN in) (NP (NP (DT the) (NN case)) (PP (IN of) (NP (NN image) (NNS datasets))))) (, ,) (ADJP (ADVP (RB quantitatively)) (JJR sharper))))))))))) (. .))
(FRAG (FRAG (NP (NP (PRP$ Our) (VBN proposed) (NN approach) (NNS yields)) (NP (NP (NNS benefits)) (PP (IN across) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNS architectures))))) (, ,) (PP (IN in) (NP (NN comparison))))) (PP (IN to) (CC and) (IN in) (NP (NN conjunction))) (PP (IN with) (NP (NP (NNS methods)) (PP (JJ such) (IN as) (NP (NP (NN Dropout)) (CC and) (NP (NN Batch) (NN Normalization))))))) (, ,) (CC and) (S (NP (PRP$ our) (NNS results)) (ADVP (RB strongly)) (VP (VBP suggest) (SBAR (IN that) (S (NP (NML (JJ deep) (NN learning)) (NNS techniques)) (VP (MD can) (VP (VB benefit) (PP (IN from) (NP (NP (NN model) (NN complexity) (NN control) (NNS methods)) (PP (JJ such) (IN as) (NP (DT the) (NML (NN LCNN) (NN learning)) (NN rule))))))))))) (. .))
