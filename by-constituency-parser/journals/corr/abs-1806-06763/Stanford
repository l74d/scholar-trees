(S (NP (NP (JJ Adaptive) (NN gradient) (NNS methods)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP adopt) (NP (JJ historical) (NN gradient) (NN information)) (PP (IN to) (S (ADVP (RB automatically)) (VP (VB adjust) (NP (DT the) (NN learning) (NN rate))))) (, ,) (PP (IN despite) (NP (NP (DT the) (JJ nice) (NN property)) (PP (IN of) (NP (JJ fast) (NN convergence)))))))) (, ,)) (VP (VBP have) (VP (VBN been) (VP (VBN observed) (S (VP (TO to) (VP (VB generalize) (NP (ADJP (ADJP (JJR worse) (PP (IN than) (NP (JJ stochastic) (NN gradient) (NN descent))) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))) (PP (IN with) (NP (NP (NN momentum)) (PP (IN in) (NP (NN training)))))) (JJ deep) (JJ neural) (NNS networks)))))))) (. .))
(S (NP (DT This)) (VP (VBZ leaves) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB close) (NP (NP (DT the) (NN generalization) (NN gap)) (PP (IN of) (NP (NP (JJ adaptive) (NN gradient) (NNS methods)) (NP (DT an) (JJ open) (NN problem)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (JJ adaptive) (NN gradient) (NNS methods)) (PP (JJ such) (IN as) (NP (NNP Adam) (, ,) (NNP Amsgrad) (, ,)))) (VP (VBP are) (ADVP (RB sometimes)) (NP (`` ") (NP (IN over)) (SBAR (S (VP (VBN adapted)))) ('' ")))))) (. .))
(FRAG (S (NP (PRP We)) (VP (VBP design) (NP (NP (DT a) (JJ new) (NN algorithm)) (, ,) (VP (VBN called) (ADVP (RB Partially)) (NP (NP (JJ adaptive) (NN momentum) (NN estimation) (NN method)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ unifies) (NP (NP (DT the) (NNP Adam) (HYPH /) (NNP Amsgrad)) (PP (IN with) (NP (NNP SGD)))) (PP (IN by) (S (VP (VBG introducing) (NP (DT a) (JJ partial) (JJ adaptive) (NN parameter))))))))))))) (FRAG (NP ($ $)) (FRAG (NP (NN p)) (FRAG (NP ($ $)) (, ,) (S (VP (TO to) (VP (VB achieve) (NP (DT the) (JJS best)) (PP (IN from) (NP (DT both) (NNS worlds))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP prove) (NP (NP (DT the) (NN convergence) (NN rate)) (PP (IN of) (NP (NP (PRP$ our) (VBN proposed) (NN algorithm)) (PP (IN to) (NP (NP (DT a) (JJ stationary) (NN point)) (PP (IN in) (NP (DT the) (JJ stochastic) (NML (NN nonconvex) (NN optimization)) (NN setting))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (JJ standard) (NNS benchmarks)))) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (VBN proposed) (NN algorithm)) (VP (MD can) (VP (VB maintain) (NP (DT a) (JJ fast) (NN convergence) (NN rate)) (PP (IN as) (NP (NNP Adam) (HYPH /) (NNP Amsgrad))) (PP (IN while) (S (VP (VBG generalizing)))) (NAC (CONJP (RB as) (RB well) (IN as)) (NP (NP (NNP SGD)) (PP (IN in) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks)))))))))))) (. .))
(S (NP (DT These) (NNS results)) (VP (MD would) (VP (VB suggest) (S (NP (NNS practitioners)) (VP (VB pick) (PRT (RP up)) (NP (JJ adaptive) (NN gradient) (NNS methods)) (PP (ADVP (RB once) (RB again)) (IN for) (NP (NP (JJR faster) (NN training)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks))))))))) (. .))
