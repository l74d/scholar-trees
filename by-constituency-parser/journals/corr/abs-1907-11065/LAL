(S (NP (NNS Variants) (VBP dropout) (NNS methods)) (VP (VBP have) (VP (VBN been) (VP (VP (VBN designed) (PP (IN for) (NP (NP (DT the) (NX (NX (JJ fully-connected) (NN layer)) (, ,) (NX (JJ convolutional) (NN layer)) (CC and) (NX (NN recurrent) (NN layer)))) (PP (IN in) (NP (JJ neural) (NNS networks)))))) (, ,) (CC and) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (JJ effective) (S (VP (TO to) (VP (VB avoid) (NP (NN overfitting))))))))))))) (. .))
(S (PP (IN As) (NP (NP (DT an) (VBG appealing) (NN alternative)) (PP (TO to) (NP (VB recurrent) (CC and) (JJ convolutional) (NNS layers))))) (, ,) (NP (DT the) (JJ fully-connected) (NN self-attention) (NN layer)) (VP (ADVP (RB surprisingly)) (VBZ lacks) (NP (DT a) (NN specific) (NN dropout) (NN method))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ explores) (NP (NP (DT the) (NN possibility)) (PP (IN of) (S (VP (VBG regularizing) (NP (NP (DT the) (NN attention) (NNS weights)) (PP (IN in) (NP (NNP Transformers)))) (S (VP (TO to) (VP (VB prevent) (NP (JJ different) (JJ contextualized) (NN feature) (NNS vectors)) (PP (IN from) (NP (NN co-adaption))))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNS tasks)))))) (VP (VBP show) (SBAR (IN that) (S (NP (NNP DropAttention)) (VP (MD can) (VP (VP (VB improve) (NP (NN performance))) (CC and) (VP (VB reduce) (NP (NN overfitting)))))))) (. .))
