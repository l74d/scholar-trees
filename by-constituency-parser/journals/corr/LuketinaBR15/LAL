(S (NP (NNP Hyperparameter) (NN selection)) (ADVP (RB generally)) (VP (VBZ relies) (PP (IN on) (S (VP (VBG running) (NP (JJ multiple) (JJ full) (NN training) (NNS trials)) (, ,) (SBAR (IN with) (S (NP (NN selection)) (VP (VBN based) (PP (IN on) (NP (NN validation) (VBN set) (NN performance)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ gradient-based) (NN approach)) (PP (IN for) (S (VP (ADVP (RB locally)) (VBG adjusting) (NP (NNS hyperparameters)) (PP (IN during) (NP (NP (NN training)) (PP (IN of) (NP (DT the) (NN model)))))))))) (. .))
(S (NP (NNS Hyperparameters)) (VP (VBP are) (VP (VBN adjusted) (SBAR (RB so) (IN as) (S (VP (TO to) (VP (VB make) (S (NP (NP (DT the) (NN model) (NN parameter) (NNS gradients)) (, ,) (CC and) (ADVP (RB hence)) (NP (NNS updates)) (, ,)) (ADJP (RBR more) (JJ advantageous) (PP (IN for) (NP (DT the) (NN validation) (NN cost))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP explore) (NP (NP (DT the) (NN approach)) (PP (IN for) (S (VP (VBG tuning) (NP (NN regularization) (NNS hyperparameters))))))) (CC and) (VP (VB find) (SBAR (DT that) (S (PP (IN in) (NP (NP (NNS experiments)) (PP (IN on) (NP (NNP MNIST) (, ,) (NNP SVHN) (CC and) (NNP CIFAR-10))))) (, ,) (NP (DT the) (VBG resulting) (NN regularization) (NNS levels)) (VP (VBP are) (PP (IN within) (NP (DT the) (JJ optimal) (NNS regions)))))))) (. .))
(S (S (NP (DT The) (JJ additional) (NN computational) (NN cost)) (VP (VBZ depends) (PP (IN on) (SBAR (WHADVP (WRB how) (RB frequently)) (S (NP (DT the) (NNS hyperparameters)) (VP (VBP are) (VP (VBN trained)))))))) (, ,) (CC but) (S (NP (DT the) (JJ tested) (NN scheme)) (VP (VBZ adds) (NP (ADJP (QP (RB only) (CD 30)) (NN %)) (JJ computational) (JJ overhead)) (ADVP (NN regardless) (PP (IN of) (NP (DT the) (NN model) (NN size)))))) (. .))
(S (SBAR (IN Since) (S (NP (DT the) (NN method)) (VP (VP (VBZ is) (ADJP (ADJP (ADVP (RB significantly) (RBR less)) (RB computationally) (VBG demanding)) (PP (VBN compared) (PP (TO to) (NP (NP (JJ similar) (JJ gradient-based) (NNS approaches)) (PP (TO to) (NP (VB hyperparameter) (NN optimization)))))))) (, ,) (CC and) (VP (ADVP (RB consistently)) (VBZ finds) (NP (JJ good) (NN hyperparameter) (NNS values)))))) (, ,) (NP (PRP it)) (VP (MD can) (VP (VB be) (NP (NP (DT a) (JJ useful) (NN tool)) (PP (IN for) (S (VP (VBG training) (NP (JJ neural) (NN network) (NNS models)))))))) (. .))
