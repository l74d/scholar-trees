(S (PP (IN In) (NP (JJ many) (NNS environments))) (NP (NP (RB only) (DT a) (JJ tiny) (NN subset)) (PP (IN of) (NP (DT all) (NNS states)))) (VP (VBP yield) (NP (JJ high) (NN reward))) (. .))
(S (PP (IN In) (NP (DT these) (NNS cases))) (, ,) (NP (NP (JJ few)) (PP (IN of) (NP (NP (DT the) (NNS interactions)) (PP (IN with) (NP (DT the) (NN environment)))))) (VP (VB provide) (NP (DT a) (JJ relevant) (NN learning) (NN signal))) (. .))
(S (ADVP (RB Hence)) (, ,) (NP (PRP we)) (VP (MD may) (VP (VB want) (S (VP (TO to) (ADVP (RB preferentially)) (VP (VB train) (PP (IN on) (NP (NP (DT those) (NML (JJ high) (HYPH -) (NN reward)) (NNS states)) (CC and) (NP (NP (DT the) (JJ probable) (NNS trajectories)) (VP (VBG leading) (PP (IN to) (NP (PRP them)))))))))))) (. .))
(S (PP (IN To) (NP (DT this) (NN end))) (, ,) (NP (PRP we)) (VP (VBP advocate) (PP (IN for) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (DT a) (NN backtracking) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (VBZ predicts) (NP (NP (DT the) (VBG preceding) (NNS states)) (SBAR (WHNP (WDT that)) (S (VP (VBP terminate) (PP (IN at) (NP (DT a) (VBN given) (NML (JJ high) (HYPH -) (NN reward)) (NN state))))))))))))))) (. .))
(S (NP (PRP We)) (VP (MD can) (VP (VB train) (NP (NP (NP (DT a) (NN model)) (SBAR (WHNP (WDT which)) (, ,) (S (PP (VBG starting) (PP (IN from) (NP (NP (DT a) (JJ high) (NN value) (NN state)) (-LRB- -LRB-) (CC or) (NP (NP (CD one)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBN estimated) (S (VP (TO to) (VP (VB have) (NP (JJ high) (NN value)))))))))) (-RRB- -RRB-)))) (, ,) (VP (VBZ predicts))))) (CC and) (NP (NP (NN sample)) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (DT the) (NP (NP (-LRB- -LRB-) (NP (NN state)) (, ,) (NP (NN action)) (-RRB- -RRB-)) (HYPH -) (NP (NNS tuples)))) (VP (MD may) (VP (VB have) (VP (VBN led) (PP (IN to) (NP (DT that) (JJ high) (NN value) (NN state)))))))))))) (. .))
(S (S (NP (NP (NP (DT These) (NNS traces)) (PP (IN of) (NP (-LRB- -LRB-) (NML (NN state) (, ,) (NN action)) (-RRB- -RRB-) (NNS pairs)))) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP refer) (PP (IN to) (SBAR (IN as) (S (NP (NNP Recall)) (VP (VP (VBZ Traces)) (, ,) (VP (VBN sampled) (PP (IN from) (NP (DT this) (NN backtracking) (NN model)))) (S (VP (VBG starting) (PP (IN from) (NP (DT a) (JJ high) (NN value) (NN state)))))))))))) (, ,)) (VP (VBP are) (ADJP (JJ informative) (SBAR (IN as) (S (NP (PRP they)) (VP (VBP terminate) (PP (IN in) (NP (JJ good) (NNS states))))))))) (, ,) (CC and) (S (ADVP (RB hence)) (NP (PRP we)) (VP (MD can) (VP (VB use) (NP (DT these) (NNS traces)) (S (VP (TO to) (VP (VB improve) (NP (DT a) (NN policy)))))))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (DT a) (JJ variational) (NN interpretation)) (PP (IN for) (NP (NP (DT this) (NN idea)) (CC and) (NP (NP (DT a) (JJ practical) (NN algorithm)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (DT the) (NN backtracking) (NN model) (NNS samples)) (PP (IN from) (NP (NP (DT an) (JJ approximate) (JJ posterior) (NN distribution)) (PP (IN over) (NP (NP (NNS trajectories)) (SBAR (WHNP (WDT which)))))))) (VP (VBP lead) (PP (IN to) (NP (JJ large) (NNS rewards)))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ improves) (NP (NP (DT the) (NN sample) (NN efficiency)) (PP (IN of) (NP (DT both)))) (PP (IN on) (HYPH -) (NP (NP (CC and) (NP (NML (RB off) (HYPH -) (NN policy)) (NN RL) (NNS algorithms))) (PP (IN across) (NP (JJ several) (NNS environments) (CC and) (NNS tasks)))))) (. .))
