(S (PP (IN In) (NP (JJ many) (NNS environments))) (NP (NP (RB only) (DT a) (JJ tiny) (NN subset)) (PP (IN of) (NP (DT all) (NNS states)))) (VP (VBP yield) (NP (JJ high) (NN reward))) (. .))
(S (PP (IN In) (NP (DT these) (NNS cases))) (, ,) (NP (NP (JJ few)) (PP (IN of) (NP (NP (DT the) (NNS interactions)) (PP (IN with) (NP (DT the) (NN environment)))))) (VP (VBP provide) (NP (DT a) (JJ relevant) (JJ learning) (NN signal))) (. .))
(S (ADVP (RB Hence)) (, ,) (NP (PRP we)) (VP (MD may) (VP (VB want) (S (VP (TO to) (VP (ADVP (RB preferentially)) (VB train) (PP (IN on) (NP (NP (DT those) (JJ high-reward) (NNS states)) (CC and) (NP (NP (DT the) (JJ probable) (NNS trajectories)) (VP (VBG leading) (PP (TO to) (NP (PRP them)))))))))))) (. .))
(S (PP (TO To) (NP (DT this) (NN end))) (, ,) (NP (PRP we)) (VP (VBP advocate) (PP (IN for) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (DT a) (NN backtracking) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (VBZ predicts) (NP (NP (DT the) (VBG preceding) (NNS states)) (SBAR (WHNP (IN that)) (S (VP (VBP terminate) (PP (IN at) (NP (DT a) (VBN given) (NN high-reward) (NN state))))))))))))))) (. .))
(S (NP (PRP We)) (VP (MD can) (VP (VB train) (NP (NP (DT a) (NN model)) (SBAR (WHNP (WDT which)) (, ,) (S (S (VP (VBG starting) (PP (IN from) (NP (NP (DT a) (JJ high) (NN value) (NN state)) (PRN (-LRB- -LRB-) (CC or) (NP (NP (CD one)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBN estimated) (S (VP (TO to) (VP (VB have) (NP (JJ high) (NN value)))))))))) (-RRB- -RRB-)))))) (, ,) (VP (NNS predicts) (CC and) (NN sample) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (DT the) (PRN (-LRB- -LRB-) (NN state) (, ,) (NN action) (-RRB- -RRB-)) (NNS -tuples)) (VP (MD may) (VP (VB have) (VP (VBN led) (PP (TO to) (NP (DT that) (JJ high) (NN value) (NN state)))))))))))))) (. .))
(S (S (NP (NP (DT These) (NNS traces)) (PP (IN of) (NP (PRN (-LRB- -LRB-) (NN state) (, ,) (NN action) (-RRB- -RRB-)) (NN pairs))) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP refer) (PP (TO to)) (PP (IN as) (NP (NNP Recall) (NNP Traces)))))) (, ,) (VP (VBD sampled) (PP (IN from) (NP (DT this) (VBG backtracking) (NN model))) (S (VP (VBG starting) (PP (IN from) (NP (DT a) (JJ high) (NN value) (NN state)))))) (, ,)) (VP (VBP are) (ADJP (JJ informative)) (SBAR (IN as) (S (NP (PRP they)) (VP (VBP terminate) (PP (IN in) (NP (JJ good) (NNS states)))))))) (, ,) (CC and) (S (ADVP (RB hence)) (NP (PRP we)) (VP (MD can) (VP (VB use) (NP (DT these) (NNS traces)) (S (VP (TO to) (VP (VB improve) (NP (DT a) (NN policy)))))))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (NP (NP (DT a) (JJ variational) (NN interpretation)) (PP (IN for) (NP (DT this) (NN idea)))) (CC and) (NP (NP (DT a) (JJ practical) (NN algorithm)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT the) (NN backtracking) (NN model)) (VP (NNS samples) (PP (IN from) (NP (NP (DT an) (JJ approximate) (JJ posterior) (NN distribution)) (PP (IN over) (NP (NP (NNS trajectories)) (SBAR (WHNP (WDT which)) (S (VP (VBP lead) (PP (TO to) (NP (JJ large) (NNS rewards)))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ improves) (NP (NP (DT the) (JJ sample) (NN efficiency)) (PP (IN of) (NP (UCP (DT both) (JJ on-) (CC and) (JJ off-policy)) (NNP RL) (NN algorithms)))) (PP (IN across) (NP (JJ several) (NNS environments) (CC and) (NNS tasks)))) (. .))
