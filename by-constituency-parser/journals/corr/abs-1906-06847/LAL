(S (NP (NP (JJ Recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))) (VP (VBP have) (ADVP (RB recently)) (VP (VBN achieved) (NP (JJ remarkable) (NNS successes)) (PP (IN in) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (NNS applications))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NX (NX (JJ huge) (NN sizes)) (CC and) (NX (JJ computational) (NN burden)))) (PP (IN of) (NP (DT these) (NNS models)))) (VP (VBP make) (S (NP (NP (PRP it))) (ADJP (JJ difficult)) (PP (IN for) (NP (NP (PRP$ their) (NN deployment)) (PP (IN on) (NP (NN edge) (NNS devices))))))) (. .))
(S (NP (DT A) (ADJP (RB practically) (JJ effective)) (NN approach)) (VP (VBZ is) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (JJ overall) (NN storage) (CC and) (NN computation) (NNS costs)) (PP (IN of) (NP (NNP RNNs)))) (PP (IN by) (NP (NN network) (VBG pruning) (NNS techniques))))))) (. .))
(S (PP (IN Despite) (NP (PRP$ their) (JJ successful) (NNS applications))) (, ,) (NP (NP (DT those) (VBG pruning) (NNS methods)) (VP (VBN based) (PP (IN on) (NP (NNP Lasso))))) (ADVP (CC either)) (VP (VB produce) (NP (NP (NP (JJ irregular) (NN sparse) (NNS patterns)) (PP (IN in) (NP (NN weight) (NNS matrices)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (RB not) (ADJP (JJ helpful) (PP (IN in) (NP (JJ practical) (NN speedup))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS issues))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ structured) (NN pruning) (NN method)) (PP (IN through) (NP (NN neuron) (NN selection))) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB reduce) (NP (NP (DT the) (NN sizes)) (PP (IN of) (NP (NP (JJ basic) (NNS structures)) (PP (IN of) (NP (NNP RNNs)))))))))))) (. .))
(S (ADVP (RBR More) (RB specifically)) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (CD two) (NNS sets)) (PP (IN of) (NP (JJ binary) (NN random) (NNS variables))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN interpreted) (PP (IN as) (NP (NP (NNS gates) (CC or) (NNS switches)) (PP (TO to) (NP (NP (NP (DT the) (NN input) (NNS neurons)) (CC and) (NP (DT the) (JJ hidden) (NNS neurons))) (, ,) (ADVP (RB respectively))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (JJ corresponding) (NN optimization) (NN problem)) (VP (MD can) (VP (VB be) (VP (VBN addressed) (PP (IN by) (S (VP (VBG minimizing) (NP (NP (DT the) (NNP L0) (NN norm)) (PP (IN of) (NP (DT the) (NN weight) (NN matrix))))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (NP (JJ experimental) (NNS results)) (PP (IN on) (NP (NN language) (NN modeling) (CC and) (NN machine) (NN reading) (NN comprehension) (NNS tasks)))) (VP (VBP have) (VP (VBN indicated) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (NP (DT the) (VBN proposed) (NN method))) (PP (IN in) (NP (NP (NN comparison)) (PP (IN with) (NP (JJ state-of-the-art) (NN pruning) (NNS competitors)))))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (NP (NP (QP (RB nearly) (CD 20) (JJ x)) (JJ practical) (NN speedup)) (PP (IN during) (NP (NN inference)))) (VP (VBD was) (VP (VBN achieved) (PP (IN without) (S (VP (VBG losing) (NP (NP (NN performance)) (PP (IN for) (NP (NN language) (NN model))) (PP (IN on) (NP (DT the) (NNP Penn) (NNP TreeBank) (NN dataset))))))) (, ,) (S (VP (VBG indicating) (NP (NP (DT the) (JJ promising) (NN performance)) (PP (IN of) (NP (DT the) (VBN proposed) (NN method)))))))))
