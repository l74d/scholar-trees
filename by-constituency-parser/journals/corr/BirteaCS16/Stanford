(S (NP (PRP We)) (VP (VBP propose) (SBAR (S (NP (NP (DT a) (JJ new) (NN training) (NN method)) (PP (IN for) (NP (NP (DT a) (JJ feedforward) (JJ neural) (NN network)) (VP (VBG having) (NP (DT the) (NN activation)))))) (VP (VBZ functions) (PP (IN with) (NP (DT the) (JJ geometric) (NN contraction) (NN property))))))) (. .))
(S (NP (DT The) (NN method)) (VP (VBZ consists) (PP (IN of) (S (VP (VBG constructing) (NP (DT a) (JJ new) (JJ functional)) (SBAR (IN that) (S (VP (VBZ is) (NP (NP (JJR less) (JJ nonlinear)) (PP (IN in) (NP (NP (NN comparison)) (PP (IN with) (NP (DT the) (JJ classical) (ADJP (JJ functional) (PP (IN by) (S (VP (VBG removing) (NP (NP (DT the) (NN nonlinearity)) (PP (IN of) (NP (DT the) (NN activation) (NN function)))) (PP (IN from) (NP (DT the) (NN output))))))) (NN layer))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP validate) (NP (DT this) (JJ new) (NN method)) (PP (IN by) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (NP (NNS experiments)) (SBAR (WHNP (WDT that)) (S (VP (VBP show) (NP (DT an) (JJ improved) (NML (NML (NN learning) (NN speed)) (CC and) (NML (JJR better) (NN classification))) (NN error)))))))))) (. .))
