(S (NP (NN Experience) (NN replay)) (VP (VBZ enables) (S (VP (NN reinforcement) (VBG learning) (NP (NNS agents) (S (VP (TO to) (VP (VB memorize) (CC and) (VB reuse) (NP (NP (JJ past) (NNS experiences)) (, ,) (CONJP (RB just) (IN as)) (NP (NP (NNS humans)) (NP (NN replay) (NNS memories)))) (PP (IN for) (NP (NP (DT the) (NN situation)) (PP (IN at) (NP (NN hand)))))))))))) (. .))
(UCP (NP (NP (JJ Contemporary) (ADJP (IN off) (HYPH -) (NN policy)) (NNS algorithms)) (PP (CC either) (NP (NN replay))) (PP (IN past) (NP (NP (NNS experiences)) (ADVP (RB uniformly))))) (CC or) (SINV (VP (VB utilize) (NP (DT a) (ADJP (NN rule) (HYPH -) (VBN based)) (NN replay))) (NP (NP (NN strategy)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD may) (VP (VB be) (ADJP (JJ sub-optimal)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP consider) (S (VP (VBG learning) (NP (DT a) (NN replay) (NN policy)) (S (VP (TO to) (VP (VB optimize) (NP (DT the) (JJ cumulative) (NN reward)))))))) (. .))
(S (S (NP (NNP Replay) (NN learning)) (VP (VBZ is) (ADJP (JJ challenging)) (SBAR (IN because) (S (NP (DT the) (NN replay) (NN memory)) (VP (VBZ is) (ADJP (JJ noisy) (CC and) (JJ large))))))) (, ,) (CC and) (S (NP (DT the) (JJ cumulative) (NN reward)) (VP (VBZ is) (ADJP (JJ unstable)))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS issues))))) (, ,) (NP (PRP we)) (VP (VP (VBP propose) (NP (DT a) (JJ novel) (NN experience) (NN replay) (NN optimization) (-LRB- -LRB-) (NN ERO) (-RRB- -RRB-) (NN framework)) (SBAR (WHNP (WDT which)) (S (ADVP (RB alternately)) (NP (NP (NNS updates)) (NP (CD two) (NNS policies)))))) (: :) (NP (NP (DT the) (NN agent) (NN policy)) (, ,) (CC and) (NP (DT the) (NN replay) (NN policy)))) (. .))
(S (NP (DT The) (NN agent)) (VP (VBZ is) (VP (VBN updated) (S (VP (TO to) (VP (VB maximize) (NP (DT the) (JJ cumulative) (NN reward)) (PP (VBN based) (PP (IN on) (NP (DT the) (VBN replayed) (NNS data))))))) (, ,) (SBAR (IN while) (S (NP (DT the) (NN replay) (NN policy)) (VP (VBZ is) (VP (VBN updated) (S (VP (TO to) (VP (VB provide) (NP (DT the) (NN agent)) (PP (IN with) (NP (DT the) (ADJP (RBS most) (JJ useful)) (NNS experiences)))))))))))) (. .))
(S (NP (NP (DT The) (NML (S (VP (VBN conducted)))) (NNS experiments)) (PP (IN on) (NP (JJ various) (JJ continuous) (NN control) (NNS tasks)))) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NNP ERO)))) (, ,) (S (ADVP (RB empirically)) (VP (VBG showing) (NP (NN promise)) (PP (IN in) (NP (NN experience) (NN replay) (NN learning))) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NML (RB off) (HYPH -) (NN policy)) (NN reinforcement)))) (S (VP (VBG learning) (NP (NNS algorithms)))))))))) (. .))
