(S (NP (NN Experience) (NN replay)) (VP (VBZ enables) (S (NP (JJ reinforcement) (VBG learning) (NNS agents)) (VP (TO to) (VP (VB memorize) (CC and) (VB reuse) (NP (JJ past) (NNS experiences)) (, ,) (SBAR (RB just) (IN as) (S (NP (NNS humans)) (VP (VBP replay) (NP (NP (NNS memories)) (PP (IN for) (NP (NP (DT the) (NN situation)) (PP (IN at) (NP (NN hand))))))))))))) (. .))
(S (NP (JJ Contemporary) (NN off-policy) (NN algorithms)) (VP (CC either) (VP (NN replay) (NP (NN past) (NNS experiences)) (ADVP (RB uniformly))) (CC or) (VP (VB utilize) (NP (NP (DT a) (JJ rule-based) (NN replay) (NN strategy)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD may) (VP (VB be) (ADJP (JJ sub-optimal))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP consider) (S (VP (VBG learning) (NP (DT a) (NN replay) (NN policy)) (S (VP (TO to) (VP (VB optimize) (NP (DT the) (JJ cumulative) (NN reward)))))))) (. .))
(S (NP (NNP Replay) (NN learning)) (VP (VBZ is) (ADJP (VBG challenging)) (SBAR (IN because) (S (S (NP (DT the) (NN replay) (NN memory)) (VP (VBZ is) (ADJP (JJ noisy) (CC and) (JJ large)))) (, ,) (CC and) (S (NP (DT the) (JJ cumulative) (NN reward)) (VP (VBZ is) (ADJP (JJ unstable))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS issues))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN experience) (NN replay) (NN optimization) (PRN (-LRB- -LRB-) (NNP ERO) (-RRB- -RRB-)) (NN framework)) (SBAR (WHNP (WDT which)) (S (VP (ADVP (RB alternately)) (VBZ updates) (NP (NP (CD two) (NNS policies)) (: :) (NP (NP (DT the) (NN agent) (NN policy)) (, ,) (CC and) (NP (DT the) (NN replay) (NN policy))))))))) (. .))
(S (NP (DT The) (NN agent)) (VP (VBZ is) (VP (VBN updated) (S (VP (TO to) (VP (VB maximize) (NP (NP (DT the) (JJ cumulative) (NN reward)) (VP (VBN based) (PP (IN on) (NP (DT the) (VBN replayed) (NNS data)))))))) (, ,) (SBAR (IN while) (S (NP (DT the) (NN replay) (NN policy)) (VP (VBZ is) (VP (VBN updated) (S (VP (TO to) (VP (VB provide) (NP (DT the) (NN agent)) (PP (IN with) (NP (DT the) (ADJP (RBS most) (JJ useful)) (NNS experiences)))))))))))) (. .))
(S (NP (NP (DT The) (JJ conducted) (NNS experiments)) (PP (IN on) (NP (JJ various) (JJ continuous) (NN control) (NNS tasks)))) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NNP ERO)))) (, ,) (S (VP (ADVP (RB empirically)) (VBG showing) (NP (NP (NN promise)) (PP (IN in) (NP (NP (NN experience) (NN replay) (VBG learning)) (SBAR (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ off-policy) (NN reinforcement) (VBG learning) (NNS algorithms)))))))))))))) (. .))
