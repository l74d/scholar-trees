(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (JJ novel) (NN training) (NN principle)) (PP (IN for) (NP (JJ probabilistic) (NNS models))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (NP (NP (DT an) (JJ alternative)) (PP (TO to) (NP (JJ maximum) (NN likelihood))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NNP Generative) (NNP Stochastic) (NNP Networks) (PRN (-LRB- -LRB-) (NP (NNP GSN)) (-RRB- -RRB-)) (NN framework)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (S (VP (VBG learning) (NP (NP (DT the) (NN transition) (NN operator)) (PP (IN of) (NP (NP (DT a) (NNP Markov) (NN chain)) (SBAR (WHNP (WP$ whose) (JJ stationary) (NN distribution)) (S (VP (VBZ estimates) (NP (DT the) (NN data) (NN distribution))))))))))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NN transition) (NN distribution)) (VP (VBZ is) (NP (NP (DT a) (JJ conditional) (NN distribution)) (VP (ADVP (RB generally)) (VBG involving) (NP (DT a) (JJ small) (NN move))))))) (, ,) (NP (PRP it)) (VP (VBZ has) (NP (JJR fewer) (JJ dominant) (NNS modes)) (, ,) (S (VP (VBG being) (ADJP (JJ unimodal)) (PP (IN in) (NP (NP (DT the) (NN limit)) (PP (IN of) (NP (JJ small) (NNS moves)))))))) (. .))
(S (ADVP (RB Thus)) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJR easier) (SBAR (S (VP (TO to) (VP (VB learn)))))) (, ,) (PP (ADVP (JJR more)) (IN like) (S (VP (VBG learning) (S (VP (TO to) (VP (VB perform) (NP (NP (JJ supervised) (NN function) (NN approximation)) (, ,) (PP (IN with) (NP (NP (NNS gradients)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN obtained) (PP (IN by) (NP (NN back-propagation)))))))))))))))))) (. .))
(S (NP (NP (DT The) (NN theorems)) (VP (VBD provided) (ADVP (RB here)))) (VP (VP (JJ generalize) (NP (NP (JJ recent) (NN work)) (PP (IN on) (NP (NP (DT the) (JJ probabilistic) (NN interpretation)) (PP (IN of) (S (VP (VBG denoising) (NP (NNS auto-encoders))))))))) (CC and) (VP (VB provide) (NP (NP (DT an) (JJ interesting) (NN justification)) (PP (IN for) (NP (NP (NN dependency) (NNS networks)) (CC and) (NP (VBN generalized) (NN pseudolikelihood))))) (PRN (-LRB- -LRB-) (PP (IN along) (PP (IN with) (S (VP (VBG defining) (NP (DT an) (JJ appropriate) (NN joint) (NN distribution) (CC and) (VBG sampling) (NN mechanism)) (, ,) (SBAR (WHADVP (RB even) (WRB when)) (S (NP (DT the) (NNS conditionals)) (VP (VBP are) (RB not) (ADJP (JJ consistent))))))))) (-RRB- -RRB-)))) (. .))
(S (NP (PRP We)) (VP (VBP study) (SBAR (WHADVP (WRB how)) (S (NP (NNP GSNs)) (VP (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN with) (NP (VBG missing) (NNS inputs)))))) (CC and) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (JJ sample) (NP (NP (NNS subsets)) (PP (IN of) (NP (NNS variables))))))) (PP (VBN given) (NP (DT the) (NN rest)))))))))) (. .))
(S (NP (JJ Successful) (NNS experiments)) (VP (VBP are) (VP (VBN conducted) (, ,) (S (VP (VBG validating) (NP (DT these) (JJ theoretical) (NNS results)))) (, ,) (PP (PP (IN on) (NP (CD two) (NN image) (NNS datasets))) (CC and) (PP (IN with) (NP (NP (DT a) (JJ particular) (NN architecture)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ mimics) (NP (DT the) (NNP Deep) (NNP Boltzmann) (NNP Machine) (NNP Gibbs) (NN sampler))) (CC but) (VP (VBZ allows) (S (NP (VBG training)) (VP (TO to) (VP (VB proceed) (PP (IN with) (NP (NN backprop))) (, ,) (PP (IN without) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NN layerwise) (NN pretraining))))))))))))))))) (. .))
