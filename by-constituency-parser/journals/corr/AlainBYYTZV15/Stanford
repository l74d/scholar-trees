(S (NP (PRP We)) (VP (VBP introduce) (NP (DT a) (JJ novel) (NN training) (NN principle)) (PP (IN for) (NP (NP (JJ probabilistic) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (NP (NP (DT an) (NN alternative)) (PP (IN to) (NP (JJ maximum) (NN likelihood)))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NML (NNP Generative) (NNP Stochastic) (NNP Networks) (-LRB- -LRB-) (NNP GSN) (-RRB- -RRB-)) (NN framework)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (S (VP (VBG learning) (NP (NP (NP (DT the) (NN transition) (NN operator)) (PP (IN of) (NP (DT a) (NNP Markov) (NN chain)))) (SBAR (WHNP (WP$ whose)) (S (NP (JJ stationary) (NN distribution)) (VP (VBZ estimates) (NP (DT the) (NNS data) (NN distribution))))))))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NN transition) (NN distribution)) (VP (VBZ is) (NP (NP (DT a) (JJ conditional) (NN distribution)) (VP (ADVP (RB generally)) (VBG involving) (NP (DT a) (JJ small) (NN move))))))) (, ,) (NP (PRP it)) (VP (VBZ has) (NP (NP (JJR fewer) (JJ dominant) (NNS modes)) (, ,) (VP (VBG being) (ADJP (JJ unimodal) (PP (IN in) (NP (NP (DT the) (NN limit)) (PP (IN of) (NP (JJ small) (NNS moves))))))))) (. .))
(S (ADVP (RB Thus)) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJR easier)) (S (VP (TO to) (VP (VB learn) (, ,) (PP (ADVP (RBR more)) (IN like) (S (VP (VBG learning) (S (VP (TO to) (VP (VB perform) (NP (JJ supervised) (NN function) (NN approximation)))))))) (, ,) (PP (IN with) (NP (NP (NNS gradients)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN obtained) (PP (IN by) (ADVP (RB back)) (NP (HYPH -) (NN propagation)))))))))))))) (. .))
(S (NP (NP (DT The) (NNS theorems)) (VP (VBN provided) (ADVP (RB here)))) (VP (VP (VB generalize) (NP (JJ recent) (NN work)) (PP (IN on) (NP (NP (DT the) (JJ probabilistic) (NN interpretation)) (PP (IN of) (NP (VBG denoising) (NN auto) (HYPH -) (NNS encoders)))))) (CC and) (VP (VB provide) (NP (NP (NP (DT an) (JJ interesting) (NN justification)) (PP (IN for) (NP (NN dependency) (NNS networks)))) (CC and) (NP (NP (VBN generalized) (NN pseudolikelihood)) (PP (-LRB- -LRB-) (IN along) (PP (IN with) (S (VP (VBG defining) (NP (NP (DT an) (JJ appropriate) (JJ joint) (NML (NN distribution) (CC and) (NN sampling)) (NN mechanism)) (, ,) (SBAR (WHADVP (RB even) (WRB when)) (S (NP (DT the) (NNS conditionals)) (VP (VBP are) (RB not) (ADJP (JJ consistent))))))))) (-RRB- -RRB-)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP study) (SBAR (WHADVP (WRB how)) (S (NP (NNS GSNs)) (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN with) (NP (VBG missing) (NNS inputs))))))))) (CC and) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB sample) (NP (NP (NNS subsets)) (PP (IN of) (NP (NP (NNS variables)) (VP (VBN given) (NP (DT the) (NN rest))))))))))))) (. .))
(S (NP (JJ Successful) (NNS experiments)) (VP (VBP are) (VP (VBN conducted) (, ,) (S (VP (VBG validating) (NP (DT these) (JJ theoretical) (NNS results)))) (, ,) (PP (PP (IN on) (NP (CD two) (NN image) (NNS datasets))) (CC and) (PP (IN with) (NP (NP (DT a) (JJ particular) (NN architecture)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ mimics) (NP (DT the) (JJ Deep) (NNP Boltzmann) (NNP Machine) (NNP Gibbs) (NN sampler))) (CC but) (VP (VBZ allows) (NP (NN training)) (S (VP (TO to) (VP (VB proceed) (PP (IN with) (NP (NN backprop))) (, ,) (PP (IN without) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NN layerwise) (NN pretraining))))))))))))))))) (. .))
