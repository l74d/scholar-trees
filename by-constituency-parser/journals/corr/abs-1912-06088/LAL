(S (NP (JJ Current) (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NNP RL) (-RRB- -RRB-)) (NN algorithms)) (VP (MD can) (VP (VB be) (ADJP (ADJP (JJ brittle)) (CC and) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB use))))))) (, ,) (SBAR (ADVP (RB especially)) (WRB when) (S (VP (VBG learning) (NP (JJ goal-reaching) (NNS behaviors)) (PP (IN from) (NP (JJ sparse) (NNS rewards)))))))) (. .))
(S (SBAR (IN Although) (S (NP (VBN supervised) (NN imitation) (VBG learning)) (VP (VBZ provides) (NP (DT a) (ADJP (JJ simple) (CC and) (JJ stable)) (NN alternative))))) (, ,) (NP (PRP it)) (VP (VBZ requires) (NP (NP (NN access)) (PP (TO to) (NP (NNS demonstrations))) (PP (IN from) (NP (DT a) (JJ human) (NN supervisor))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (NNP RL) (NN algorithms)) (PP (IN for) (S (VP (VBG learning) (NP (ADJP (NN goal) (VBG reaching)) (NNS policies))))) (SBAR (WHNP (WDT that)) (S (VP (VBP leverage) (NP (NP (DT the) (NN stability)) (PP (IN of) (NP (NN imitation) (VBG learning)))) (PP (IN without) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (JJ explicit) (JJ expert) (NNS demonstrations)))))))))) (. .))
(S (PP (IN In) (NP (NP (NN lieu)) (PP (IN of) (NP (JJ expert) (NNS demonstrations))))) (, ,) (NP (NN supervision)) (VP (MD can) (VP (VB be) (VP (VBN derived) (PP (IN by) (S (VP (VBG leveraging) (NP (DT the) (NN property) (SBAR (IN that) (S (NP (DT any) (NN trajectory)) (VP (VBZ is) (NP (NP (DT a) (JJ successful) (NN demonstration)) (PP (IN for) (S (VP (VBG reaching) (NP (DT the) (JJ final) (NN state)) (PP (IN in) (NP (DT that) (JJ same) (NN trajectory))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ simple) (NN algorithm)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT an) (NN agent)) (VP (ADVP (RB continually)) (NNS relabels) (CC and) (VBZ imitates) (NP (PRP$ its) (JJ own) (NN experience)) (S (VP (TO to) (VP (ADVP (RB progressively)) (VB learn) (NP (JJ goal-reaching) (NNS behaviors)))))))))) (. .))
(S (NP (DT Each) (NN iteration)) (, ,) (NP (DT the) (NN agent)) (VP (VP (VBZ collects) (NP (JJ new) (NNS trajectories)) (S (VP (VBG using) (NP (DT the) (JJS latest) (NN policy))))) (, ,) (CC and) (VP (VBZ maximizes) (NP (NP (DT the) (NN likelihood)) (PP (IN of) (NP (NP (DT the) (NNS actions)) (PP (IN along) (NP (DT these) (NNS trajectories))) (PP (IN under) (NP (NP (DT the) (NN goal)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (ADVP (RB actually)) (VP (VBN reached)))))))))) (, ,) (SBAR (RB so) (IN as) (S (VP (TO to) (VP (VB improve) (NP (DT the) (NN policy)))))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (RB formally)) (VBP link) (NP (PRP$ our) (JJ supervised) (VBG learning) (JJ objective)) (PP (TO to) (NP (DT the) (JJ true) (NNP RL) (NN objective)))) (, ,) (VP (JJ derive) (NP (NN performance) (NNS bounds))) (, ,) (CC and) (VP (VB demonstrate) (NP (NP (VBN improved) (NN performance)) (PP (IN over) (NP (JJ current) (NNP RL) (NN algorithms))) (PP (IN on) (NP (NN goal-reaching))) (PP (IN in) (NP (JJ several) (NN benchmark) (NNS tasks)))))) (. .))
