(S (NP (NP (DT The) (NML (NN storage) (CC and) (NN computation)) (NNS requirements)) (PP (IN of) (NP (NNP Convolutional) (JJ Neural) (NNS Networks) (PRN (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-))))) (VP (MD can) (VP (VB be) (ADJP (JJ prohibitive) (PP (IN for) (S (VP (VBG exploiting) (NP (NP (DT these) (NNS models)) (PP (IN over) (NP (UCP (NML (JJ low) (HYPH -) (NN power)) (CC or) (ADJP (VBN embedded))) (NNS devices)))))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ reduces) (NP (NP (DT the) (JJ computational) (NN complexity)) (PP (IN of) (NP (DT the) (NNS CNNs)))) (PP (IN by) (S (VP (VBG minimizing) (NP (DT an) (JJ objective) (NN function))))) (, ,) (PP (VBG including) (NP (NP (DT the) (NN recognition) (NN loss)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBN augmented) (PP (IN with) (NP (DT a) (ADJP (NN sparsity) (HYPH -) (VBG promoting)) (NN penalty) (NN term)))))))))) (. .))
(S (NP (NP (DT The) (NN sparsity) (NN structure)) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBZ is) (VP (VBN identified) (S (VP (VBG using) (NP (NP (DT the) (NNP Alternating) (NNP Direction) (NNP Method)) (PP (IN of) (NP (NP (NP (NNPS Multipliers)) (-LRB- -LRB-) (NP (NNP ADMM)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADVP (RB widely)) (VP (VBN used) (PP (IN in) (NP (JJ large) (NN optimization) (NNS problems)))))))))))))) (. .))
(S (NP (DT This) (NN method)) (VP (VBZ alternates) (PP (IN between) (S (VP (VP (VBG promoting) (NP (NP (DT the) (NN sparsity)) (PP (IN of) (NP (DT the) (NN network))))) (CC and) (VP (VBG optimizing) (NP (NP (DT the) (NN recognition) (NN performance)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB exploit) (NP (NP (DT the) (NML (CD two) (HYPH -) (NN part)) (NN structure)) (PP (IN of) (NP (DT the) (VBG corresponding) (JJ objective) (NNS functions)))))))))))))))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (NP (PRP we)) (VP (VBP take) (NP (NP (NN advantage)) (PP (IN of) (NP (NP (DT the) (NN separability)) (PP (IN of) (NP (ADJP (NP (DT the) (NN sparsity)) (HYPH -) (VBG inducing)) (NN penalty) (NNS functions)))))) (PP (IN to) (S (VP (VB decompose) (NP (DT the) (NN minimization) (NN problem)) (PP (IN into) (NP (NP (NNS sub-problems)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN solved) (ADVP (RB sequentially))))))))))))) (. .))
(S (S (VP (VBG Applying) (NP (PRP$ our) (NN method)) (PP (IN to) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNP CNN) (NNS models))))))) (, ,) (NP (PRP$ our) (JJ proposed) (NN method)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB simplify) (NP (DT the) (JJ original) (NN model)))))) (, ,) (S (VP (VBG generating) (NP (NNS models)) (PP (IN with) (NP (NP (JJR less) (NN computation)) (CC and) (NP (JJR fewer) (NNS parameters)))))) (, ,) (SBAR (IN while) (S (S (VP (VBG maintaining))) (CC and) (S (ADVP (RB often)) (VP (VBG improving) (NP (NN generalization) (NN performance))))))) (. .))
(S (NP (NP (NNS Accomplishments)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS models)))))) (ADVP (RB strongly)) (VP (VBP verify) (SBAR (IN that) (S (NP (PRP$ our) (ADJP (VBN proposed)) (ADJP (NP (NN ADMM)) (HYPH -) (VBN based)) (NN method)) (VP (MD can) (VP (VB be) (NP (NP (DT a) (ADJP (RB very) (JJ useful)) (NN tool)) (PP (IN for) (S (VP (VBG simplifying) (CC and) (VBG improving) (NP (JJ deep) (NNS CNNs))))))))))) (. .))
