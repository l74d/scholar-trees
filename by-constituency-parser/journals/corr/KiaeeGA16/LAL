(S (NP (NP (DT The) (NN storage) (CC and) (NN computation) (NNS requirements)) (PP (IN of) (NP (NP (NNP Convolutional) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP CNNs)) (-RRB- -RRB-))))) (VP (MD can) (VP (VB be) (ADJP (JJ prohibitive)) (PP (IN for) (S (VP (VBG exploiting) (NP (DT these) (NNS models)) (PP (IN over) (NP (ADJP (JJR low-power) (CC or) (VBN embedded)) (NNS devices)))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ reduces) (NP (NP (DT the) (JJ computational) (NN complexity)) (PP (IN of) (NP (DT the) (NNP CNNs)))) (PP (IN by) (S (VP (VBG minimizing) (NP (NP (DT an) (JJ objective) (NN function)) (, ,) (PP (VBG including) (NP (NP (DT the) (NN recognition) (NN loss)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBN augmented) (PP (IN with) (NP (DT a) (JJ sparsity-promoting) (NN penalty) (NN term)))))))))))))) (. .))
(S (NP (NP (DT The) (NN sparsity) (NN structure)) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBZ is) (VP (VBN identified) (S (VP (VBG using) (NP (NP (NP (DT the) (NNP Alternating) (NNP Direction) (NNP Method)) (PP (IN of) (NP (NNP Multipliers)))) (PRN (-LRB- -LRB-) (NP (NNP ADMM)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (ADVP (RB widely)) (VBN used) (PP (IN in) (NP (JJ large) (NN optimization) (NNS problems)))))))))))) (. .))
(S (NP (DT This) (NN method)) (VP (VBZ alternates) (PP (IN between) (S (VP (VP (VBG promoting) (NP (NP (DT the) (NN sparsity)) (PP (IN of) (NP (DT the) (NN network))))) (CC and) (VP (VBG optimizing) (NP (NP (DT the) (NN recognition) (NN performance)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB exploit) (NP (NP (DT the) (JJ two-part) (NN structure)) (PP (IN of) (NP (DT the) (JJ corresponding) (JJ objective) (NNS functions)))))))))))))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (NP (PRP we)) (VP (VBP take) (NP (NN advantage)) (PP (IN of) (NP (NP (DT the) (NN separability)) (PP (IN of) (NP (DT the) (JJ sparsity-inducing) (NN penalty) (NNS functions))))) (S (VP (TO to) (VP (VB decompose) (NP (DT the) (NN minimization) (NN problem)) (PP (IN into) (NP (NP (NNS sub-problems)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN solved) (ADVP (RB sequentially))))))))))))) (. .))
(S (S (VP (VBG Applying) (NP (PRP$ our) (NN method)) (PP (TO to) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (JJ state-of-the-art) (NNP CNN) (NNS models))))))) (, ,) (NP (PRP$ our) (VBN proposed) (NN method)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB simplify) (NP (DT the) (JJ original) (NN model)) (, ,) (S (VP (VBG generating) (NP (NP (NNS models)) (PP (IN with) (NP (NP (JJR less) (NN computation)) (CC and) (NP (JJR fewer) (NNS parameters))))))) (, ,) (SBAR (IN while) (S (VP (VP (VBG maintaining)) (CC and) (VP (ADVP (RB often)) (JJ improving)) (NP (NN generalization) (NN performance)))))))))) (. .))
(S (NP (NP (NNS Accomplishments)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS models)))))) (VP (ADVP (RB strongly)) (VBP verify) (SBAR (IN that) (S (NP (PRP$ our) (VBN proposed) (JJ ADMM-based) (NN method)) (VP (MD can) (VP (VB be) (NP (NP (DT a) (ADJP (RB very) (JJ useful)) (NN tool)) (PP (IN for) (S (VP (VBG simplifying) (CC and) (VBG improving) (NP (JJ deep) (NNP CNNs))))))))))) (. .))
