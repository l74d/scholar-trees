(S (NP (NP (DT The) (JJ stunning) (JJ empirical) (NNS successes)) (PP (IN of) (NP (JJ neural) (NNS networks)))) (ADVP (RB currently)) (VP (VBP lack) (NP (JJ rigorous) (JJ theoretical) (NN explanation))) (. .))
(SBARQ (WHNP (WP What) (NN form)) (SQ (MD would) (NP (VB such) (DT an) (NN explanation)) (VP (NN take) (, ,) (PP (IN in) (NP (NP (DT the) (NN face)) (PP (IN of) (NP (VBG existing) (JJ complexity-theoretic) (JJR lower) (NNS bounds))))))) (. ?))
(S (NP (DT A) (JJ first) (NN step)) (VP (MD might) (VP (VB be) (S (VP (TO to) (VP (VB show) (SBAR (IN that) (S (NP (NP (NNS data)) (VP (VBN generated) (PP (IN by) (NP (NP (JJ neural) (NNS networks)) (PP (IN with) (NP (NP (DT a) (JJ single) (NN hidden) (NN layer)) (, ,) (NP (JJ smooth) (NN activation) (NNS functions)) (CC and) (NP (JJ benign) (NN input) (NNS distributions)))))))) (VP (MD can) (VP (VB be) (VP (VBN learned) (ADVP (RB efficiently)))))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP demonstrate) (ADVP (RB here)) (NP (NP (DT a) (JJ comprehensive) (JJR lower) (NN bound)) (VP (VBG ruling) (PRT (RP out)) (NP (DT this) (NN possibility)))))) (: :) (S (S (PP (IN for) (NP (NP (NP (DT a) (JJ wide) (NN class)) (PP (IN of) (NP (NP (NN activation) (NNS functions)) (PRN (-LRB- -LRB-) (PP (VBG including) (NP (NP (DT all)) (VP (ADVP (RB currently)) (VBN used)))) (-RRB- -RRB-))))) (, ,) (CC and) (NP (NP (NNS inputs)) (VP (VBP drawn) (PP (IN from) (NP (DT any) (JJ logconcave) (NN distribution))))))) (, ,) (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (NN family)) (PP (IN of) (NP (NP (JJ one-hidden-layer) (NNS functions)) (SBAR (WHNP (WP$ whose) (NN output)) (S (VP (VBZ is) (NP (DT a) (JJ sum) (NN gate))))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ hard) (SBAR (S (VP (TO to) (VP (VB learn) (PP (IN in) (NP (DT a) (JJ precise) (NN sense)))))))))))))))) (: :) (S (NP (NP (DT any) (JJ statistical) (NN query) (NN algorithm)) (PRN (-LRB- -LRB-) (SBAR (WHNP (WDT which)) (S (VP (VBZ includes) (NP (NP (DT all) (JJ known) (NNS variants)) (PP (IN of) (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (PP (IN with) (NP (DT any) (NN loss) (NN function))))))))) (-RRB- -RRB-))) (VP (VBZ needs) (NP (NP (DT an) (JJ exponential) (NN number)) (PP (IN of) (NP (NNS queries)))) (S (VP (ADVP (RB even)) (VBG using) (NP (NP (NN tolerance)) (ADJP (RB inversely) (JJ proportional) (PP (TO to) (NP (DT the) (NN input) (NN dimensionality)))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NP (DT this) (JJ hard) (NN family)) (PP (IN of) (NP (NNS functions)))) (VP (VBZ is) (ADJP (JJ realizable)) (PP (IN with) (NP (NP (DT a) (JJ small) (PRN (-LRB- -LRB-) (ADJP (JJ sublinear) (PP (IN in) (NP (NN dimension)))) (-RRB- -RRB-)) (NN number)) (PP (IN of) (NP (NN activation) (NNS units))) (PP (IN in) (NP (DT the) (JJ single) (NN hidden) (NN layer)))))) (. .))
(S (NP (DT The) (JJR lower) (NN bound)) (VP (VBZ is) (ADVP (RB also)) (ADJP (JJ robust) (PP (TO to) (NP (NP (JJ small) (NNS perturbations)) (PP (IN of) (NP (DT the) (JJ true) (NNS weights))))))) (. .))
(S (NP (JJ Systematic) (NNS experiments)) (VP (VBP illustrate) (NP (NP (DT a) (NN phase) (NN transition)) (PP (IN in) (NP (DT the) (NN training) (NN error))) (SBAR (IN as) (S (VP (VBN predicted) (PP (IN by) (NP (DT the) (NN analysis)))))))) (. .))
