(S (NP (NP (NN Self-attention) (NN network)) (, ,) (NP (DT an) (JJ attention-based) (NN feedforward) (JJ neural) (NN network)) (, ,)) (VP (VBZ has) (ADVP (RB recently)) (VP (VBN shown) (NP (DT the) (JJ potential) (S (VP (TO to) (VP (VB replace) (NP (NP (JJ recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))) (PP (IN in) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNP NLP) (NNS tasks))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (PRP it))) (VP (VBZ is) (RB not) (ADJP (JJ clear)) (SBAR (IN if) (S (NP (DT the) (NN self-attention) (NN network)) (VP (MD could) (VP (VB be) (NP (NP (DT a) (JJ good) (NN alternative)) (PP (IN of) (NP (NP (NNP RNNs)) (PP (IN in) (NP (NP (NP (JJ automatic) (NN speech) (NN recognition)) (PRN (-LRB- -LRB-) (NP (NNP ASR)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ processes) (NP (DT the) (RBR longer) (JJ speech) (NNS sequences))) (CC and) (VP (MD may) (VP (VB have) (NP (NN online) (NN recognition) (NNS requirements))))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ RNN-free) (JJ end-to-end) (NN model)) (: :) (NP (NP (NN self-attention) (NN aligner)) (PRN (-LRB- -LRB-) (NP (NNP SAA)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ applies) (NP (DT the) (NN self-attention) (NNS networks)) (PP (TO to) (NP (DT a) (JJ simplified) (NN recurrent) (JJ neural) (NN aligner) (PRN (-LRB- -LRB-) (NNP RNA) (-RRB- -RRB-)) (NN framework))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP propose) (NP (NP (DT a) (JJ chunk-hopping) (NN mechanism)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ enables) (S (NP (DT the) (NNP SAA) (NN model)) (VP (TO to) (VP (VB encode) (PP (IN on) (NP (JJ segmented) (NN frame) (NNS chunks))) (NP (NP (CD one)) (PP (IN after) (NP (DT another)))) (S (VP (TO to) (VP (VB support) (NP (JJ online) (NN recognition))))))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (CD two) (NNP Mandarin) (NNP ASR) (VBZ datasets)))) (VP (VBP show) (SBAR (S (NP (NP (DT the) (NN replacement)) (PP (IN of) (NP (NNP RNNs))) (PP (IN by) (NP (DT the) (NN self-attention) (NNS networks)))) (VP (VBZ yields) (NP (DT a) (ADJP (QP (QP (CD 8.4) (NN %) (CD -10.2)) (NN %))) (JJ relative) (NN character) (NN error) (NN rate) (PRN (-LRB- -LRB-) (NNP CER) (-RRB- -RRB-)) (NN reduction)))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (DT the) (JJ chunk-hopping) (NN mechanism)) (VP (VBZ allows) (S (NP (DT the) (NNP SAA)) (VP (TO to) (VP (VB have) (NP (RB only) (DT a) (ADJP (CD 2.5) (NN %)) (JJ relative) (NNP CER) (NN degradation)) (PP (IN with) (NP (DT a) (CD 320ms) (NN latency))))))) (. .))
(S (PP (IN After) (S (VP (ADVP (RB jointly)) (VBG training) (PP (IN with) (NP (DT a) (NN self-attention) (NN network) (NN language) (NN model)))))) (, ,) (NP (PRP$ our) (NNP SAA) (NN model)) (VP (VBZ obtains) (NP (JJ further) (NN error) (NN rate) (NN reduction)) (PP (IN on) (NP (JJ multiple) (NNS datasets)))) (. .))
(S (ADVP (RB Especially)) (, ,) (NP (PRP it)) (VP (VBZ achieves) (NP (ADJP (CD 24.12) (NN %)) (NNP CER)) (PP (IN on) (NP (NP (DT the) (NNP Mandarin) (NNP ASR) (NN benchmark)) (PRN (-LRB- -LRB-) (NP (NNP HKUST)) (-RRB- -RRB-)))) (, ,) (S (VP (VBG exceeding) (NP (DT the) (JJS best) (JJ end-to-end) (NN model)) (PP (IN by) (NP (ADJP (QP (IN over) (CD 2)) (NN %)) (JJ absolute) (NNP CER)))))) (. .))
