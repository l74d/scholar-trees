(S (NP (NP (DT The) (JJ cross-entropy) (NN loss)) (VP (ADVP (RB commonly)) (VBN used) (PP (IN in) (NP (JJ deep) (NN learning))))) (VP (VP (VBZ is) (VP (ADVP (RB closely)) (VBN related) (PP (TO to) (NP (NP (DT the) (VBG defining) (NNS properties)) (PP (IN of) (NP (JJ optimal) (NNS representations))))))) (, ,) (CC but) (VP (VBZ does) (RB not) (VP (VB enforce) (NP (NP (DT some)) (PP (IN of) (NP (DT the) (NN key) (NNS properties))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this)) (VP (MD can) (VP (VB be) (VP (VBN solved) (PP (IN by) (S (VP (VBG adding) (NP (NP (DT a) (NN regularization) (NN term)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (PP (IN in) (NP (NN turn))) (VP (VBN related) (PP (TO to) (S (VP (VBG injecting) (NP (NP (JJ multiplicative) (NN noise))) (PP (IN in) (NP (NP (DT the) (NNS activations)) (PP (IN of) (NP (DT a) (NNP Deep) (NNP Neural) (NNP Network))))) (, ,) (SBAR (WHNP (WHNP (DT a) (JJ special) (NN case)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBZ is) (NP (NP (DT the) (JJ common) (NN practice)) (PP (IN of) (NP (NN dropout)))))))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (JJ regularized) (NN loss) (NN function)) (VP (MD can) (VP (VB be) (ADVP (RB efficiently)) (VP (VBN minimized) (S (VP (VBG using) (NP (NP (NN Information) (NNP Dropout)) (, ,) (NP (NP (DT a) (NN generalization)) (PP (IN of) (NP (NN dropout))) (VP (VBN rooted) (PP (IN in) (NP (NN information) (JJ theoretic) (NNS principles)))) (SBAR (WHNP (WDT that)) (S (VP (VP (ADVP (RB automatically)) (VBZ adapts) (PP (TO to) (NP (DT the) (NNS data)))) (CC and) (VP (MD can) (VP (ADVP (VB better)) (JJ exploit) (NP (NP (NNS architectures)) (PP (IN of) (NP (JJ limited) (NN capacity))))))))))))))))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (NP (DT the) (NN task)) (VP (VBZ is) (NP (NP (DT the) (NN reconstruction)) (PP (IN of) (NP (DT the) (NN input))))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN loss) (NN function)) (VP (VBZ yields) (NP (DT a) (JJ Variational) (NNP Autoencoder)) (PP (IN as) (NP (DT a) (JJ special) (NN case))) (, ,) (S (ADVP (RB thus)) (VP (VBG providing) (NP (NP (DT a) (NN link)) (PP (IN between) (NP (NP (NN representation) (NN learning)) (, ,) (NP (NN information) (NN theory)) (CC and) (NP (JJ variational) (NN inference))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (PRP we)) (VP (VP (MD can) (VP (VB promote) (NP (NP (DT the) (NN creation)) (PP (IN of) (NP (JJ disentangled) (NNS representations)))) (PP (ADVP (RB simply)) (IN by) (S (VP (VBG enforcing) (NP (DT a) (JJ factorized) (NN prior))))))) (, ,) (NP (NP (DT a) (NN fact)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN observed) (ADVP (RB empirically)) (PP (IN in) (NP (JJ recent) (NN work))))))))))))) (. .))
(S (S (NP (PRP$ Our) (NNS experiments)) (VP (VBP validate) (NP (NP (DT the) (JJ theoretical) (NNS intuitions)) (PP (IN behind) (NP (PRP$ our) (NN method)))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP find) (SBAR (DT that) (S (NP (NN information) (NN dropout)) (VP (VBZ achieves) (NP (NP (DT a) (ADJP (JJ comparable) (CC or) (JJR better)) (NN generalization) (NN performance)) (PP (IN than) (NP (JJ binary) (NN dropout)))) (, ,) (PP (ADVP (RB especially)) (IN on) (NP (JJR smaller) (NNS models))) (, ,) (SBAR (IN since) (S (NP (PRP it)) (VP (MD can) (ADVP (RB automatically)) (VP (VB adapt) (NP (DT the) (NN noise)) (PP (PP (TO to) (NP (NP (DT the) (NN structure)) (PP (IN of) (NP (DT the) (NN network))))) (, ,) (CONJP (RB as) (RB well) (IN as)) (PP (TO to) (NP (DT the) (NN test) (NN sample))))))))))))) (. .))
