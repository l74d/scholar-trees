(S (NP (NP (DT A) (JJ significant) (NN advance)) (PP (IN in) (S (VP (VBG accelerating) (NP (JJ neural) (NN network) (NN training)))))) (VP (VBZ has) (VP (VBN been) (NP (NP (NP (DT the) (NN development)) (PP (IN of) (NP (NN normalization) (NNS methods)))) (, ,) (VP (VBG permitting) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ deep) (NNS models))) (UCP (DT both) (ADVP (RBR faster)) (CC and) (PP (IN with) (NP (JJR better) (NN accuracy))))))))) (. .))
(S (S (NP (DT These) (NNS advances)) (VP (VBP come) (PP (IN with) (NP (JJ practical) (NNS challenges))))) (: :) (S (PP (IN for) (NP (NN instance))) (, ,) (NP (NN batch) (NN normalization)) (VP (VBZ ties) (NP (NP (DT the) (NN prediction)) (PP (IN of) (NP (JJ individual) (NNS examples)))) (PP (IN with) (NP (NP (JJ other) (NNS examples)) (PP (IN within) (NP (DT a) (NN batch))))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (NP (DT a) (NN network)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (RB heavily) (JJ dependent) (PP (IN on) (NP (NN batch) (NN size))))))))))))) (. .))
(S (NP (NP (NNP Layer) (NN normalization)) (CC and) (NP (NN group) (NN normalization))) (VP (VP (VBP are) (ADJP (JJ data-dependent))) (CC and) (VP (ADVP (RB thus)) (MD must) (VP (VB be) (ADVP (RB continually)) (VP (VBN used) (, ,) (PP (ADVP (RB even)) (IN at) (NP (NN test-time))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (NP (DT the) (NNS issues)) (SBAR (WHNP (WDT that)) (S (VP (VBP arise) (PP (IN from) (S (VP (VBG using) (NP (JJ explicit) (NN normalization) (NNS techniques)))))))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB replace) (NP (VBG existing) (NN normalization) (NNS methods)) (PP (IN with) (NP (NP (DT a) (JJ simple) (, ,) (JJ secondary) (JJ objective) (NN loss)) (SBAR (WHNP (IN that)) (S (NP (PRP we)) (VP (NN term) (S (NP (DT a) (NN standardization) (NN loss)))))))))))) (. .))
(S (S (NP (DT This) (NN formulation)) (VP (VBZ is) (ADJP (JJ flexible) (CC and) (JJ robust)) (PP (IN across) (NP (JJ different) (NN batch) (NNS sizes))))) (CC and) (S (ADVP (RB surprisingly)) (, ,) (NP (DT this) (JJ secondary) (NN objective)) (VP (NNS accelerates) (NP (NP (VBG learning)) (PP (IN on) (NP (DT the) (JJ primary) (NN training) (NN objective)))))) (. .))
(S (SBAR (IN Because) (S (NP (PRP it)) (VP (VBZ is) (NP (DT a) (NN training) (NN loss))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADVP (RB simply)) (VP (VBN removed) (PP (IN at) (NP (NN test-time))))) (, ,) (CC and) (S (NP (DT no) (JJ further) (NN effort)) (VP (VBZ is) (VP (VBN needed) (S (VP (TO to) (VP (VB maintain) (NP (JJ normalized) (NNS activations)))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (DT a) (NN standardization) (NN loss)) (VP (VP (VBZ accelerates) (NP (NP (VBG training)) (PP (IN on) (NP (ADJP (DT both) (JJ small-) (CC and) (JJ large-scale)) (NN image) (NN classification) (NNS experiments))))) (, ,) (VP (VBZ works) (PP (IN with) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS architectures)))))) (, ,) (CC and) (VP (VBZ is) (ADJP (RB largely) (JJ robust) (PP (TO to) (NP (NP (VBG training)) (PP (IN across) (NP (JJ different) (NN batch) (NNS sizes))))))))))) (. .))
