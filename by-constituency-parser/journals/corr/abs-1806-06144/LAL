(S (NP (JJ Modern) (NN machine) (NN learning) (NNS models)) (VP (VBP are) (ADVP (RB typically)) (VP (JJ trained) (S (VP (VBG using) (NP (NP (JJ Stochastic) (NNP Gradient) (NNP Descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))) (PP (IN on) (NP (NP (ADJP (RB massively) (JJ parallel)) (VBG computing) (NNS resources)) (PP (JJ such) (IN as) (NP (NNP GPUs))))))))) (. .))
(S (S (VP (VBG Increasing) (NP (NN mini-batch) (NN size)))) (VP (VBZ is) (NP (NP (DT a) (ADJP (JJ simple) (CC and) (JJ direct)) (NN way)) (SBAR (S (VP (TO to) (VP (VB utilize) (NP (DT the) (JJ parallel) (NN computing) (NN capacity)))))))) (. .))
(S (PP (IN For) (NP (JJ small) (NN batch))) (NP (NP (DT an) (NN increase)) (PP (IN in) (NP (NN batch) (NN size)))) (VP (NNS results) (PP (IN in) (NP (NP (NP (DT the) (JJ proportional) (NN reduction)) (PP (IN in) (NP (DT the) (NN training) (NN time)))) (, ,) (NP (NP (DT a) (NN phenomenon)) (VP (VBN known) (PP (IN as) (NP (JJ linear) (NN scaling)))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG increasing) (NP (NN batch) (NN size)) (PP (IN beyond) (NP (DT a) (JJ certain) (NN value))))) (VP (VBZ leads) (PP (TO to) (NP (NP (DT no) (JJ further) (NN improvement)) (PP (IN in) (NP (NN training) (NN time)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP develop) (NP (NP (DT the) (JJ first) (JJ analytical) (NN framework)) (SBAR (WHNP (WDT that)) (S (VP (VBZ extends) (NP (JJ linear) (VBG scaling)) (S (VP (TO to) (VP (VB match) (NP (NP (DT the) (JJ parallel) (VBG computing) (NN capacity)) (PP (IN of) (NP (DT a) (NN resource)))))))))))) (. .))
(S (NP (DT The) (NN framework)) (VP (VBZ is) (VP (VBN designed) (PP (IN for) (NP (NP (DT a) (NN class)) (PP (IN of) (NP (JJ classical) (NN kernel) (NNS machines))))))) (. .))
(S (NP (PRP It)) (VP (ADVP (RB automatically)) (VBZ modifies) (NP (DT a) (JJ standard) (NN kernel) (NN machine)) (S (VP (S (VP (TO to) (NN output) (NP (DT a) (ADJP (RB mathematically) (JJ equivalent)) (NN prediction) (NN function)))) (, ,) (S (ADVP (RB yet)) (VP (VBG allowing) (PP (IN for) (NP (NP (VBN extended) (JJ linear) (NN scaling)) (, ,) (FW i.e.) (, ,) (NP (NP (JJR higher) (JJ effective) (NN parallelization)) (CC and) (NP (NP (RBR faster) (NN training) (NN time)) (PP (IN on) (NP (VBN given) (NN hardware)))))))))))) (. .))
(S (NP (DT The) (JJ resulting) (NNS algorithms)) (VP (VBP are) (ADJP (ADJP (JJ accurate)) (, ,) (ADJP (JJ principled)) (CC and) (ADJP (RB very) (RB fast)))) (. .))
(S (SBAR (IN As) (S (NP (DT the) (NNS parameters)) (VP (VBP are) (VP (VBN chosen) (ADVP (RB analytically)) (, ,) (PP (VBN based) (PP (IN on) (NP (DT the) (JJ theoretical) (NNS bounds)))) (, ,))))) (NP (NP (JJ little) (VBG tuning)) (PP (IN beyond) (S (VP (VBG selecting) (NP (NP (DT the) (NN kernel)) (CC and) (NP (DT the) (NN kernel) (NN parameter))))))) (VP (VBZ is) (VP (VBN needed) (, ,) (S (VP (ADVP (RBR further)) (VBG facilitating) (NP (NP (DT the) (JJ practical) (NN use)) (PP (IN of) (NP (DT these) (NNS methods)))))))) (. .))
