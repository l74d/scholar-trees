(S (S (VP (VBG Training) (NP (JJ deep) (JJ neural) (NNS networks)))) (VP (VBZ requires) (NP (NP (JJ intricate) (NN initialization)) (CC and) (NP (NP (JJ careful) (NN selection)) (PP (IN of) (NP (VBG learning) (NNS rates)))))) (. .))
(S (NP (NP (DT The) (NN emergence)) (PP (IN of) (NP (NP (NP (JJ stochastic) (NN gradient) (NN optimization) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (NP (JJ adaptive) (NN learning) (NNS rates)) (VP (VBN based) (PP (IN on) (NP (JJ squared) (JJ past) (NNS gradients))))))))) (, ,) (PRN (SINV (INTJ (NN e.g.)) (, ,) (NP (NP (NNP AdaGrad)) (, ,) (NP (NNP AdaDelta)) (, ,) (CC and) (NP (NNP Adam))))) (, ,)))) (VP (VBZ eases) (NP (DT the) (NN job)) (ADVP (RB slightly))) (. .))
(S (ADVP (RB However)) (, ,) (NP (JJ such) (NNS methods)) (VP (VBP have) (ADVP (RB also)) (VP (VBN been) (VP (VBN proven) (S (ADJP (JJ problematic))) (PP (IN in) (NP (JJ recent) (NNS studies))) (PP (IN with) (NP (NP (PRP$ their) (JJ own) (NNS pitfalls)) (PP (VBG including) (NP (NP (JJ non-convergence) (NNS issues)) (CC and) (ADVP (RB so) (IN on))))))))) (. .))
(S (NP (NP (JJ Alternative) (NNS variants))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN for) (NP (NN enhancement))) (, ,) (PP (JJ such) (IN as) (NP (NNP AMSGrad) (, ,) (NP (NNP AdaShift)) (CC and) (NNP AdaBound)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP identify) (NP (NP (DT a) (JJ new) (NN problem)) (PP (IN of) (NP (JJ adaptive) (VBG learning) (NN rate) (NNS methods))) (SBAR (WHNP (IN that)) (S (VP (NNS exhibits) (PP (IN at) (NP (NP (DT the) (NN beginning)) (PP (IN of) (NP (VBG learning))) (SBAR (WHADVP (WRB where)) (S (NP (NNP Adam)) (VP (VBZ produces) (NP (NP (ADJP (RB extremely) (JJ large)) (VBG learning) (NNS rates)) (SBAR (WHNP (WDT that)) (S (VP (VBP inhibit) (NP (NP (DT the) (NN start)) (PP (IN of) (NP (NN learning)))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT the) (ADJP (NNP Adaptive) (CC and) (NNP Momental) (NNP Bound)) (PRN (-LRB- -LRB-) (NP (NNP AdaMod)) (-RRB- -RRB-)) (NN method)) (SBAR (S (VP (TO to) (VP (VB restrict) (NP (DT the) (JJ adaptive) (NN learning) (NNS rates)) (PP (IN with) (NP (ADJP (JJ adaptive) (CC and) (JJ momental)) (JJ upper) (NNS bounds))))))))) (. .))
(S (NP (DT The) (JJ dynamic) (JJ learning) (NN rate) (NNS bounds)) (VP (VBP are) (VP (VBN based) (PP (IN on) (NP (NP (DT the) (JJ exponential) (NN moving) (NNS averages)) (PP (IN of) (NP (NP (NP (DT the) (JJ adaptive) (NN learning) (NNS rates)) (NP (PRP themselves))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ smooth) (PRT (RP out)) (NP (JJ unexpected) (JJ large) (VBG learning) (NNS rates))) (CC and) (VP (VB stabilize) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))))))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VB verify) (SBAR (IN that) (S (NP (NNP AdaMod)) (VP (VP (VBZ eliminates) (NP (DT the) (ADJP (RB extremely) (JJ large)) (VBG learning) (NNS rates)) (PP (IN throughout) (NP (DT the) (NN training)))) (CC and) (VP (VBZ brings) (NP (JJ significant) (NNS improvements)) (PP (ADVP (RB especially)) (IN on) (NP (NP (JJ complex) (NNS networks)) (PP (JJ such) (IN as) (NP (NNP DenseNet) (CC and) (NNP Transformer))))) (, ,) (PP (VBN compared) (PP (TO to) (NP (NNP Adam))))))))) (. .))
(S (NP (PRP$ Our) (NN implementation)) (VP (VBZ is) (ADJP (JJ available)) (PP (IN at) (: :) (NP (DT this) (NN https) (NNP URL)))))
