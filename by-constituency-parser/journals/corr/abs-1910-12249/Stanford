(S (S (VP (VBG Training) (NP (JJ deep) (JJ neural) (NNS networks)))) (VP (VBZ requires) (NP (NP (JJ intricate) (NN initialization)) (CC and) (NP (NP (JJ careful) (NN selection)) (PP (IN of) (NP (NN learning) (NNS rates)))))) (. .))
(S (NP (NP (NP (NP (DT The) (NN emergence)) (PP (IN of) (NP (JJ stochastic) (NML (NN gradient) (NN optimization)) (NNS methods)))) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (JJ adaptive) (NN learning) (NNS rates)) (PP (VBN based) (PP (IN on) (NP (NP (ADJP (JJ squared)) (JJ past) (NNS gradients)) (, ,) (ADVP (FW e.g.))))))))) (, ,) (NP (NNP AdaGrad) (, ,) (NNP AdaDelta) (, ,) (CC and) (NNP Adam)) (, ,)) (VP (VBZ eases) (NP (DT the) (NN job)) (ADVP (RB slightly))) (. .))
(S (ADVP (RB However)) (, ,) (NP (JJ such) (NNS methods)) (VP (VBP have) (ADVP (RB also)) (VP (VBN been) (VP (VBN proven) (UCP (ADJP (JJ problematic) (PP (IN in) (NP (NP (JJ recent) (NNS studies)) (PP (IN with) (NP (NP (PRP$ their) (JJ own) (NNS pitfalls)) (PP (VBG including) (NP (NN non-convergence) (NNS issues)))))))) (CC and) (ADVP (RB so) (RB on)))))) (. .))
(S (NP (JJ Alternative) (NNS variants)) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN for) (NP (NN enhancement))) (, ,) (PP (JJ such) (PP (IN as) (NP (NNP AMSGrad) (, ,) (NNP AdaShift) (CC and) (NNP AdaBound))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP identify) (NP (NP (NP (DT a) (JJ new) (NN problem)) (PP (IN of) (NP (JJ adaptive) (NML (NN learning) (NN rate)) (NNS methods)))) (SBAR (WHNP (WDT that)) (S (VP (VBZ exhibits) (PP (IN at) (NP (NP (DT the) (NN beginning)) (PP (IN of) (NP (NN learning))))) (SBAR (WHADVP (WRB where)) (S (NP (NNP Adam)) (VP (VBZ produces) (NP (NP (ADJP (RB extremely) (JJ large)) (NN learning) (NNS rates)) (SBAR (WHNP (WDT that)) (S (VP (VBP inhibit) (NP (NP (DT the) (NN start)) (PP (IN of) (NP (NN learning)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (NP (DT the) (ADJP (JJ Adaptive) (CC and) (JJ Momental)) (NN Bound) (PRN (-LRB- -LRB-) (NP (NNP AdaMod)) (-RRB- -RRB-)) (NN method)) (VP (TO to) (VP (VB restrict) (NP (DT the) (JJ adaptive) (NN learning) (NNS rates)) (PP (IN with) (NP (NP (JJ adaptive)) (CC and) (NP (JJ momental) (JJ upper) (NNS bounds)))))))) (. .))
(S (NP (DT The) (NML (JJ dynamic) (NN learning) (NN rate)) (NNS bounds)) (VP (VBP are) (VP (VBN based) (PP (IN on) (NP (NP (NP (DT the) (ADJP (JJ exponential) (VBG moving)) (NNS averages)) (PP (IN of) (NP (NP (DT the) (JJ adaptive) (NN learning) (NNS rates)) (ADVP (PRP themselves))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBP smooth) (PRT (RP out)) (NP (JJ unexpected) (NML (JJ large) (NN learning)) (NNS rates))) (CC and) (VP (VB stabilize) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP verify) (SBAR (IN that) (S (NP (NNP AdaMod)) (VP (VP (VBZ eliminates) (NP (DT the) (ADJP (RB extremely) (JJ large)) (NN learning) (NNS rates)) (PP (IN throughout) (NP (DT the) (NN training)))) (CC and) (VP (VBZ brings) (NP (JJ significant) (NNS improvements)) (ADVP (RB especially)) (PP (IN on) (NP (NP (JJ complex) (NNS networks)) (PP (JJ such) (IN as) (NP (NNP DenseNet) (CC and) (NNP Transformer))))) (, ,) (PP (VBN compared) (PP (IN to) (NP (NNP Adam))))))))) (. .))
(S (S (NP (PRP$ Our) (NN implementation)) (VP (VBZ is) (ADJP (JJ available) (PP (IN at))))) (: :) (S (NP (DT this)) (VP (VBZ https) (NP (NN URL)))))
