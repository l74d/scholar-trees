(S (PP (IN In) (NP (JJ many) (NML (JJ real) (HYPH -) (NN world)) (NNS settings))) (, ,) (NP (NP (DT a) (NN team)) (PP (IN of) (NP (NNS agents)))) (VP (MD must) (VP (VB coordinate) (NP (PRP$ their) (NN behaviour)) (PP (IN while) (S (VP (VBG acting) (PP (IN in) (NP (DT a) (VBN decentralised) (NN way)))))))) (. .))
(S (PP (IN At) (NP (DT the) (JJ same) (NN time))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (RB often) (JJ possible)) (S (VP (TO to) (VP (VB train) (NP (DT the) (NNS agents)) (PP (IN in) (NP (NP (DT a) (JJ centralised) (NN fashion)) (PP (IN in) (NP (DT a) (UCP (JJ simulated) (CC or) (NN laboratory)) (NN setting)))))))) (, ,) (SBAR (WHADVP (WRB where)) (S (S (NP (JJ global) (NN state) (NN information)) (VP (VBZ is) (ADJP (JJ available)))) (CC and) (S (NP (NN communication) (NNS constraints)) (VP (VBP are) (VP (VBN lifted))))))) (. .))
(S (S (S (VP (VBG Learning) (NP (NP (JJ joint) (NN action) (HYPH -) (NNS values)) (VP (VBN conditioned) (PP (IN on) (NP (JJ extra) (NN state) (NN information))))))) (VP (VBZ is) (NP (DT an) (JJ attractive) (NN way) (S (VP (TO to) (VP (VB exploit) (NP (JJ centralised) (NN learning)))))))) (, ,) (CC but) (S (NP (NP (DT the) (JJS best) (NN strategy)) (PP (IN for) (S (ADVP (RB then)) (VP (VBG extracting) (NP (VBN decentralised) (NNS policies)))))) (VP (VBZ is) (ADJP (JJ unclear)))) (. .))
(S (NP (PRP$ Our) (NN solution)) (VP (VBZ is) (NP (NP (NP (NN QMIX)) (, ,) (NP (DT a) (JJ novel) (ADJP (NN value) (HYPH -) (VBN based)) (NN method))) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB train) (NP (NP (VBN decentralised) (NNS policies)) (PP (IN in) (NP (DT a) (JJ centralised) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NN fashion)))))))))) (. .))
(S (NP (NNP QMIX)) (VP (VBZ employs) (NP (NP (DT a) (NN network)) (SBAR (WHNP (WDT that)) (S (VP (VBZ estimates) (NP (NP (NP (JJ joint) (NN action) (HYPH -) (NNS values)) (PP (IN as) (NP (NP (DT a) (JJ complex) (JJ non-linear) (NN combination)) (PP (IN of) (NP (NML (IN per) (HYPH -) (NN agent)) (NNS values)))))) (SBAR (WHNP (WDT that)) (S (VP (VBP condition) (ADVP (RB only)) (PP (IN on) (NP (JJ local) (NNS observations)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB structurally)) (VP (VBP enforce) (SBAR (IN that) (S (NP (DT the) (NML (JJ joint) (HYPH -) (NN action)) (NN value)) (VP (VBZ is) (ADJP (JJ monotonic) (PP (IN in) (NP (NP (DT the) (NML (IN per) (HYPH -) (NN agent)) (NNS values)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ allows) (NP (NP (JJ tractable) (NN maximisation)) (PP (IN of) (NP (NP (DT the) (JJ joint) (NN action) (HYPH -) (NN value)) (PP (IN in) (NP (NML (RB off) (HYPH -) (NN policy)) (NN learning))))))) (, ,) (CC and) (VP (VBZ guarantees) (NP (NP (NN consistency)) (PP (IN between) (NP (NP (DT the) (VBN centralised)) (CC and) (NP (VBN decentralised) (NNS policies)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (NNP QMIX)) (PP (IN on) (NP (NP (DT a) (JJ challenging) (NN set)) (PP (IN of) (NP (NML (NNP StarCraft) (NNP II)) (NN micromanagement) (NNS tasks)))))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (NNP QMIX)) (ADVP (RB significantly)) (VP (VBZ outperforms) (S (VP (VBG existing) (NP (ADJP (NN value) (HYPH -) (VBN based)) (JJ multi-agent) (NML (NN reinforcement) (VBG learning)) (NNS methods))))))))) (. .))
