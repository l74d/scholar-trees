(S (S (NP (NNPS Transformers)) (VP (VBP have) (VP (VBN become) (ADVP (RB widely)) (S (VP (VBN used) (PP (IN for) (NP (NML (NML (NN language) (NN modeling)) (CC and) (NML (NN sequence) (NN learning))) (NNS tasks)))))))) (, ,) (CC and) (SINV (VBP are) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (ADJP (RBS most) (JJ important)) (NN machine)))) (VP (VBG learning) (NP (NNS workloads)) (NP-TMP (NN today)))) (. .))
(S (S (S (VP (VBG Training) (NP (CD one)))) (VP (VBZ is) (S (NP (DT a) (RB very)) (VP (VB compute) (HYPH -) (NP (JJ intensive) (NN task)) (, ,) (S (ADVP (RB often)) (VP (VBG taking) (NP (NNS days) (CC or) (NNS weeks)))))))) (, ,) (CC and) (S (NP (JJ significant) (NN attention)) (VP (VBZ has) (VP (VBN been) (VP (VBN given) (PP (IN to) (S (VP (VBG optimizing) (NP (NNS transformers))))))))) (. .))
(S (PP (IN Despite) (NP (DT this))) (, ,) (NP (VBG existing) (NNS implementations)) (VP (VBP do) (RB not) (ADVP (RB efficiently)) (VP (VB utilize) (NP (NNS GPUs)))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NNS data) (NN movement)) (VP (VBZ is) (NP (NP (DT the) (JJ key) (NN bottleneck)) (SBAR (WHADVP (WRB when)) (FRAG (NP (NN training))))))))) (. .))
(S (PP (IN Due) (PP (IN to) (NP (NP (NP (NNP Amdahl) (POS 's)) (NNP Law)) (CC and) (NP (NP (JJ massive) (NNS improvements)) (PP (IN in) (S (VP (VB compute) (NP (NN performance))))))))) (, ,) (NP (NN training)) (VP (VBZ has) (ADVP (RB now)) (VP (VBN become) (S (ADJP (NN memory) (HYPH -) (VBN bound))))) (. .))
(S (ADVP (RB Further)) (, ,) (NP (VBG existing) (NNS frameworks)) (VP (VBP use) (NP (JJ suboptimal) (NNS data) (NNS layouts))) (. .))
(S (S (VP (VBG Using) (NP (DT these) (NNS insights)))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (DT a) (NN recipe)) (PP (IN for) (S (ADVP (RB globally)) (VP (VBG optimizing) (NP (NP (NNS data) (NN movement)) (PP (IN in) (NP (NNS transformers)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP reduce) (NP (NNS data) (NN movement)) (PP (IN by) (NP (QP (RB up) (IN to) (CD 22.91)) (NN %)))) (CC and) (ADVP (JJ overall)) (VP (VB achieve) (NP (DT a) (NML (QP (CD 1.30) (SYM x))) (NN performance) (NN improvement)) (PP (IN over) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS frameworks))) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (NNP BERT))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VP (VBZ is) (ADJP (JJ applicable) (ADVP (RBR more) (RB broadly)) (PP (IN to) (S (VP (VBG optimizing) (NP (JJ deep) (JJ neural) (NNS networks))))))) (, ,) (CC and) (VP (VBZ offers) (NP (NN insight)) (PP (IN into) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB tackle) (NP (VBG emerging) (NN performance) (NNS bottlenecks))))))))) (. .))
