(S (NP (JJ Deep) (JJ neural) (NNS networks)) (VP (VBP achieve) (NP (JJ stellar) (NN generalisation)) (ADVP (RB even)) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBP have) (NP (JJ enough) (NNS parameters) (S (VP (TO to) (ADVP (RB easily)) (VP (VB fit) (NP (PDT all) (PRP$ their) (NN training) (NNS data)))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP study) (NP (DT this) (NN phenomenon)) (PP (IN by) (S (VP (VBG analysing) (NP (DT the) (NNS dynamics))))))) (CC and) (S (NP (NP (DT the) (NN performance)) (PP (IN of) (S (VP (VBN over-parameterised) (NP (NML (CD two) (HYPH -) (NN layer)) (JJ neural) (NNS networks)) (PP (IN in) (NP (DT the) (NML (NN teacher) (HYPH -) (NN student)) (NN setup))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (CD one) (NN network)) (, ,) (NP (DT the) (NN student)) (, ,)) (VP (VBZ is) (VP (VBN trained) (PP (IN on) (NP (NP (NNS data)) (VP (VBN generated) (PP (IN by) (NP (DT another) (NN network)))))))))))))) (, ,) (VP (VBD called) (NP (DT the) (NN teacher)))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (JJ stochastic) (NN gradient) (NN descent) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))))) (VP (VP (VBZ is) (VP (VBN captured) (PP (IN by) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ differential) (NNS equations))))))) (CC and) (VP (VB prove) (SBAR (IN that) (S (NP (DT this) (NN description)) (VP (VBZ is) (ADJP (RB asymptotically) (JJ exact) (PP (IN in) (NP (NP (DT the) (NN limit)) (PP (IN of) (NP (JJ large) (NNS inputs)))))))))))))) (. .))
(S (S (VP (VBG Using) (NP (DT this) (NN framework)))) (, ,) (NP (PRP we)) (VP (VBP calculate) (NP (NP (DT the) (JJ final) (NN generalisation) (NN error)) (PP (IN of) (NP (NP (NN student) (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (NP (NP (JJR more) (NNS parameters)) (PP (IN than) (NP (PRP$ their) (NNS teachers))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NP (DT the) (JJ final) (NN generalisation) (NN error)) (PP (IN of) (NP (DT the) (NN student)))) (VP (VP (VBZ increases) (PP (IN with) (NP (NN network) (NN size))) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (RB only) (DT the) (JJ first) (NN layer)))))) (, ,) (CC but) (VP (VBZ stays) (ADJP (JJ constant))))) (CC or) (RB even) (S (VP (VBZ decreases) (PP (IN with) (NP (NN size))) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (DT both) (NNS layers))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT these) (JJ different) (NNS behaviours)) (VP (VBP have) (NP (NP (PRP$ their) (NN root)) (PP (IN in) (NP (NP (DT the) (JJ different) (NNS solutions)) (SBAR (S (NP (NNP SGD)) (VP (VBZ finds) (PP (IN for) (NP (JJ different) (NN activation) (NNS functions))))))))))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP indicate) (SBAR (IN that) (S (S (VP (VBG achieving) (NP (JJ good) (NN generalisation)) (PP (IN in) (NP (JJ neural) (NNS networks))))) (VP (VP (VBZ goes) (PP (IN beyond) (NP (NP (DT the) (NNS properties)) (PP (IN of) (NP (NNP SGD))))) (ADVP (RB alone))) (CC and) (VP (VBZ depends) (PP (IN on) (NP (NP (NP (DT the) (NN interplay)) (PP (IN of) (NP (QP (ADVP (IN at) (RBS least))) (DT the) (NN algorithm)))) (, ,) (NP (DT the) (NN model) (NN architecture)) (, ,) (CC and) (NP (DT the) (NNS data) (NN set))))))))) (. .))
