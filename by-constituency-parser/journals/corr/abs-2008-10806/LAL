(S (NP (DT This) (NN paper)) (VP (VBZ aims) (S (VP (TO to) (VP (VB establish) (NP (NP (DT an) (JJ entropy-regularized) (JJ value-based) (NN reinforcement) (VBG learning) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB ensure) (NP (NP (DT the) (JJ monotonic) (NN improvement)) (PP (IN of) (NP (NNS policies)))) (PP (IN at) (NP (DT each) (NN policy) (NN update)))))))))))) (. .))
(S (PP (IN Unlike) (NP (NP (ADJP (RB previously) (VBN proposed)) (NNS lower-bounds)) (PP (IN on) (NP (NN policy) (NN improvement))) (PP (IN in) (NP (JJ general) (JJ infinite-horizon) (NNP MDPs))))) (, ,) (NP (PRP we)) (VP (VBP derive) (NP (DT an) (ADJP (NN entropy-regularization) (JJ aware)) (JJR lower) (NN bound))) (. .))
(S (SBAR (IN Since) (S (NP (PRP$ our) (IN bound)) (ADVP (RB only)) (VP (VBZ requires) (S (NP (DT the) (JJ expected) (NN policy) (NN advantage) (NN function)) (VP (TO to) (VP (VB be) (VP (VBN estimated)))))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ scalable) (PP (TO to) (NP (JJ large-scale) (PRN (-LRB- -LRB-) (JJ continuous) (-RRB- -RRB-)) (NN state-space) (NNS problems))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN reinforcement) (VBG learning) (NNS algorithm)) (SBAR (WHNP (IN that)) (S (VP (VBZ exploits) (NP (DT this) (NN lower-bound)) (PP (IN as) (NP (NP (DT a) (NN criterion)) (PP (IN for) (S (VP (VBG adjusting) (NP (NP (DT the) (NN degree)) (PP (IN of) (NP (DT a) (NN policy) (NN update)))) (PP (IN for) (S (VP (VBG alleviating) (NP (NN policy) (NN oscillation))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (PRP$ our) (NN approach)))) (PP (IN in) (NP (DT both) (NP (JJ discrete-state) (NN maze)) (CC and) (NN continuous-state) (JJ inverted) (NN pendulum) (NNS tasks))) (S (VP (VBG using) (NP (DT a) (JJ linear) (NN function) (NN approximator)) (PP (IN for) (NP (NN value) (NN estimation)))))) (. .))
