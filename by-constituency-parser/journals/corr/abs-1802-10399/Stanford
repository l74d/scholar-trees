(S (NP (JJ Neural) (NNS networks)) (VP (MD can) (VP (VB be) (VP (VBN compressed) (S (VP (VP (TO to) (VP (VB reduce) (NP (NP (NN memory)) (CC and) (NP (JJ computational) (NNS requirements))))) (, ,) (CC or) (VP (TO to) (VP (VB increase) (NP (NN accuracy)) (PP (IN by) (S (VP (VBG facilitating) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (DT a) (JJR larger) (NN base) (NN architecture)))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP focus) (PP (IN on) (NP (NP (NN pruning) (JJ individual) (NNS neurons)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (ADVP (RB simultaneously)) (VP (VB trim) (NP (NP (NN model) (NN size)) (, ,) (NP (NNS FLOPs)) (, ,) (CC and) (NP (ADJP (VB run) (HYPH -) (NN time)) (NN memory)))))))))) (. .))
(S (S (VP (TO To) (VP (VB improve) (PP (IN upon) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (VBG existing) (NN compression) (NNS algorithms)))))))) (NP (PRP we)) (VP (VBP utilize) (NP (NP (DT the) (NN information) (NN bottleneck) (NN principle)) (VP (VBN instantiated) (PP (IN via) (NP (NP (DT a) (ADJP (JJ tractable)) (NN variational)) (VP (VBN bound))))))) (. .))
(S (NP (NP (NN Minimization)) (PP (IN of) (NP (NP (DT this) (NN information)) (ADJP (JJ theoretic) (JJ bound))))) (VP (VBZ reduces) (NP (NP (DT the) (NN redundancy)) (PP (IN between) (NP (JJ adjacent) (NNS layers)))) (PP (IN by) (S (VP (VBG aggregating) (NP (JJ useful) (NN information)) (PP (IN into) (NP (NP (DT a) (NN subset)) (PP (IN of) (NP (NP (NNS neurons)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN preserved)))))))))))))) (. .))
(S (PP (IN In) (NP (NN contrast))) (, ,) (NP (NP (DT the) (NNS activations)) (PP (IN of) (NP (JJ disposable) (NNS neurons)))) (VP (VBP are) (VP (VBN shut) (PRT (RP off)) (PP (IN via) (NP (NP (DT an) (JJ attractive) (NN form)) (PP (IN of) (NP (NP (JJ sparse) (NN regularization)) (SBAR (WHNP (WDT that)) (S (VP (VBZ emerges) (ADVP (RB naturally)) (PP (IN from) (NP (DT this) (NN framework))) (, ,) (S (VP (VBG providing) (NP (NP (JJ tangible) (NNS advantages)) (PP (IN over) (NP (JJ traditional) (NN sparsity) (NNS penalties)))) (PP (IN without) (S (VP (VBG contributing) (NP (JJ additional) (NN tuning) (NNS parameters)) (PP (IN to) (NP (DT the) (NN energy) (NN landscape))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NN compression) (NNS rates)) (PP (IN across) (NP (NP (DT an) (NN array)) (PP (IN of) (NP (NP (NNS datasets)) (CC and) (NP (NN network) (NNS architectures))))))) (. .))
