(S (NP (PRP We)) (VP (VBP give) (NP (NP (DT a) (JJ new) (NN algorithm)) (PP (IN for) (S (VP (VBG learning) (NP (DT a) (JJ two-layer) (JJ neural) (NN network)) (PP (IN under) (NP (NP (DT a) (JJ general) (NN class)) (PP (IN of) (NP (NN input) (NNS distributions)))))))))) (. .))
(S (NP (NP (DT The) (JJ only) (NN requirement)) (PP (IN on) (NP (DT the) (JJ input) ($ $) (JJ x) ($ $)))) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ symmetric)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB still)) (VP (VBZ allows) (NP (ADJP (RB highly) (VBN complicated) (CC and) (VBN structured)) (NN input))))))))) (. .))
(S (NP (PRP$ Our) (NN algorithm)) (VP (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (DT the) (NNS method-of-moments) (NN framework))))) (CC and) (VP (VBZ extends) (NP (NP (JJ several) (NNS results)) (PP (IN in) (NP (JJ tensor) (NNS decompositions)))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (JJ spectral) (NN algorithms)) (S (VP (TO to) (VP (VB avoid) (NP (NP (DT the) (JJ complicated) (JJ non-convex) (NN optimization)) (PP (IN in) (S (VP (VBG learning) (NP (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN algorithm)) (VP (MD can) (VP (ADVP (VB robustly)) (VB learn) (NP (DT the) (JJ ground-truth) (JJ neural) (NN network)) (PP (IN with) (NP (NP (DT a) (JJ small) (NN number)) (PP (IN of) (NP (NNS samples))))) (PP (IN for) (NP (JJ many) (JJ symmetric) (NN input) (NNS distributions)))))))) (. .))
