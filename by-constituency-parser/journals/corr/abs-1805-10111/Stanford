(S (NP (NP (JJ Modern) (VBN distributed) (NN training)) (PP (IN of) (NP (NML (NN machine) (NN learning)) (NNS models)))) (VP (VBZ suffers) (PP (IN from) (NP (NP (JJ high) (NN communication) (NN overhead)) (PP (IN for) (NP (VBG synchronizing) (JJ stochastic) (NNS gradients) (CC and) (NN model) (NNS parameters)))))) (. .))
(S (NP (ADJP (NP (CD Three) (NN communication)) (HYPH -) (JJ efficient)) (NNS algorithms)) (VP (VBP are) (VP (VBN proposed) (PP (IN under) (NP (DT this) (JJ general) (NN scheme))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (S (LST (-LRB- -LRB-) (LS i) (-RRB- -RRB-)) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NML (JJ low) (HYPH -) (NN precision)) (NN algorithm) (NN AsyLPG)) (PP (IN with) (NP (JJ asynchronous) (NN parallelism)))))) (, ,) (S (LST (-LRB- -LRB-) (LS ii) (-RRB- -RRB-)) (S (NP (PRP we)) (VP (VP (VB explore) (S (VP (VBG integrating) (NP (NN gradient) (NN sparsification)) (PP (IN with) (NP (JJ double) (NN quantization)))))) (CC and) (VP (VB develop) (NP (JJ Sparse) (HYPH -) (NN AsyLPG))))) (, ,) (S (LST (-LRB- -LRB-) (LS iii) (-RRB- -RRB-)) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ double) (NN quantization)) (VP (MD can) (ADVP (RB also)) (VP (VB be) (VP (VBN accelerated) (PP (IN by) (NP (NN momentum) (NN technique)))))))))) (CC and) (S (NP (NN design)) (VP (VBD accelerated) (NP (NNP AsyLPG))))) (. .))
(S (NP (PRP We)) (VP (VBP establish) (NP (NP (NP (JJ rigorous) (NN performance) (NNS guarantees)) (PP (IN for) (NP (DT the) (NNS algorithms)))) (, ,) (CC and) (NP (NP (NN conduct) (NNS experiments)) (PP (IN on) (NP (DT a) (JJ multi-server) (NN test) (HYPH -) (NN bed))))) (S (VP (TO to) (VP (VB demonstrate) (SBAR (IN that) (S (NP (PRP$ our) (NNS algorithms)) (VP (MD can) (ADVP (RB effectively)) (VP (VB save) (NP (VBN transmitted) (NNS bits)) (PP (IN without) (NP (NN performance) (NN degradation))))))))))) (. .))
