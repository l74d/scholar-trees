(S (NP (NP (NNP Modern) (VBD distributed) (NN training)) (PP (IN of) (NP (NN machine) (NN learning) (NNS models)))) (VP (NNS suffers) (PP (IN from) (NP (NP (JJ high) (NN communication) (NN overhead)) (PP (IN for) (S (VP (VBG synchronizing) (NP (NP (JJ stochastic) (NNS gradients)) (CC and) (NP (NN model) (NNS parameters))))))))) (. .))
(S (NP (CD Three) (JJ communication-efficient) (NNS algorithms)) (VP (VBP are) (VP (VBN proposed) (PP (IN under) (NP (DT this) (JJ general) (NN scheme))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (S (PRN (-LRB- -LRB-) (NN i) (-RRB- -RRB-)) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN low-precision) (NN algorithm)) (NP (NNP AsyLPG)) (PP (IN with) (NP (JJ asynchronous) (NN parallelism)))))) (, ,) (S (PRN (-LRB- -LRB-) (NN ii) (-RRB- -RRB-)) (NP (PRP we)) (VP (VP (VBP explore) (S (VP (VBG integrating) (NP (NN gradient) (NN sparsification)) (PP (IN with) (NP (JJ double) (NN quantization)))))) (CC and) (VP (VB develop) (NP (NNP Sparse-AsyLPG))))) (, ,) (S (PRN (-LRB- -LRB-) (NN iii) (-RRB- -RRB-)) (NP (PRP we)) (VP (VP (VBP show) (SBAR (IN that) (S (NP (JJ double) (NN quantization)) (VP (MD can) (ADVP (RB also)) (VP (VB be) (VP (VBN accelerated) (PP (IN by) (NP (NN momentum) (NN technique))))))))) (CC and) (VP (NN design) (NP (VBN accelerated) (NNP AsyLPG))))) (. .))
(S (NP (PRP We)) (VP (VP (VB establish) (NP (NP (JJ rigorous) (NN performance) (NNS guarantees)) (PP (IN for) (NP (DT the) (NN algorithms))))) (, ,) (CC and) (VP (NN conduct) (NP (NNS experiments)) (PP (IN on) (NP (DT a) (JJ multi-server) (JJ test-bed))) (S (VP (TO to) (VP (VB demonstrate) (SBAR (IN that) (S (NP (PRP$ our) (NN algorithms)) (VP (MD can) (VP (ADVP (RB effectively)) (VB save) (NP (VBN transmitted) (NNS bits)) (PP (IN without) (NP (NN performance) (NN degradation)))))))))))) (. .))
