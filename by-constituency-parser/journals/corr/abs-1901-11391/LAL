(S (NP (NP (NNS Parameters)) (PP (IN of) (NP (JJ recent) (JJ neural) (NNS networks)))) (VP (VBP require) (NP (NP (DT a) (JJ huge) (NN amount)) (PP (IN of) (NP (NN memory))))) (. .))
(S (NP (DT These) (NNS parameters)) (VP (VBP are) (VP (VBN used) (PP (IN by) (NP (JJ neural) (NNS networks))) (S (VP (TO to) (VP (VB perform) (NP (NN machine) (VBG learning) (NNS tasks)) (SBAR (WHADVP (WRB when)) (S (VP (VBG processing) (NP (NNS inputs)))))))))) (. .))
(S (S (VP (TO To) (VP (VB speed) (PRT (RP up)) (NP (NN inference))))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (NNP Partition) (NNP Pruning)) (, ,) (NP (NP (DT an) (JJ innovative) (NN scheme)) (SBAR (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NNS parameters)) (VP (VBN used))) (SBAR (IN while) (S (VP (VBG taking) (PP (IN into) (NP (NN consideration))) (NP (NN parallelization)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBD evaluated) (NP (NP (DT the) (NN performance) (CC and) (NN energy) (NN consumption)) (PP (IN of) (NP (NP (JJ parallel) (NN inference)) (PP (IN of) (NP (NP (JJ partitioned) (NNS models)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD showed) (NP (NP (NP (DT a) (CD 7.72x) (NN speed) (RB up)) (PP (IN of) (NP (NN performance)))) (CC and) (NP (NP (NP (DT a) (CD 2.73x) (NN reduction)) (PP (IN in) (NP (NP (DT the) (NN energy)) (VP (VBN used) (PP (IN for) (S (VP (VBG computing) (NP (NP (JJ pruned) (NNS layers)) (PP (IN of) (NP (NNP TinyVGG16))))))))))) (PP (IN in) (NP (NP (NN comparison)) (PP (TO to) (S (VP (VBG running) (NP (DT the) (JJ unpruned) (NN model)) (PP (IN on) (NP (DT a) (JJ single) (NN accelerator))))))))))))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (PRP$ our) (NN method)) (VP (VBD showed) (NP (NP (NP (DT a) (JJ limited) (NN reduction)) (NP (DT some) (NNS numbers))) (PP (IN in) (NP (NN accuracy)))) (SBAR (IN while) (S (VP (VBG partitioning) (NP (ADJP (RB fully) (VBN connected)) (NNS layers)))))) (. .))
