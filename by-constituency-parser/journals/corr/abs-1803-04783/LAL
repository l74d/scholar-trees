(S (NP (NP (JJS Most) (NNS investigations)) (PP (IN into) (NP (NP (JJ near-memory) (NN hardware) (NNS accelerators)) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks)))))) (VP (VBP have) (VP (ADVP (RB primarily)) (VBN focused) (PP (IN on) (NP (NN inference))) (, ,) (SBAR (IN while) (S (NP (NP (DT the) (NN potential)) (PP (IN of) (NP (VBG accelerating) (NN training)))) (VP (VBZ has) (VP (VBN received) (NP (ADJP (RB relatively) (JJ little)) (NN attention)) (ADVP (RB so) (RB far)))))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (NP (DT an) (JJ in-depth) (NN analysis)) (PP (IN of) (NP (NP (DT the) (JJ key) (JJ computational) (NNS patterns)) (PP (IN in) (NP (JJ state-of-the-art) (JJ gradient-based) (NN training) (NNS methods)))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (JJ efficient) (JJ near-memory) (NN acceleration) (NN engine)) (VP (VBN called) (S (NP (NNP NTX)))) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB train) (NP (JJ state-of-the-art) (JJ deep) (JJ convolutional) (JJ neural) (NNS networks)) (PP (IN at) (NP (NN scale))))))))))))) (. .))
(S (NP (PRP$ Our) (JJ main) (NNS contributions)) (VP (VBP are) (: :) (NP (NP (NP (LST (-LRB- -LRB-) (NN i) (-RRB- -RRB-)) (NP (DT a) (JJ loose) (NN coupling))) (PP (IN of) (NP (NP (NNP RISC-V) (NNS cores)) (CC and) (NP (NNP NTX) (NNS co-processors)))) (VP (VBG reducing) (NP (VBG offloading) (JJ overhead)) (PP (IN by) (NP (CD 7x))) (PP (IN over) (NP (RB previously) (VBN published) (NNS results))))) (: ;) (NP (PRN (-LRB- -LRB-) (NN ii) (-RRB- -RRB-)) (NP (NP (DT an) (JJ optimized) (NNP IEEE754) (NN compliant) (NNS data) (NN path)) (PP (IN for) (NP (NP (JJ fast) (NN high-precision) (NNS convolutions)) (CC and) (NP (JJ gradient) (NN propagation)))))) (: ;) (NP (NP (PRN (-LRB- -LRB-) (NN iii) (-RRB- -RRB-)) (NP (NN evaluation))) (PP (IN of) (NP (NP (JJ near-memory) (VBG computing)) (PP (IN with) (NP (NP (NNP NTX)) (VP (VBD embedded) (PP (IN into) (NP (NP (JJ residual) (NN area)) (PP (IN on) (NP (NP (DT the) (NNP Logic) (NNP Base) (NN die)) (PP (IN of) (NP (DT a) (NNP Hybrid) (NNP Memory) (NNP Cube))))))))))))) (: ;) (CC and) (NP (LST (-LRB- -LRB-) (NN iv) (-RRB- -RRB-)) (NP (NP (DT a) (NN scaling) (NN analysis)) (PP (TO to) (NP (NP (NNS meshes)) (PP (IN of) (NP (NNP HMCs))) (PP (IN in) (NP (DT a) (NN data) (NN center) (NN scenario))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (NP (NP (SBAR (DT a) (QP (CD 2.7x)))) (NN energy) (NN efficiency) (NN improvement)) (PP (IN of) (NP (NNP NTX))) (PP (IN over) (NP (JJ contemporary) (NNP GPUs))) (PP (IN at) (NP (QP (CD 4.4x)) (JJR less) (JJ silicon) (NN area)))) (, ,) (CC and) (NP (NP (DT a) (JJ compute) (NN performance)) (PP (IN of) (NP (CD 1.2) (NNP Tflop/s))) (PP (IN for) (S (VP (VBG training) (NP (JJ large) (JJ state-of-the-art) (NNS networks)) (PP (IN with) (NP (JJ full) (JJ floating-point) (NN precision))))))))) (. .))
(S (PP (IN At) (NP (DT the) (NNS data) (NN center) (NN scale))) (, ,) (NP (NP (DT a) (NN mesh)) (PP (IN of) (NP (NNP NTX)))) (VP (NNS achieves) (NP (ADJP (QP (IN above) (CD 95)) (NN %)) (NN parallel) (CC and) (NN energy) (NN efficiency)) (, ,) (SBAR (IN while) (S (VP (VBG providing) (NP (NP (CD 2.1x) (NN energy) (NNS savings)) (CC or) (NP (NP (CD 3.1x) (NN performance) (NN improvement)) (PP (IN over) (NP (DT a) (JJ GPU-based) (NN system))))))))) (. .))
