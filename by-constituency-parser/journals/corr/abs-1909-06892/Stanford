(S (NP (NP (DT The) (NN use)) (PP (IN of) (NP (JJR lower) (NN precision)))) (VP (VBZ has) (VP (VBN emerged) (PP (IN as) (NP (NP (DT a) (JJ popular) (NN technique) (S (VP (TO to) (VP (VB optimize) (S (NP (DT the)) (VP (VB compute))))))) (CC and) (NP (NP (NN storage) (NNS requirements)) (PP (IN of) (NP (NP (JJ complex) (JJ Deep) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-)))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (NN quest)) (PP (IN for) (NP (JJR lower) (NN precision))))) (, ,) (NP (JJ recent) (NNS studies)) (VP (VBP have) (VP (VBN shown) (SBAR (IN that) (S (NP (NP (JJ ternary) (NNS DNNs)) (-LRB- -LRB-) (SBAR (WHNP (WDT which)) (S (VP (VBP represent) (NP (NNS weights) (CC and) (NNS activations)) (PP (IN by) (NP (VBN signed) (JJ ternary) (NNS values)))))) (-RRB- -RRB-)) (VP (VBP represent) (NP (DT a) (JJ promising) (JJ sweet) (NN spot)) (, ,) (S (VP (VBG achieving) (NP (NN accuracy) (NN close)) (PP (IN to) (NP (NML (JJ full) (HYPH -) (NN precision)) (NNS networks))) (PP (IN on) (NP (JJ complex) (NNS tasks)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NNP TiM) (HYPH -) (NNP DNN)) (, ,) (NP (NP (DT a) (JJ programmable) (NML (PP (IN in) (HYPH -) (NP (NN memory)))) (NN accelerator)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADVP (RB specifically)) (VP (VBN designed) (S (VP (TO to) (VP (VB execute) (NP (JJ ternary) (NNS DNNs)))))))))))) (. .))
(S (NP (NNP TiM) (HYPH -) (NNP DNN)) (VP (VBZ supports) (NP (NP (JJ various) (JJ ternary) (NNS representations)) (PP (VBG including) (NP (NP (NP (JJ unweighted)) (-LRB- {) (NP (HYPH -) (NN 1,0,1)) (-RRB- })) (, ,) (NP (NP (NP (JJ symmetric)) (VP (VBN weighted))) (-LRB- {) (NP (PP (HYPH -) (NP (DT a) (NN ,0))) (, ,) (NP (DT a))) (-RRB- })) (, ,) (CC and) (NP (NP (NP (NP (JJ asymmetric)) (VP (VBN weighted))) (-LRB- {) (NP (PP (HYPH -) (NP (DT a) (NN ,0))) (, ,) (NN b)) (-RRB- })) (NP (JJ ternary) (NNS systems))))))) (. .))
(S (NP (NP (DT The) (NN building) (NNS blocks)) (PP (IN of) (NP (NNP TiM) (HYPH -) (NNP DNN)))) (VP (VBP are) (NP (NP (NNP TiM) (NNS tiles)) (: --) (NP (NP (NP (JJ specialized) (NN memory) (NNS arrays)) (SBAR (WHNP (WDT that)) (S (VP (VBP perform) (ADVP (RB massively)) (ADJP (JJ parallel)))))) (VP (VBN signed) (NP (NN ternary) (NML (NN vector) (HYPH -) (NN matrix)) (NNS multiplications)) (PP (IN with) (NP (DT a) (JJ single) (NN access))))))) (. .))
(S (NP (NNP TiM) (NNS tiles)) (VP (VBP are) (PP (IN in) (NP (NP (NN turn)) (VP (VBN composed) (PP (IN of) (NP (NP (NP (NNP Ternary) (NNP Processing) (NNS Cells)) (-LRB- -LRB-) (NP (NNS TPCs)) (-RRB- -RRB-)) (, ,) (NP (NP (NN bit) (HYPH -) (NNS cells)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP function) (PP (IN as) (NP (DT both) (JJ ternary) (NN storage) (NNS units)))) (CC and) (VP (VBD signed) (NP (JJ ternary) (NN multiplication) (NNS units))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NP (DT an) (NN implementation)) (PP (IN of) (NP (NNP TiM) (HYPH -) (NNP DNN)))) (PP (IN in) (NP (NP (JJ 32nm) (NN technology)) (VP (VBG using) (NP (NP (DT an) (JJ architectural) (NN simulator)) (VP (VBN calibrated) (PP (IN with) (NP (NP (NN SPICE) (NNS simulations)) (CC and) (NP (NN RTL) (NN synthesis)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NP (NNP TiM) (HYPH -) (NNP DNN)) (PP (IN across) (NP (NP (DT a) (NN suite)) (PP (IN of) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN DNN) (NNS benchmarks))))) (PP (VBG including) (NP (CC both) (NP (JJ deep) (ADJP (JJ convolutional) (CC and) (JJ recurrent)) (JJ neural) (NNS networks)))))) (. .))
(SINV (S (NP (NP (DT A) (NML (CD 32) (HYPH -) (NN tile)) (NN instance)) (PP (IN of) (NP (NNP TiM) (HYPH -) (NNP DNN)))) (VP (VBZ achieves) (NP (NP (DT a) (NN peak) (NN performance)) (PP (IN of) (NP (NP (CD 114) (NNS TOPs)) (PP (SYM /) (NP (NN s)))))))) (, ,) (VP (VP (VBZ consumes) (NP (CD 0.9) (JJ W) (NN power))) (, ,) (CC and) (VP (VBZ occupies))) (NP (CD 1.96) (NML (NN mm2) (NN chip)) (NN area)) (, ,) (S (VP (VBG representing) (NP (DT a) (NML (NN 300X) (CC and) (NN 388X)) (NN improvement)) (PP (IN in) (NP (NP (NN TOPS) (HYPH /) (NN W)) (CC and) (NP (NN TOPS) (HYPH /) (NN mm2)))) (, ,) (ADVP (RB respectively)) (, ,) (PP (VBN compared) (PP (IN to) (NP (DT an) (NNP NVIDIA) (NNP Tesla) (NNP V100) (NNP GPU)))))) (. .))
(S (PP (IN In) (NP (NP (NN comparison)) (PP (IN to) (NP (JJ specialized) (NN DNN) (NNS accelerators))))) (, ,) (NP (NNP TiM) (HYPH -) (NNP DNN)) (VP (VBZ achieves) (NP (NML (NML (NN 55X) (HYPH -) (NN 240X)) (CC and) (NML (NN 160X) (HYPH -) (NN 291X))) (NN improvement)) (PP (IN in) (NP (NP (NN TOPS) (HYPH /) (NN W)) (CC and) (NP (NN TOPS) (HYPH /) (NN mm2)))) (, ,) (ADVP (RB respectively))) (. .))
(S (ADVP (RB Finally)) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBN compared) (PP (IN to) (NP (NP (DT a) (ADJP (RB well) (HYPH -) (VBN optimized)) (NML (PP (IN near) (HYPH -) (NP (NN memory)))) (NN accelerator)) (PP (IN for) (NP (JJ ternary) (NNS DNNs)))))))) (, ,) (NP (NNP TiM) (HYPH -) (NNP DNN)) (VP (VBZ demonstrates) (NP (NP (QP (CD 3.9x) (HYPH -) (CD 4.7)) (SYM x) (NN improvement)) (PP (IN in) (NP (NML (NN system) (HYPH -) (NN level)) (NML (NML (NN energy)) (CC and) (NML (NML (NN 3.2x) (HYPH -) (CD 4.2)) (PP (SYM x) (NP (NN speedup)))))))) (, ,) (S (VP (VBG underscoring) (NP (NP (DT the) (NN potential)) (PP (IN of) (NP (NML (PP (IN in) (HYPH -) (NP (NN memory)))) (NN computing)))) (PP (IN for) (NP (JJ ternary) (NNS DNNs)))))) (. .))
