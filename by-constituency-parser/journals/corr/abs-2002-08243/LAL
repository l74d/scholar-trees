(S (NP (NN Policy) (NN optimization) (NNS methods)) (VP (VBP are) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (ADJP (RBS most) (RB widely) (JJ used)) (NNS classes)) (PP (IN of) (NP (NNP Reinforcement) (NNP Learning) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)) (NN algorithms))))))) (. .))
(S (ADVP (RB Yet)) (, ,) (ADVP (RB so) (RB far)) (, ,) (NP (JJ such) (NNS methods)) (VP (VBP have) (VP (VBN been) (ADVP (RB mostly)) (VP (VBN analyzed) (PP (IN from) (NP (DT an) (NN optimization) (NN perspective))) (, ,) (PP (PP (IN without) (S (VP (VBG addressing) (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (NN exploration))))))) (, ,) (CC or) (PP (IN by) (S (VP (VBG making) (NP (NP (JJ strong) (NNS assumptions)) (PP (IN on) (NP (NP (DT the) (NN interaction)) (PP (IN with) (NP (DT the) (NN environment))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP consider) (NP (NP (JJ model-based) (NNP RL)) (PP (IN in) (NP (NP (DT the) (JJ tabular) (JJ finite-horizon) (NNP MDP) (VBG setting)) (PP (IN with) (NP (NP (JJ unknown) (NNS transitions)) (CC and) (NP (NN bandit) (NN feedback)))))))) (. .))
(S (ADVP (RB Interestingly)) (, ,) (NP (DT this) (NN result)) (VP (VBZ matches) (NP (NP (JJ previous) (NNS bounds)) (VP (VBN derived) (PP (IN for) (NP (DT the) (NN bandit) (NN feedback) (NN case))))) (, ,) (PP (ADVP (RB yet)) (PP (IN with) (NP (JJ known) (NNS transitions))))) (. .))
(S (PP (TO To) (NP (NP (DT the) (JJS best)) (PP (IN of) (NP (PRP$ our) (NN knowledge))))) (, ,) (NP (DT the) (CD two) (NNS results)) (VP (VBP are) (NP (NP (DT the) (JJ first) (JJ sub-linear) (NN regret) (NNS bounds)) (VP (VBN obtained) (PP (IN for) (NP (NP (NN policy) (NN optimization) (IN algorithms)) (PP (IN with) (NP (NP (JJ unknown) (NNS transitions)) (CC and) (NP (NN bandit) (NN feedback))))))))) (. .))
