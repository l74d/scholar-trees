(S (NP (NP (NNP Reinforcement) (NNP Learning)) (, ,) (NP (NP (DT a) (NN machine) (NN learning) (NN framework)) (PP (IN for) (S (VP (VBG training) (NP (DT an) (JJ autonomous) (NN agent)) (PP (VBN based) (PP (IN on) (NP (NNS rewards)))))))) (, ,)) (VP (VBZ has) (VP (VBN shown) (NP (JJ outstanding) (NNS results)) (PP (IN in) (NP (JJ various) (NNS domains))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBN known) (SBAR (IN that) (S (S (VP (VBG learning) (NP (DT a) (JJ good) (NN policy)))) (VP (VBZ is) (ADJP (JJ difficult)) (PP (IN in) (NP (NP (DT a) (NN domain)) (SBAR (WHADVP (WRB where)) (S (NP (NNS rewards)) (VP (VBP are) (ADJP (JJ rare)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (NN method)) (, ,) (NP (NP (JJ optimistic) (NN proximal) (NN policy) (NN optimization)) (PRN (-LRB- -LRB-) (NP (NNP OPPO)) (-RRB- -RRB-))) (SBAR (S (VP (TO to) (VP (VB alleviate) (NP (DT this) (NN difficulty)))))))) (. .))
(S (NP (NNP OPPO)) (VP (VP (VBZ considers) (NP (NP (DT the) (NN uncertainty)) (PP (IN of) (NP (DT the) (JJ estimated) (JJ total) (NN return))))) (CC and) (VP (ADVP (RB optimistically)) (VBZ evaluates) (NP (DT the) (NN policy)) (PP (VBN based) (PP (IN on) (NP (DT that) (NN amount)))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP OPPO)) (VP (VBZ outperforms) (NP (DT the) (VBG existing) (NNS methods)) (PP (IN in) (NP (DT a) (JJ tabular) (NN task))))))) (. .))
