(S (NP (PRP We)) (VP (VBP study) (NP (NP (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-))) (PP (IN in) (NP (NP (ADJP (JJ high) (JJ dimensional)) (JJ episodic) (NNP Markov) (NN decision) (NNS processes)) (-LRB- -LRB-) (NP (NN MDP)) (-RRB- -RRB-))))) (. .))
(S (NP (PRP We)) (VP (VBP consider) (NP (NP (ADJP (NN value) (HYPH -) (VBN based)) (NNP RL)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (JJ optimal) (NN Q) (HYPH -) (NN value)) (VP (VBZ is) (NP (ADJP (NP (NP (DT a) (JJ linear) (NN function)) (PP (IN of) (NP (NN d)))) (HYPH -) (JJ dimensional)) (NML (NN state) (HYPH -) (NN action)) (NN feature) (NN representation))))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (PP (IN in) (NP (NML (JJ deep) (HYPH -) (NN Q)) (NNS networks) (PRN (-LRB- -LRB-) (NP (NN DQN)) (-RRB- -RRB-)))) (, ,) (NP (DT the) (NN Q) (HYPH -) (NN value)) (VP (VBZ is) (NP (NP (DT a) (JJ linear) (NN function)) (PP (IN of) (NP (DT the) (NN feature) (NN representation) (NN layer) (PRN (-LRB- -LRB-) (NP (NN output) (NN layer)) (-RRB- -RRB-)))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (CD two) (NNS algorithms)) (, ,) (NP (NP (CD one)) (PP (VBN based) (PP (IN on) (NP (NN optimism))))) (, ,) (NP (NN LINUCB)) (, ,) (CC and) (NP (NP (DT another)) (PP (VBN based) (PP (IN on) (NP (NP (JJ posterior) (NN sampling)) (, ,) (NP (NNP LINPSRL)))))))) (. .))
(S (NP (PRP We)) (VP (VBP guarantee) (NP (ADJP (JJ frequentist) (CC and) (JJ Bayesian)) (NN regret)) (NP (NP (JJ upper) (NNS bounds)) (PP (IN of) (NP (NP (NP (NN O) (PRN (-LRB- -LRB-) (NP (NN d) (NML (NN sqrt) (-LRB- {) (NN T) (-RRB- }))) (-RRB- -RRB-))) (PP (IN for) (NP (DT these) (CD two) (NNS algorithms)))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NN T)) (VP (VBZ is) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS episodes))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP extend) (NP (DT these) (NNS methods)) (S (VP (TO to) (ADVP (RB deep)) (VP (VB RL) (CC and) (VB propose) (NP (NP (NML (JJ Bayesian) (JJ deep) (NN Q)) (HYPH -) (NNS networks)) (-LRB- -LRB-) (NP (NN BDQN)) (-RRB- -RRB-) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NP (DT an) (JJ efficient) (NNP Thompson) (NN sampling) (NN algorithm)) (PP (IN for) (NP (ADJP (JJ high) (JJ dimensional)) (NN RL)))))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP deploy) (NP (DT the) (NML (NML (JJ double) (NN DQN)) (-LRB- -LRB-) (NML (NN DDQN)) (-RRB- -RRB-)) (NN approach)))) (, ,) (CC and) (S (PP (RB instead) (IN of) (S (VP (VBG learning) (NP (NP (DT the) (JJ last) (NN layer)) (PP (IN of) (NP (NP (NN Q) (HYPH -) (NN network)) (VP (VBG using) (NP (JJ linear) (NN regression))))))))) (, ,) (NP (PRP we)) (VP (VBP use) (NP (NP (NML (JJ Bayesian) (JJ linear)) (NN regression)) (, ,) (VP (VBG resulting) (PP (IN in) (NP (NP (DT an)) (VP (VBN approximated) (S (ADJP (JJ posterior))) (PP (IN over) (NP (NN Q) (HYPH -) (NN function)))))))))) (. .))
(S (NP (DT This)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (ADVP (RB directly)) (VP (VP (VB incorporate) (NP (NP (DT the) (NN uncertainty)) (PP (IN over) (NP (DT the) (NML (NN Q) (HYPH -) (NN function)))))) (CC and) (VP (VB deploy) (NP (NNP Thompson) (NN sampling)) (PP (IN on) (NP (NP (DT the) (PRN (S (VP (VBN learned)))) (JJ posterior) (NN distribution)) (VP (VBG resulting) (PP (IN in) (NP (JJ efficient) (NML (NN exploration) (HYPH /) (NN exploitation)) (NN trade) (HYPH -) (NN off))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB empirically)) (VP (VB study) (NP (NP (DT the) (NN behavior)) (PP (IN of) (NP (NNP BDQN)))) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNP Atari) (NNS games)))))) (. .))
(S (SBAR (IN Since) (S (NP (NNP BDQN)) (VP (VBZ carries) (PRT (RP out)) (NP (ADJP (RBR more) (JJ efficient)) (NN exploration) (CC and) (NN exploitation))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB reach) (NP (JJR higher) (NN return)) (ADVP (RB substantially) (RBR faster)) (PP (VBN compared) (PP (IN to) (NP (NNP DDQN))))))))) (. .))
