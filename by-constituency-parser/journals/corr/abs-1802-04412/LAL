(S (NP (PRP We)) (VP (VBP study) (NP (NP (JJ reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-))) (PP (IN in) (NP (NP (JJ high) (JJ dimensional) (JJ episodic) (NNP Markov) (NN decision) (NNS processes)) (PRN (-LRB- -LRB-) (NP (NNP MDP)) (-RRB- -RRB-))))) (. .))
(S (NP (PRP We)) (VP (VBP consider) (NP (JJ value-based) (NNP RL)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (JJ optimal) (NNP Q-value)) (VP (VBZ is) (NP (NP (DT a) (JJ linear) (NN function)) (PP (IN of) (NP (JJ d-dimensional) (JJ state-action) (NN feature) (NN representation)))))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (PP (IN in) (NP (NP (JJ deep-Q) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP DQN)) (-RRB- -RRB-)))) (, ,) (NP (DT the) (NNP Q-value)) (VP (VBZ is) (NP (NP (DT a) (JJ linear) (NN function)) (PP (IN of) (NP (NP (DT the) (NN feature) (NN representation) (NN layer)) (PRN (-LRB- -LRB-) (NP (NN output) (NN layer)) (-RRB- -RRB-)))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (CD two) (NN algorithms)) (, ,) (NP (NP (NP (NP (CD one)) (VP (VBN based) (PP (IN on) (NP (NN optimism))))) (, ,) (NP (NNP LINUCB))) (, ,) (CC and) (NP (NP (NP (DT another)) (VP (VBN based) (PP (IN on) (NP (JJ posterior) (NN sampling))))) (, ,) (NP (NNP LINPSRL)))))) (. .))
(S (NP (PRP We)) (VP (VBP guarantee) (NP (NP (JJ frequentist) (CC and) (JJ Bayesian) (NN regret) (JJ upper) (NNS bounds)) (PP (IN of) (NP (NP (NNP O)) (PRN (-LRB- -LRB-) (NP (NP (JJ d) (NN sqrt)) (PRN (-LRB- -LCB-) (NP (NNP T)) (-RRB- -RCB-))) (-RRB- -RRB-)))) (PP (IN for) (NP (NP (DT these) (CD two) (NN algorithms)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NNP T)) (VP (VBZ is) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS episodes))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP extend) (NP (DT these) (NNS methods)) (PP (TO to) (NP (VB deep) (NNP RL)))) (CC and) (VP (JJ propose) (NP (NP (JJ Bayesian) (JJ deep) (NNS Q-networks)) (PRN (-LRB- -LRB-) (NP (NNP BDQN)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NP (DT an) (JJ efficient) (NNP Thompson) (VBG sampling) (NN algorithm)) (PP (IN for) (NP (ADJP (JJ high) (JJ dimensional)) (NNP RL)))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP deploy) (NP (DT the) (JJ double) (NNP DQN) (PRN (-LRB- -LRB-) (NNP DDQN) (-RRB- -RRB-)) (NN approach)))) (, ,) (CC and) (S (PP (RB instead) (IN of) (S (VP (VBG learning) (NP (NP (DT the) (JJ last) (NN layer)) (PP (IN of) (NP (NNP Q-network)))) (S (VP (VBG using) (NP (JJ linear) (NN regression))))))) (, ,) (NP (PRP we)) (VP (VBP use) (NP (JJ Bayesian) (JJ linear) (NN regression)) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (NP (DT an) (JJ approximated) (NN posterior)) (PP (IN over) (NP (NNP Q-function))))))))) (. .))
(S (NP (DT This)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VP (ADVP (RB directly)) (VB incorporate) (NP (NP (DT the) (NN uncertainty)) (PP (IN over) (NP (DT the) (NNP Q-function))))) (CC and) (VP (VB deploy) (NP (NNP Thompson) (VBG sampling)) (PP (IN on) (NP (DT the) (VBN learned) (JJ posterior) (NN distribution)))) (S (VP (VBG resulting) (PP (IN in) (NP (JJ efficient) (NN exploration/exploitation) (NN trade-off))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB empirically)) (VBP study) (NP (NP (DT the) (NN behavior)) (PP (IN of) (NP (NNP BDQN))) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNP Atari) (NNS games))))))) (. .))
(S (SBAR (IN Since) (S (NP (NNP BDQN)) (VP (VBZ carries) (PRT (RP out)) (NP (ADJP (RBR more) (JJ efficient)) (NN exploration) (CC and) (NN exploitation))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB reach) (NP (JJR higher) (NN return)) (ADVP (RB substantially) (RBR faster)) (PP (VBN compared) (PP (TO to) (NP (NNP DDQN))))))))) (. .))
