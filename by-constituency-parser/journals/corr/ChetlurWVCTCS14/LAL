(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT a) (NN library)) (PP (IN of) (NP (NP (JJ efficient) (NNS implementations)) (PP (IN of) (NP (JJ deep) (NN learning) (NNS primitives))))))) (. .))
(S (S (NP (NNP Deep) (NN learning) (NNS workloads)) (VP (VBP are) (ADJP (RB computationally) (JJ intensive)))) (, ,) (CC and) (S (S (VP (VBG optimizing) (NP (PRP$ their) (NNS kernels)))) (VP (VBZ is) (ADJP (JJ difficult) (CC and) (JJ time-consuming)))) (. .))
(S (SBAR (IN As) (S (NP (JJ parallel) (NNS architectures)) (VP (VBP evolve)))) (, ,) (NP (NNS kernels)) (VP (MD must) (VP (VB be) (VP (VP (VBN reoptimized)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (S (VP (S (VP (VBG maintaining) (NP (NNS codebases)))) (ADJP (JJ difficult)))) (PP (IN over) (NP (NN time)))))))))) (. .))
(S (NP (JJ Similar) (NNS issues)) (VP (VBP have) (ADVP (RB long)) (VP (VBN been) (VP (VBN addressed) (PP (IN in) (NP (DT the) (NNP HPC) (NN community))) (PP (IN by) (NP (NP (NNS libraries)) (PP (JJ such) (IN as) (NP (NP (DT the) (NNP Basic) (NNP Linear) (NNP Algebra) (NNP Subroutines)) (PRN (-LRB- -LRB-) (NP (NNP BLAS)) (-RRB- -RRB-))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (EX there)) (VP (VBZ is) (NP (NP (DT no) (JJ analogous) (NN library)) (PP (IN for) (NP (JJ deep) (NN learning))))) (. .))
(S (PP (IN Without) (NP (PDT such) (DT a) (NN library))) (, ,) (NP (NP (NNS researchers)) (VP (VBG implementing) (NP (JJ deep) (NN learning) (NNS workloads)) (PP (IN on) (NP (JJ parallel) (NNS processors))))) (VP (MD must) (VP (VB create) (CC and) (VB optimize) (NP (NP (PRP$ their) (JJ own) (NNS implementations)) (PP (IN of) (NP (DT the) (JJ main) (JJ computational) (NNS kernels)))))) (, ,) (CC and) (S (NP (DT this) (NN work)) (VP (MD must) (VP (VB be) (VP (VBN repeated) (SBAR (IN as) (S (NP (JJ new) (JJ parallel) (NNS processors)) (VP (VBP emerge)))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this) (NN problem))))) (, ,) (NP (PRP we)) (VP (VBP have) (VP (VBN created) (NP (NP (DT a) (JJ library)) (ADJP (JJ similar) (PP (IN in) (NP (NN intent))) (PP (TO to) (NP (NNP BLAS)))) (, ,) (PP (IN with) (NP (NP (JJ optimized) (NNS routines)) (PP (IN for) (NP (JJ deep) (NN learning) (NNS workloads)))))))) (. .))
(S (NP (PRP$ Our) (NN implementation)) (VP (VBZ contains) (NP (NP (NNS routines)) (PP (IN for) (NP (NNP GPUs)))) (, ,) (SBAR (IN although) (S (ADVP (RB similarly) (PP (TO to) (NP (DT the) (NNP BLAS) (NN library)))) (, ,) (NP (DT these) (NNS routines)) (VP (MD could) (VP (VB be) (VP (VBN implemented) (PP (IN for) (NP (JJ other) (NNS platforms))))))))) (. .))
(S (NP (DT The) (NN library)) (VP (VP (VBZ is) (ADJP (JJ easy) (SBAR (S (VP (TO to) (VP (VB integrate) (PP (IN into) (NP (VBG existing) (NNS frameworks))))))))) (, ,) (CC and) (VP (VBZ provides) (NP (JJ optimized) (NN performance) (CC and) (NN memory) (NN usage)))) (. .))
(S (PP (IN For) (NP (NN example))) (, ,) (S (VP (VBG integrating) (NP (NN cuDNN)) (PP (IN into) (NP (NP (NNP Caffe)) (, ,) (NP (NP (DT a) (JJ popular) (NN framework)) (PP (IN for) (NP (JJ convolutional) (NNS networks)))) (, ,))))) (VP (NNS improves) (NP (NN performance)) (PP (IN by) (NP (CD 36) (NN %))) (PP (IN on) (NP (DT a) (JJ standard) (NN model))) (SBAR (IN while) (S (ADVP (RB also)) (VP (VBG reducing) (NP (NN memory) (NN consumption)))))) (. .))
