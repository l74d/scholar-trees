(S (NP (JJ Modern) (NN machine) (NN learning)) (VP (VBZ focuses) (PP (IN on) (NP (NP (ADJP (RB highly) (JJ expressive)) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB fit) (CC or) (VB interpolate) (NP (DT the) (NNS data)) (ADVP (RB completely))))))))))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (NML (CD zero) (NN training)) (NN loss)))))) (. .))
(S (PP (IN For) (NP (JJ such) (NNS models))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (JJ stochastic) (NNS gradients)) (PP (IN of) (NP (JJ common) (NN loss) (NNS functions)))) (VP (VBP satisfy) (NP (DT a) (JJ strong) (NN growth) (NN condition)))))) (. .))
(S (PP (IN Under) (NP (DT this) (NN condition))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (NP (NP (JJ constant) (NML (NN step) (HYPH -) (NN size)) (JJ stochastic) (NN gradient) (NN descent)) (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)) (PP (IN with) (NP (NNP Nesterov) (NN acceleration)))) (VP (VBZ matches) (NP (NP (DT the) (NN convergence) (NN rate)) (PP (IN of) (NP (NP (DT the) (JJ deterministic) (JJ accelerated) (NN method)) (PP (IN for) (NP (NP (DT both) (NN convex)) (CC and) (NP (ADJP (RB strongly) (HYPH -) (JJ convex)) (NNS functions))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this) (NN condition)) (VP (VBZ implies) (SBAR (IN that) (S (NP (NNP SGD)) (VP (MD can) (VP (VB find) (NP (NP (DT a) (NML (JJ first) (HYPH -) (NN order)) (JJ stationary) (NN point)) (PP (IN as) (NP (ADJP (ADVP (RB efficiently) (RB as)) (JJ full)) (NN gradient) (NN descent)))) (PP (IN in) (NP (JJ non-convex) (NNS settings))))))))))) (. .))
(S (PP (IN Under) (NP (NN interpolation))) (, ,) (NP (PRP we)) (ADVP (RB further)) (VP (VBP show) (SBAR (IN that) (S (NP (DT all) (JJ smooth) (NN loss)) (VP (VBZ functions) (SBAR (IN with) (S (NP (DT a) (NML (NN finite) (HYPH -) (NN sum)) (NN structure)) (VP (VBP satisfy) (NP (DT a) (JJR weaker) (NN growth) (NN condition))))))))) (. .))
(S (PP (VBN Given) (NP (DT this) (JJR weaker) (NN condition))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (NP (NNP SGD)) (PP (IN with) (NP (DT a) (JJ constant) (NN step) (HYPH -) (NN size)))) (VP (VBZ attains) (NP (DT the) (JJ deterministic) (NN convergence) (NN rate)) (PP (IN in) (NP (CC both) (NP (DT the) (ADJP (RB strongly) (HYPH -) (JJ convex))) (CC and) (NP (JJ convex) (NNS settings)))))))) (. .))
(S (PP (IN Under) (NP (JJ additional) (NNS assumptions))) (, ,) (NP (DT the) (JJ above) (NNS results)) (VP (VBP enable) (S (NP (PRP us)) (VP (TO to) (VP (VB prove) (NP (NP (DT an) (NN O) (-LRB- -LRB-) (NP (CD 1) (SYM /) (CD k) (SYM ^) (CD 2)) (-RRB- -RRB-) (NN mistake)) (VP (VBN bound) (PP (IN for) (NP (NP (CD k) (NNS iterations)) (PP (IN of) (NP (DT a) (JJ stochastic) (NN perceptron) (NN algorithm))))) (S (VP (VBG using) (NP (DT the) (ADJP (JJ squared) (HYPH -) (NN hinge)) (NN loss)))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP validate) (NP (PRP$ our) (JJ theoretical) (NNS findings)) (PP (IN with) (NP (NP (NNS experiments)) (PP (IN on) (NP (NML (JJ synthetic) (CC and) (JJ real)) (NNS datasets)))))) (. .))
