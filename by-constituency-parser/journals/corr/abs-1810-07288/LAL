(S (NP (JJ Modern) (NN machine) (NN learning)) (VP (VBZ focuses) (PP (IN on) (NP (NP (ADJP (RB highly) (JJ expressive)) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB fit) (CC or) (VB interpolate) (NP (DT the) (NN data)) (ADVP (RB completely)) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (CD zero) (NN training) (NN loss))))))))))))))) (. .))
(S (PP (IN For) (NP (JJ such) (NNS models))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (JJ stochastic) (NNS gradients)) (PP (IN of) (NP (JJ common) (NN loss) (NNS functions)))) (VP (VBP satisfy) (NP (DT a) (JJ strong) (NN growth) (NN condition)))))) (. .))
(S (PP (IN Under) (NP (DT this) (NN condition))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (DT that) (S (NP (NP (JJ constant) (JJ step-size) (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)) (PP (IN with) (NP (NNP Nesterov) (NN acceleration)))) (VP (VBZ matches) (NP (NP (DT the) (NN convergence) (NN rate)) (PP (IN of) (NP (DT the) (JJ deterministic) (VBD accelerated) (NN method)))) (PP (IN for) (NP (ADJP (DT both) (NNS convex) (CC and) (JJ strongly-convex)) (NNS functions))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this) (NN condition)) (VP (VBZ implies) (SBAR (IN that) (S (NP (NNP SGD)) (VP (MD can) (VP (VB find) (NP (DT a) (JJ first-order) (JJ stationary) (NN point)) (ADVP (ADVP (RB as) (RB efficiently)) (PP (IN as) (NP (JJ full) (NN gradient) (NN descent)))) (PP (IN in) (NP (JJ non-convex) (NNS settings))))))))))) (. .))
(S (PP (IN Under) (NP (NN interpolation))) (, ,) (NP (PRP we)) (ADVP (VBP further)) (VP (VB show) (SBAR (IN that) (S (NP (NP (DT all) (JJ smooth) (NN loss) (NNS functions)) (PP (IN with) (NP (DT a) (JJ finite-sum) (NN structure)))) (VP (VBZ satisfy) (NP (DT a) (JJR weaker) (NN growth) (NN condition)))))) (. .))
(S (PP (VBN Given) (NP (DT this) (JJR weaker) (NN condition))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (NP (NNP SGD)) (PP (IN with) (NP (DT a) (JJ constant) (NN step-size)))) (VP (VBZ attains) (NP (DT the) (JJ deterministic) (NN convergence) (NN rate)) (PP (IN in) (NP (DT both) (DT the) (ADJP (NN strongly-convex) (CC and) (JJ convex)) (NNS settings))))))) (. .))
(S (PP (IN Under) (NP (JJ additional) (NNS assumptions))) (, ,) (NP (DT the) (JJ above) (NNS results)) (VP (JJ enable) (S (NP (PRP us)) (VP (TO to) (VP (VB prove) (NP (NP (DT an) (NNP O) (PRN (-LRB- -LRB-) (CD 1/k^2) (-RRB- -RRB-)) (NN mistake)) (VP (NN bound) (PP (IN for) (NP (NP (JJ k) (NNS iterations)) (PP (IN of) (NP (NP (DT a) (JJ stochastic) (NN perceptron) (NN algorithm)) (VP (VBG using) (NP (DT the) (JJ squared-hinge) (NN loss))))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP validate) (NP (PRP$ our) (JJ theoretical) (NNS findings)) (PP (IN with) (NP (NP (NNS experiments)) (PP (IN on) (NP (ADJP (JJ synthetic) (CC and) (JJ real)) (NNS datasets)))))) (. .))
