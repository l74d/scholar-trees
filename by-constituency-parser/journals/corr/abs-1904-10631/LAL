(S (NP (NN Memory)) (VP (VBZ is) (ADVP (RB increasingly) (RB often)) (NP (DT the) (NN bottleneck)) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (JJ neural) (NN network) (NNS models)))))) (. .))
(S (PP (IN Despite) (NP (DT this))) (, ,) (NP (NP (NNS techniques)) (SBAR (S (VP (TO to) (VP (VB lower) (NP (NP (DT the) (JJ overall) (NN memory) (NNS requirements)) (PP (IN of) (NP (NN training))))))))) (VP (VBP have) (VP (VBN been) (ADJP (ADVP (RBR less) (RB widely)) (VBN studied)) (PP (VBN compared) (PP (TO to) (NP (NP (DT the) (JJ extensive) (NN literature)) (PP (IN on) (S (VP (VBG reducing) (NP (NP (DT the) (NN memory) (NNS requirements)) (PP (IN of) (NP (NN inference)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP study) (NP (NP (DT a) (JJ fundamental) (NN question)) (: :) (SBAR (WHNP (WHADJP (WRB How) (JJ much)) (NN memory)) (S (VP (VBZ is) (ADVP (RB actually)) (VP (VBN needed) (S (VP (TO to) (VP (VB train) (NP (DT a) (JJ neural) (NN network))))))))))) (. ?))
(S (S (VP (TO To) (VP (VB answer) (NP (DT this) (NN question))))) (, ,) (NP (PRP we)) (VP (VP (VBP profile) (NP (NP (DT the) (JJ overall) (NN memory) (NN usage)) (PP (IN of) (PP (VBG training) (PP (IN on) (NP (NP (CD two) (JJ representative) (JJ deep) (NN learning) (NNS benchmarks)) (: —) (NP (NP (NP (DT the) (NNP WideResNet) (NN model)) (PP (IN for) (NP (NN image) (NN classification)))) (CC and) (NP (NP (DT the) (NNP DynamicConv) (NNP Transformer) (NN model)) (PP (IN for) (NP (NN machine) (NN translation))))) (: —))))))) (CC and) (VP (ADVP (RB comprehensively)) (VB evaluate) (NP (NP (CD four) (NN standard) (NNS techniques)) (PP (IN for) (S (VP (VBG reducing) (NP (DT the) (NN training) (NN memory) (NNS requirements))))) (: :) (NP (LST (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (VP (VBG imposing) (NP (NN sparsity)) (PP (IN on) (NP (DT the) (NN model)))) (, ,) (SBAR (PRN (-LRB- -LRB-) (CD 2) (-RRB- -RRB-)) (S (VP (VBG using) (NP (JJ low) (NN precision))))) (, ,) (NP (PRN (-LRB- -LRB-) (CD 3) (-RRB- -RRB-)) (NP (NN microbatching))) (, ,) (CC and) (NP (PRN (-LRB- -LRB-) (CD 4) (-RRB- -RRB-)) (NP (NN gradient) (NN checkpointing))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP explore) (SBAR (WHADVP (WRB how)) (S (NP (NP (DT each)) (PP (IN of) (NP (DT these) (NNS techniques))) (PP (IN in) (NP (NN isolation)))) (VP (NNS affects) (NP (DT both) (NP (NP (DT the) (JJ peak) (NN memory) (NN usage)) (PP (IN of) (NP (NN training)))) (CC and) (NP (NP (DT the) (NN quality)) (PP (IN of) (NP (DT the) (NN end) (NN model))))))))) (, ,) (CC and) (VP (VB explore) (NP (NP (DT the) (NN memory) (, ,) (NN accuracy) (, ,) (CC and) (NN computation) (NNS tradeoffs)) (VP (VBD incurred) (SBAR (WHADVP (WRB when)) (S (VP (VBG combining) (NP (DT these) (NNS techniques))))))))) (. .))
(S (S (VP (VBG Using) (NP (NP (JJ appropriate) (NNS combinations)) (PP (IN of) (NP (DT these) (NNS techniques)))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (JJ possible)) (S (VP (TO to) (VP (VP (DT the) (VP (VB reduce) (NP (NP (DT the) (NN memory)) (VP (VBN required) (S (VP (TO to) (VP (VB train) (NP (DT a) (JJ WideResNet-28-2)) (PP (IN on) (NP (NN CIFAR-10)))))))) (PP (IN by) (NP (QP (IN up) (TO to) (CD 60.7x)))) (PP (IN with) (NP (NP (DT a) (ADJP (CD 0.4) (NN %)) (NN loss)) (PP (IN in) (NP (NN accuracy))))))) (, ,) (CC and) (VP (VB reduce) (NP (NP (DT the) (NN memory)) (VP (VBN required) (S (VP (TO to) (VP (VB train) (NP (DT a) (NNP DynamicConv) (NN model)) (PP (IN on) (NP (JJ IWSLT'14) (NAC (NNP German) (TO to) (VB English)) (NN translation)))))))) (PP (IN by) (NP (QP (IN up) (TO to) (CD 8.7x)))) (PP (IN with) (NP (NP (DT a) (NNP BLEU) (NN score) (NN drop)) (PP (IN of) (NP (CD 0.15))))))))))))) (. .))
