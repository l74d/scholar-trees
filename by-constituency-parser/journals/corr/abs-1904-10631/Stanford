(S (NP (NN Memory)) (VP (VBZ is) (ADVP (RB increasingly)) (ADVP (RB often) (NP (DT the) (NN bottleneck))) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (JJ neural) (NN network) (NNS models)))))) (. .))
(S (PP (IN Despite) (NP (DT this))) (, ,) (NP (NNS techniques) (S (VP (TO to) (VP (VB lower) (NP (NP (DT the) (JJ overall) (NN memory) (NNS requirements)) (PP (IN of) (NP (NN training)))))))) (VP (VBP have) (VP (VBN been) (ADVP (RBR less) (RB widely)) (VP (VBN studied) (PP (VBN compared) (PP (IN to) (NP (NP (DT the) (JJ extensive) (NN literature)) (PP (IN on) (S (VP (VBG reducing) (NP (NP (DT the) (NN memory) (NNS requirements)) (PP (IN of) (NP (NN inference))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP study) (NP (DT a) (JJ fundamental) (NN question)) (: :) (SBAR (WHADJP (WRB How) (JJ much)) (S (NP (NN memory)) (VP (VBZ is) (ADVP (RB actually)) (VP (VBN needed) (S (VP (TO to) (VP (VB train) (NP (DT a) (JJ neural) (NN network)))))))))) (. ?))
(S (S (VP (TO To) (VP (VB answer) (NP (DT this) (NN question))))) (, ,) (S (NP (PRP we)) (VP (VBP profile) (NP (NP (DT the) (JJ overall) (NN memory) (NN usage)) (PP (IN of) (NP (NN training)))) (PP (IN on) (NP (NP (NP (CD two) (JJ representative) (NML (JJ deep) (NN learning)) (NNS benchmarks)) (: --) (NP (NP (DT the) (NNP WideResNet) (NN model)) (PP (IN for) (NP (NN image) (NN classification))))) (CC and) (NP (NP (DT the) (NNP DynamicConv) (NNP Transformer) (NN model)) (PP (IN for) (NP (NN machine) (NN translation)))))))) (: --) (CC and) (S (ADVP (RB comprehensively)) (VP (VB evaluate) (NP (CD four) (JJ standard) (NNS techniques)) (PP (IN for) (S (VP (VBG reducing) (NP (DT the) (NML (NN training) (NN memory)) (NNS requirements))))) (: :) (S (S (LST (-LRB- -LRB-) (LS 1) (-RRB- -RRB-)) (VP (VBG imposing) (NP (NN sparsity)) (PP (IN on) (NP (DT the) (NN model))))) (, ,) (S (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (VP (VBG using) (NP (NP (JJ low) (NN precision)) (, ,) (NP (LST (-LRB- -LRB-) (LS 3) (-RRB- -RRB-)) (NP (NN microbatching))) (, ,) (CC and) (NP (LST (-LRB- -LRB-) (LS 4) (-RRB- -RRB-)) (NP (NN gradient) (NN checkpointing))))))))) (. .))
(S (NP (PRP We)) (VP (VBP explore) (SBAR (WHADVP (WRB how)) (S (NP (NP (DT each)) (PP (IN of) (NP (NP (DT these) (NNS techniques)) (PP (IN in) (NP (NN isolation)))))) (VP (VP (VBZ affects) (NP (CC both) (NP (NP (DT the) (NN peak) (NN memory) (NN usage)) (PP (IN of) (NP (NN training)))) (CC and) (NP (NP (DT the) (NN quality)) (PP (IN of) (NP (DT the) (NN end) (NN model)))))) (, ,) (CC and) (VP (VB explore) (NP (NP (DT the) (NML (NN memory) (, ,) (NN accuracy) (, ,) (CC and) (NN computation)) (NNS tradeoffs)) (VP (VBN incurred) (SBAR (WHADVP (WRB when)) (S (VP (VBG combining) (NP (DT these) (NNS techniques)))))))))))) (. .))
(S (S (VP (VBG Using) (NP (NP (JJ appropriate) (NNS combinations)) (PP (IN of) (NP (DT these) (NNS techniques)))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ possible) (PP (IN to) (NP (NP (DT the) (NML (S (VP (VP (VB reduce) (NP (NP (DT the) (NN memory)) (VP (VBN required) (S (VP (TO to) (VP (VB train) (NP (DT a) (NNP WideResNet) (NN -28-2)) (PP (IN on) (NP (NN CIFAR) (HYPH -) (CD 10))) (PP (IN by) (ADVP (RB up) (PP (IN to) (NP (QP (CD 60.7) (SYM x))) (PP (IN with) (NP (NP (DT a) (NML (CD 0.4) (NN %)) (NN loss)) (PP (IN in) (NP (NN accuracy)))))))))))))) (, ,) (CC and) (VP (VB reduce) (NP (NP (DT the) (NN memory)) (VP (VBN required) (S (VP (TO to) (VP (VB train) (NP (DT a) (NNP DynamicConv) (NN model)) (PP (IN on) (NP (NNP IWSLT) (CD '14))) (ADVP (ADJP (JJ German)) (TO to) (ADVP (PP (NP (NNP English) (NN translation)) (IN by)) (RB up) (PP (IN to) (NP (QP (CD 8.7) (SYM x))))) (PP (IN with) (NP (DT a) (NN BLEU) (NN score))))))))))))) (NN drop)) (PP (IN of) (NP (CD 0.15)))))))))) (. .))
