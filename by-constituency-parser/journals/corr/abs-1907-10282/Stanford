(S (NP (DT The) (JJ extreme) (NN learning) (NN machine)) (VP (VBZ needs) (NP (NP (DT a) (JJ large) (NN number)) (PP (IN of) (NP (JJ hidden) (NNS nodes)))) (PP (IN to) (NP (NML (S (VP (VB generalize) (NP (DT a) (JJ single) (JJ hidden) (NN layer))))) (JJ neural) (NN network))) (PP (IN for) (NP (DT a) (VBN given) (NML (NN training) (NN data)) (HYPH -) (NN set)))) (. .))
(S (NP (NP (DT The) (NN need)) (PP (IN for) (NP (NP (JJR more) (NN number)) (PP (IN of) (NP (JJ hidden) (NNS nodes)))))) (VP (VBZ suggests) (SBAR (IN that) (S (NP (DT the) (NML (JJ neural) (HYPH -) (NN network))) (VP (VBZ is) (VP (VBG memorizing) (PP (RB rather) (IN than) (S (VP (VBG generalizing) (NP (DT the) (NN model)))))))))) (. .))
(S (ADVP (RB Hence)) (, ,) (NP (DT a) (JJ supervised) (NN learning) (NN method)) (VP (VBZ is) (VP (VBN described) (ADVP (RB here)) (SBAR (IN that) (S (VP (VBZ uses) (NP (NML (NNP Moore) (HYPH -) (NNP Penrose)) (NN approximation)) (S (VP (TO to) (VP (VP (VB determine) (NP (NP (DT both) (NML (NML (NN input) (HYPH -) (NN weight)) (CC and) (NML (NN output) (HYPH -) (NN weight)))) (PP (IN in) (NP (CD two) (NNS epochs)))) (, ,) (ADVP (RB namely)) (, ,) (NP (JJ backward) (HYPH -) (NN pass))) (CC and) (VP (ADVP (RB forward)) (HYPH -) (VB pass)))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN technique)) (VP (VP (VBZ has) (NP (NP (DT an) (NN advantage)) (PP (IN over) (NP (NP (DT the) (NML (NN back) (HYPH -) (NN propagation)) (NN method)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (NNS iterations)) (VP (VBN required)))))))))) (CC and) (VP (VBZ is) (ADJP (JJ superior) (PP (IN to) (NP (NP (DT the) (JJ extreme) (NN learning) (NN machine)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (VBN hidden) (NNS units)) (ADJP (JJ necessary) (PP (IN for) (NP (NN generalization))))))))))))))) (. .))
