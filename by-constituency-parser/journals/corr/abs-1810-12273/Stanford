(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (NNP Kalman) (NNP Gradient) (NNP Descent)) (, ,) (NP (NP (DT a) (JJ stochastic) (NN optimization) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (NP (NNP Kalman)) (VP (VBG filtering) (S (VP (TO to) (ADVP (RB adaptively)) (VP (VB reduce) (NP (NP (NN gradient) (NN variance)) (PP (IN in) (NP (JJ stochastic) (NN gradient) (NN descent)))) (PP (IN by) (S (VP (VBG filtering) (NP (DT the) (NN gradient) (NNS estimates)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (DT both) (NP (NP (DT a) (JJ theoretical) (NN analysis)) (PP (IN of) (NP (NP (NN convergence)) (PP (IN in) (NP (DT a) (JJ non-convex) (NN setting)))))) (CC and) (NP (NP (JJ experimental) (NNS results)) (SBAR (WHNP (WDT which)) (S (VP (VBP demonstrate) (NP (NP (VBN improved) (NN performance)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NML (NN machine) (NN learning)) (NNS areas))))) (PP (VBG including) (NP (NML (NML (JJ neural) (NNS networks)) (CC and) (NML (JJ black) (NN box))) (JJ variational) (NN inference)))))))))) (. .))
(S (S (NP (PRP We)) (ADVP (RB also)) (VP (VBP present) (NP (NP (DT a) (VBN distributed) (NN version)) (PP (IN of) (NP (NP (PRP$ our) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (NP (ADJP (JJ large) (HYPH -) (JJ dimensional)) (NN optimization)))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP extend) (NP (PRP$ our) (NN algorithm)) (PP (IN to) (NP (NP (NNP SGD)) (PP (IN with) (NP (NN momentum) (CC and) (NN RMSProp))))))) (. .))
