(S (NP (NP (NN Convergence)) (PP (IN of) (NP (DT the) (JJ gradient) (NN descent) (NN algorithm)))) (VP (VBZ has) (VP (VBN been) (VP (VBG attracting) (NP (VBN renewed) (NN interest)) (PP (JJ due) (TO to) (NP (NP (PRP$ its) (NN utility)) (PP (IN in) (NP (JJ deep) (NN learning) (NNS applications)))))))) (. .))
(S (SBAR (RB Even) (IN as) (S (NP (NP (JJ multiple) (NNS variants)) (PP (IN of) (NP (JJ gradient) (NN descent)))) (VP (VBD were) (VP (VBN proposed))))) (, ,) (NP (DT the) (NN assumption) (SBAR (IN that) (S (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (DT the) (NN objective)))) (VP (VBZ is) (ADJP (NNP Lipschitz) (JJ continuous)))))) (VP (VBD remained) (NP (NP (DT an) (JJ integral) (NN part)) (PP (IN of) (NP (DT the) (NN analysis)))) (PP (IN until) (NP (RB recently)))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP look) (PP (IN at) (NP (NN convergence) (NN analysis))) (PP (IN by) (S (VP (VBG focusing) (PP (IN on) (NP (NP (NP (DT a) (NN property)) (SBAR (WHNP (IN that)) (S (NP (PRP we)) (VP (NN term) (PP (IN as) (NP (NN concavifiability))))))) (, ,) (PP (RB instead) (IN of) (NP (NP (NNP Lipschitz) (NN continuity)) (PP (IN of) (NP (NNS gradients))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (DT that) (S (NP (NN concavifiability)) (VP (VBZ is) (NP (NP (DT a) (JJ necessary) (CC and) (JJ sufficient) (NN condition)) (SBAR (S (VP (TO to) (VP (VB satisfy) (NP (NP (DT the) (JJ upper) (JJ quadratic) (NN approximation)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ key) (PP (IN in) (S (VP (VBG proving) (SBAR (IN that) (S (NP (DT the) (JJ objective) (NN function)) (VP (NNS decreases) (PP (IN after) (NP (DT every) (NN gradient) (NN descent) (NN update))))))))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (DT any) (JJ gradient) (NNP Lipschitz) (NN function)) (VP (NNS satisfies) (NP (NN concavifiability)))))) (. .))
(S (NP (NP (DT A) (JJ constant)) (VP (VBN known) (PP (IN as) (NP (DT the) (NN concavifier)))) (ADJP (JJ analogous) (PP (TO to) (NP (DT the) (NN gradient) (NNP Lipschitz) (NN constant))))) (VP (VBZ is) (VP (VBN derived) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ indicative) (PP (IN of) (NP (DT the) (JJ optimal) (NN step) (NN size))))))))) (. .))
(S (PP (IN As) (NP (DT an) (NN application))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (NP (DT the) (NN utility)) (PP (IN of) (S (VP (VBG finding) (NP (DT the) (NN concavifier)) (NP (NP (DT the)) (PP (IN in) (NP (NP (NN convergence)) (PP (IN of) (NP (JJ gradient) (NN descent)))))))))) (PP (IN through) (NP (NP (DT an) (NN example)) (VP (VBN inspired) (PP (IN by) (NP (JJ neural) (NNS networks))))))) (. .))
(S (NP (PRP We)) (VP (VBP derive) (NP (NP (NNS bounds)) (PP (IN on) (NP (DT the) (NN concavifier)))) (S (VP (TO to) (VP (VB obtain) (NP (NP (DT a) (JJ fixed) (NN step) (NN size)) (PP (IN for) (NP (DT a) (JJ single) (NN hidden) (NN layer) (NNP ReLU) (NN network)))))))) (. .))
