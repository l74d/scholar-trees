(S (NP (JJ Deep) (NNP Reinforcement) (NNP Learning) (PRN (-LRB- -LRB-) (NP (NNP DRL)) (-RRB- -RRB-)) (NN algorithms)) (VP (VBP are) (VP (VBN known) (S (VP (TO to) (VP (VB be) (ADJP (JJ data) (NN inefficient))))))) (. .))
(S (NP (CD One) (NN reason)) (VP (VBZ is) (SBAR (IN that) (S (NP (DT a) (NNP DRL) (NN agent)) (VP (VBZ learns) (NP (CC both) (NP (DT the) (NN feature)) (CC and) (NP (DT the) (NN policy) (NN tabula) (NN rasa))))))) (. .))
(S (S (VP (VBG Integrating) (NP (JJ prior) (NN knowledge)) (PP (IN into) (NP (NNP DRL) (NN algorithms))))) (VP (VBZ is) (NP (NP (CD one) (NN way)) (SBAR (S (VP (TO to) (VP (VB improve) (NP (VBG learning) (NN efficiency)) (SBAR (IN since) (S (NP (PRP it)) (VP (VBZ helps) (S (VP (TO to) (VP (VB build) (NP (JJ helpful) (NNS representations)))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP consider) (S (VP (VBG incorporating) (NP (NN human) (NN knowledge)) (S (VP (TO to) (VP (VB accelerate) (NP (DT the) (JJ asynchronous) (NN advantage) (JJ actor-critic) (PRN (-LRB- -LRB-) (NNP A3C) (-RRB- -RRB-)) (NN algorithm)) (PP (IN by) (S (VP (VBG pre-training) (NP (NP (DT a) (JJ small) (NN amount)) (PP (IN of) (NP (JJ non-expert) (JJ human) (NNS demonstrations))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP leverage) (NP (DT the) (JJ supervised) (NN autoencoder) (NN framework))) (CC and) (VP (VB propose) (NP (NP (DT a) (JJ novel) (JJ pre-training) (NN strategy)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB jointly)) (VBZ trains) (NP (NP (DT a) (JJ weighted) (JJ supervised) (NN classification) (NN loss)) (, ,) (NP (DT an) (JJ unsupervised) (NN reconstruction) (NN loss)) (, ,) (CC and) (NP (DT an) (JJ expected) (NN return) (NN loss))))))))) (. .))
(S (NP (DT The) (VBG resulting) (JJ pre-trained) (NN model)) (VP (VBZ learns) (NP (ADJP (RBR more) (JJ useful)) (NNS features)) (PP (VBN compared) (PP (TO to) (S (VP (ADVP (RB independently)) (VBG training) (PP (IN in) (NP (ADJP (VBN supervised) (CC or) (JJ unsupervised)) (NN fashion)))))))) (. .))
(S (NP (PRP$ Our) (JJ pre-training) (NN method)) (VP (ADVP (RB drastically)) (VBD improved) (NP (NP (DT the) (JJ learning) (NN performance)) (PP (IN of) (NP (DT the) (NNP A3C) (NN agent))) (PP (IN in) (NP (NP (NNP Atari) (NNS games)) (PP (IN of) (NP (NNP Pong) (CC and) (NNP MsPacman)))))) (, ,) (S (VP (VBG exceeding) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (JJ state-of-the-art) (NN algorithms)))) (PP (IN at) (NP (NP (DT a) (ADJP (RB much) (JJR smaller)) (NN number)) (PP (IN of) (NP (NN game) (NNS interactions)))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ is) (ADJP (JJ light-weight) (CC and) (JJ easy) (SBAR (S (VP (TO to) (VP (VB implement) (PP (IN in) (NP (DT a) (JJ single) (NN machine))))))))) (. .))
(S (PP (IN For) (NP (NN reproducibility))) (, ,) (NP (PRP$ our) (NN code)) (VP (VBZ is) (ADJP (JJ available)) (PP (IN at) (NP (NN github.com/gabrieledcjr/DeepRL/tree/A3C-ALA2019)))))
