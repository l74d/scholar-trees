(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (ADJP (NP (DT a) (NN model)) (HYPH -) (VBN based)) (NN image) (NN reconstruction) (NN framework)) (PP (IN with) (NP (NP (DT a) (NN convolution) (JJ neural) (NN network) (PRN (-LRB- -LRB-) (NP (NNP CNN)) (-RRB- -RRB-))) (VP (VBN based) (NP (NN regularization)) (PP (JJ prior))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN formulation)) (VP (VBZ provides) (NP (DT a) (JJ systematic) (NN approach)) (PP (IN for) (S (VP (VBG deriving) (NP (JJ deep) (NNS architectures)) (PP (IN for) (NP (NP (NN inverse) (NNS problems)) (PP (IN with) (NP (DT the) (JJ arbitrary) (NN structure))))))))) (. .))
(S (SBAR (IN Since) (S (NP (DT the) (JJ forward) (NN model)) (VP (VBZ is) (ADVP (RB explicitly)) (VP (VBN accounted) (PP (IN for)))))) (, ,) (NP (NP (DT a) (JJR smaller) (NN network)) (PP (IN with) (NP (JJR fewer) (NNS parameters)))) (VP (VBZ is) (ADJP (JJ sufficient) (S (VP (TO to) (VP (VB capture) (NP (DT the) (NN image) (NN information)) (PP (VBN compared) (PP (IN to) (NP (NML (JJ black) (HYPH -) (NN box)) (NML (JJ deep) (NN learning)) (NNS approaches)))) (, ,) (S (ADVP (RB thus)) (VP (VBG reducing) (NP (DT the) (NN demand)) (PP (IN for) (NP (NP (NN training) (NNS data)) (CC and) (NP (NN training) (NN time))))))))))) (. .))
(S (SBAR (IN Since) (S (NP (PRP we)) (VP (VBP rely) (PP (IN on) (NP (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NN training)))))) (, ,) (NP (DT the) (NNP CNN) (NNS weights)) (VP (VBP are) (VP (VBN customized) (PP (IN to) (NP (DT the) (JJ forward) (NN model))) (, ,) (S (ADVP (RB thus)) (VP (VBG offering) (NP (NP (VBN improved) (NN performance)) (PP (IN over) (NP (NP (NNS approaches)) (SBAR (WHNP (WDT that)) (S (VP (VBP rely) (PP (IN on) (NP (JJ pre-trained) (NNS denoisers))))))))))))) (. .))
(S (NP (NP (DT The) (JJ main) (NN difference)) (PP (IN of) (NP (NP (DT the) (NN framework)) (PP (IN from) (NP (VBG existing) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN training)))) (NNS strategies)))))) (VP (VBZ is) (NP (NP (DT the) (NN sharing)) (PP (IN of) (NP (NP (DT the) (NN network) (NNS weights)) (PP (IN across) (NP (NNS iterations) (CC and) (NNS channels))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN decoupling)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS iterations)) (PP (IN from) (NP (NP (DT the) (NN network) (NN complexity)) (VP (VBN offered) (PP (IN by) (NP (DT this) (NN approach))))))))))) (VP (VBZ provides) (NP (NP (NP (NNS benefits)) (PP (VBG including) (NP (NP (JJR lower) (NN demand)) (PP (IN for) (NP (NN training) (NNS data)))))) (, ,) (NP (NP (VBN reduced) (NN risk)) (PP (IN of) (NP (NN overfitting)))) (, ,) (CC and) (NP (NP (NNS implementations)) (PP (IN with) (NP (ADJP (RB significantly) (VBN reduced)) (NN memory) (NN footprint))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP propose) (S (VP (TO to) (VP (VB enforce) (NP (NML (NNS data)) (HYPH -) (NN consistency)) (PP (IN by) (S (VP (VBG using) (NP (NP (JJ numerical) (NN optimization) (NNS blocks)) (PP (JJ such) (IN as) (NP (NP (JJ conjugate) (NNS gradients) (NN algorithm)) (PP (IN within) (NP (DT the) (NN network)))))))))))))) (: ;) (S (NP (DT this) (NN approach)) (VP (VBZ offers) (ADVP (RBR faster)) (NP (NP (NN convergence)) (PP (IN per) (NP (NN iteration)))) (, ,) (PP (VBN compared) (PP (IN to) (NP (NP (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP rely) (PP (IN on) (NP (JJ proximal) (NNS gradients) (NNS steps))) (S (VP (TO to) (VP (VB enforce) (NP (NNS data) (NN consistency))))))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (SBAR (IN that) (S (ADVP (DT the) (RBR faster)) (NP (NN convergence)) (VP (VBZ translates) (PP (IN to) (NP (VBN improved) (NN performance)))))) (, ,) (RB especially) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (JJ available) (NNP GPU) (NN memory)) (VP (VBZ restricts) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS iterations))))))))) (. .))
