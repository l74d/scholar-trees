(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT an) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN speaker)))) (NN verification) (NN system)) (VP (VP (VBN based) (PP (IN on) (NP (DT the) (JJ neural) (NN network)))) (CC and) (VP (VBN trained) (PP (IN by) (NP (DT a) (NN loss) (NN function))) (PP (IN with) (NP (JJR less) (JJ computational) (NN complexity))))))) (. .))
(S (NP (NP (DT The) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN speaker)))) (NN verification) (NN system)) (PP (IN in) (NP (DT this) (NN paper)))) (VP (VP (VBZ consists) (PP (IN of) (NP (DT a) (NNP ResNet) (NN architecture))) (S (VP (TO to) (VP (VB extract) (NP (NNS features)) (PP (IN from) (NP (NN utterance))))))) (, ,) (VP (ADVP (RB then)) (VBZ produces) (NP (NML (NN utterance) (HYPH -) (NN level)) (NN speaker) (NNS embeddings))) (, ,) (CC and) (VP (NN train) (S (VP (VBG using) (NP (DT the) (NML (JJ large) (HYPH -) (NN margin)) (NML (NNP Gaussian) (NNP Mixture)) (NN loss) (NN function)))))) (. .))
(SINV (VP (VBN Influenced) (PP (IN by) (NP (DT the) (NML (NML (JJ large) (HYPH -) (NN margin)) (CC and) (NML (NN likelihood) (NN regularization))) (, ,) (NML (JJ large) (HYPH -) (NN margin)) (NML (NNP Gaussian) (NNP Mixture)) (NN loss) (NN function)))) (VP (VBZ benefits)) (NP (DT the) (NML (NN speaker) (NN verification)) (NN performance)) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT the) (JJ Residual) (NNP CNN)) (PP (IN with) (NP (NML (JJ large) (HYPH -) (NN margin)) (NML (NNP Gaussian) (NNP Mixture)) (NN loss)))) (VP (VBZ outperforms) (S (NP (ADJP (NP (NN DNN)) (HYPH -) (VBN based)) (NN i) (HYPH -) (NN vector)) (NP (NP (NN baseline)) (PP (IN by) (NP (NP (NML (QP (JJR more) (IN than) (CD 10)) (NN %)) (NN improvement)) (PP (IN in) (NP (NN accuracy) (NN rate))))))))))) (. .))
