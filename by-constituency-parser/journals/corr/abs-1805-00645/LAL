(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT an) (JJ end-to-end) (NN speaker) (NN verification) (NN system)) (VP (VP (VBN based) (PP (IN on) (NP (DT the) (JJ neural) (NN network)))) (CC and) (VP (VBN trained) (PP (IN by) (NP (NP (DT a) (NN loss) (NN function)) (PP (IN with) (NP (JJR less) (JJ computational) (NN complexity))))))))) (. .))
(S (NP (NP (DT The) (JJ end-to-end) (NN speaker) (NN verification) (NN system)) (PP (IN in) (NP (DT this) (NN paper)))) (VP (VBZ consists) (PP (IN of) (NP (NP (DT a) (NNP ResNet) (NN architecture)) (SBAR (S (VP (TO to) (VP (VP (VB extract) (NP (NNS features)) (PP (IN from) (NP (NN utterance)))) (, ,) (VP (ADVP (RB then)) (VBZ produces) (NP (JJ utterance-level) (NN speaker) (NNS embeddings))) (, ,) (CC and) (VP (NN train) (S (VP (VBG using) (NP (DT the) (JJ large-margin) (JJ Gaussian) (NNP Mixture) (NN loss) (NN function)))))))))))) (. .))
(S (S (VP (VBN Influenced) (PP (IN by) (NP (DT the) (NN large-margin) (CC and) (NN likelihood) (NN regularization))))) (, ,) (NP (JJ large-margin) (JJ Gaussian) (NNP Mixture) (NN loss) (NN function)) (VP (NNS benefits) (NP (DT the) (NN speaker) (NN verification) (NN performance))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT the) (NNP Residual) (NNP CNN)) (PP (IN with) (NP (JJ large-margin) (JJ Gaussian) (NNP Mixture) (NN loss)))) (VP (VBZ outperforms) (NP (JJ DNN-based) (JJ i-vector) (NN baseline)) (PP (IN by) (NP (NP (ADJP (QP (JJR more) (IN than) (CD 10)) (NN %)) (NN improvement)) (PP (IN in) (NP (NN accuracy) (NN rate))))))))) (. .))
