(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (S (VP (TO to) (VP (VB learn) (NP (NP (NP (ADJP (NP (JJ high) (HYPH -) (NN performance)) (JJ deep)) (NNPS ConvNets)) (PP (IN with) (NP (JJ sparse) (JJ neural) (NNS connections)))) (, ,) (VP (VBN referred) (PP (IN to) (PP (IN as) (NP (JJ sparse) (NNPS ConvNets)))) (, ,) (PP (IN for) (NP (NN face) (NN recognition))))))))) (. .))
(S (S (NP (DT The) (JJ sparse) (NNPS ConvNets)) (VP (VBP are) (VP (VBN learned) (PP (IN in) (NP (DT an) (JJ iterative) (NN way)))))) (, ,) (S (NP-TMP (DT each) (NN time)) (NP (CD one) (JJ additional) (NN layer)) (VP (VBZ is) (VP (VBN sparsified)))) (CC and) (S (NP (DT the) (JJ entire) (NN model)) (VP (VBZ is) (VP (VBN re-trained) (PP (VBN given) (NP (NP (DT the) (JJ initial) (NNS weights)) (VP (VBN learned) (PP (IN in) (NP (JJ previous) (NNS iterations))))))))) (. .))
(S (NP (CD One) (JJ important) (NN finding)) (VP (VBZ is) (SBAR (WHNP (WHNP (DT that)) (S (ADVP (RB directly)) (VP (VBG training) (NP (DT the) (JJ sparse) (NNP ConvNet)) (PP (IN from) (NP (NN scratch)))))) (S (VP (VBD failed) (S (VP (TO to) (VP (VB find) (NP (JJ good) (NNS solutions)) (PP (IN for) (NP (NN face) (NN recognition))) (, ,) (SBAR (IN while) (S (S (VP (VBG using) (NP (NP (DT a) (RB previously)) (VP (VBN learned) (NP (JJR denser) (NN model)) (S (VP (TO to) (ADVP (RB properly)) (VP (VB initialize) (NP (DT a) (JJR sparser) (NN model))))))))) (VP (VBZ is) (ADJP (JJ critical) (S (VP (TO to) (VP (VB continue) (S (VP (VBG learning) (NP (JJ effective) (NNS features)) (PP (IN for) (NP (NN face) (NN recognition))))))))))))))))))) (. .))
(S (NP (DT This) (NN paper)) (ADVP (RB also)) (VP (VP (VBZ proposes) (NP (DT a) (JJ new) (ADJP (NP (JJ neural) (NN correlation)) (HYPH -) (VBN based)) (NML (NN weight) (NN selection)) (NN criterion))) (CC and) (VP (ADVP (RB empirically)) (VBZ verifies) (NP (PRP$ its) (NN effectiveness)) (PP (IN in) (S (VP (VBG selecting) (NP (NP (NP (JJ informative) (NNS connections)) (PP (IN from) (ADVP (RB previously)))) (VP (VBN learned) (NP (NNS models)) (PP (IN in) (NP (DT each) (NN iteration)))))))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (VP (VBG taking) (NP (NP (DT a) (ADJP (RB moderately) (JJ sparse)) (NN structure)) (-LRB- -LRB-) (NP (NP (QP (CD 26) (NN %) (HYPH -) (CD 76) (NN %))) (PP (IN of) (NP (NP (NNS weights)) (PP (IN in) (NP (DT the) (JJ dense) (NN model)))))) (-RRB- -RRB-))))) (, ,) (NP (DT the) (VBN proposed) (NML (JJ sparse) (NNP ConvNet)) (NN model)) (VP (ADVP (RB significantly)) (VBZ improves) (NP (NP (DT the) (NML (NN face) (NN recognition)) (NN performance)) (PP (IN of) (NP (NP (NP (DT the) (JJ previous) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN DeepID2)) (SYM +) (NP (NNS models))) (VP (VBN given) (NP (DT the) (JJ same) (NN training)) (NP (NNS data)))))) (, ,) (SBAR (IN while) (S (NP (PRP it)) (VP (VBZ keeps) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (NN baseline) (NN model)))) (PP (IN with) (NP (NP (QP (RB only) (CD 12)) (NN %)) (PP (IN of) (NP (DT the) (JJ original) (NNS parameters))))))))) (. .))
