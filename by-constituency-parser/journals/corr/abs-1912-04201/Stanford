(S (NP (ADJP (NN Model) (HYPH -) (VBN based)) (NML (NN reinforcement) (NN learning)) (NNS methods)) (ADVP (RB typically)) (VP (VBP learn) (NP (NP (NNS models)) (PP (IN for) (NP (ADJP (JJ high) (HYPH -) (JJ dimensional)) (NN state) (NNS spaces)))) (PP (IN by) (S (VP (VBG aiming) (S (VP (TO to) (VP (VB reconstruct) (CC and) (VB predict) (NP (DT the) (JJ original) (NNS observations))))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG drawing) (NP (NN inspiration)) (PP (IN from) (NP (NML (NN model) (HYPH -) (JJ free)) (NN reinforcement) (NN learning))))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (VBG learning) (NP (DT a) (NN latent) (NNS dynamics) (NN model)) (ADVP (RB directly)) (PP (IN from) (NP (NNS rewards)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (ADJP (NP (NN model)) (HYPH -) (VBN based)) (NN planning) (NN framework)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ learns) (NP (DT a) (NN latent) (NN reward) (NN prediction) (NN model))) (CC and) (ADVP (RB then)) (VP (VBZ plans) (PP (IN in) (NP (DT the) (JJ latent) (NN state) (HYPH -) (NN space))))))))) (. .))
(S (NP (DT The) (NN latent) (NN representation)) (VP (VBZ is) (VP (VBN learned) (ADVP (RB exclusively)) (PP (IN from) (NP (NP (JJ multi-step) (NN reward) (NN prediction)) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP show) (S (VP (TO to) (VP (VB be) (NP (NP (DT the) (ADJP (RB only) (JJ necessary)) (NN information)) (PP (IN for) (NP (JJ successful) (NN planning)))))))))))))) (. .))
(S (PP (IN With) (NP (DT this) (NN framework))) (, ,) (NP (PRP we)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB benefit) (PP (IN from) (NP (NP (DT the) (ADJP (NP (JJ concise) (NN model)) (HYPH -) (JJ free)) (NN representation)) (, ,) (SBAR (IN while) (S (ADVP (RB still)) (VP (VBG enjoying) (NP (DT the) (ADJP (NP (NML (NN data) (HYPH -) (NN efficiency)) (PP (IN of) (NP (NN model)))) (HYPH -) (VBN based)) (NNS algorithms)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (PRP$ our) (NN framework)) (PP (IN in) (NP (NP (NN multi-pendulum)) (CC and) (NP (JJ multi-cheetah) (NNS environments)))) (SBAR (SBAR (WHADVP (WRB where)) (S (NP (JJ several) (NNS pendulums) (CC or) (NNS cheetahs)) (VP (VBP are) (VP (VBN shown) (PP (IN to) (NP (DT the) (NN agent))))))) (CONJP (CC but) (RB only)) (SBAR (WHNP (NP (CD one)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBZ produces) (NP (NNS rewards))))))) (. .))
(S (PP (IN In) (NP (DT these) (NNS environments))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ important) (PP (IN for) (NP (DT the) (NN agent)))) (S (VP (TO to) (VP (VB construct) (NP (DT a) (JJ concise) (NN latent) (NN representation)) (PP (IN to) (NP (NN filter))) (PP (IN out) (NP (ADJP (JJ irrelevant)) (NNS observations))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (MD can) (ADVP (RB successfully)) (VP (VB learn) (NP (DT an) (JJ accurate) (NN latent) (NN reward) (NN prediction) (NN model)) (PP (IN in) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (DT the) (ADJP (JJ irrelevant)) (NN information))))) (SBAR (IN while) (S (NP (ADJP (NP (VBG existing) (NN model)) (HYPH -) (VBN based)) (NNS methods)) (VP (VBP fail))))))))) (. .))
(S (VP (VBG Planning) (PP (IN in) (NP (DT the) (UCP (VP (VBN learned) (NP (NP (NN latent) (NML (NN state) (HYPH -) (NN space)) (NNS shows)) (ADJP (NP (NP (JJ strong) (NML (NML (NN performance)) (CC and) (NML (JJ high) (NN sample))) (NN efficiency)) (PP (IN over) (NP (NN model)))) (HYPH -) (JJ free)))) (CC and) (ADJP (NP (NN model)) (HYPH -) (VBN based))) (NNS baselines)))) (. .))
