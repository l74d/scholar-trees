(S (NP (NML (NML (NN End)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN reinforcement)))) (VBG learning) (NNS agents)) (VP (VBP learn) (NP (NP (DT a) (NN state) (NN representation)) (CC and) (NP (DT a) (NN policy))) (PP (IN at) (NP (DT the) (JJ same) (NN time)))) (. .))
(S (NP (NP (JJ Recurrent) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (VP (VBP have) (VP (VBN been) (VP (VBN trained) (ADVP (RB successfully)) (PP (IN as) (S (VP (NN reinforcement) (VBG learning) (NP (NP (NNS agents)) (PP (IN in) (NP (NP (NNS settings)) (PP (IN like) (NP (NP (NN dialogue)) (SBAR (WHNP (WDT that)) (S (VP (VBP require) (NP (JJ structured) (NN prediction)))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP investigate) (NP (NP (DT the) (NNS representations)) (VP (VBN learned) (PP (IN by) (NP (ADJP (NP (NN RNN)) (HYPH -) (VBN based)) (NNS agents))))) (SBAR (WHADVP (WRB when)) (S (VP (VBN trained) (PP (IN with) (NP (NP (DT both) (NN policy) (NN gradient)) (CC and) (NP (ADJP (NN value) (HYPH -) (VBN based)) (NNS methods)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (PP (IN through) (NP (NP (JJ extensive) (NNS experiments)) (CC and) (NP (NN analysis)))) (SBAR (WHNP (WDT that)) (S (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBN trained) (PP (IN with) (NP (NN policy) (NN gradient)))))) (, ,) (NP (JJ recurrent) (JJ neural) (NNS networks)) (ADVP (RB often)) (VP (VBP fail) (S (VP (TO to) (VP (VB learn) (NP (NP (DT a) (NN state) (NN representation)) (SBAR (WHNP (WDT that)) (S (VP (VBZ leads) (PP (IN to) (NP (NP (DT an) (JJ optimal) (NN policy)) (PP (IN in) (NP (NNS settings))))) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (JJ same) (NN action)) (VP (MD should) (VP (VB be) (VP (VBN taken) (PP (IN at) (NP (JJ different) (NNS states))))))))))))))))))) (. .))
(S (S (VP (TO To) (VP (VB explain) (NP (DT this) (NN failure))))) (, ,) (NP (PRP we)) (VP (VBD highlight) (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (NP (NN state) (NN aliasing)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ entails) (S (VP (VBG conflating) (NP (NP (QP (CD two) (CC or) (JJR more)) (JJ distinct) (NNS states)) (PP (IN in) (NP (DT the) (NN representation) (NN space))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NN state) (NN aliasing)) (VP (VBZ occurs) (SBAR (WHADVP (WRB when)) (S (NP (JJ several) (NNS states)) (VP (VBP share) (SBAR (S (NP (NP (DT the) (JJ same) (JJ optimal) (NN action)) (CC and) (NP (DT the) (NN agent))) (VP (VBZ is) (VP (VBN trained) (PP (IN via) (NP (NN policy) (NN gradient)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP characterize) (NP (DT this) (NN phenomenon)) (PP (IN through) (NP (NP (NNS experiments)) (PP (IN on) (NP (NP (DT a) (NML (JJ simple) (NN maze)) (NN setting)) (CC and) (NP (DT a) (ADJP (RBR more) (JJ complex)) (ADJP (NN text) (HYPH -) (VBN based)) (NN game))))))) (, ,) (CC and) (VP (VB make) (NP (NP (NNS recommendations)) (PP (IN for) (NP (NN training) (NNS RNNs)))) (PP (IN with) (NP (NN reinforcement) (NN learning))))) (. .))
