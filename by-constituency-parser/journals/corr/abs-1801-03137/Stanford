(S (NP (NP (DT The) (NN rise)) (PP (IN of) (NP (NP (JJ deep) (NN learning)) (PP (IN in) (NP (JJ recent) (NNS years)))))) (VP (VBZ has) (VP (VBN brought) (PP (IN with) (NP (PRP it)) (NP (ADJP (RB increasingly) (JJ clever)) (NN optimization) (NNS methods))) (S (VP (TO to) (VP (VB deal) (PP (IN with) (NP (JJ complex) (, ,) (JJ non-linear) (NN loss) (NNS functions)))))))) (. .))
(S (NP (DT These) (NNS methods)) (VP (VP (VBP are) (ADVP (RB often)) (VP (VBN designed) (PP (IN with) (NP (NN convex) (NN optimization))) (PP (IN in) (NP (NN mind))))) (, ,) (CC but) (VP (VBP have) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB work) (ADVP (RB well) (PP (IN in) (NP (NN practice)))) (ADVP (RB even)) (PP (IN for) (NP (NP (DT the) (ADJP (RB highly) (JJ non-convex)) (NN optimization)) (VP (VBN associated) (PP (IN with) (NP (JJ neural) (NNS networks))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (CD one) (JJ significant) (NN drawback)) (PP (IN of) (NP (NP (DT these) (NNS methods)) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBP are) (VP (VBN applied) (PP (IN to) (NP (JJ deep) (NN learning)))))))))) (VP (VBZ is) (SBAR (IN that) (S (NP (NP (DT the) (NN magnitude)) (PP (IN of) (NP (DT the) (NN update) (NN step)))) (VP (VBZ is) (ADJP (RB sometimes) (JJ disproportionate) (PP (IN to) (NP (NP (DT the) (NN magnitude)) (PP (IN of) (NP (NP (NP (DT the) (NNS weights)) (-LRB- -LRB-) (ADJP (ADJP (RB much) (JJR smaller)) (CC or) (ADJP (JJR larger))) (-RRB- -RRB-)) (, ,) (VP (VBG leading) (PP (IN to) (NP (NP (NN training) (NNS instabilities)) (PP (JJ such) (IN as) (NP (NP (VBG vanishing)) (CC and) (NP (VBG exploding) (NNS gradients)))))))))))))))) (. .))
(S (NP (DT An) (NN idea) (S (VP (TO to) (VP (VB combat) (NP (DT this) (NN issue)))))) (VP (VBZ is) (NP (NP (NN gradient) (NN descent)) (PP (IN with) (NP (JJ proportional) (NNS updates))))) (. .))
(S (NP (NP (NN Gradient) (NN descent)) (PP (IN with) (NP (JJ proportional) (NNS updates)))) (VP (VBD was) (VP (VBN introduced) (PP (IN in) (NP (CD 2017))))) (. .))
(S (NP (PRP It)) (VP (VBD was) (ADVP (RB independently)) (VP (VBN developed) (PP (IN by) (NP (PRP You))) (ADVP (ADVP (FW et) (FW al) (PRN (-LRB- -LRB-) (NP (JJ Layer-wise) (JJ Adaptive) (NML (NML (NN Rate) (NN Scaling)) (-LRB- -LRB-) (NML (NP (NNP LARS))) (-RRB- -RRB-)) (NN algorithm)) (-RRB- -RRB-))) (CC and) (PP (IN by) (NP (NNP Abu) (HYPH -) (NNP El) (HYPH -) (NNP Haija)))) (PRN (-LRB- -LRB-) (NP (NNP PercentDelta) (NN algorithm)) (-RRB- -RRB-)))) (. .))
(S (NP (NP (DT The) (JJ basic) (NN idea)) (PP (IN of) (NP (NP (DT both)) (PP (IN of) (NP (DT these) (NNS algorithms)))))) (VP (VBZ is) (S (VP (TO to) (VP (VB make) (NP (NP (DT each) (NN step)) (PP (IN of) (NP (NP (NP (DT the) (NN gradient) (NN descent)) (ADJP (ADJP (JJ proportional) (PP (IN to) (NP (DT the) (JJ current) (NN weight) (NN norm)))) (CC and) (ADJP (JJ independent)))) (PP (IN of) (NP (DT the) (NN gradient) (NN magnitude)))))))))) (. .))
(S (NP (PRP It)) (VP (VP (VBZ is) (ADJP (JJ common) (PP (IN in) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (JJ new) (NN optimization) (NNS methods))))) (S (VP (TO to) (VP (VB prove) (NP (NN convergence))))))) (CC or) (VP (VBP derive) (NP (NN regret) (NNS bounds)) (PP (IN under) (NP (NP (DT the) (NN assumption)) (PP (IN of) (NP (NNP Lipschitz) (NN continuity) (CC and) (NN convexity))))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (RB even) (IN though) (S (NP (NNP LARS) (CC and) (NNP PercentDelta)) (VP (VBD were) (VP (VBN shown) (S (VP (TO to) (VP (VB work) (ADVP (RB well)) (PP (IN in) (NP (NN practice)))))))))) (, ,) (NP (EX there)) (VP (VBZ is) (NP (NP (DT no) (JJ theoretical) (NN analysis)) (PP (IN of) (NP (NP (DT the) (NN convergence) (NNS properties)) (PP (IN of) (NP (DT these) (NNS algorithms))))))) (. .))
(S (ADVP (RB Thus)) (NP (PRP it)) (VP (VBZ is) (RB not) (ADJP (JJ clear)) (SBAR (SBAR (IN if) (S (NP (NP (DT the) (NN idea)) (PP (IN of) (NP (NP (NN gradient) (NN descent)) (PP (IN with) (NP (JJ proportional) (NNS updates)))))) (VP (VBZ is) (VP (VBN used) (PP (IN in) (NP (DT the) (JJ optimal) (NN way))))))) (, ,) (CC or) (SBAR (IN if) (S (NP (PRP it)) (VP (MD could) (VP (VB be) (VP (VBN improved) (PP (IN by) (S (VP (VBG using) (NP (NP (NP (DT a) (JJ different) (NN norm)) (CC or) (NP (JJ specific) (VBG learning) (NN rate) (NN schedule))) (, ,) (PP (IN for) (NP (NN example)))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP it)) (VP (VBZ is) (RB not) (ADJP (JJ clear)) (SBAR (IN if) (S (NP (DT these) (NNS algorithms)) (VP (MD can) (VP (VB be) (VP (VBN extended) (PP (IN to) (NP (JJ other) (NNS problems))) (, ,) (PP (IN besides) (NP (JJ neural) (NNS networks))))))))) (. .))
(S (NP (PRP We)) (VP (VBP attempt) (S (VP (TO to) (VP (VB answer) (NP (DT these) (NNS questions)) (PP (IN by) (S (VP (VP (VBG establishing) (NP (NP (DT the) (JJ theoretical) (NN analysis)) (PP (IN of) (NP (NN gradient) (NN descent)))) (PP (IN with) (NP (JJ proportional) (NNS updates)))) (, ,) (CC and) (VP (VBG verifying) (NP (DT this) (NN analysis)) (PP (IN with) (NP (JJ empirical) (NNS examples))))))))))) (. .))
