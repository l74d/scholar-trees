(S (S (VP (VBN Distributed))) (NP (NN machine) (NN learning) (PRN (-LRB- -LRB-) (NP (NN ML)) (-RRB- -RRB-))) (VP (MD can) (VP (VB bring) (NP (JJR more) (JJ computational) (NNS resources)) (S (VP (TO to) (VP (VB bear) (PP (IN than) (NP (NML (JJ single) (HYPH -) (NN machine)) (NN learning))) (, ,) (S (VP (VBG reducing) (NP (NN training) (NN time))))))))) (. .))
(S (ADVP (RB Further)) (, ,) (NP (NN distribution)) (VP (VBZ allows) (NP (NNS models)) (S (VP (TO to) (VP (VB be) (VP (VBN partitioned) (PP (IN over) (NP (JJ many) (NNS machines))) (, ,) (S (VP (VBG allowing) (NP (ADJP (RB very) (JJ large)) (NNS models)) (S (VP (TO to) (VP (VB be) (VP (VBN trained) (: --) (NP (NP (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (MD may) (VP (VB be) (ADJP (ADJP (RB much) (JJR larger)) (PP (IN than) (NP (NP (DT the) (JJ available) (NN memory)) (PP (IN of) (NP (DT any) (JJ individual) (NN machine)))))))))))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (NN practice))) (, ,) (NP (VBN distributed) (NNP ML)) (VP (VBZ remains) (ADJP (JJ challenging)) (, ,) (PP (ADVP (RB primarily)) (IN due) (IN to) (NP (NML (JJ high) (NN communication)) (NNS costs)))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (JJ new) (NN approach)) (PP (IN to) (NP (NP (VBN distributed) (NML (JJ neural) (NN network)) (NN learning)) (, ,) (VP (VBN called) (NP (JJ independent) (NN subnet) (NN training))))) (PRN (-LRB- -LRB-) (NP (NN IST)) (-RRB- -RRB-))) (. .))
(S (PP (IN In) (NP (NN IST))) (, ,) (NP (DT a) (JJ neural) (NN network)) (VP (VBZ is) (VP (VBN decomposed) (PP (IN into) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NNS subnetworks)) (PP (IN of) (NP (DT the) (JJ same) (NN depth))))))) (PP (IN as) (NP (NP (DT the) (JJ original) (NN network)) (, ,) (SBAR (WHNP (NP (DT each)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBZ is) (VP (VBN trained) (ADVP (RB locally)) (, ,) (SBAR (IN before) (S (S (NP (DT the) (JJ various) (NNS subnets)) (VP (VBP are) (VP (VBN exchanged)))) (CC and) (S (NP (DT the) (NN process)) (VP (VBZ is) (VP (VBN repeated)))))))))))))) (. .))
(S (NP (NN IST) (NN training)) (VP (VBZ has) (NP (NP (JJ many) (NNS advantages)) (PP (IN over) (NP (NP (JJ standard) (NNS data)) (NP (JJ parallel) (NNS approaches)))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NNS subsets)) (VP (VBP are) (ADJP (JJ independent))))) (, ,) (NP (NN communication) (NN frequency)) (VP (VBZ is) (VP (VBN reduced))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (JJ original) (NN network)) (VP (VBZ is) (VP (VBN decomposed) (PP (IN into) (NP (JJ independent) (NNS parts))))))) (, ,) (NP (NN communication) (NN volume)) (VP (VBZ is) (VP (VBN reduced))) (. .))
(S (ADVP (RB Further)) (, ,) (NP (DT the) (NN decomposition)) (VP (VBZ makes) (NP (NP (NP (NN IST)) (RRC (RRC (ADVP (RB naturally)) (NP (NN model) (NN parallel)) (, ,)) (CC and) (RRC (ADVP (RB so)) (NP (NP (JJ IST) (NNS scales)) (PP (IN to) (NP (ADJP (RB very) (JJ large)) (NNS models))))))) (SBAR (WHNP (WDT that)) (S (VP (MD can) (RB not) (VP (VB fit) (PP (IN on) (NP (DT any) (JJ single) (NN machine))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (ADVP (RB experimentally)) (SBAR (SBAR (IN that) (S (NP (NP (NP (NN IST) (NNS results)) (PP (IN in) (NP (NN training) (NN time)))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (ADJP (RB much) (JJR lower)) (PP (IN than) (NP (NNS data)))))))) (NP (NP (JJ parallel) (NNS approaches)) (PP (IN to) (NP (VBN distributed) (NN learning)))))) (, ,) (CC and) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ scales) (PP (IN to) (NP (NP (JJ large) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (RB not) (VP (VB be) (VP (VBN learned) (S (VP (VBG using) (NP (JJ standard) (NNS approaches)))))))))))))))) (. .))
