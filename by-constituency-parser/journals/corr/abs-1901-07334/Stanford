(S (NP (JJ Recurrent) (JJ neural) (NNS networks)) (VP (MD can) (VP (VB be) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB train) (PRT (RP on)) (NP (NML (JJ long) (NN sequence)) (NNS data)) (PP (IN due) (IN to) (NP (NP (DT the) (ADJP (NN well) (HYPH -) (VBN known)) (VBG vanishing) (NN gradient)) (NP (NN problem)))))))))) (. .))
(S (NP (DT Some) (NNS architectures)) (VP (VB incorporate) (NP (NNS methods)) (S (VP (TO to) (VP (VB reduce) (NP (NN RNN) (NN state) (NNS updates)) (, ,) (S (ADVP (RB therefore)) (VP (VBG allowing) (NP (DT the) (NN network)) (S (VP (TO to) (VP (VB preserve) (NP (NN memory)) (PP (IN over) (NP (JJ long) (JJ temporal) (NNS intervals)))))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (NP (DT these) (NNS problems)) (PP (IN of) (NP (NN convergence))))))) (PRN (, ,) (S (NP (DT this) (NN paper)) (VP (VBZ proposes) (NP (DT a) (JJ timing-gated) (NML (NN LSTM) (NN RNN)) (NN model)))) (, ,)) (VP (VBD called) (NP (DT the) (JJ Gaussian-gated) (NN LSTM)) (PRN (-LRB- -LRB-) (NP (NN g) (HYPH -) (NN LSTM)) (-RRB- -RRB-))) (. .))
(S (NP (DT The) (NN time) (NN gate)) (VP (VBZ controls) (SBAR (WHADVP (WRB when)) (S (NP (DT a) (NN neuron)) (VP (MD can) (VP (VB be) (VP (VBN updated) (PP (IN during) (NP (NN training))) (, ,) (S (VP (VBG enabling) (NP (NP (NML (JJR longer) (NN memory)) (NN persistence)) (CC and) (NP (JJR better) (NML (NN error) (HYPH -) (NN gradient)) (NN flow))))))))))) (. .))
(S (NP (DT This) (NN model)) (VP (VBZ captures) (NP (ADJP (RB long) (HYPH -) (JJ temporal)) (NNS dependencies)) (ADJP (JJR better)) (SBAR (IN than) (S (NP (NP (DT an) (NN LSTM)) (CC and) (NP (DT the) (NN time) (NN gate) (NNS parameters))) (VP (MD can) (VP (VB be) (VP (VBN learned) (ADVP (RB even)) (PP (IN from) (NP (JJ non-optimal) (NN initialization) (NNS values))))))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NN time) (NN gate)) (VP (VBZ limits) (NP (NP (DT the) (NNS updates)) (PP (IN of) (NP (DT the) (NN neuron) (NN state))))))) (, ,) (NP (NP (DT the) (NN number)) (PP (IN of) (FRAG (VP (VBZ computes) (VP (VBN needed) (PP (IN for) (NP (DT the) (NN network) (NN update)))))))) (VP (VBZ is) (ADVP (RB also)) (VP (VBN reduced))) (. .))
(S (PP (IN By) (S (VP (VBG adding) (NP (DT a) (JJ computational) (NN budget) (NN term)) (PP (IN to) (NP (DT the) (NN training) (NN loss)))))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB obtain) (NP (NP (DT a) (NN network)) (SBAR (WHNP (WDT which)) (S (ADVP (RB further)) (VP (VBZ reduces) (SBAR (S (NP (NP (DT the) (NN number)) (PP (IN of))) (VP (VBZ computes) (PP (IN by) (NP (QP (ADVP (IN at) (RBS least)) (CD 10x))))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (PP (IN by) (S (VP (VBG employing) (NP (DT a) (JJ temporal) (NN curriculum)) (S (VP (VBG learning) (NP (NN schedule)) (PP (IN for) (NP (DT the) (NML (NN g) (HYPH -) (NN LSTM))))))))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB reduce) (NP (NP (DT the) (NN convergence) (NN time)) (PP (IN of) (NP (DT the) (JJ equivalent) (NNP LSTM) (NN network)))) (PP (IN on) (NP (JJ long) (NNS sequences))))) (. .))
