(S (NP (NN Batch) (NN Normalization)) (VP (VBZ is) (NP (DT a) (ADJP (RB commonly) (VBN used)) (NN trick) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks))))))))) (. .))
(S (NP (DT These) (JJ neural) (NNS networks)) (VP (VBP use) (NP (NN L2) (NN regularization)) (, ,) (ADVP (RB also)) (VP (VBN called) (NP (NN weight) (NN decay)) (, ,) (S (ADVP (RB ostensibly)) (VP (TO to) (VP (VB prevent) (NP (NN overfitting))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NN L2) (NN regularization)) (VP (VBZ has) (NP (DT no) (VBG regularizing) (NN effect)) (ADVP (WRB when)) (VP (VBN combined) (PP (IN with) (NP (NN normalization)))))))) (. .))
(S (ADVP (RB Instead)) (, ,) (NP (NN regularization)) (VP (VBZ has) (NP (NP (DT an) (NN influence)) (PP (PP (IN on) (NP (NP (DT the) (NN scale)) (PP (IN of) (NP (NNS weights))))) (, ,) (CC and) (ADVP (RB thereby)) (PP (IN on) (NP (DT the) (JJ effective) (NN learning) (NN rate)))))) (. .))
(S (NP (PRP We)) (VP (VBP investigate) (S (NP (DT this) (NN dependence))) (, ,) (UCP (CC both) (PP (IN in) (NP (NN theory))) (, ,) (CC and) (ADVP (RB experimentally)))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (JJ popular) (NN optimization) (NNS methods)) (PP (JJ such) (IN as) (NP (NN ADAM)))) (ADVP (RB only) (RB partially)) (VP (VB eliminate) (NP (NP (DT the) (NN influence)) (PP (IN of) (NP (NN normalization)))) (PP (IN on) (NP (DT the) (NN learning) (NN rate))))))) (. .))
(S (NP (DT This)) (VP (VBZ leads) (PP (IN to) (NP (NP (DT a) (NN discussion)) (PP (IN on) (NP (JJ other) (NNS ways))))) (S (VP (TO to) (VP (VB mitigate) (NP (DT this) (NN issue)))))) (. .))
