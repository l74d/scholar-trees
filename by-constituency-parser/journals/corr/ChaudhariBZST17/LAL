(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN algorithm)) (VP (VBN called) (S (NP (NNP Parle)))) (PP (IN for) (NP (NP (JJ parallel) (NN training)) (PP (IN of) (NP (JJ deep) (NNS networks))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ converges) (ADVP (ADVP (NP (JJ 2-4x)) (NN faster)) (PP (IN than) (NP (NP (DT a) (JJ data-parallel) (NN implementation)) (PP (IN of) (NP (NNP SGD)))))) (, ,) (SBAR (IN while) (S (VP (VBG achieving) (NP (NP (ADJP (RB significantly) (VBN improved)) (NN error) (NNS rates)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RB nearly) (JJ state-of-the-art)) (PP (IN on) (NP (NP (JJ several) (NNS benchmarks)) (PP (VBG including) (NP (JJ CIFAR-10) (CC and) (NNP CIFAR-100)))))))))))) (, ,) (PP (IN without) (S (VP (VBG introducing) (NP (DT any) (JJ additional) (NNS hyper-parameters)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP exploit) (NP (NP (DT the) (NN phenomenon)) (PP (IN of) (NP (JJ flat) (NN minima))) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB lead) (PP (TO to) (NP (NP (VBN improved) (NN generalization) (NN error)) (PP (IN for) (NP (JJ deep) (NNS networks))))))))))))))) (. .))
(S (NP (NNP Parle)) (VP (VP (VBZ requires) (NP (NP (ADJP (RB very) (JJ infrequent)) (NN communication)) (PP (IN with) (NP (DT the) (NN parameter) (NN server))))) (CC and) (VP (ADVP (RB instead)) (NNS performs) (NP (JJR more) (NN computation)) (PP (IN on) (NP (DT each) (NN client))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (NP (PRP it)) (ADJP (JJ well-suited) (PP (TO to) (NP (DT both) (NP (JJ single-machine) (, ,) (JJ multi-GPU) (NNS settings)) (CC and) (NP (JJ distributed) (NNS implementations))))))))))) (. .))
