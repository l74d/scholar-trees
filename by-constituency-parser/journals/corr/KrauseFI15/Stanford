(S (S (VP (VBG Estimating) (NP (DT the) (NML (NN log) (HYPH -) (NN likelihood)) (NN gradient)) (PP (IN with) (NP (NP (NN respect)) (PP (IN to) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT a) (VBN Restricted) (NNP Boltzmann) (NNP Machine))))))) (PRN (-LRB- -LRB-) (NP (NNP RBM)) (-RRB- -RRB-)))) (ADVP (RB typically)) (VP (VBZ requires) (NP (NN sampling)) (S (VP (VBG using) (NP (NNP Markov) (NML (NNP Chain) (NNP Monte) (NNP Carlo) (-LRB- -LRB-) (NNP MCMC) (-RRB- -RRB-)) (NNS techniques))))) (. .))
(S (S (VP (TO To) (VP (VB save) (NP (NN computation) (NN time))))) (, ,) (NP (DT the) (NNP Markov) (NNS chains)) (VP (VBP are) (NP (NP (JJ only) (NN run)) (PP (IN for) (NP (NP (DT a) (JJ small) (NN number)) (PP (IN of) (NP (NP (NNS steps)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ leads) (PP (IN to) (NP (DT a) (JJ biased) (NN estimate)))))))))))) (. .))
(S (NP (DT This) (NN bias)) (VP (MD can) (VP (VB cause) (NP (NP (NNP RBM) (NN training) (NNS algorithms)) (PP (JJ such) (IN as) (NP (NP (NNP Contrastive) (NNP Divergence) (-LRB- -LRB-) (NNP CD) (-RRB- -RRB-)) (VP (VBG learning) (S (VP (TO to) (VP (VB deteriorate)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP adopt) (NP (NP (DT the) (NN idea)) (PP (IN behind) (NP (NML (NML (NNP Population) (NNP Monte) (NNP Carlo)) (-LRB- -LRB-) (NML (NP (NNP PMC))) (-RRB- -RRB-)) (NNS methods)))) (S (VP (TO to) (VP (VB devise) (NP (NP (DT a) (JJ new) (NNP RBM) (NN training) (NN algorithm)) (VP (VBN termed) (NP (NNP Population) (HYPH -) (NNP Contrastive) (HYPH -) (NNP Divergence))))))) (PRN (-LRB- -LRB-) (NP (NN pop) (HYPH -) (NN CD)) (-RRB- -RRB-))) (. .))
(S (PP (VBN Compared) (PP (IN to) (NP (NNP CD)))) (, ,) (NP (PRP it)) (VP (VP (VBZ leads) (PP (IN to) (NP (DT a) (JJ consistent) (NN estimate)))) (CC and) (VP (MD may) (VP (VB have) (NP (DT a) (ADJP (RB significantly) (JJR lower)) (NN bias))))) (. .))
(S (NP (PRP$ Its) (JJ computational) (NN overhead)) (VP (VBZ is) (ADJP (JJ negligible)) (PP (VBN compared) (PP (IN to) (NP (NN CD))))) (. .))
(FRAG (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN variance)) (PP (IN of) (NP (DT the) (NN gradient) (NN estimate) (NNS increases)))) (. .))
(S (NP (PRP We)) (ADVP (RB experimentally)) (VP (VBP show) (SBAR (IN that) (S (NP (NN pop) (HYPH -) (NN CD)) (VP (MD can) (ADVP (RB significantly)) (VP (VB outperform) (NP (NN CD))))))) (. .))
(S (PP (IN In) (NP (JJ many) (NNS cases))) (, ,) (NP (PRP we)) (VP (VP (VBD observed) (NP (DT a) (JJR smaller) (NN bias))) (CC and) (VP (VBD achieved) (NP (JJR higher) (NML (NN log) (HYPH -) (NN likelihood)) (NNS values)))) (. .))
(S (S (ADVP (RB However)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NNP RBM) (NN distribution)) (VP (VBZ has) (NP (JJ many) (JJ hidden) (NNS neurons))))) (, ,) (NP (NP (DT the) (JJ consistent) (NN estimate)) (PP (IN of) (NP (NN pop) (HYPH -) (NN CD)))) (VP (MD may) (ADVP (RB still)) (VP (VB have) (NP (DT a) (JJ considerable) (NN bias))))) (CC and) (S (NP (NP (DT the) (NN variance)) (PP (IN of) (NP (DT the) (NN gradient) (NN estimate)))) (VP (VBZ requires) (NP (DT a) (JJR smaller) (NN learning) (NN rate)))) (. .))
(S (ADVP (RB Thus)) (, ,) (PP (IN despite) (NP (PRP$ its) (JJ superior) (JJ theoretical) (NNS properties))) (, ,) (NP (PRP it)) (VP (VBZ is) (RB not) (ADJP (JJ advisable) (S (VP (TO to) (VP (VB use) (NP (NP (NN pop) (HYPH -) (NN CD)) (PP (IN in) (NP (PRP$ its) (JJ current) (NN form)))) (PP (IN on) (NP (JJ large) (NNS problems)))))))) (. .))
