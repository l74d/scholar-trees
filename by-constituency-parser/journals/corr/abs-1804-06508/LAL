(S (NP (NP (JJ Convolutional) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP CNNs)) (-RRB- -RRB-))) (VP (VBP have) (VP (VBN begun) (S (VP (TO to) (VP (VB permeate) (NP (NP (DT all) (NNS corners)) (PP (IN of) (NP (JJ electronic) (NN society)))) (PRN (-LRB- -LRB-) (PP (PP (IN from) (NP (NN voice) (NN recognition))) (PP (TO to) (NP (VB scene) (NN generation)))) (-RRB- -RRB-))))) (PP (RB due) (TO to) (NP (NP (PRP$ their) (NX (NX (JJ high) (NN accuracy)) (CC and) (NX (NN machine) (NN efficiency)))) (PP (IN per) (NP (NN operation))))))) (. .))
(S (PP (IN At) (NP (PRP$ their) (NN core))) (, ,) (NP (NNP CNN) (NNS computations)) (VP (VBP are) (VP (VBN made) (PRT (IN up)) (PP (IN of) (NP (NP (JJ multi-dimensional) (NN dot) (NNS products)) (PP (IN between) (NP (NP (NN weight)) (CC and) (NP (NN input) (NNS vectors)))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (NNS studies) (SBAR (WHADVP (WRB how)) (S (NP (NP (JJ weight) (NN repetition)) (PRN (PRN (: —) (SBAR (WHADVP (VBP -when)) (S (NP (DT the) (JJ same) (NN weight)) (VP (VBZ occurs) (NP (JJ multiple) (NNS times)) (PP (IN in) (CC or) (IN across) (NP (JJ weight) (NNS vectors)))))) (: —)) (: -))) (VP (MD can) (VP (VB be) (VP (VBN exploited) (S (VP (TO to) (VP (VP (VB save) (NP (NN energy))) (CC and) (VP (VB improve) (NP (NN performance))) (PP (IN during) (NP (NNP CNN) (NN inference)))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ generalizes) (NP (NP (DT a) (JJ popular) (NN line)) (PP (IN of) (NP (NN work))) (SBAR (S (VP (TO to) (VP (VB improve) (NP (NN efficiency)) (PP (IN from) (NP (NNP CNN) (NN weight) (NN sparsity)))))))) (, ,) (SBAR (IN as) (S (S (VP (VBG reducing) (NP (NP (NN computation)) (ADJP (JJ due) (PP (TO to) (NP (VBN repeated) (CD zero) (NNS weights))))))) (VP (VBZ is) (NP (NP (DT a) (JJ special) (NN case)) (PP (IN of) (S (VP (VBG reducing) (NP (NP (NN computation)) (ADJP (JJ due) (PP (TO to) (NP (JJ repeated) (NNS weights))))))))))))) (. .))
(S (S (VP (TO To) (VP (VB exploit) (NP (NN weight) (NN repetition))))) (, ,) (NP (DT this) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (JJ new) (NNP CNN) (NN accelerator)) (VP (VBD called) (S (NP (S (NP (DT the) (NNP Unique) (NNP Weight) (NNP CNN) (NNP Accelerator))) (PRN (-LRB- -LRB-) (NP (NNP UCNN)) (-RRB- -RRB-))))))) (. .))
(S (NP (JJ UCNN)) (VP (NNS uses) (NP (VBD weight) (NN repetition)) (S (VP (VP (TO to) (VP (VB reuse) (NP (NP (NNP CNN) (NNS sub-computations)) (PRN (-LRB- -LRB-) (NN e.g.) (, ,) (NP (NN dot) (NNS products)) (-RRB- -RRB-))))) (CC and) (VP (TO to) (VP (VB reduce) (NP (NNP CNN) (NN model) (NN size)) (SBAR (WHADVP (WRB when)) (S (VP (VBN stored) (PP (IN in) (NP (JJ off-chip) (NNP DRAM)))))))) (: —) (SBAR (WHNP (WHNP (DT -both)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBP save) (NP (NN energy)))))))) (. .))
(S (NP (NNP UCNN)) (VP (ADVP (JJ further)) (NNS improves) (NP (NN performance)) (PP (IN by) (S (VP (VBG exploiting) (NP (NP (NN sparsity)) (PP (IN in) (NP (NNS weights)))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NNP UCNN)) (PP (PP (IN with) (NP (DT an) (JJ accelerator-level) (NN cycle) (CC and) (NN energy) (NN model))) (CC and) (PP (IN with) (NP (NP (DT an) (NNP RTL) (NN implementation)) (PP (IN of) (NP (DT the) (NNP UCNN) (NN processing) (NN element))))))) (. .))
(S (PP (IN On) (NP (CD three) (JJ contemporary) (NNP CNNs))) (, ,) (NP (NNP UCNN)) (VP (VBZ improves) (NP (JJ throughput-normalized) (NN energy) (NN consumption)) (PP (IN by) (NP (CD 1.2x) (: -) (CD 4x))) (, ,) (ADVP (JJ relative) (PP (TO to) (NP (NP (DT a) (ADJP (RB similarly) (VBN provisioned)) (NN baseline) (NN accelerator)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (JJ Eyeriss-style) (NN sparsity) (NNS optimizations))))))))) (. .))
(S (PP (IN At) (NP (DT the) (JJ same) (NN time))) (, ,) (NP (DT the) (NNP UCNN) (NN processing) (NN element)) (VP (VBZ adds) (NP (ADJP (QP (RB only) (JJ 17-24)) (NN %)) (NN area) (JJ overhead)) (ADVP (NN relative) (PP (TO to) (NP (DT the) (JJ same) (NN baseline))))) (. .))
