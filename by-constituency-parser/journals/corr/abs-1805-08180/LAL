(S (NP (NN Reinforcement) (NNP Learning) (PRN (-LRB- -LRB-) (NNP RL) (-RRB- -RRB-)) (NN algorithms)) (VP (MD can) (VP (VB suffer) (PP (IN from) (NP (JJ poor) (NN sample) (NN efficiency))) (SBAR (WHADVP (WRB when)) (S (NP (NNS rewards)) (VP (VBP are) (ADJP (ADJP (VBN delayed)) (CC and) (ADJP (JJ sparse)))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (NN solution)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (S (NP (NNS agents)) (VP (TO to) (VP (VB learn) (NP (ADJP (RB temporally) (JJ extended)) (NNS actions)) (PP (IN at) (NP (NP (JJ multiple) (NNS levels)) (PP (IN of) (NP (NN abstraction))))) (PP (IN in) (NP (DT a) (ADJP (JJ sample) (NN efficient) (CC and) (JJ automated)) (NN fashion))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (NNS combines) (NP (NP (JJ universal) (NN value) (NNS functions)) (CC and) (NP (NN hindsight) (NN learning))) (, ,) (S (VP (VBG allowing) (S (NP (NNS agents)) (VP (TO to) (VP (VB learn) (NP (NP (NNS policies)) (VP (VBG belonging) (PP (TO to) (NP (JJ different) (NN time) (NNS scales))))) (PP (IN in) (NP (NN parallel))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (ADVP (RB significantly)) (VBZ accelerates) (NP (VBG learning)) (PP (IN in) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (ADJP (JJ discrete) (CC and) (JJ continuous)) (NNS tasks))))))))) (. .))
