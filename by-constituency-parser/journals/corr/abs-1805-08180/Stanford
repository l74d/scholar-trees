(S (NP (NP (NN Reinforcement) (NN Learning) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-))) (NP (NNS algorithms))) (VP (MD can) (VP (VB suffer) (PP (IN from) (NP (JJ poor) (NN sample) (NN efficiency))) (SBAR (WHADVP (WRB when)) (S (NP (NNS rewards)) (VP (VBP are) (ADJP (ADJP (VBN delayed)) (CC and) (ADJP (JJ sparse)))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (NN solution)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (NP (NNS agents)) (S (VP (TO to) (VP (VB learn) (NP (ADJP (RB temporally) (VBN extended)) (NNS actions)) (PP (IN at) (NP (NP (NP (JJ multiple) (NNS levels)) (PP (IN of) (NP (NN abstraction)))) (PP (IN in) (NP (DT a) (NN sample))) (UCP (ADJP (JJ efficient)) (CC and) (NML (JJ automated) (NN fashion))))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ combines) (NP (NP (JJ universal) (NN value) (NNS functions)) (CC and) (NP (NN hindsight) (NN learning))) (, ,) (S (VP (VBG allowing) (NP (NNS agents)) (S (VP (TO to) (VP (VB learn) (NP (NP (NNS policies)) (VP (VBG belonging) (PP (IN to) (NP (NP (JJ different) (NN time) (NNS scales)) (PP (IN in) (NP (NN parallel))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (ADVP (RB significantly)) (VP (VBZ accelerates) (NP (NP (NN learning)) (PP (IN in) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (ADJP (JJ discrete) (CC and) (JJ continuous)) (NNS tasks)))))))))) (. .))
