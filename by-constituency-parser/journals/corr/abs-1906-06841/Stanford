(S (NP (PRP We)) (VP (VBP present) (NP (DT a) (JJ novel) (ADJP (NP (NN reinforcement) (NN learning)) (HYPH -) (VBN based)) (NML (JJ natural) (NNS media)) (NN painting) (NN algorithm))) (. .))
(S (S (NP (PRP$ Our) (NN goal)) (VP (VBZ is) (S (VP (TO to) (VP (VB reproduce) (NP (DT a) (NN reference) (NN image)) (S (VP (VBG using) (NP (NN brush) (NNS strokes))))))))) (CC and) (S (NP (PRP we)) (VP (VBP encode) (NP (DT the) (NN objective)) (PP (IN through) (NP (NNS observations))))) (. .))
(S (S (NP (PRP$ Our) (NN formulation)) (VP (VBZ takes) (PP (IN into) (NP (NN account))) (SBAR (IN that) (S (NP (NP (DT the) (NN distribution)) (PP (IN of) (NP (NP (DT the) (NN reward)) (PP (IN in) (NP (DT the) (NN action) (NN space)))))) (VP (VBZ is) (ADJP (JJ sparse))))))) (CC and) (S (S (VP (VBG training) (NP (DT a) (NN reinforcement)) (S (VP (VBG learning) (NP (NN algorithm)) (PP (IN from) (NP (NN scratch))))))) (VP (MD can) (VP (VB be) (ADJP (JJ difficult))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT an) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ combines) (NP (ADJP (NN self) (HYPH -) (JJ supervised)) (NN learning) (CC and) (NN reinforcement)) (S (VP (VBG learning) (PP (IN to) (NP (NP (ADVP (RB effectively)) (NN transfer)) (NP (JJ negative) (NNS samples)))) (PP (IN into) (NP (JJ positive) (NNS ones)))))) (CC and) (VP (VB change) (NP (DT the) (NN reward) (NN distribution)))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (NP (PRP$ our) (NN painting) (NN agent)))) (S (VP (TO to) (VP (VB reproduce) (NP (NN reference) (NNS images)) (PP (IN with) (NP (NN brush) (NNS strokes))))))) (. .))
(S (S (NP (DT The) (NN training) (NN phase)) (VP (VBZ takes) (NP (QP (RB about) (CD one)) (NN hour)))) (CC and) (S (NP (DT the) (NN runtime) (NN algorithm)) (VP (VBZ takes) (PP (NP (QP (RB about) (CD 30)) (NNS seconds)) (IN on) (NP (DT a) (NN GTX1080) (NN GPU))) (S (VP (VBG reproducing) (NP (DT a) (NN 1000x800) (NN image)) (PP (IN with) (NP (CD 20,000) (NNS strokes))))))) (. .))
