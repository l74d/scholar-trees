(S (NP (PRP We)) (VP (VBP aim) (S (VP (TO to) (VP (VB design) (NP (NP (JJ adaptive) (JJ online) (NN learning) (NNS algorithms)) (SBAR (WHNP (WDT that)) (S (VP (VBP take) (NP (NP (NN advantage)) (PP (IN of) (NP (NP (DT any) (JJ special) (NN structure)) (SBAR (WHNP (WDT that)) (S (VP (MD might) (VP (VB be) (ADJP (JJ present)) (PP (IN in) (NP (NP (NP (DT the) (NN learning) (NN task)) (PP (IN at) (NP (NN hand)))) (, ,) (CONJP (IN with) (RB as)) (NP (NP (JJ little) (JJ manual) (NN tuning)) (PP (IN by) (NP (DT the) (NN user)))))) (SBAR (IN as) (FRAG (ADJP (JJ possible))))))))))))))))))) (. .))
(S (NP (NP (DT A) (JJ fundamental) (NN obstacle)) (SBAR (WHNP (WDT that)) (S (VP (VBZ comes) (PRT (RP up)) (PP (IN in) (NP (NP (DT the) (NN design)) (PP (IN of) (NP (JJ such) (JJ adaptive) (NNS algorithms))))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB calibrate) (NP (DT a) (ADJP (RB so) (HYPH -) (VBN called)) (NML (NML (NN step) (HYPH -) (NN size)) (CC or) (NML (NN learning) (NN rate))) (NN hyperparameter)) (PP (VBG depending) (PP (IN on) (NP (NP (NN variance)) (, ,) (NP (NN gradient) (NNS norms)) (, ,) (ADVP (FW etc.))))))))) (. .))
(S (NP (DT A) (JJ recent) (NN technique)) (VP (VBZ promises) (S (VP (TO to) (VP (VB overcome) (NP (DT this) (NN difficulty)) (PP (IN by) (S (VP (VBG maintaining) (NP (JJ multiple) (NN learning) (NNS rates)) (PP (IN in) (NP (NN parallel)))))))))) (. .))
(S (NP (DT This) (NN technique)) (VP (VBZ has) (VP (VBN been) (VP (VBN applied) (PP (IN in) (NP (NP (NP (DT the) (NNP MetaGrad) (NN algorithm)) (PP (IN for) (NP (JJ online) (NN convex) (NN optimization)))) (CC and) (NP (NP (DT the) (NNP Squint) (NN algorithm)) (PP (IN for) (NP (NN prediction)))))) (PP (IN with) (NP (NN expert) (NN advice)))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (DT both) (NNS cases))) (NP (DT the) (NN user)) (ADVP (RB still)) (VP (VBZ has) (S (VP (TO to) (VP (VB provide) (PP (IN in) (NP (NN advance))) (NP (NP (DT a) (NNP Lipschitz) (NN hyperparameter)) (SBAR (WHNP (WDT that)) (S (VP (VBZ bounds) (NP (NP (DT the) (NN norm)) (PP (IN of) (NP (DT the) (NNS gradients)))))))))))) (. .))
(S (S (SBAR (IN Although) (S (NP (DT this) (NN hyperparameter)) (VP (VBZ is) (ADVP (RB typically)) (RB not) (ADJP (JJ available) (PP (IN in) (NP (NN advance))))))) (, ,) (VP (VB tuning) (SBAR (S (NP (PRP it)) (ADVP (RB correctly)) (VP (VBZ is) (ADJP (JJ crucial))))))) (: :) (S (SBAR (IN if) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN set) (S (ADJP (RB too) (JJ small))))))) (, ,) (NP (DT the) (NNS methods)) (VP (MD may) (VP (VB fail) (ADVP (RB completely))))) (: ;) (CC but) (S (SBAR (IN if) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN taken) (S (ADJP (RB too) (JJ large))))))) (, ,) (NP (NN performance)) (VP (VBZ deteriorates) (ADVP (RB significantly)))) (. .))
(SQ (PP (IN In) (NP (DT the) (JJ present) (NN work))) (NP (PRP we)) (VP (VB remove) (NP (DT this) (NNP Lipschitz) (NN hyperparameter)) (PP (IN by) (S (VP (VBG designing) (NP (NP (NP (JJ new) (NNS versions)) (PP (IN of) (NP (NNP MetaGrad) (CC and) (NNP Squint)))) (SBAR (WHNP (WDT that)) (S (VP (VBP adapt) (PP (IN to) (NP (PRP$ its) (JJ optimal) (NN value))) (ADVP (RB automatically)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP achieve) (NP (DT this)) (PP (IN by) (S (ADVP (RB dynamically)) (VP (VBG updating) (NP (NP (DT the) (NN set)) (PP (IN of) (NP (JJ active) (NN learning) (NNS rates)))))))) (. .))
(S (PP (IN For) (NP (NNP MetaGrad))) (, ,) (S (NP (PRP we)) (ADVP (RB further)) (VP (VB improve) (NP (NP (DT the) (JJ computational) (NN efficiency)) (PP (IN of) (S (VP (VBG handling) (NP (NNS constraints)) (PP (IN on) (NP (NP (DT the) (NN domain)) (PP (IN of) (NP (NN prediction))))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VB remove) (NP (DT the) (NN need)) (S (VP (TO to) (VP (VB specify) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS rounds)) (PP (IN in) (NP (NN advance))))))))))) (. .))
