(S (S (VP (ADVP (RB Effectively)) (VBG leveraging) (NP (JJ large) (, ,) (ADJP (RB previously) (VBN collected)) (NNS datasets)) (PP (IN in) (NP (NP (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)))))) (VP (VBZ is) (NP (NP (DT a) (JJ key) (NN challenge)) (PP (IN for) (NP (JJ large-scale) (NN real-world) (NNS applications))))) (. .))
(S (NP (NNP Offline) (NNP RL) (RB algorithms)) (VP (NN promise) (S (VP (TO to) (VP (VB learn) (NP (JJ effective) (NNS policies)) (PP (IN from) (NP (JJ previously-collected) (, ,) (JJ static) (NNS datasets))) (PP (IN without) (NP (JJ further) (NN interaction))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (NN practice))) (, ,) (S (NP (JJ offline) (NNP RL)) (VP (VBZ presents) (NP (DT a) (JJ major) (NN challenge)))) (, ,) (CC and) (S (NP (JJ standard) (NN off-policy) (NNP RL) (NNS methods)) (VP (MD can) (VP (VB fail) (PP (JJ due) (PP (TO to) (NP (NP (NN overestimation)) (PP (IN of) (NP (NP (NNS values)) (VP (VBN induced) (PP (IN by) (NP (NP (DT the) (JJ distributional) (NN shift)) (PP (IN between) (NP (NP (DT the) (NN dataset)) (CC and) (NP (DT the) (JJ learned) (NN policy)))))))))))) (, ,) (SBAR (ADVP (RB especially)) (WRB when) (S (VP (VBG training) (PP (IN on) (NP (ADJP (JJ complex) (CC and) (JJ multi-modal)) (NNS data) (NNS distributions))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ conservative) (NNP Q-learning)) (PRN (-LRB- -LRB-) (NP (NNP CQL)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ aims) (S (VP (TO to) (VP (VB address) (NP (DT these) (NNS limitations)) (PP (IN by) (S (VP (VBG learning) (NP (DT a) (JJ conservative) (NN Q-function)) (SBAR (JJ such) (IN that) (S (NP (NP (DT the) (JJ expected) (NN value)) (PP (IN of) (NP (DT a) (NN policy))) (PP (IN under) (NP (DT this) (JJ Q-function)))) (VP (VBZ lower-bounds) (NP (PRP$ its) (JJ true) (NN value)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB theoretically)) (VBP show) (SBAR (SBAR (IN that) (S (NP (NNP CQL)) (VP (VBZ produces) (NP (NP (DT a) (JJR lower) (NN bound)) (PP (IN on) (NP (NP (DT the) (NN value)) (PP (IN of) (NP (DT the) (JJ current) (NN policy))))))))) (CC and) (SBAR (IN that) (S (NP (PRP it)) (VP (MD can) (VP (VB be) (VP (VBN incorporated) (PP (IN into) (NP (DT a) (NN policy) (VBG learning) (NN procedure))) (PP (IN with) (NP (JJ theoretical) (NN improvement) (NNS guarantees)))))))))) (. .))
(S (PP (IN In) (NP (NN practice))) (, ,) (NP (NNP CQL)) (VP (VBZ augments) (NP (DT the) (JJ standard) (NNP Bellman) (NN error) (NN objective)) (PP (IN with) (NP (NP (DT a) (JJ simple) (NNP Q-value) (NN regularizer)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ straightforward) (SBAR (S (VP (TO to) (VP (VB implement) (PP (IN on) (NP (NP (NN top)) (PP (IN of) (NP (VBG existing) (UCP (JJ deep) (JJ Q-learning) (CC and) (JJ actor-critic)) (NNS implementations)))))))))))))))) (. .))
(S (PP (IN On) (NP (DT both) (ADJP (JJ discrete) (CC and) (JJ continuous)) (NN control) (NNS domains))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP CQL)) (VP (ADVP (RB substantially)) (VBZ outperforms) (NP (VBG existing) (JJ offline) (NNP RL) (NNS methods)) (, ,) (S (ADVP (RB often)) (VP (VBG learning) (NP (NP (NNS policies)) (SBAR (WHNP (WDT that)) (S (VP (VBP attain) (NP (ADJP (QP (JJ 2-5) (NNS times)) (RBR higher)) (JJ final) (NN return)))))) (, ,) (SBAR (WHADVP (ADVP (RB especially)) (WRB when)) (S (VP (VBG learning) (PP (IN from) (NP (ADJP (JJ complex) (CC and) (JJ multi-modal)) (NNS data) (NNS distributions)))))))))))) (. .))
