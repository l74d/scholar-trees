(S (NP (ADJP (NP (NN Magnitude)) (HYPH -) (VBN based)) (NN pruning)) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (JJS simplest) (NNS methods)) (PP (IN for) (NP (NN pruning) (JJ neural) (NNS networks))))))) (. .))
(S (PP (IN Despite) (NP (PRP$ its) (NN simplicity))) (, ,) (NP (NP (ADJP (NP (NN magnitude)) (HYPH -) (VBN based)) (NN pruning)) (CC and) (NP (PRP$ its) (NNS variants))) (VP (VBD demonstrated) (NP (JJ remarkable) (NNS performances)) (PP (IN for) (NP (NN pruning) (JJ modern) (NNS architectures)))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (NP (DT the) (NN observation)) (SBAR (IN that) (S (NP (ADJP (NP (NN magnitude)) (HYPH -) (VBN based)) (NN pruning)) (ADVP (RB indeed)) (VP (VBZ minimizes) (NP (NP (DT the) (NNP Frobenius) (NN distortion)) (PP (IN of) (NP (NP (DT a) (JJ linear) (NN operator)) (VP (VBG corresponding) (PP (IN to) (NP (DT a) (JJ single) (NN layer))))))))))))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (DT a) (JJ simple) (NN pruning) (NN method)) (, ,) (VP (VBN coined) (NP (NN lookahead) (NN pruning)) (, ,) (PP (IN by) (S (VP (VBG extending) (NP (DT the) (JJ single) (NN layer) (NN optimization)) (PP (IN to) (NP (DT a) (JJ multi-layer) (NN optimization))))))))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (JJ proposed) (NN method)) (ADVP (RB consistently)) (VP (VBZ outperforms) (NP (NP (ADJP (NP (NN magnitude)) (HYPH -) (VBN based)) (NN pruning)) (PP (PP (IN on) (NP (NP (JJ various) (NNS networks)) (, ,) (PP (VBG including) (NP (NP (NN VGG)) (CC and) (NP (NNP ResNet)))))) (, ,) (RB particularly) (PP (IN in) (NP (DT the) (NML (JJ high) (HYPH -) (NN sparsity)) (NN regime))))))))) (. .))
(S (VP (VB See) (S (NP (DT this)) (VP (VBZ https) (NP (NP (NN URL)) (PP (IN for) (NP (NNS codes))))))) (. .))
