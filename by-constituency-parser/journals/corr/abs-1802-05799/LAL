(S (S (VP (VBG Training) (NP (JJ modern) (JJ deep) (NN learning) (NNS models)))) (VP (VBZ requires) (NP (NP (JJ large) (NNS amounts)) (PP (IN of) (NP (NN computation))) (, ,) (VP (ADVP (RB often)) (VBN provided) (PP (IN by) (NP (NNP GPUs)))))) (. .))
(S (S (VP (VBG Scaling) (NP (NN computation)) (PP (IN from) (NP (CD one) (NNP GPU))) (PP (TO to) (NP (JJ many))))) (VP (VP (MD can) (VP (VB enable) (NP (ADJP (JJ much) (JJR faster)) (NN training) (CC and) (NN research) (NN progress)))) (CC but) (VP (VBZ entails) (NP (CD two) (NNS complications)))) (. .))
(S (ADVP (RB First)) (, ,) (NP (DT the) (NN training) (NN library)) (VP (MD must) (VP (VB support) (NP (JJ inter-GPU) (NN communication)))) (. .))
(S (PP (VBG Depending) (PP (IN on) (NP (NP (DT the) (JJ particular) (NNS methods)) (VP (VBN employed))))) (, ,) (NP (DT this) (NN communication)) (VP (MD may) (VP (VB entail) (NP (ADJP (RB anywhere) (PP (PP (IN from) (ADJP (JJ negligible))) (TO to) (ADJP (JJ significant)))) (NN overhead)))) (. .))
(S (ADVP (JJ Second)) (, ,) (NP (DT the) (NN user)) (VP (MD must) (VP (VB modify) (NP (PRP$ his) (CC or) (PRP$ her) (NN training) (NN code)) (S (VP (TO to) (VP (VB take) (NP (NN advantage)) (PP (IN of) (NP (JJ inter-GPU) (NN communication)))))))) (. .))
(S (PP (VBG Depending) (PP (IN on) (NP (NP (DT the) (NN training) (NN library) (POS 's)) (NNP API)))) (, ,) (NP (NP (DT the) (NN modification)) (VP (VBN required))) (VP (MD may) (VP (VB be) (ADJP (CC either) (JJ significant) (CC or) (JJ minimal)))) (. .))
(S (NP (NP (VBG Existing) (NNS methods)) (PP (IN for) (S (VP (VBG enabling) (NP (JJ multi-GPU) (NN training)) (PP (IN under) (NP (DT the) (NNP TensorFlow) (JJ library))))))) (VP (VP (NN entail) (NP (JJ non-negligible) (NN communication) (NN overhead))) (CC and) (VP (NN require) (S (NP (NNS users)) (VP (TO to) (VP (ADVP (RB heavily)) (VB modify) (NP (PRP$ their) (JJ model-building) (NN code)))))) (, ,) (S (VP (VBG leading) (S (NP (JJ many) (NNS researchers)) (VP (TO to) (VP (VP (VB avoid) (NP (DT the) (JJ whole) (NN mess))) (CC and) (VP (NN stick) (PP (IN with) (NP (JJR slower) (JJ single-GPU) (NN training)))))))))) (. .))
(S (S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP introduce) (NP (NP (NNP Horovod)) (, ,) (NP (NP (DT an) (JJ open) (NN source) (NN library)) (SBAR (WHNP (WDT that)) (S (VP (VBZ improves) (PP (IN on) (NP (NP (DT both) (NNS obstructions)) (PP (TO to) (NP (NN scaling)))))))))))) (: :) (S (NP (PRP it)) (VP (VP (VBZ employs) (NP (NP (JJ efficient) (JJ inter-GPU) (NN communication)) (PP (IN via) (NP (VBG ring) (NN reduction))))) (CC and) (VP (VBZ requires) (NP (NP (QP (RB only) (DT a) (JJ few)) (NNS lines)) (PP (IN of) (NP (NP (NN modification)) (PP (TO to) (NP (VB user) (NN code))))))) (, ,) (S (VP (VBG enabling) (NP (NP (RBR faster) (, ,) (JJR easier) (VBD distributed) (NN training)) (PP (IN in) (NP (NNP TensorFlow)))))))) (. .))
(S (NP (NNP Horovod)) (VP (VBZ is) (ADJP (JJ available) (PP (IN under) (NP (DT the) (NNP Apache) (CD 2.0) (NN license)))) (PP (IN at) (NP (DT this) (NN https) (NNP URL)))))
