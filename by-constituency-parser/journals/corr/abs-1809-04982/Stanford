(S (NP (NP (JJ Neuromorphic) (NML (NML (NNP Multiply)) (HYPH -) (CC And) (HYPH -) (NML (NN Accumulate)) (NML (-LRB- -LRB-) (NNP MAC) (-RRB- -RRB-))) (NNS circuits)) (VP (VBG utilizing) (NP (JJ synaptic) (NN weight) (NNS elements)) (PP (VBN based) (PP (IN on) (NP (NNP SRAM) (CC or) (JJ novel) (JJ Non-Volatile) (NNP Memories))))) (PRN (-LRB- -LRB-) (NP (NNS NVMs)) (-RRB- -RRB-))) (VP (VBP provide) (NP (DT a) (JJ promising) (NN approach)) (PP (IN for) (NP (NP (ADJP (RB highly) (JJ efficient)) (NN hardware) (NNS representations)) (PP (IN of) (NP (JJ neural) (NNS networks)))))) (. .))
(S (NP (NNP NVM) (NN density) (CC and) (NN robustness) (NNS requirements)) (VP (VBP suggest) (SBAR (IN that) (S (NP (NML (PP (IN off) (HYPH -) (NP (NN line)))) (NN training)) (VP (VBZ is) (NP (NP (DT the) (JJ right) (NN choice)) (PP (IN for) (NP (NP (`` ") (NN edge) ('' ") (NNS devices)) (, ,) (SBAR (IN since) (S (NP (NP (DT the) (NNS requirements)) (PP (IN for) (NP (NN synapse) (NN precision)))) (VP (VBP are) (ADJP (ADVP (RB much) (RBR less)) (JJ stringent)))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (NML (PP (IN off) (HYPH -) (NP (NN line)))) (NN training)) (VP (VBG using) (NP (JJ ideal) (JJ mathematical) (NNS weights) (CC and) (NNS activations)))) (VP (MD can) (VP (VB result) (PP (IN in) (NP (NP (JJ significant) (NN loss)) (PP (IN of) (NP (NN inference) (NN accuracy))))) (SBAR (WHADVP (WRB when)) (S (VP (VBN applied) (PP (IN to) (NP (JJ non-ideal) (NN hardware)))))))) (. .))
(S (NP (NP (NNS Non-idealities)) (PP (JJ such) (IN as) (NP (NP (NP (JJ multi-bit) (NN quantization)) (PP (IN of) (NP (NNS weights) (CC and) (NNS activations)))) (, ,) (NP (NP (NN non-linearity)) (PP (IN of) (NP (NNS weights)))) (, ,) (NP (NP (JJ finite) (NML (NN max) (HYPH /) (NN min)) (NNS ratios)) (PP (IN of) (NP (NN NVM) (NNS elements)))) (, ,) (CC and) (NP (NP (NN asymmetry)) (PP (IN of) (NP (ADJP (JJ positive) (CC and) (JJ negative)) (NN weight) (NNS components))))))) (ADVP (DT all)) (VP (VBP result) (PP (IN in) (NP (JJ degraded) (NN inference) (NN accuracy)))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBN demonstrated) (SBAR (IN that) (S (NP (NP (JJ non-ideal) (NML (NNP Multi-Layer) (NNP Perceptron) (-LRB- -LRB-) (NNP MLP) (-RRB- -RRB-)) (NNS architectures)) (VP (VBG using) (NP (JJ low) (JJ bitwidth) (NNS weights) (CC and) (NNS activations)))) (VP (MD can) (VP (VB be) (VP (VBN trained) (PP (IN with) (NP (NML (NML (JJ negligible) (NN loss)) (PP (IN of) (NP (NN inference) (NN accuracy)))) (ADJP (JJ relative) (PP (IN to) (NP (NP (PRP$ their) (ADJP (NP (VBG Floating) (NN Point)) (HYPH -) (VBN trained)) (NNS counterparts)) (VP (VBG using) (NP (DT a) (VBN proposed)) (PP (IN off) (HYPH -) (NP (NN line))) (, ,) (ADVP (RB continuously)))))) (ADJP (NP (JJ differentiable) (NNP HW)) (HYPH -) (JJ aware)) (NN training) (NN algorithm)))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN algorithm)) (VP (VP (VBZ is) (ADJP (JJ applicable) (PP (IN to) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NN hardware) (NNS models))))))) (, ,) (CC and) (VP (VBZ uses) (NP (RB only) (NML (JJ standard) (JJ neural) (NN network)) (NN training) (NNS methods)))) (. .))
(S (NP (DT The) (NN algorithm)) (VP (VBZ is) (VP (VBN demonstrated) (PP (IN on) (NP (DT the) (NML (NN MNIST) (CC and) (NN EMNIST)) (NNS datasets))) (, ,) (S (VP (VBG using) (NP (JJ standard) (NNS MLPs)))))) (. .))
