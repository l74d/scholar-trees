(S (NP (NP (DT The) (ADJP (RBS most) (JJ common)) (NN method)) (PP (IN for) (NP (NNP DNN) (NN pruning)))) (VP (VBZ is) (NP (NP (NP (JJ hard) (NN thresholding)) (PP (IN of) (NP (NN network) (NNS weights)))) (, ,) (VP (VBN followed) (PP (IN by) (NP (NP (VBG retraining)) (SBAR (S (VP (TO to) (VP (VB recover) (NP (DT any) (JJ lost) (NN accuracy))))))))))) (. .))
(S (NP (ADJP (RB Recently) (VBN developed)) (JJ smart) (VBG pruning) (NN algorithms)) (VP (IN use) (NP (NP (DT the) (NNP DNN) (NN response)) (PP (IN over) (NP (DT the) (NN training) (VBN set)))) (PP (IN for) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NN cost) (NNS functions))))) (S (VP (TO to) (VP (VB determine) (NP (JJ redundant) (NN network) (NNS weights))))) (, ,) (S (VP (VBG leading) (PP (TO to) (NP (NP (JJR less) (JJ accuracy) (NN degradation)) (CC and) (ADVP (RB possibly)) (NP (RBR less) (JJ retraining) (NN time))))))) (. .))
(S (PP (IN For) (NP (NP (NNS experiments)) (PP (IN on) (NP (NP (DT the) (JJ total) (NN pruning) (NN time)) (PRN (-LRB- -LRB-) (NP (NP (JJ pruning) (NN time)) (IN +) (NP (VBG retraining) (NN time))) (-RRB- -RRB-)))))) (NP (PRP we)) (VP (VBP show) (SBAR (DT that) (S (NP (NP (JJ hard) (NN thresholding)) (VP (VBN followed) (PP (IN by) (NP (VBG retraining))))) (VP (VBZ remains) (NP (NP (DT the) (ADJP (RBS most) (JJ efficient)) (NN way)) (PP (IN of) (S (VP (VBG reducing) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NN network) (NNS parameters)))))))))))) (. .))
(S (ADVP (RB However)) (NP (JJ smart) (VBG pruning) (NN algorithms)) (ADVP (RB still)) (VP (VBP have) (NP (NNS advantages)) (SBAR (WHADVP (WRB when)) (S (NP (VBG retraining)) (VP (VBZ is) (RB not) (ADJP (JJ possible)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN context))) (NP (PRP we)) (VP (VP (VBP propose) (NP (NP (DT a) (JJ novel) (JJ smart) (VBG pruning) (NN algorithm)) (VP (VBN based) (PP (IN on) (NP (NAC (NP (NN difference)) (PP (IN of) (NP (JJ convex) (NNS functions)))) (NN optimisation)))))) (CC and) (VP (NN show) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADVP (RB often)) (ADJP (ADJP (NP (NP (NNS orders)) (PP (IN of) (NP (NN magnitude)))) (RBR faster)) (PP (IN than) (NP (VBG competing) (NNS approaches)))) (SBAR (IN while) (S (VP (VBG achieving) (NP (DT the) (JJS lowest) (NN classification) (NN accuracy) (NN degradation)))))))))) (. .))
(S (ADVP (IN Furthermore)) (NP (PRP we)) (VP (VBP investigate) (ADVP (RB theoretically)) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (JJ hard) (VBG thresholding))) (PP (IN on) (NP (NNP DNN) (NN accuracy))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NN accuracy) (NN degradation)) (VP (NNS increases) (PP (IN with) (NP (NP (VBG remaining) (NN network) (NN depth)) (PP (IN from) (NP (DT the) (VBN pruned) (NN layer))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBD discover) (NP (NP (DT a) (NN link)) (PP (IN between) (NP (NP (NP (DT the) (JJ latent) (NN dimensionality)) (PP (IN of) (NP (DT the) (NN training) (NNS data) (NN manifold)))) (CC and) (NP (NP (NN network) (NN robustness)) (PP (TO to) (NP (VB hard) (NN thresholding)))))))) (. .))
