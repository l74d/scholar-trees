(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (NP (JJ Deep) (NNP Linear) (NNP Discriminant) (NNP Analysis)) (-LRB- -LRB-) (NP (NNP DeepLDA)) (-RRB- -RRB-)) (SBAR (WHNP (WDT which)) (S (VP (VBZ learns) (NP (RB linearly) (JJ separable) (NN latent) (NNS representations)) (PP (IN in) (NP (DT an) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NN fashion)))))))) (. .))
(FRAG (NP (NNP Classic) (NNP LDA)) (NP (NP (NNS extracts) (NNS features)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBP preserve) (NP (NN class) (NN separability))) (CC and) (VP (VBZ is) (VP (VBN used) (PP (IN for) (NP (NN dimensionality) (NN reduction))) (PP (IN for) (NP (JJ many) (NN classification) (NNS problems))))))))) (. .))
(S (NP (NP (DT The) (JJ central) (NN idea)) (PP (IN of) (NP (DT this) (NN paper)))) (VP (VBZ is) (S (VP (TO to) (VP (VB put) (NP (NN LDA)) (PP (IN on) (NP (NP (NN top)) (PP (IN of) (NP (DT a) (JJ deep) (JJ neural) (NN network))))))))) (. .))
(S (NP (DT This)) (VP (MD can) (VP (VB be) (VP (VBN seen) (PP (IN as) (NP (NP (DT a) (JJ non-linear) (NN extension)) (PP (IN of) (NP (JJ classic) (NN LDA)))))))) (. .))
(S (S (PP (RB Instead) (IN of) (S (VP (VBG maximizing) (NP (NP (DT the) (NN likelihood)) (PP (IN of) (NP (NN target) (NNS labels)))) (PP (IN for) (NP (JJ individual) (NNS samples)))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (JJ objective) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (VBZ pushes) (NP (DT the) (NN network) (S (VP (TO to) (VP (VB produce) (NP (NN feature) (NNS distributions)) (SBAR (WHNP (WDT which))))))))))))) (: :) (S (LST (-LRB- -LRB-) (LS a) (-RRB- -RRB-)) (VP (VB have) (NP (JJ low) (NN variance)) (PP (IN within) (NP (NP (DT the) (JJ same) (NN class)) (CC and) (NP (LST (-LRB- -LRB-) (LS b) (-RRB- -RRB-)) (NP (JJ high) (NN variance)) (PP (IN between) (NP (JJ different) (NNS classes)))))))) (. .))
(S (NP (PRP$ Our) (NN objective)) (VP (VP (VBZ is) (VP (VBN derived) (PP (IN from) (NP (DT the) (NML (JJ general) (NN LDA)) (NN eigenvalue) (NN problem))))) (CC and) (ADVP (RB still)) (VP (VBZ allows) (S (VP (TO to) (VP (VB train) (PP (IN with) (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (CC and) (NP (RB back) (HYPH -) (NN propagation))))))))) (. .))
(S (PP (IN For) (NP (NN evaluation))) (NP (PRP we)) (VP (VBP test) (NP (PRP$ our) (NN approach)) (PP (IN on) (NP (CD three) (JJ different) (NN benchmark) (NNS datasets))) (PRN (-LRB- -LRB-) (NP (NN MNIST)) (, ,) (NP (NML (NN CIFAR) (HYPH -) (CD 10)) (CC and) (NML (NNP STL) (HYPH -) (CD 10))) (-RRB- -RRB-))) (. .))
(S (NP (NNP DeepLDA)) (VP (VP (VBZ produces) (NP (JJ competitive) (NNS results)) (PP (IN on) (NP (NN MNIST) (CC and) (NN CIFAR) (HYPH -) (CD 10)))) (CC and) (VP (VBZ outperforms) (NP (NP (DT a) (NN network)) (VP (VBN trained) (PP (IN with) (NP (ADJP (JJ categorical)) (NN cross) (NN entropy) (PRN (-LRB- -LRB-) (NP (JJ same) (NN architecture)) (-RRB- -RRB-)))) (PP (IN on) (NP (NP (DT a) (JJ supervised) (NN setting)) (PP (IN of) (NP (NNP STL) (HYPH -) (CD 10))))))))) (. .))
