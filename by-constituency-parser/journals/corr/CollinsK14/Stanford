(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP investigate) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (ADJP (NN sparsity) (HYPH -) (VBG inducing)) (NNS regularizers)) (PP (IN during) (NP (NP (NN training)) (PP (IN of) (NP (NNP Convolution) (JJ Neural) (NNS Networks)))))))) (PRN (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-))) (. .))
(S (NP (DT These) (NNS regularizers)) (VP (VBP encourage) (SBAR (IN that) (S (NP (NP (JJR fewer) (NNS connections)) (PP (IN in) (NP (NP (DT the) (NN convolution)) (CC and) (NP (ADJP (RB fully) (JJ connected)) (NNS layers))))) (VP (VP (VBP take) (NP (JJ non-zero) (NNS values))) (CC and) (VP (PP (IN in) (NP (NN effect) (NN result))) (PP (IN in) (NP (NP (JJ sparse) (NN connectivity)) (PP (IN between) (NP (NP (JJ hidden) (NNS units)) (PP (IN in) (NP (DT the) (JJ deep) (NN network)))))))))))) (. .))
(S (NP (NP (DT This)) (PP (IN in) (NP (NN turn)))) (VP (VBZ reduces) (NP (NP (DT the) (NML (NN memory) (CC and) (NN runtime)) (NN cost)) (VP (VBN involved) (PP (IN in) (S (VP (VBG deploying) (NP (DT the) (NML (S (VP (VBN learned)))) (NNS CNNs)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NN training)) (PP (IN with) (NP (JJ such) (NN regularization)))) (VP (MD can) (ADVP (RB still)) (VP (VB be) (VP (VBN performed) (S (VP (VBG using) (NP (JJ stochastic) (NN gradient) (NN descent)) (S (VP (VBG implying) (SBAR (IN that) (S (NP (PRP it)) (VP (MD can) (VP (VB be) (VP (VBN used) (ADVP (RB easily)) (PP (IN in) (NP (VBG existing) (NNS codebases)))))))))))))))))) (. .))
(S (NP (NP (NP (JJ Experimental) (NN evaluation)) (PP (IN of) (NP (NP (PRP$ our) (NN approach)) (PP (IN on) (NP (NNP MNIST) (, ,) (NNP CIFAR) (, ,) (CC and) (NNP ImageNet)))))) (NP (NNS datasets))) (VP (VBZ shows) (SBAR (IN that) (S (NP (PRP$ our) (NNS regularizers)) (VP (MD can) (VP (VB result) (PP (IN in) (NP (NP (JJ dramatic) (NNS reductions)) (PP (IN in) (NP (NN memory) (NNS requirements)))))))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBN applied) (PP (IN on) (NP (NNP AlexNet)))))) (, ,) (NP (PRP$ our) (NN method)) (VP (MD can) (VP (VB reduce) (NP (DT the) (NN memory) (NN consumption)) (PP (IN by) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (CD four))))) (PP (IN with) (NP (NP (JJ minimal) (NN loss)) (PP (IN in) (NP (NN accuracy))))))) (. .))
