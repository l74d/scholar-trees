(S (PP (IN In) (NP (JJ recent) (NNS years))) (NP (RB there)) (VP (VBP have) (VP (VBN been) (NP (NP (JJ many) (NNS successes)) (PP (IN of) (S (VP (VBG using) (NP (JJ deep) (NNS representations)) (PP (IN in) (NP (NN reinforcement) (NN learning))))))))) (. .))
(S (ADVP (RB Still)) (, ,) (NP (NP (JJ many)) (PP (IN of) (NP (DT these) (NNS applications)))) (VP (VBP use) (NP (NP (JJ conventional) (NNS architectures)) (, ,) (PP (JJ such) (IN as) (NP (NP (JJ convolutional) (NNS networks)) (, ,) (NP (NNP LSTMs)) (, ,) (CC or) (NP (NNS auto-encoders)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ new) (JJ neural) (NN network) (NN architecture)) (PP (IN for) (NP (JJ model-free) (NN reinforcement) (NN learning))))) (. .))
(S (NP (PRP$ Our) (VBG dueling) (NN network)) (VP (VBZ represents) (NP (NP (CD two) (JJ separate) (NNS estimators)) (: :) (NP (NP (NP (CD one)) (PP (IN for) (NP (DT the) (NN state) (NN value) (NN function)))) (CC and) (NP (NP (CD one)) (PP (IN for) (NP (DT the) (JJ state-dependent) (NN action) (NN advantage) (NN function))))))) (. .))
(S (NP (NP (DT The) (JJ main) (NN benefit)) (PP (IN of) (NP (DT this) (NN factoring)))) (VP (VBZ is) (S (VP (TO to) (VP (VB generalize) (NP (JJ learning)) (PP (IN across) (NP (NNS actions))) (PP (IN without) (S (VP (VBG imposing) (NP (DT any) (NN change)) (PP (TO to) (NP (DT the) (JJ underlying) (NN reinforcement) (VBG learning) (NN algorithm)))))))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this) (NN architecture)) (VP (VBZ leads) (PP (TO to) (NP (RBR better) (NN policy) (NN evaluation))) (PP (IN in) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (JJ many) (JJ similar-valued) (NNS actions))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (DT the) (NN dueling) (NN architecture)) (VP (VBZ enables) (S (NP (PRP$ our) (NNP RL) (NN agent)) (VP (TO to) (VP (VB outperform) (NP (DT the) (NN state-of-the-art)) (PP (IN on) (NP (DT the) (NNP Atari) (CD 2600) (NN domain))))))) (. .))
