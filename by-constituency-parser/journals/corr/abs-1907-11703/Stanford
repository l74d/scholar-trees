(S (S (NP (JJ Deep) (NN reinforcement) (NN learning)) (VP (VBZ has) (VP (VBN achieved) (NP (JJ great) (NNS successes)) (PP (IN in) (NP (JJ recent) (NNS years)))))) (, ,) (S (ADVP (RB however)) (, ,) (NP (CD one) (JJ main) (NN challenge)) (VP (VBZ is) (NP (DT the) (NN sample) (NN inefficiency)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP focus) (PP (IN on) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB use) (NP (NN action) (NN guidance)) (PP (IN by) (NP (NP (NNS means)) (PP (IN of) (NP (DT a) (NN non-expert) (NN demonstrator))))) (S (VP (TO to) (VP (VB improve) (NP (NP (NN sample) (NN efficiency)) (PP (IN in) (NP (DT a) (NN domain)))) (PP (IN with) (NP (NP (JJ sparse) (, ,) (ADJP (ADJP (VBN delayed)) (, ,) (CC and) (ADJP (RB possibly) (JJ deceptive))) (NNS rewards)) (: :) (NP (NP (DT the) (ADJP (RB recently) (HYPH -) (VBN proposed)) (JJ multi-agent) (NN benchmark)) (PP (IN of) (NP (NNP Pommerman))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (JJ new) (NN framework)) (SBAR (WHADVP (WRB where) (RB even)) (S (NP (DT a) (NN non-expert)) (VP (VBD simulated) (SBAR (S (NP (NP (NN demonstrator)) (, ,) (ADVP (FW e.g.))) (, ,) (S (VP (VBG planning) (S (NP (NP (NNS algorithms)) (PP (JJ such) (IN as) (NP (NML (NNP Monte) (NNP Carlo)) (NN tree)))) (VP (VB search) (PP (IN with) (NP (DT a) (JJ small) (NN number) (NNS rollouts))))))) (, ,) (VP (MD can) (VP (VB be) (VP (VBN integrated) (PP (IN within) (NP (ADJP (JJ asynchronous) (VBN distributed)) (JJ deep) (NML (NN reinforcement) (VBG learning)) (NNS methods)))))))))))) (. .))
(S (PP (VBN Compared) (PP (IN to) (NP (DT a) (NML (NN vanilla) (JJ deep) (NN RL)) (NN algorithm)))) (, ,) (NP (PRP$ our) (VBN proposed) (NNS methods)) (VP (CC both) (VP (VBP learn) (ADVP (RBR faster))) (CC and) (VP (VB converge) (S (VP (TO to) (ADVP (RBR better)) (VP (NP (NNS policies)) (PP (IN on) (NP (NP (DT a) (NML (CD two) (HYPH -) (NN player)) (JJ mini) (NN version)) (PP (IN of) (NP (DT the) (NNP Pommerman) (NN game)))))))))) (. .))
