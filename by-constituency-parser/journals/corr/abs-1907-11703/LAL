(S (S (NP (JJ Deep) (NN reinforcement) (NN learning)) (VP (VBZ has) (VP (VBN achieved) (NP (JJ great) (NNS successes)) (PP (IN in) (NP (JJ recent) (NNS years)))))) (, ,) (S (ADVP (RB however)) (, ,) (NP (CD one) (JJ main) (NN challenge)) (VP (VBZ is) (NP (DT the) (JJ sample) (NN inefficiency)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP focus) (PP (IN on) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB use) (NP (NN action) (NN guidance)) (PP (IN by) (NP (NP (NNS means)) (PP (IN of) (NP (DT a) (JJ non-expert) (NN demonstrator))))) (S (VP (TO to) (VP (VB improve) (NP (NN sample) (NN efficiency)) (PP (IN in) (NP (NP (NP (DT a) (NN domain)) (PP (IN with) (NP (ADJP (ADJP (NN sparse)) (, ,) (ADJP (VBN delayed)) (, ,) (CC and) (ADJP (RB possibly) (JJ deceptive))) (NNS rewards)))) (: :) (NP (NP (DT the) (JJ recently-proposed) (JJ multi-agent) (NN benchmark)) (PP (IN of) (NP (NNP Pommerman))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN framework)) (SBAR (WHADVP (WRB where)) (S (NP (NP (RB even) (DT a) (JJ non-expert) (JJ simulated) (NN demonstrator)) (, ,) (INTJ (NN e.g.)) (, ,) (VP (VBG planning) (NP (NP (NNS algorithms)) (PP (JJ such) (IN as) (NP (NP (NNP Monte) (NNP Carlo) (VBD tree) (NN search)) (PP (IN with) (NP (DT a) (JJ small) (NN number) (NNS rollouts))))))) (, ,)) (VP (MD can) (VP (VB be) (VP (VBN integrated) (PP (IN within) (NP (JJ asynchronous) (JJ distributed) (JJ deep) (NN reinforcement) (VBG learning) (NNS methods)))))))))) (. .))
(S (PP (VBN Compared) (PP (TO to) (NP (DT a) (NN vanilla) (JJ deep) (NNP RL) (NN algorithm)))) (, ,) (NP (PRP$ our) (VBN proposed) (NNS methods)) (VP (DT both) (VP (VBP learn) (ADVP (JJR faster))) (CC and) (VP (NN converge) (PP (TO to) (NP (JJR better) (NNS policies))) (PP (IN on) (NP (NP (DT a) (JJ two-player) (NN mini) (NN version)) (PP (IN of) (NP (DT the) (NNP Pommerman) (NN game))))))) (. .))
