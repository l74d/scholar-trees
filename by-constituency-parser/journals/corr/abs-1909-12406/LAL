(S (NP (JJ Simultaneous) (NN machine) (NN translation) (NNS models)) (VP (VBP start) (S (VP (VBG generating) (NP (DT a) (NN target) (NN sequence)))) (SBAR (IN before) (S (NP (PRP they)) (VP (VBP have) (VP (VBN encoded) (CC or) (VBN read) (NP (DT the) (NN source) (NN sequence))))))) (. .))
(S (NP (NP (JJ Recent) (NNS approaches)) (PP (IN for) (NP (DT this) (NN task)))) (VP (DT either) (VP (VB apply) (NP (NP (DT a) (JJ fixed) (NN policy)) (PP (IN on) (NP (DT a) (ADJP (JJ state-of-the) (NN art)) (NNP Transformer) (NN model))))) (, ,) (CC or) (NP (NP (DT a) (JJ learnable) (JJ monotonic) (NN attention)) (PP (IN on) (NP (DT a) (JJR weaker) (JJ recurrent) (JJ neural) (JJ network-based) (NN structure))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN attention) (NN mechanism)) (, ,) (NP (NP (NNP Monotonic) (NNP Multihead) (NNP Attention)) (PRN (-LRB- -LRB-) (NP (NNP MMA)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ extends) (NP (DT the) (JJ monotonic) (NN attention) (NN mechanism)) (PP (TO to) (NP (VB multihead) (NN attention)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP introduce) (NP (NP (CD two) (ADJP (NN novel) (CC and) (JJ interpretable)) (NNS approaches)) (PP (IN for) (NP (NN latency) (NN control))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (ADVP (RB specifically)) (VBN designed) (PP (IN for) (NP (JJ multiple) (NNS attentions) (NNS heads))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP apply) (NP (NNP MMA)) (PP (TO to) (NP (DT the) (JJ simultaneous) (NN machine) (NN translation) (NN task)))) (CC and) (VP (VB demonstrate) (NP (NP (JJR better) (NN latency-quality) (NNS tradeoffs)) (PP (VBN compared) (PP (TO to) (NP (NP (NNP MILk)) (, ,) (NP (DT the) (JJ previous) (JJ state-of-the-art) (NN approach)))))))) (. .))
(S (S (NP (PRP We)) (ADVP (RB also)) (VP (VBP analyze) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN latency) (VBZ controls)) (VP (VBP affect) (NP (DT the) (NN attention) (NN span))))))) (CC and) (S (NP (PRP we)) (VP (VBP motivate) (NP (NP (DT the) (NN introduction)) (PP (IN of) (NP (PRP$ our) (NN model)))) (PP (IN by) (S (VP (VBG analyzing) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NN decoder) (NNS layers) (CC and) (NNS heads))))) (PP (IN on) (NP (NN quality) (CC and) (NN latency))))))))) (. .))
