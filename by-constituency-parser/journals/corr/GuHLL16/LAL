(S (NP (NNP Reinforcement) (VBG learning)) (VP (VBZ holds) (NP (NP (DT the) (NN promise)) (PP (IN of) (S (VP (VBG enabling) (S (NP (JJ autonomous) (NNS robots)) (VP (TO to) (VP (VB learn) (NP (NP (JJ large) (NNS repertoires)) (PP (IN of) (NP (JJ behavioral) (NNS skills)))) (PP (IN with) (NP (JJ minimal) (JJ human) (NN intervention))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (JJ robotic) (NNS applications)) (PP (IN of) (NP (NN reinforcement) (VBG learning)))) (ADVP (RB often)) (VP (VB compromise) (NP (NP (DT the) (NN autonomy)) (PP (IN of) (NP (DT the) (NN learning) (NN process)))) (PP (IN in) (NP (NP (NN favor)) (PP (IN of) (S (VP (VBG achieving) (NP (NP (VBG training) (NNS times)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ practical) (PP (IN for) (NP (JJ real) (JJ physical) (NNS systems)))))))))))))) (. .))
(S (NP (DT This)) (ADVP (RB typically)) (VP (VBZ involves) (S (VP (VBG introducing) (NP (NP (JJ hand-engineered) (NN policy) (NNS representations)) (CC and) (NP (JJ human-supplied) (NNS demonstrations)))))) (. .))
(S (S (NP (JJ Deep) (NN reinforcement) (VBG learning)) (VP (NNS alleviates) (NP (DT this) (NN limitation)) (PP (IN by) (S (VP (VBG training) (NP (JJ general-purpose) (JJ neural) (NN network) (NNS policies))))))) (, ,) (CC but) (S (NP (NP (NNS applications)) (PP (IN of) (NP (JJ direct) (JJ deep) (NN reinforcement) (VBG learning) (NNS algorithms)))) (VP (VBP have) (ADVP (RB so) (RB far)) (VP (VBN been) (VP (VBN restricted) (PP (TO to) (NP (NP (VBN simulated) (NNS settings)) (CC and) (NP (ADJP (RB relatively) (JJ simple)) (NNS tasks)))) (, ,) (PP (JJ due) (TO to) (NP (PRP$ their) (JJ apparent) (JJ high) (NN sample) (NN complexity))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT a) (JJ recent) (JJ deep) (NN reinforcement) (VBG learning) (NNS algorithm)) (VP (VBN based) (PP (IN on) (NP (NP (JJ off-policy) (NN training)) (PP (IN of) (NP (JJ deep) (NNS Q-functions))))))) (VP (VP (MD can) (VP (VB scale) (PP (TO to) (NP (VB complex) (CD 3D) (NN manipulation) (NNS tasks))))) (CC and) (VP (MD can) (VP (VB learn) (NP (JJ deep) (JJ neural) (NN network) (NNS policies)) (ADVP (RB efficiently) (RB enough) (S (VP (TO to) (VP (VB train) (PP (IN on) (NP (JJ real) (JJ physical) (NNS robots))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (NN training) (NNS times)) (VP (MD can) (VP (VB be) (ADVP (RB further)) (VP (VBN reduced) (PP (IN by) (S (VP (VBG parallelizing) (NP (DT the) (NN algorithm)) (PP (IN across) (NP (NP (JJ multiple) (NNS robots)) (SBAR (WHNP (WDT which)) (S (VP (VBP pool) (NP (PRP$ their) (NN policy) (VBZ updates)) (ADVP (RB asynchronously)))))))))))))))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NN evaluation)) (VP (VBZ shows) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (MD can) (VP (VP (VB learn) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (CD 3D) (NN manipulation) (NNS skills)))) (PP (IN in) (NP (NN simulation)))) (CC and) (VP (NP (DT a) (JJ complex) (NN door) (VBG opening) (NN skill)) (PP (IN on) (NP (JJ real) (NNS robots)))) (PP (IN without) (NP (DT any) (NX (NX (JJ prior) (NNS demonstrations)) (CC or) (NX (ADJP (RB manually) (VBN designed)) (NNS representations)))))))))) (. .))
