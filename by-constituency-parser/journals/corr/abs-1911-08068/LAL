(S (NP (NN Interference)) (VP (VBZ is) (NP (DT a) (VBN known) (NN problem)) (SBAR (WHADVP (WRB when)) (S (VP (NN learning) (PP (IN in) (NP (NP (JJ online) (NNS settings)) (, ,) (PP (JJ such) (IN as) (NP (NP (JJ continual) (NN learning)) (CC or) (NP (NN reinforcement) (NN learning)))))))))) (. .))
(S (NP (NN Interference)) (VP (VBZ occurs) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNS updates)) (, ,) (S (VP (TO to) (VP (VB improve) (NP (NP (NN performance)) (PP (IN for) (NP (DT some) (NNS inputs))))))) (, ,)) (VP (NNS degrades) (NP (NP (NN performance)) (PP (IN for) (NP (NNS others)))))))) (. .))
(S (NP (JJ Recent) (NN work)) (VP (VBZ has) (VP (VBN shown) (SBAR (IN that) (S (NP (NP (JJ sparse) (NNS representations)) (PRN (: —) (SBAR (WHADVP (RB -where)) (S (NP (NP (RB only) (DT a) (JJ small) (NN percentage)) (PP (IN of) (NP (NNS units)))) (VP (VBP are) (ADJP (JJ active))))) (: —))) (VP (JJ -can) (VP (ADVP (RB significantly)) (VB reduce) (NP (NN interference)))))))) (. .))
(S (NP (DT Those) (NNS works)) (, ,) (ADVP (RB however)) (, ,) (VP (VBD relied) (PP (IN on) (NP (NP (ADJP (RB relatively) (JJ complex)) (NN regularization) (CC or) (JJ meta-learning) (NNS approaches)) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (ADVP (RB only)) (VP (VBN been) (VP (VBN used) (ADVP (NN offline)) (PP (IN in) (NP (DT a) (JJ pre-training) (NN phase))))))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (NN approach))) (, ,) (NP (PRP we)) (VP (VBP design) (NP (NP (DT an) (NN activation) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (VP (ADVP (RB naturally)) (VBZ produces) (NP (JJ sparse) (NNS representations))) (, ,) (CC and) (VP (ADVP (RB so)) (VBZ is) (ADJP (ADVP (RB much) (RBR more)) (JJ amenable) (PP (TO to) (NP (VB online) (NN training)))))))))) (. .))
(S (NP (DT The) (NN idea)) (VP (VP (NNS relies) (PP (IN on) (NP (NP (DT the) (JJ simple) (NN approach)) (PP (IN of) (NP (NN binning)))))) (, ,) (CC but) (VP (VBZ overcomes) (NP (NP (NP (DT the) (CD two) (JJ key) (NNS limitations)) (PP (IN of) (NP (NN binning)))) (: :) (NP (NP (NP (NN zero) (NNS gradients)) (PP (IN for) (NP (DT the) (JJ flat) (NNS regions))) (ADVP (RB almost) (RB everywhere))) (, ,) (CC and) (NP (NP (VBN lost) (NN precision)) (: —) (NP (JJ -reduced) (NN discrimination)) (: —) (ADJP (JJ -due) (PP (TO to) (NP (VB coarse) (NN aggregation))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (NNP Leaky) (NNP Tiling) (NNP Activation)) (PRN (-LRB- -LRB-) (NP (NNP LTA)) (-RRB- -RRB-)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ provides) (NP (JJ non-negligible) (NNS gradients))) (CC and) (VP (VBZ produces) (NP (NP (VBP overlap)) (PP (IN between) (NP (NNS bins))) (SBAR (WHNP (WDT that)) (S (VP (VBZ improves) (NP (NN discrimination)))))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB empirically)) (VB investigate) (NP (NP (UCP (DT both) (JJ value-based) (CC and) (NN policy)) (NN gradient) (NN reinforcement) (VBG learning) (NNS algorithms)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (JJ neural) (NNS networks)) (PP (IN with) (NP (NNP LTAs))))))) (, ,) (PP (IN in) (NP (NP (JJ classic) (NN discrete-action) (NN control) (NNS environments)) (CC and) (NP (NNP Mujoco) (NN continuous-action) (NNS environments))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (, ,) (PP (IN with) (NP (NNP LTAs))) (, ,) (NP (NN learning)) (VP (VBZ is) (ADJP (RBR faster)) (, ,) (PP (IN with) (NP (ADJP (RBR more) (JJ stable)) (NNS policies))) (, ,) (PP (IN without) (S (VP (VBG needing) (NP (NN target) (NNS networks)))))))) (. .))
