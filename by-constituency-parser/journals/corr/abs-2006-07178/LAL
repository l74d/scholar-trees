(S (NP (NNP Reinforcement) (VBG learning) (NNS algorithms)) (VP (MD can) (VP (VB acquire) (NP (NP (NNS policies)) (PP (IN for) (NP (JJ complex) (NNS tasks)))) (ADVP (RB autonomously)))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS samples))) (VP (VBN required) (S (VP (TO to) (VP (VB learn) (NP (NP (DT a) (JJ diverse) (NN set)) (PP (IN of) (NP (NNS skills))))))))) (VP (MD can) (VP (VB be) (ADJP (RB prohibitively) (JJ large)))) (. .))
(S (SBAR (IN While) (S (NP (JJ meta-reinforcement) (VBG learning) (NNS methods)) (VP (VBP have) (VP (VBN enabled) (S (NP (NNS agents)) (VP (TO to) (VP (VB leverage) (NP (JJ prior) (NN experience)) (S (VP (TO to) (VP (VB adapt) (ADVP (RB quickly)) (PP (TO to) (NP (JJ new) (NNS tasks))))))))))))) (, ,) (NP (PRP$ their) (NN performance)) (VP (VBZ depends) (ADVP (RB crucially)) (PP (IN on) (SBAR (WHADJP (WRB how) (RB close)) (S (NP (DT the) (JJ new) (NN task)) (VP (VBZ is) (PP (TO to) (NP (DT the) (ADJP (RB previously) (JJ experienced)) (NNS tasks)))))))) (. .))
(S (NP (JJ Current) (NNS approaches)) (VP (VP (VBP are) (ADVP (RB either)) (RB not) (ADJP (JJ able) (S (VP (TO to) (VP (VB extrapolate) (ADVP (RB well))))))) (, ,) (CC or) (VP (MD can) (VP (VB do) (ADVP (RB so)) (PP (IN at) (NP (NP (DT the) (NN expense)) (PP (IN of) (S (VP (VBG requiring) (NP (NP (ADJP (RB extremely) (JJ large)) (NNS amounts)) (PP (IN of) (NP (NNS data)))) (PP (IN for) (NP (JJ on-policy) (NN meta-training))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NP (JJ model) (NN identification) (CC and) (NN experience) (NN relabeling)) (PRN (-LRB- -LRB-) (NP (NNP MIER)) (-RRB- -RRB-))) (, ,) (NP (NP (DT a) (JJ meta-reinforcement) (NN learning) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ is) (DT both) (JJ efficient)) (CC and) (VP (VP (VBZ extrapolates) (ADVP (RB well))) (SBAR (WHADVP (WRB when)) (S (VP (VBN faced) (PP (IN with) (NP (NN out-of-distribution) (NNS tasks))) (PP (IN at) (NP (NN test) (NN time))))))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (NP (DT a) (JJ simple) (NN insight)) (: :) (S (NP (PRP we)) (VP (VBP recognize) (SBAR (IN that) (S (NP (NNS dynamics) (NNS models)) (VP (MD can) (VP (VB be) (VP (VBN adapted) (ADVP (RB efficiently) (CC and) (RB consistently)) (PP (IN with) (NP (JJ off-policy) (NNS data))) (, ,) (ADVP (ADVP (JJR more) (RB easily)) (PP (IN than) (NP (NP (NNS policies)) (CC and) (NP (NN value) (NNS functions)))))))))))))))) (. .))
(S (NP (DT These) (NNS dynamics) (NNS models)) (VP (MD can) (ADVP (RB then)) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB continue) (S (VP (VBG training) (NP (NP (NNS policies)) (CC and) (NP (NN value) (NNS functions))) (PP (IN for) (NP (NN out-of-distribution) (NNS tasks))) (PP (IN without) (S (VP (VBG using) (NP (JJ meta-reinforcement) (NN learning)) (ADVP (IN at) (DT all))))))) (, ,) (PP (IN by) (S (VP (VBG generating) (NP (NP (JJ synthetic) (NN experience)) (PP (IN for) (NP (DT the) (JJ new) (NN task))))))))))))) (. .))
