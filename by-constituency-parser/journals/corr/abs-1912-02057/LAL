(S (S (VP (TO To) (VP (VB deploy) (NP (JJ deep) (JJ neural) (NNS networks)) (PP (IN on) (NP (JJ resource-limited) (NNS devices)))))) (, ,) (NP (NN quantization)) (VP (VBZ has) (VP (VBN been) (VP (ADVP (RB widely)) (VBN explored)))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT the) (ADJP (RB extremely) (JJ low-bit)) (NNS networks)) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (NP (NP (JJ tremendous) (NX (JJ speed-up)) (, ,) (NN memory) (VBG saving)) (PP (IN with) (NP (JJ quantized) (NN activation) (CC and) (NNS weights))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB first)) (VP (VB bring) (PRT (RP up)) (NP (NP (NP (CD three) (VBN omitted) (NNS issues)) (PP (IN in) (NP (ADJP (RB extremely) (JJ low-bit)) (NNS networks)))) (: :) (NP (NP (NP (DT the) (VBG squashing) (NN range)) (PP (IN of) (NP (JJ quantized) (NNS values)))) (: ;) (NP (NP (DT the) (NN gradient)) (VP (VBG vanishing) (PP (IN during) (NP (NN backpropagation))))) (CC and) (NP (NP (DT the) (JJ unexploited) (NN hardware) (NN acceleration)) (PP (IN of) (NP (JJ ternary) (NNS networks))))))) (. .))
(S (PP (IN By) (S (VP (VBG reparameterizing) (NP (JJ quantized) (NN activation) (CC and) (NNS weights) (NN vector)) (PP (IN with) (NP (JJ full) (NN precision) (NN scale) (CC and) (NN offset))) (PP (IN for) (NP (JJ fixed) (JJ ternary) (NN vector)))))) (, ,) (NP (PRP we)) (VP (VBP decouple) (NP (DT the) (NN range) (CC and) (NN magnitude)) (PP (IN from) (NP (DT the) (NN direction))) (S (VP (TO to) (VP (VB extenuate) (NP (DT the) (CD three) (NNS issues)))))) (. .))
(S (NP (JJ Learnable) (NN scale) (CC and) (NN offset)) (VP (MD can) (VP (ADVP (RB automatically)) (VB adjust) (NP (NP (DT the) (NN range)) (PP (IN of) (NP (JJ quantized) (NNS values) (CC and) (NN sparsity)))) (PP (IN without) (S (NP (NN gradient)) (VP (NN vanishing)))))) (. .))
(S (NP (DT A) (JJ novel) (NN encoding) (CC and) (NN computation) (JJ pat-tern)) (VP (VBP are) (VP (VBN designed) (S (VP (TO to) (VP (VB support) (NP (JJ efficient) (VBG computing)) (PP (IN for) (NP (NP (PRP$ our) (JJ reparameterized) (JJ ternary) (NN network)) (PRN (-LRB- -LRB-) (NP (NNP RTN)) (-RRB- -RRB-))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NNP ResNet-18))) (PP (IN for) (NP (NNP ImageNet)))) (VP (NN demonstrate) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NNP RTN)) (VP (VP (VBZ finds) (NP (NP (DT a) (ADJP (RB much) (JJR better)) (NN efficiency)) (PP (IN between) (NP (NN bitwidth) (CC and) (NN accuracy))))) (, ,) (CC and) (VP (VBZ achieves) (NP (ADJP (QP (RB up) (TO to) (CD 26.76)) (NN %)) (JJ relative) (NN accuracy) (NN improvement)) (PP (VBN compared) (PP (IN with) (NP (JJ state-of-the-art) (NNS methods))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (S (NP (PRP we)) (VP (VBP validate) (NP (NP (DT the) (VBN proposed) (NN computation) (NN pattern)) (PP (IN on) (NP (NP (NNP Field) (NNP Programmable) (NNP Gate) (NNP Arrays)) (PRN (-LRB- -LRB-) (NP (NNP FPGA)) (-RRB- -RRB-))))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBZ brings) (NP (NP (CD 46.46x) (CC and) (CD 89.17x) (NNS savings)) (PP (IN on) (NP (NN power) (CC and) (NN area))) (ADVP (RB respectively))) (PP (VBN compared) (PP (IN with) (NP (DT the) (JJ full) (NN precision) (NN convolution)))))) (. .))
