(S (NP (PRP We)) (VP (VBP develop) (NP (NP (DT a) (NN class)) (PP (IN of) (NP (NNS algorithms)))) (, ,) (PP (IN as) (NP (NP (NNS variants)) (PP (IN of) (NP (NP (NP (NP (DT the) (ADJP (RB stochastically) (VBN controlled)) (JJ stochastic) (NN gradient)) (-LRB- -LRB-) (NP (NN SCSG)) (-RRB- -RRB-)) (NP (NNS methods)) (PRN (-LRB- -LRB-) (NP (NNP Lei) (CC and) (NNP Jordan)) (, ,) (NP (CD 2016)) (-RRB- -RRB-))) (, ,) (PP (IN for) (NP (DT the) (NML (JJ smooth) (NN non-convex)) (NML (NN finite) (HYPH -) (NN sum)) (NN optimization) (NN problem)))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (S (NP (NNP SCSG)) (VP (VBZ is) (ADVP (RB never)) (ADJP (ADJP (JJR worse)) (PP (IN than) (NP (DT the) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS methods)))) (PP (VBN based) (PP (IN on) (NP (NN variance) (NN reduction)))))) (CC and) (S (NP (PRP it)) (ADVP (RB significantly)) (VP (VBZ outperforms) (NP (PRP them)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN target) (NN accuracy)) (VP (VBZ is) (ADJP (JJ low))))))) (. .))
(S (NP (DT A) (JJ similar) (NN acceleration)) (VP (VBZ is) (ADVP (RB also)) (VP (VBN achieved) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NNS functions)) (VP (VBP satisfy) (NP (DT the) (NML (NNP Polyak) (HYPH -) (NNP Lojasiewicz)) (NN condition))))))) (. .))
(S (NP (JJ Empirical) (NNS experiments)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NNP SCSG)) (VP (VBZ outperforms) (NP (NP (JJ stochastic) (NN gradient) (NNS methods)) (PP (IN on) (NP (NP (NN training) (NNS multi-layers)) (NP (JJ neural) (NNS networks))))) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (DT both) (NN training)) (CC and) (NP (NN validation) (NN loss)))))))))) (. .))
