(S (NP (NP (NN Today) (POS 's)) (NML (JJ high) (NN performance)) (NML (JJ deep) (NN learning)) (NNS architectures)) (VP (VBP involve) (NP (JJ large) (NNS models)) (PP (IN with) (NP (JJ numerous) (NNS parameters)))) (. .))
(S (NP (JJ Low) (NN precision) (NNS numerics)) (VP (VBZ has) (VP (VBN emerged) (PP (IN as) (NP (DT a) (JJ popular) (NN technique))) (S (VP (TO to) (VP (VB reduce) (NP (CC both) (NP (DT the) (S (VP (VB compute)))) (CC and) (NP (NP (NN memory) (NNS requirements)) (PP (IN of) (NP (DT these) (JJ large) (NNS models)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG lowering) (NP (NN precision)) (ADVP (RB often)))) (VP (VBZ leads) (PP (IN to) (NP (NN accuracy) (NN degradation)))) (. .))
(S (NP (PRP We)) (VP (VBP describe) (NP (NP (CD three) (NNS schemes)) (SBAR (WHADVP (WRB whereby)) (S (NP (PRP one)) (VP (MD can) (VP (CC both) (VB train) (CC and) (VB do) (NP (JJ efficient) (NN inference))))))) (S (VP (VBG using) (NP (JJ low) (NN precision) (NNS numerics)) (PP (IN without) (S (VP (VBG hurting) (NP (NN accuracy)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP describe) (NP (NP (DT an) (JJ efficient) (NN hardware) (NN accelerator)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB take) (NP (NP (NN advantage)) (PP (IN of) (NP (DT the) (VBN proposed) (JJ low) (NN precision) (NNS numerics)))))))))) (. .))
