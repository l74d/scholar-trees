(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT the) (NNP HSIC) (PRN (-LRB- -LRB-) (NP (NNP Hilbert-Schmidt) (NN independence) (NN criterion)) (-RRB- -RRB-)) (NN bottleneck)) (PP (IN for) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks))))))) (. .))
(S (NP (DT The) (NNP HSIC) (NN bottleneck)) (VP (VBZ is) (NP (NP (DT an) (JJ alternative)) (PP (TO to) (NP (DT the) (JJ conventional) (JJ cross-entropy) (NN loss) (CC and) (NN backpropagation))) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (JJ distinct) (NNS advantages))))))))) (. .))
(S (NP (PRP It)) (VP (VBZ mitigates) (NP (ADJP (VBG exploding) (CC and) (VBG vanishing)) (NNS gradients)) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (DT the) (NN ability) (S (VP (TO to) (VP (VB learn) (NP (ADJP (RB very) (JJ deep)) (NNS networks)) (PP (IN without) (NP (JJ skip) (NNS connections))))))))))) (. .))
(S (NP (EX There)) (VP (VBZ is) (NP (NP (DT no) (NN requirement)) (PP (IN for) (NP (NP (JJ symmetric) (NN feedback)) (CC or) (NP (JJ update) (NN locking)))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (DT the) (NNP HSIC) (NN bottleneck)) (VP (VBZ provides) (NP (NP (NN performance)) (PP (IN on) (NP (NNP MNIST/FashionMNIST/CIFAR10) (NN classification))) (ADJP (NN comparable) (PP (TO to) (NP (NP (NN backpropagation)) (PP (IN with) (NP (DT a) (JJ cross-entropy) (NN target))))))) (, ,) (SBAR (RB even) (WRB when) (S (NP (DT the) (NN system)) (VP (VBZ is) (RB not) (VP (VBN encouraged) (S (VP (TO to) (VP (VB make) (S (NP (DT the) (NN output)) (VP (VB resemble) (NP (DT the) (NN classification) (NNS labels))))))))))))))) (. .))
(S (S (VP (VBG Appending) (NP (NP (DT a) (JJ single) (NN layer)) (VP (VBN trained) (PP (IN with) (NP (NNP SGD))) (PRN (-LRB- -LRB-) (PP (IN without) (NP (NN backpropagation))) (-RRB- -RRB-)) (S (VP (TO to) (VP (VB reformat) (NP (DT the) (NN information))))))))) (ADVP (JJ further)) (VP (VBZ improves) (NP (NN performance))) (. .))
