(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (VP (VBN distributed) (NP (NP (NNS algorithms)) (PP (IN for) (NP (NML (JJ large) (HYPH -) (NN scale)) (NN AUC) (NN maximization)))) (PP (IN with) (NP (NP (DT a) (JJ deep) (JJ neural) (NN network)) (PP (IN as) (NP (DT a) (JJ predictive) (NN model))))))) (. .))
(S (SBAR (IN Although) (S (NP (VBN distributed) (NN learning) (NNS techniques)) (VP (VBP have) (VP (VBN been) (VP (VBN investigated) (ADVP (RB extensively)) (PP (IN in) (NP (JJ deep) (NN learning)))))))) (, ,) (NP (PRP they)) (VP (VBP are) (RB not) (ADJP (RB directly) (JJ applicable) (PP (IN to) (NP (NP (JJ stochastic) (NN AUC) (NN maximization)) (PP (IN with) (NP (JJ deep) (JJ neural) (NNS networks)))))) (PP (IN due) (PP (IN to) (NP (NP (PRP$ its) (JJ striking) (NNS differences)) (PP (IN from) (NP (JJ standard) (NN loss) (NN minimization) (NNS problems)))))) (PRN (-LRB- -LRB-) (ADVP (FW e.g.)) (, ,) (NP (NN cross-entropy)) (-RRB- -RRB-))) (. .))
(S (PP (VBN Compared) (PP (IN with) (NP (NP (DT the) (JJ naive) (JJ parallel) (NN version)) (PP (IN of) (NP (NP (DT an) (VBG existing) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ computes) (S (NP (NP (JJ stochastic) (NNS gradients)) (PP (IN at) (NP (JJ individual) (NNS machines) (CC and) (NNS averages)))) (NP (PRP them))) (PP (IN for) (S (VP (VBG updating) (NP (DT the) (NN model) (NN parameter))))))))))))) (, ,) (NP (PRP$ our) (NN algorithm)) (VP (VP (VBZ requires) (NP (NP (DT a) (ADJP (RB much) (JJR less)) (NN number)) (PP (IN of) (NP (NN communication) (NNS rounds))))) (CC and) (ADVP (RB still)) (VP (VBZ achieves) (NP (DT a) (JJ linear) (NN speedup)) (PP (IN in) (NP (NN theory))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (PP (IN on) (NP (JJ several) (NN benchmark) (NNS datasets)))) (VP (VP (VBP show) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (PRP$ our) (NN algorithm))))) (CC and) (ADVP (RB also)) (VP (VBP confirm) (NP (PRP$ our) (NN theory)))) (. .))
