(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (VBN distributed) (NN algorithms)) (PP (IN for) (NP (JJ large-scale) (NNP AUC) (NN maximization)))) (PP (IN with) (NP (NP (DT a) (JJ deep) (JJ neural) (NN network)) (PP (IN as) (NP (DT a) (JJ predictive) (NN model)))))) (. .))
(S (SBAR (IN Although) (S (NP (VBN distributed) (VBG learning) (NNS techniques)) (VP (VBP have) (VP (VBN been) (VP (VBN investigated) (ADVP (RB extensively)) (PP (IN in) (NP (JJ deep) (NN learning)))))))) (, ,) (NP (PRP they)) (VP (VBP are) (RB not) (ADJP (RB directly) (JJ applicable) (PP (TO to) (NP (NP (JJ stochastic) (NNP AUC) (NN maximization)) (PP (IN with) (NP (JJ deep) (JJ neural) (NNS networks)))))) (PP (JJ due) (TO to) (NP (NP (PRP$ its) (VBG striking) (NNS differences)) (PP (IN from) (NP (NP (JJ standard) (NN loss) (NN minimization) (NNS problems)) (PRN (-LRB- -LRB-) (VB e.g.) (, ,) (NP (NN cross-entropy)) (-RRB- -RRB-))))))) (. .))
(S (PP (VBN Compared) (PP (IN with) (NP (NP (DT the) (JJ naive) (JJ parallel) (NN version)) (PP (IN of) (NP (NP (DT an) (VBG existing) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ computes) (NP (JJ stochastic) (NNS gradients)) (PP (IN at) (NP (JJ individual) (NNS machines)))) (CC and) (VP (NNS averages) (NP (PRP them)) (PP (IN for) (S (VP (VBG updating) (NP (DT the) (NN model) (NN parameter)))))))))))))) (, ,) (NP (PRP$ our) (JJ algorithm)) (VP (VP (VBZ requires) (NP (NP (DT a) (ADJP (RB much) (JJR less)) (NN number)) (PP (IN of) (NP (NN communication) (NNS rounds))))) (CC and) (VP (ADVP (RB still)) (VBZ achieves) (NP (NP (DT a) (JJ linear) (NN speedup)) (PP (IN in) (NP (NN theory)))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (PP (IN on) (NP (JJ several) (NN benchmark) (NNS datasets)))) (VP (VP (VBP show) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (PRP$ our) (NN algorithm))))) (CC and) (VP (ADVP (RB also)) (VB confirm) (NP (PRP$ our) (NN theory)))) (. .))
