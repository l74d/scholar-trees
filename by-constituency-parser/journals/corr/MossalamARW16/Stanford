(S (NP (PRP We)) (VP (VBP propose) (NP (NML (NNP Deep) (NNP Optimistic)) (NNP Linear) (NNP Support) (NNP Learning) (PRN (-LRB- -LRB-) (NP (NNP DOL)) (-RRB- -RRB-))) (S (VP (TO to) (VP (VB solve) (NP (ADJP (JJ high) (HYPH -) (JJ dimensional)) (JJ multi-objective) (NN decision) (NNS problems)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (JJ relative) (NNS importances)) (PP (IN of) (NP (DT the) (NNS objectives)))) (VP (VBP are) (RB not) (VP (VBN known) (ADVP (FW a) (FW priori)))))))))) (. .))
(S (S (VP (VBG Using) (NP (NNS features)) (PP (IN from) (NP (DT the) (ADJP (JJ high) (HYPH -) (JJ dimensional)) (NNS inputs))))) (, ,) (NP (NNP DOL)) (VP (VBZ computes) (NP (NP (DT the) (NN convex) (NN coverage) (NN set)) (VP (VBG containing) (NP (NP (DT all) (JJ potential) (JJ optimal) (NNS solutions)) (PP (IN of) (NP (NP (DT the) (NN convex) (NNS combinations)) (PP (IN of) (NP (DT the) (NNS objectives))))))))) (. .))
(S (PP (IN To) (NP (PRP$ our) (NN knowledge))) (, ,) (NP (DT this)) (VP (VBZ is) (NP (NP (DT the) (JJ first) (NN time)) (SBAR (WHNP (WDT that)) (S (NP (JJ deep) (NN reinforcement) (NN learning)) (VP (VBZ has) (VP (VBN succeeded) (PP (IN in) (S (VP (VBG learning) (NP (JJ multi-objective) (NNS policies))))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (PRP we)) (VP (VBP provide) (NP (DT a) (NN testbed)) (PP (IN with) (NP (CD two) (NNS experiments))) (S (VP (TO to) (VP (VB be) (VP (VBN used) (PP (IN as) (NP (NP (DT a) (NN benchmark)) (PP (IN for) (NP (JJ deep) (JJ multi-objective) (NN reinforcement) (NN learning)))))))))) (. .))
