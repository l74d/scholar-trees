(S (NP (NN Policy) (NN gradient) (NN algorithms)) (ADVP (RB typically)) (VP (JJ combine) (NP (VBN discounted) (JJ future) (NNS rewards)) (PP (IN with) (NP (DT an) (VBN estimated) (NN value) (NN function))) (, ,) (S (VP (TO to) (VP (VB compute) (NP (NP (DT the) (NN direction) (CC and) (NN magnitude)) (PP (IN of) (NP (NN parameter) (NNS updates)))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN for) (NP (JJS most) (NNP Reinforcement) (NNP Learning) (NNS tasks))) (, ,) (NP (NNS humans)) (VP (MD can) (VP (VB provide) (NP (JJ additional) (NN insight)) (S (VP (TO to) (VP (VB constrain) (NP (DT the) (NN policy) (NN learning))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (JJ general) (NN method)) (SBAR (S (VP (TO to) (VP (VB incorporate) (NP (JJ multiple) (JJ different) (NN feedback) (NNS channels)) (PP (IN into) (NP (DT a) (JJ single) (NN policy) (NN gradient) (NN loss))))))))) (. .))
(S (PP (IN In) (NP (NP (PRP$ our) (NN formulation)) (, ,) (NP (NP (DT the) (NNP Multi-Preference) (NNP Actor) (NNP Critic)) (PRN (-LRB- -LRB-) (NP (NNP M-PAC)) (-RRB- -RRB-))) (, ,))) (NP (NP (DT these) (JJ different) (NNS types)) (PP (IN of) (NP (NN feedback)))) (VP (VBP are) (VP (VBN implemented) (PP (IN as) (NP (NP (NNS constraints)) (PP (IN on) (NP (DT the) (NN policy))))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (DT a) (JJ Lagrangian) (NN relaxation)) (S (VP (TO to) (VP (VB satisfy) (NP (DT these) (NNS constraints)) (S (VP (VBG using) (NP (JJ gradient) (NN descent))))))) (SBAR (IN while) (S (VP (VBG learning) (NP (NP (DT a) (NN policy)) (SBAR (WHNP (WDT that)) (S (VP (VBZ maximizes) (NP (NNS rewards)))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN in) (NP (NNP Atari) (CC and) (NNP Pendulum)))) (VP (VBP verify) (SBAR (IN that) (S (NP (NNS constraints)) (VP (VP (VBP are) (VP (VBG being) (VP (VBN respected)))) (CC and) (VP (MD can) (VP (VB accelerate) (NP (DT the) (NN learning) (NN process)))))))) (. .))
