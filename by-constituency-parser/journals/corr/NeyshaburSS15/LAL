(S (NP (PRP We)) (VP (VBP revisit) (NP (NP (DT the) (NN choice)) (PP (IN of) (NP (NNP SGD))) (PP (IN for) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks)))))) (PP (IN by) (S (VP (VBG reconsidering) (NP (NP (DT the) (JJ appropriate) (NN geometry)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (VP (TO to) (VP (VB optimize) (NP (DT the) (NNS weights))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP argue) (PP (IN for) (NP (NP (DT a) (NN geometry)) (ADJP (NN invariant) (PP (TO to) (NP (NP (NN rescaling)) (PP (IN of) (NP (NNS weights)))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ does) (RB not) (VP (VB affect) (NP (NP (DT the) (NN output)) (PP (IN of) (NP (DT the) (NN network))))))))))) (, ,) (CC and) (VP (JJS suggest) (NP (NP (NNP Path-SGD)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (DT an) (JJ approximate) (NN steepest) (NN descent) (NN method)) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (NP (DT a) (JJ path-wise) (NN regularizer)) (VP (VBN related) (PP (TO to) (NP (JJ max-norm) (NN regularization)))))))))))))) (. .))
(S (NP (NNP Path-SGD)) (VP (VP (VBZ is) (ADJP (JJ easy) (CC and) (JJ efficient) (SBAR (S (VP (TO to) (VP (VB implement))))))) (CC and) (VP (VBZ leads) (PP (TO to) (NP (NP (JJ empirical) (NNS gains)) (PP (IN over) (NP (NNP SGD) (CC and) (NNP AdaGrad))))))) (. .))
