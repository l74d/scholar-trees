(S (NP (PRP We)) (VP (VBP develop) (NP (DT a) (JJ new) (NN method)) (PP (IN for) (S (VP (VBG regularising) (NP (JJ neural) (NNS networks)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP learn) (NP (DT a) (NN probability) (NN distribution)) (PP (IN over) (NP (NP (DT the) (NNS activations)) (PP (IN of) (NP (NP (DT all) (NNS layers)) (PP (IN of) (NP (DT the) (NN model)))))))) (CC and) (ADVP (RB then)) (VP (VB insert) (NP (JJ imputed) (NNS values)) (PP (IN into) (NP (NP (DT the) (NN network)) (PP (IN during) (NP (NN training))))))) (. .))
(S (NP (PRP We)) (VP (VBP obtain) (NP (DT a) (JJ posterior)) (PP (IN for) (NP (NP (DT an) (JJ arbitrary) (NN subset)) (PP (IN of) (NP (NP (NNS activations)) (VP (VBN conditioned) (PP (IN on) (NP (DT the) (NN remainder))))))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (NP (NP (NP (DT a) (NN generalisation)) (PP (IN of) (NP (NP (NNS data) (NN augmentation)) (PP (IN to) (NP (NP (DT the) (JJ hidden) (NNS layers)) (PP (IN of) (NP (DT a) (NN network)))))))) (, ,) (CC and) (NP (NP (DT a) (NN form)) (PP (IN of) (NP (ADJP (NN data) (HYPH -) (JJ aware)) (NN dropout)))))) (. .))
(S (S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (PRP$ our) (NN training) (NN method)) (VP (VBZ leads) (PP (IN to) (NP (NP (ADJP (NP (NP (JJR higher) (NN test) (NN accuracy)) (CC and) (NP (JJR lower) (NN test))) (HYPH -) (VBN set)) (NN cross-entropy)) (PP (IN for) (NP (NP (JJ neural) (NNS networks)) (VP (VBN trained) (PP (IN on) (NP (NML (NML (NN CIFAR) (HYPH -) (CD 10)) (CC and) (NML (NN SVHN)) (PP (VBN compared) (PP (IN to) (NP (JJ standard) (NN regularisation))))) (NNS baselines))))))))))))) (: :) (S (NP (PRP$ our) (NN approach)) (VP (VBZ leads) (PP (IN to) (S (NP (NP (NNS networks)) (PP (IN with) (NP (NP (JJR better)) (VP (VBN calibrated) (NP (NP (NN uncertainty)) (PP (IN over) (NP (DT the) (NN class) (NNS posteriors)))) (NP-TMP (PDT all) (DT the) (NN while)))))) (VP (VBG delivering) (NP (NP (JJR greater)) (VP (NN test) (HYPH -) (VBN set) (S (NP (NN accuracy)))))))))) (. .))
