(S (NP (ADJP (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (NN gradient)))) (HYPH -) (VBN based)) (NN optimization) (NNS strategies)) (VP (VBZ depends) (ADVP (RB heavily)) (PP (IN on) (NP (NP (DT the) (JJ initial) (NNS weights)) (PP (IN of) (NP (DT the) (JJ parametric) (NN model)))))) (. .))
(S (NP (JJ Recent) (NNS works)) (VP (VBP show) (SBAR (SBAR (IN that) (S (NP (EX there)) (VP (VBP exist) (NP (NP (NN weight) (NNS initializations)) (SBAR (WHPP (IN from) (WHNP (WDT which))) (S (NP (NN optimization) (NNS procedures)) (VP (MD can) (VP (VB find) (NP (DT the) (ADJP (NN task) (HYPH -) (JJ specific)) (NNS parameters)) (ADVP (RBR faster) (IN than)) (PP (IN from) (NP (ADJP (RB uniformly) (JJ random)) (NNS initializations))))))))))) (CC and) (SBAR (IN that) (S (NP (PDT such) (DT a) (NN weight) (NN initialization)) (VP (MD can) (VP (VB be) (VP (VBN learned) (PP (IN by) (S (VP (VBG optimizing) (NP (DT a) (JJ specific) (NN model) (NN architecture)) (PP (IN across) (NP (NP (NP (JJ similar) (NNS tasks)) (PP (IN via) (NP (NNP MAML)))) (-LRB- -LRB-) (NP (NNP Model) (HYPH -) (NNP Agnostic) (NNP Meta) (HYPH -) (NNP Learning)) (-RRB- -RRB-))))))))))))) (. .))
(S (NP (JJ Current) (NNS methods)) (VP (VBP are) (VP (VBN limited) (PP (IN to) (NP (NP (NNS populations)) (PP (IN of) (NP (NP (NN classification) (NNS tasks)) (SBAR (WHNP (WDT that)) (S (VP (VBP share) (NP (NP (DT the) (JJ same) (NN number)) (PP (IN of) (NP (NNS classes)))) (PP (IN due) (IN to) (NP (NP (DT the) (NN static) (NN model) (NNS architectures)) (VP (VBN used) (PP (IN during) (NP (NN meta) (HYPH -) (NN learning))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NNP HIDRA)) (, ,) (NP (NP (DT a) (NML (NN meta) (HYPH -) (NN learning)) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ enables) (NP (NN training))) (CC and) (VP (VBG evaluating) (PP (IN across) (NP (NP (NNS tasks)) (PP (IN with) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (NN target) (NNS variables)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (NP (NP (NN Model) (HYPH -) (JJ Agnostic)) (SBAR (S (VP (NN Meta) (HYPH -) (VBG Learning) (NP (NP (NP (NNS trains)) (NP (NP (DT a) (NN distribution)) (PP (IN for) (NP (NP (PDT all) (DT the) (NNS neurons)) (PP (IN in) (NP (DT the) (NN output) (NN layer))))))) (CC and) (NP (NP (DT a) (JJ specific) (NN weight) (NN initialization)) (PP (IN for) (NP (NP (DT the) (NNS ones)) (PP (IN in) (NP (DT the) (JJ hidden) (NNS layers))))))))))))) (. .))
(S (NP (NNP HIDRA)) (VP (VBZ explores) (NP (DT this)) (PP (IN by) (S (VP (VBG learning) (NP (NP (CD one) (NN master) (NN neuron)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN used) (S (VP (TO to) (VP (VB initialize) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (NN output) (NNS neurons)))) (PP (IN for) (NP (DT a) (JJ new) (NN task))))))))))))))) (. .))
(S (NP (NP (JJ Extensive) (NNS experiments)) (PP (IN on) (NP (DT the) (NNP Miniimagenet) (CC and) (NNP Omniglot) (NNS data) (NNS sets)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NN HIDRA)) (VP (VBZ improves) (PP (IN over) (NP (JJ standard) (NNS approaches))) (PP (IN while) (S (VP (VBG generalizing) (PP (IN to) (NP (NP (NNS tasks)) (PP (IN with) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (NN target) (NNS variables)))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ is) (VP (VBN shown) (S (VP (TO to) (VP (VB robustify) (NP (NML (JJ low) (HYPH -) (NN capacity)) (NNS models)) (PP (IN in) (S (VP (VBG learning) (PP (IN across) (NP (JJ complex) (NNS tasks))) (PP (IN with) (NP (NP (DT a) (JJ high) (NN number)) (PP (IN of) (NP (NP (NNS classes)) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (JJ regular) (NN MAML)) (VP (VBZ fails) (S (VP (TO to) (VP (VB learn) (NP (DT any) (JJ feasible) (NN initialization)))))))))))))))))))) (. .))
