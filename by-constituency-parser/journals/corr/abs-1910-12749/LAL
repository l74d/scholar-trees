(S (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (JJ gradient-based) (NN optimization) (NNS strategies)))) (VP (VBZ depends) (ADVP (RB heavily)) (PP (IN on) (NP (NP (DT the) (JJ initial) (NNS weights)) (PP (IN of) (NP (DT the) (JJ parametric) (NN model)))))) (. .))
(S (NP (JJ Recent) (VBZ works)) (VP (VBP show) (SBAR (SBAR (IN that) (S (NP (EX there)) (VP (VB exist) (NP (NP (NN weight) (NNS initializations)) (SBAR (WHPP (IN from) (WHNP (WDT which))) (S (NP (NN optimization) (NNS procedures)) (VP (MD can) (VP (VB find) (NP (DT the) (JJ task-specific) (NNS parameters)) (ADVP (ADVP (RBR faster)) (PP (IN than) (PP (IN from) (NP (ADJP (JJ uniformly) (JJ random)) (NNS initializations))))))))))))) (CC and) (SBAR (DT that) (S (NP (JJ such) (DT a) (JJ weight) (NN initialization)) (VP (MD can) (VP (VB be) (VP (VBN learned) (PP (IN by) (S (VP (VBG optimizing) (NP (DT a) (JJ specific) (NN model) (NN architecture)) (PP (IN across) (NP (JJ similar) (NNS tasks)))))) (PP (IN via) (NP (NP (NNP MAML)) (PRN (-LRB- -LRB-) (NP (JJ Model-Agnostic) (NNP Meta-Learning)) (-RRB- -RRB-))))))))))) (. .))
(S (NP (JJ Current) (NNS methods)) (VP (VBP are) (VP (VBN limited) (PP (TO to) (NP (NP (NNS populations)) (PP (IN of) (NP (NN classification) (NNS tasks))) (SBAR (WHNP (WDT that)) (S (VP (NN share) (NP (NP (DT the) (JJ same) (NN number)) (PP (IN of) (NP (NNS classes))))))))) (PP (JJ due) (TO to) (NP (NP (DT the) (JJ static) (NN model) (NNS architectures)) (VP (VBN used) (PP (IN during) (NP (NN meta-learning)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NNP HIDRA)) (, ,) (NP (NP (DT a) (JJ meta-learning) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (NP (NP (NN training) (CC and) (VBG evaluating)) (PP (IN across) (NP (NP (NNS tasks)) (PP (IN with) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (NN target) (NNS variables)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ Model-Agnostic) (JJ Meta-Learning)) (VP (VP (NNS trains) (NP (DT a) (NN distribution)) (PP (IN for) (NP (NP (PDT all) (DT the) (NNS neurons)) (PP (IN in) (NP (DT the) (NN output) (NN layer)))))) (CC and) (VP (NP (DT a) (JJ specific) (NN weight) (NN initialization)) (PP (IN for) (NP (NP (DT the) (NNS ones)) (PP (IN in) (NP (DT the) (JJ hidden) (NNS layers)))))))))) (. .))
(S (NP (NNP HIDRA)) (VP (VBZ explores) (NP (DT this)) (PP (IN by) (S (VP (VBG learning) (NP (NP (CD one) (NN master) (NN neuron)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN used) (S (VP (TO to) (VP (VB initialize) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (NN output) (NNS neurons)))) (PP (IN for) (NP (DT a) (JJ new) (NN task))))))))))))))) (. .))
(S (NP (NP (JJ Extensive) (NNS experiments)) (PP (IN on) (NP (DT the) (NNP Miniimagenet) (CC and) (NNP Omniglot) (NNS data) (NNS sets)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NNP HIDRA)) (VP (VBZ improves) (PP (RP over) (NP (JJ standard) (NNS approaches))) (SBAR (IN while) (S (VP (VBG generalizing) (PP (TO to) (NP (NP (NNS tasks)) (PP (IN with) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (NN target) (NNS variables)))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ is) (VP (VBN shown) (S (VP (TO to) (VP (VB robustify) (NP (JJ low-capacity) (NNS models)) (PP (IN in) (NP (VBG learning))) (PP (IN across) (NP (NP (JJ complex) (NNS tasks)) (PP (IN with) (NP (NP (DT a) (JJ high) (NN number)) (PP (IN of) (NP (NP (NNS classes)) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (JJ regular) (NNP MAML)) (VP (VBZ fails) (S (VP (TO to) (VP (VB learn) (NP (DT any) (JJ feasible) (NN initialization))))))))))))))))))) (. .))
