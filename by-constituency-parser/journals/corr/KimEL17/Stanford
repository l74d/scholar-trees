(S (PP (IN In) (NP (NP (DT this) (NN paper)) (, ,) (NP (NP (DT a) (JJ novel) (NN architecture)) (PP (IN for) (NP (DT a) (ADJP (JJ deep) (JJ recurrent)) (JJ neural) (NN network)))))) (, ,) (NP (JJ residual) (NN LSTM)) (VP (VBZ is) (VP (VBN introduced))) (. .))
(S (NP (DT A) (JJ plain) (NN LSTM)) (VP (VBZ has) (NP (NP (DT an) (JJ internal) (NN memory) (NN cell)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB learn) (NP (NP (NML (JJ long) (NN term)) (NNS dependencies)) (PP (IN of) (NP (JJ sequential) (NNS data)))))))))) (. .))
(S (NP (PRP It)) (ADVP (RB also)) (VP (VBZ provides) (NP (DT a) (JJ temporal) (NN shortcut) (NN path)) (S (VP (TO to) (VP (VB avoid) (NP (NP (VBG vanishing)) (CC or) (NP (NP (VBG exploding) (NNS gradients)) (PP (IN in) (NP (DT the) (JJ temporal) (NN domain))))))))) (. .))
(S (NP (DT The) (JJ residual) (NN LSTM)) (VP (VBZ provides) (NP (NP (DT an) (JJ additional) (JJ spatial) (NN shortcut) (NN path)) (PP (IN from) (NP (NP (JJR lower) (NNS layers)) (PP (IN for) (NP (NP (JJ efficient) (NN training)) (PP (IN of) (NP (JJ deep) (NNS networks)))))))) (PP (IN with) (NP (JJ multiple) (NN LSTM) (NNS layers)))) (. .))
(S (PP (VBN Compared) (PP (IN with) (NP (NP (DT the) (JJ previous) (NN work)) (, ,) (NP (NN highway) (NNP LSTM))))) (, ,) (NP (JJ residual) (NN LSTM)) (VP (VBZ separates) (NP (DT a) (JJ spatial) (NN shortcut) (NN path)) (PP (IN with) (NP (JJ temporal) (CD one))) (PP (IN by) (S (VP (VBG using) (NP (NP (NN output) (NNS layers)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB help) (S (VP (TO to) (VP (VB avoid) (SBAR (S (NP (NP (DT a) (NN conflict)) (PP (IN between) (NP (NML (ADJP (JJ spatial) (CC and) (JJ temporal)) (HYPH -) (NN domain)) (NN gradient)))) (VP (VBZ flows)))))))))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (JJ residual) (NN LSTM)) (VP (VBZ reuses) (NP (NP (DT the) (NN output) (NN projection) (NN matrix)) (CC and) (NP (NP (DT the) (NN output) (NN gate)) (PP (IN of) (NP (NNP LSTM))))) (S (VP (TO to) (VP (VB control) (NP (NP (NP (DT the) (NML (JJ spatial) (NN information)) (NN flow)) (PP (RB instead) (IN of) (NP (JJ additional) (NN gate) (NNS networks)))) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB effectively)) (VP (VBZ reduces) (NP (NP (QP (JJR more) (IN than) (CD 10)) (NN %)) (PP (IN of) (NP (NN network) (NNS parameters)))))))))))) (. .))
(S (NP (NP (DT An) (NN experiment)) (PP (IN for) (NP (NP (JJ distant) (NN speech) (NN recognition)) (PP (IN on) (NP (DT the) (NNP AMI) (NNP SDM) (NN corpus)))))) (VP (VBZ shows) (SBAR (IN that) (S (NP (NP (NML (CD 10) (HYPH -) (NN layer)) (NN plain)) (CC and) (NP (NN highway) (NNP LSTM) (NNS networks))) (VP (VBD presented) (NP (QP (CD 13.7) (NN %) (CC and) (CD 6.2) (NN %)) (NN increase)) (PP (IN in) (NP (NP (NN WER)) (PP (IN over) (NP (NML (CD 3) (HYPH -) (NN layer)) (NNS aselines))))) (, ,) (ADVP (RB respectively)))))) (. .))
(S (PP (IN On) (NP (DT the) (NN contrary))) (, ,) (NP (NML (CD 10) (HYPH -) (NN layer)) (JJ residual) (NN LSTM) (NNS networks)) (VP (VBD provided) (NP (DT the) (JJS lowest) (NN WER)) (NP (NP (CD 41.0) (NN %)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ corresponds) (NP (NP (QP (IN to) (CD 3.3) (NN %) (CC and) (CD 2.8) (NN %)) (NN WER) (NN reduction)) (PP (IN over) (NP (NML (JJ plain) (CC and) (NN highway)) (NNP LSTM) (NNS networks)))) (, ,) (ADVP (RB respectively))))))) (. .))
