(S (S (NP (NP (JJ Recurrent) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NN RNN)) (-RRB- -RRB-)) (VP (VBP are) (ADVP (RB widely)) (VP (VBN used) (S (VP (TO to) (VP (VB solve) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS problems)))))))))) (CC and) (S (SBAR (IN as) (S (NP (NP (NP (DT the) (NN quantity)) (PP (IN of) (NP (NNS data)))) (CC and) (NP (NP (DT the) (NN amount)) (PP (IN of) (ADJP (JJ available))))) (VP (VB compute) (SBAR (S (VP (VBP have) (VP (VBN increased)))))))) (, ,) (ADVP (RB so)) (VP (VBP have) (NP (NN model) (NNS sizes)))) (. .))
(S (NP (NP (DT The) (NN number)) (PP (IN of) (NP (NP (NNS parameters)) (PP (IN in) (NP (JJ recent) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS networks)))))) (VP (VBZ makes) (S (NP (PRP them)) (ADJP (JJ hard) (S (VP (TO to) (VP (VB deploy) (, ,) (PP (ADVP (RB especially)) (IN on) (NP (NP (JJ mobile) (NNS phones)) (CC and) (NP (VBN embedded) (NNS devices)))))))))) (. .))
(S (NP (DT The) (NN challenge)) (VP (VBZ is) (ADJP (JJ due) (PP (IN to) (NP (CC both) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT the) (NN model)))) (CC and) (NP (DT the) (NN time))))) (SBAR (S (NP (PRP it)) (VP (VBZ takes) (S (VP (TO to) (VP (VB evaluate) (NP (PRP it))))))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (VP (VB deploy) (NP (DT these) (NNS RNNs)) (ADVP (RB efficiently))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (NN technique)) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT a) (NN network)))) (PP (IN by) (NP (NN pruning) (NNS weights))) (PP (IN during) (NP (NP (DT the) (JJ initial) (NN training)) (PP (IN of) (NP (DT the) (NN network))))))))) (. .))
(S (PP (IN At) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NN training))))) (, ,) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBP are) (ADJP (JJ sparse) (SBAR (IN while) (S (NP (NN accuracy)) (VP (VBZ is) (ADVP (RB still)) (ADJP (JJ close) (PP (IN to) (NP (DT the) (JJ original) (JJ dense) (JJ neural) (NN network))))))))) (. .))
(S (S (NP (DT The) (NN network) (NN size)) (VP (VBZ is) (VP (VBN reduced) (PP (IN by) (NP (NN 8x)))))) (CC and) (S (NP (NP (DT the) (NN time)) (VP (VBN required) (S (VP (TO to) (VP (VB train) (NP (DT the) (NN model))))))) (VP (VBZ remains) (ADJP (JJ constant)))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB prune) (NP (DT a) (JJR larger) (JJ dense) (NN network)) (S (VP (TO to) (VP (VB achieve) (NP (JJR better)) (PP (IN than) (NP (JJ baseline) (NN performance))) (SBAR (IN while) (S (ADVP (RB still)) (VP (VBG reducing) (NP (NP (DT the) (JJ total) (NN number)) (PP (IN of) (NP (NNS parameters)))) (ADVP (RB significantly)))))))))) (. .))
(S (NP (VBG Pruning) (NNS RNNs)) (VP (VP (VBZ reduces) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT the) (NN model))))) (CC and) (VP (MD can) (ADVP (RB also)) (VP (VB help) (S (VP (VB achieve) (S (NP (NP (JJ significant) (NN inference) (NN time) (NN speed) (HYPH -) (NN up)) (VP (VBG using) (NP (JJ sparse) (NN matrix)))) (VP (VB multiply)))))))) (. .))
(S (S (NP (NNS Benchmarks)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG using) (NP (PRP$ our) (NN technique) (NN model) (NN size)))) (VP (MD can) (VP (VB be) (VP (VBN reduced) (PP (IN by) (NP (CD 90) (NN %)))))))))) (CC and) (S (NP (NN speed) (HYPH -) (NN up)) (VP (VBZ is) (PP (IN around) (NP (NN 2x))) (PP (IN to) (NP (NN 7x))))) (. .))
