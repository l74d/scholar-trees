(S (S (NP (NP (JJ Recurrent) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP RNN)) (-RRB- -RRB-))) (VP (VBP are) (VP (ADVP (RB widely)) (VBN used) (S (VP (TO to) (VP (VB solve) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS problems)))))))))) (CC and) (S (SBAR (IN as) (S (NP (NP (NP (DT the) (NN quantity)) (PP (IN of) (NP (NNS data)))) (CC and) (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (JJ available) (NN compute))))) (VP (VBP have) (VP (VBN increased))))) (, ,) (ADVP (RB so)) (VP (JJ have)) (NP (NN model) (NNS sizes))) (. .))
(S (NP (NP (DT The) (NN number)) (PP (IN of) (NP (NNS parameters))) (PP (IN in) (NP (JJ recent) (JJ state-of-the-art) (NNS networks)))) (VP (VBZ makes) (S (NP (PRP them)) (ADJP (JJ hard) (SBAR (S (VP (TO to) (VP (VB deploy))))))) (, ,) (PP (ADVP (RB especially)) (IN on) (NP (NP (JJ mobile) (NNS phones)) (CC and) (NP (VBD embedded) (NNS devices))))) (. .))
(S (NP (DT The) (NN challenge)) (VP (VBZ is) (ADJP (JJ due) (PP (TO to) (NP (DT both) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT the) (NN model)))) (CC and) (NP (NP (DT the) (NN time)) (SBAR (S (NP (PRP it)) (VP (VBZ takes) (S (VP (TO to) (VP (VB evaluate) (NP (PRP it))))))))))))) (. .))
(S (SBAR (IN In) (NN order) (S (VP (TO to) (VP (VB deploy) (NP (DT these) (NNP RNNs)) (ADVP (RB efficiently)))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN technique)) (SBAR (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT a) (NN network)))) (PP (IN by) (S (VP (VBG pruning) (NP (NNS weights)) (PP (IN during) (NP (NP (DT the) (JJ initial) (NN training)) (PP (IN of) (NP (DT the) (NN network)))))))))))))) (. .))
(S (PP (IN At) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NN training))))) (, ,) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBP are) (ADJP (VBN sparse)) (SBAR (IN while) (S (NP (NN accuracy)) (VP (VBZ is) (ADVP (ADVP (ADVP (RB still)) (ADJP (JJ close) (PP (TO to) (NP (DT the) (JJ original) (NN dense) (JJ neural) (NN network)))))))))) (. .))
(S (S (NP (DT The) (NN network) (NN size)) (VP (VBZ is) (VP (VBN reduced) (PP (IN by) (NP (CD 8x)))))) (CC and) (S (NP (NP (DT the) (NN time)) (VP (VBN required) (S (VP (TO to) (VP (VB train) (NP (DT the) (NN model))))))) (VP (VBZ remains) (ADJP (JJ constant)))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB prune) (NP (DT a) (JJR larger) (NN dense) (NN network)) (S (VP (TO to) (VP (VB achieve) (NP (ADJP (JJR better) (PP (IN than) (ADJP (JJ baseline)))) (NN performance))))) (SBAR (IN while) (S (ADVP (RB still)) (VP (VBG reducing) (NP (NP (DT the) (JJ total) (NN number)) (PP (IN of) (NP (NNS parameters)))) (ADVP (RB significantly))))))) (. .))
(S (S (VP (VBG Pruning) (NP (NNP RNNs)))) (VP (VP (VBZ reduces) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT the) (NN model))))) (CC and) (VP (MD can) (ADVP (RB also)) (VP (VB help) (S (VP (VB achieve) (NP (JJ significant) (NN inference) (NN time) (JJ speed-up)) (S (VP (VBG using) (NP (JJ sparse) (NN matrix) (NN multiply))))))))) (. .))
(S (NP (NNP Benchmarks)) (VP (VBP show) (SBAR (IN that) (S (S (S (VP (VBG using) (NP (PRP$ our) (NN technique)))) (NP (NN model) (NN size)) (VP (MD can) (VP (VB be) (VP (VBN reduced) (PP (IN by) (NP (CD 90) (NN %))))))) (CC and) (S (NP (NN speed-up)) (VP (VBZ is) (NP (QP (RB around) (CD 2x) (TO to) (CD 7x)))))))) (. .))
