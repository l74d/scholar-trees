(S (NP (NNP Sequence) (NN model) (VBG learning) (NNS algorithms)) (ADVP (RB typically)) (VP (VP (VB maximize) (NP (NP (JJ log-likelihood)) (PP (IN minus) (NP (NP (DT the) (NN norm)) (PP (IN of) (NP (DT the) (NN model))))))) (PRN (-LRB- -LRB-) (CC or) (VP (VB minimize) (NP (NP (NNP Hamming) (NN loss)) (NNP +) (NP (NN norm)))) (-RRB- -RRB-))) (. .))
(S (PP (IN In) (NP (JJ cross-lingual) (NN part-of-speech) (PRN (-LRB- -LRB-) (NNP POS) (-RRB- -RRB-)) (NN tagging))) (, ,) (NP (PRP$ our) (NN target) (NN language) (NN training) (NNS data)) (VP (NNS consists) (PP (IN of) (NP (NP (NNS sequences)) (PP (IN of) (NP (NNS sentences))) (PP (IN with) (NP (NP (JJ word-by-word) (NNS labels)) (VP (VBN projected) (PP (IN from) (NP (NP (NP (NNS translations)) (PP (IN in) (NP (ADJP ($ $) (JJ k) ($ $)) (NNS languages)))) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBP have) (VP (VBN labeled) (NP (NNS data)) (, ,) (PP (IN via) (NP (NN word) (NNS alignments))))))))))))))) (. .))
(S (S (NP (PRP$ Our) (NN training) (NNS data)) (VP (VBZ is) (ADVP (RB therefore)) (ADJP (RB very) (JJ noisy)))) (, ,) (CC and) (S (SBAR (IN if) (S (NP (NNP Rademacher) (NN complexity)) (VP (VBZ is) (ADJP (JJ high))))) (, ,) (NP (JJ learning) (NNS algorithms)) (VP (VBP are) (ADJP (JJ prone) (PP (TO to) (NP (VB overfit)))))) (. .))
(S (NP (JJ Norm-based) (NN regularization)) (VP (VBZ assumes) (NP (NP (DT a) (JJ constant) (NN width)) (CC and) (NP (NN zero) (NN mean) (RB prior)))) (. .))
(S (NP (PRP We)) (ADVP (RB instead)) (VP (VBP propose) (S (VP (TO to) (VP (VB use) (NP (DT the) (ADJP ($ $) (JJ k) ($ $)) (NN source) (NN language) (NNS models)) (S (VP (TO to) (VP (VB estimate) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT a) (JJ Gaussian) (NN prior)))) (PP (IN for) (S (VP (VBG learning) (NP (JJ new) (NNP POS) (NNS taggers)))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ leads) (PP (TO to) (NP (NP (ADJP (RB significantly) (JJR better)) (NN performance)) (PP (IN in) (NP (JJ multi-source) (NN transfer) (NNS set-ups)))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBD present) (NP (NP (DT a) (JJ drop-out) (NN version)) (SBAR (WHNP (WDT that)) (S (VP (VBZ injects) (NP (PRN (-LRB- -LRB-) (JJ empirical) (-RRB- -RRB-)) (JJ Gaussian) (NN noise)) (PP (IN during) (NP (JJ online) (NN learning)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP note) (SBAR (IN that) (S (S (VP (VBG using) (NP (JJ empirical) (JJ Gaussian) (NNS priors)))) (VP (VP (VBZ leads) (PP (TO to) (NP (ADJP (VB much) (JJR lower)) (NNP Rademacher) (NN complexity)))) (, ,) (CC and) (VP (VBZ is) (ADJP (JJ superior) (PP (TO to) (NP (ADJP (RB optimally) (JJ weighted)) (NN model) (NN interpolation))))))))) (. .))
