(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP aim) (S (VP (TO to) (VP (VB develop) (NP (NP (DT a) (ADJP (NN simple) (CC and) (JJ scalable)) (NN reinforcement) (VBG learning) (NNS algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (NN standard) (VBD supervised) (VBG learning) (NNS methods)) (PP (IN as) (NP (NNS subroutines))))))))))) (. .))
(S (NP (PRP$ Our) (NN goal)) (VP (VBZ is) (NP (NP (DT an) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ utilizes) (NP (RB only) (ADJP (JJ simple) (CC and) (JJ convergent)) (JJ maximum) (NN likelihood) (NN loss) (NNS functions)) (, ,) (SBAR (IN while) (S (ADVP (RB also)) (VP (VBG being) (ADJP (JJ able) (S (VP (TO to) (VP (VB leverage) (NP (JJ off-policy) (NNS data)))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (VBN proposed) (NN approach)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP refer) (PP (TO to)) (PP (IN as) (NP (NP (JJ advantage-weighted) (NN regression)) (PRN (-LRB- -LRB-) (NP (NNP AWR)) (-RRB- -RRB-))))))) (, ,)) (VP (VBZ consists) (PP (IN of) (NP (NP (CD two) (NN standard) (VBD supervised) (JJ learning) (NNS steps)) (: :) (NP (NP (NP (CD one)) (SBAR (S (VP (TO to) (VP (VB regress) (PP (IN onto) (NP (NP (NN target) (NNS values)) (PP (IN for) (NP (DT a) (NN value) (NN function)))))))))) (, ,) (CC and) (NP (NP (DT another)) (SBAR (S (VP (TO to) (VP (VB regress) (PP (IN onto) (NP (NP (JJ weighted) (NN target) (NNS actions)) (PP (IN for) (NP (DT the) (NN policy)))))))))))))) (. .))
(S (NP (DT The) (NN method)) (VP (VP (VBZ is) (ADJP (JJ simple) (CC and) (JJ general))) (, ,) (VP (MD can) (VP (VB accommodate) (NP (JJ continuous) (CC and) (JJ discrete) (NNS actions)))) (, ,) (CC and) (VP (MD can) (VP (VB be) (VP (VBN implemented) (PP (IN in) (NP (NP (RB just) (DT a) (JJ few) (NNS lines)) (PP (IN of) (NP (NN code))))) (PP (IN on) (NP (NP (NN top)) (PP (IN of) (NP (NN standard) (VBD supervised) (JJ learning) (NNS methods))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP provide) (NP (NP (DT a) (JJ theoretical) (NN motivation)) (PP (IN for) (NP (NNP AWR))))) (CC and) (VP (VP (VB analyze) (NP (PRP$ its) (NNS properties))) (SBAR (WHADVP (WRB when)) (S (VP (VBG incorporating) (NP (NP (NN off-policy) (NNS data)) (PP (IN from) (NP (NN experience) (NN replay))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (NNP AWR)) (PP (IN on) (NP (NP (DT a) (NN suite)) (PP (IN of) (NP (JJ standard) (NNP OpenAI) (NNP Gym) (NN benchmark) (NNS tasks)))))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ achieves) (NP (JJ competitive) (NN performance)) (PP (VBN compared) (PP (TO to) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (JJ well-established) (JJ state-of-the-art) (NNP RL) (NN algorithms))))))))))) (. .))
(S (NP (NNP AWR)) (VP (VBZ is) (ADVP (RB also)) (ADJP (JJ able) (S (VP (TO to) (VP (VB acquire) (NP (NP (ADJP (RBR more) (JJ effective)) (NNS policies)) (PP (IN than) (NP (JJS most) (JJ off-policy) (NN algorithms)))) (SBAR (WHADVP (WRB when)) (S (VP (VBG learning) (PP (IN from) (NP (ADJP (RB purely) (JJ static)) (NNS datasets))) (PP (IN with) (NP (DT no) (JJ additional) (JJ environmental) (NNS interactions))))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (PRP$ our) (NN algorithm)) (PP (IN on) (NP (NP (VBG challenging) (JJ continuous) (NN control) (NNS tasks)) (PP (IN with) (NP (ADJP (RB highly) (JJ complex)) (VBD simulated) (NNS characters)))))) (. .))
