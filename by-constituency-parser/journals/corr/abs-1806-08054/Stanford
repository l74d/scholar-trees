(S (NP (NML (JJ Large) (HYPH -) (NN scale)) (VBN distributed) (NN optimization)) (VP (VBZ is) (PP (IN of) (NP (NP (JJ great) (NN importance)) (PP (IN in) (NP (JJ various) (NNS applications)))))) (. .))
(S (PP (IN For) (NP (NP (NN data) (HYPH -) (NN parallel)) (VP (VBN based) (NP (VBN distributed) (NN learning))))) (, ,) (NP (DT the) (JJ inter-node) (NN gradient) (NN communication)) (ADVP (RB often)) (VP (VBZ becomes) (NP (DT the) (NN performance) (NN bottleneck))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT the) (NN error)) (VP (VBN compensated) (NP (VBN quantized) (JJ stochastic) (NN gradient) (NN descent) (NN algorithm)) (S (VP (TO to) (VP (VB improve) (NP (DT the) (NN training) (NN efficiency)))))))) (. .))
(S (S (NP (JJ Local) (NNS gradients)) (VP (VBP are) (VP (VBN quantized) (S (VP (TO to) (VP (VB reduce) (NP (DT the) (NN communication)) (ADVP (RB overhead)))))))) (, ,) (CC and) (S (NP (VBN accumulated) (NN quantization) (NN error)) (VP (VBZ is) (VP (VBN utilized) (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (DT the) (NN convergence)))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VP (VBP present) (NP (JJ theoretical) (NN analysis)) (PP (IN on) (NP (DT the) (NN convergence) (NN behaviour)))) (, ,) (CC and) (VP (VBP demonstrate) (NP (PRP$ its) (NN advantage)) (PP (IN over) (NP (NNS competitors))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP indicate) (SBAR (IN that) (S (NP (PRP$ our) (NN algorithm)) (VP (MD can) (VP (VB compress) (NP (NNS gradients)) (PP (IN by) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (QP (RB up) (IN to) (CD two)) (NNS magnitudes))))) (PP (IN without) (NP (NN performance) (NN degradation)))))))) (. .))
