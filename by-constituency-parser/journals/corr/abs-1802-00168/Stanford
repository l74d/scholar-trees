(S (NP (PRP We)) (VP (VBP replace) (NP (NP (DT the) (NN output) (NN layer)) (PP (IN of) (NP (NP (JJ deep) (JJ neural) (NNS nets)) (, ,) (NP (ADVP (RB typically)) (DT the) (NN softmax) (NN function)) (, ,)))) (PP (IN by) (NP (DT a) (JJ novel) (VBG interpolating) (NN function)))) (. .))
(S (CC And) (NP (PRP we)) (VP (VBP propose) (NP (NP (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN training) (CC and) (NN testing)))) (NNS algorithms)) (PP (IN for) (NP (DT this) (JJ new) (NN architecture))))) (. .))
(S (PP (VBN Compared) (PP (IN to) (NP (NP (JJ classical) (JJ neural) (NNS nets)) (PP (IN with) (NP (NP (NN softmax) (NN function)) (PP (IN as) (NP (NN output) (NN activation)))))))) (, ,) (NP (NP (DT the) (NN surrogate)) (PP (IN with) (S (VP (VBG interpolating) (NP (NN function)) (PP (IN as) (NP (NN output) (NN activation))))))) (VP (VBZ combines) (NP (NP (NNS advantages)) (PP (IN of) (NP (DT both) (ADJP (JJ deep) (CC and) (JJ manifold)) (NN learning))))) (. .))
(S (S (NP (DT The) (JJ new) (NN framework)) (VP (VBZ demonstrates) (NP (DT the) (VBG following) (JJ major) (NNS advantages)))) (: :) (S (ADVP (RB First)) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (ADJP (JJR better) (JJ applicable)) (PP (IN to) (NP (NP (DT the) (NN case)) (PP (IN with) (NP (JJ insufficient) (NN training) (NNS data)))))))) (. .))
(S (ADVP (RB Second)) (, ,) (NP (PRP it)) (ADVP (RB significantly)) (VP (VBZ improves) (NP (DT the) (NN generalization) (NN accuracy)) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN variety)) (PP (IN of) (NP (NNS networks)))))) (. .))
(S (S (NP (DT The) (NN algorithm)) (VP (VBZ is) (VP (VBN implemented) (PP (IN in) (NP (NNP PyTorch)))))) (, ,) (CC and) (S (NP (NN code)) (VP (MD will) (VP (VB be) (VP (VBN made) (S (ADJP (RB publicly) (JJ available))))))) (. .))
