(S (NP (PRP We)) (VP (VB replace) (NP (NP (NP (DT the) (NN output) (NN layer)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS nets)))) (, ,) (NP (ADVP (RB typically)) (DT the) (NN softmax) (NN function)) (, ,)) (PP (IN by) (NP (DT a) (JJ novel) (NN interpolating) (NN function)))) (. .))
(S (CC And) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ end-to-end) (NN training) (CC and) (VBG testing) (NN algorithms)) (PP (IN for) (NP (DT this) (JJ new) (NN architecture))))) (. .))
(S (PP (VBN Compared) (PP (TO to) (NP (NP (JJ classical) (JJ neural) (NNS nets)) (PP (IN with) (NP (NP (JJ softmax) (NN function)) (PP (IN as) (NP (NN output) (NN activation)))))))) (, ,) (NP (NP (DT the) (NN surrogate)) (PP (IN with) (NP (NP (VBG interpolating) (NN function)) (PP (IN as) (NP (NN output) (NN activation)))))) (VP (NNS combines) (NP (NP (NNS advantages)) (PP (IN of) (NP (ADJP (DT both) (JJ deep) (CC and) (JJ manifold)) (NN learning))))) (. .))
(S (S (NP (DT The) (JJ new) (NN framework)) (VP (VBZ demonstrates) (NP (DT the) (JJ following) (JJ major) (NNS advantages)))) (: :) (S (ADVP (RB First)) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (RBR better) (JJ applicable) (PP (TO to) (NP (NP (DT the) (NN case)) (PP (IN with) (NP (JJ insufficient) (NN training) (NNS data)))))))) (. .))
(S (ADVP (JJ Second)) (, ,) (NP (PRP it)) (VP (ADVP (RB significantly)) (VBZ improves) (NP (NP (DT the) (NN generalization) (NN accuracy)) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN variety)) (PP (IN of) (NP (NNS networks))))))) (. .))
(S (S (NP (DT The) (NN algorithm)) (VP (VBZ is) (VP (VBN implemented) (PP (IN in) (NP (NNP PyTorch)))))) (, ,) (CC and) (S (NP (NN code)) (VP (MD will) (VP (VB be) (VP (VBN made) (S (ADJP (RB publicly) (JJ available))))))) (. .))
