(S (NP (NN Batch) (NN Normalization) (PRN (-LRB- -LRB-) (NP (NNP BatchNorm)) (-RRB- -RRB-))) (VP (VBZ is) (ADVP (RB commonly)) (VP (VBN used) (PP (IN in) (NP (NNP Convolutional) (JJ Neural) (NNS Networks) (PRN (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-)))) (S (VP (TO to) (VP (VB improve) (NP (NN training) (NN speed) (CC and) (NN stability))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (EX there)) (VP (VBZ is) (ADVP (RB still)) (NP (NP (JJ limited) (NN consensus)) (PP (IN on) (SBAR (WHADVP (WRB why)) (S (NP (DT this) (NN technique)) (VP (VBZ is) (ADJP (JJ effective)))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ uses) (NP (NNS concepts)) (PP (IN from) (NP (DT the) (JJ traditional) (JJ adaptive) (NN filter) (NN domain))) (S (VP (TO to) (VP (VB provide) (NP (NN insight)) (PP (IN into) (NP (NP (DT the) (NNS dynamics)) (CC and) (NP (NP (JJ inner) (NNS workings)) (PP (IN of) (NP (NNP BatchNorm)))))))))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NML (NN convolution) (NN weight)) (NNS updates)) (VP (VBP have) (NP (NP (JJ natural) (NNS modes)) (SBAR (WHNP (WP$ whose) (NP (NP (NN stability)) (CC and) (NP (NN convergence) (NN speed)))) (S (VP (VBP are) (VP (VBN tied) (PP (IN to) (NP (NP (NP (DT the) (NNS eigenvalues)) (PP (IN of) (NP (DT the) (NML (NN input) (NN autocorrelation)) (NNS matrices)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN controlled) (PP (IN by) (NP (NNP BatchNorm))) (PP (IN through) (NP (NP (DT the) (NN convolution) (NNS layers) (POS ')) (JJ channel-wise) (NN structure)))))))))))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP$ our) (NNS experiments)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (NML (NN speed) (CC and) (NN stability)) (NNS benefits)) (VP (VBP are) (NP (JJ distinct) (NNS effects)))))) (. .))
(S (ADVP (RB At) (NP (JJ low) (NN learning) (NNS rates))) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (NP (NP (NNP BatchNorm) (POS 's)) (NN amplification)) (PP (IN of) (NP (NP (DT the) (JJS smallest) (NNS eigenvalues)) (SBAR (WHNP (WDT that)) (S (VP (VBZ improves) (NP (NN convergence) (NN speed)) (, ,) (SBAR (IN while) (S (PP (IN at) (NP (NML (JJ high) (NN learning)) (NNS rates))) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (NP (NP (NNP BatchNorm) (POS 's)) (NN suppression)) (PP (IN of) (NP (NP (DT the) (JJS largest) (NNS eigenvalues)) (SBAR (WHNP (WDT that)) (S (VP (VBZ ensures) (NP (NN stability)))))))))))))))))) (. .))
(S (ADVP (RB Lastly)) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (PP (IN in) (NP (NP (DT the) (JJ first) (NN training) (NN step)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NN normalization)) (VP (VBZ is) (VP (VBN needed) (ADVP (RBS most)))))))) (, ,) (NP (NNP BatchNorm)) (VP (VBZ satisfies) (NP (DT the) (JJ same) (NN optimization)) (PP (IN as) (NP (NP (NP (JJ Normalized)) (NP (JJS Least)) (NP (NNP Mean) (NNP Square)) (PRN (-LRB- -LRB-) (NP (NNP NLMS)) (-RRB- -RRB-))) (, ,) (SBAR (IN while) (S (NP (PRP it)) (VP (VBZ continues) (S (VP (TO to) (VP (VB approximate) (NP (DT this) (NN condition)) (PP (IN in) (NP (JJ subsequent) (NNS steps))))))))))))))) (. .))
(S (NP (NP (DT The) (NNS analyses)) (VP (VBN provided) (PP (IN in) (NP (DT this) (NN paper))))) (VP (VBD lay) (NP (DT the) (NN groundwork)) (PP (IN for) (S (VP (VBG gaining) (NP (JJ further) (NN insight)) (PP (IN into) (NP (NP (DT the) (NN operation)) (PP (IN of) (NP (JJ modern) (NML (JJ neural) (NN network)) (NNS structures))))) (S (VP (VBG using) (NP (JJ adaptive) (NN filter) (NN theory)))))))) (. .))
