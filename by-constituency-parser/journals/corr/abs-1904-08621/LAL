(S (NP (NNP TAMER)) (VP (VBZ has) (VP (VBN proven) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (JJ powerful) (JJ interactive) (NN reinforcement) (VBG learning) (NN method)) (PP (IN for) (S (VP (VBG allowing) (S (NP (JJ ordinary) (NNS people)) (VP (TO to) (VP (VB teach) (CC and) (VB personalize) (NP (NP (JJ autonomous) (NNS agents) (POS ›)) (NN behavior)) (PP (IN by) (S (VP (VBG providing) (NP (JJ evaluative) (NN feedback))))))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT a) (NNP TAMER) (NN agent)) (VP (VBG planning) (PP (IN with) (NP (NP (NNP UCT)) (: —) (NP (JJ -a) (NNP Monte) (NNP Carlo) (NNP Tree) (NNP Search) (NN strategy)) (, ,))))) (VP (VP (MD can) (ADVP (RB only)) (VP (VB update) (NP (NNS states)) (PP (IN along) (NP (PRP$ its) (NN path))))) (CC and) (VP (MD might) (VP (VB induce) (NP (NP (JJ high) (VBG learning) (NN cost)) (PP (ADVP (RB especially)) (IN for) (NP (DT a) (JJ physical) (NN robot))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VP (VB drive) (NP (NP (DT the) (NN agent) (POS 's)) (NN exploration)) (PP (IN along) (NP (DT the) (JJ optimal) (NN path)))) (CC and) (VP (VB reduce) (NP (DT the) (NN learning) (NN cost)) (PP (IN by) (S (VP (VBG initializing) (NP (NP (DT the) (NN agent) (POS 's)) (NN reward) (NN function)) (PP (IN via) (NP (NP (JJ inverse) (NN reinforcement) (VBG learning)) (PP (IN from) (NP (NN demonstration))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP test) (NP (PRP$ our) (VBN proposed) (NN method)) (PP (IN in) (NP (NP (DT the) (NNP RL) (NN benchmark) (NN domain)) (PRN (: —) (NP (JJ -Grid) (NNP World)) (: —)) (PP (JJ -with) (NP (NP (JJ different) (NNS discounts)) (PP (IN on) (NP (JJ human) (NN reward)))))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG learning) (PP (IN from) (NP (NN demonstration))))) (VP (MD can) (VP (VP (VB allow) (S (NP (DT a) (NNP TAMER) (NN agent)) (VP (TO to) (VP (VB learn) (NP (DT a) (ADJP (RB roughly) (JJ optimal)) (NN policy)) (PP (RB up) (PP (TO to) (NP (DT the) (JJS deepest) (NN search)))))))) (CC and) (VP (VB encourage) (S (NP (DT the) (NN agent)) (VP (TO to) (VP (VB explore) (PP (IN along) (NP (DT the) (JJ optimal) (NN path)))))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (S (VP (VBG learning) (PP (IN from) (NP (NN demonstration))))) (VP (MD can) (VP (VB improve) (NP (DT the) (NN learning) (NN efficiency)) (PP (IN by) (S (VP (VP (VBG reducing) (NP (NP (JJ total) (NN feedback)) (, ,) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ incorrect) (NNS actions)))))) (CC and) (VP (VBG increasing) (NP (NP (DT the) (NN ratio)) (PP (IN of) (NP (JJ correct) (NNS actions))))) (S (VP (TO to) (VP (VB obtain) (NP (DT an) (JJ optimal) (NN policy))))) (, ,) (S (VP (VBG allowing) (S (NP (DT a) (NNP TAMER) (NN agent)) (VP (TO to) (VP (VB converge) (ADVP (RBR faster))))))))))))))) (. .))
