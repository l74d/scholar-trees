(S (NP (NML (NN Policy) (NN gradient)) (NNS methods)) (VP (VBP are) (NP (DT an) (ADJP (JJ appealing)) (NN approach)) (PP (IN in) (NP (NN reinforcement) (NN learning))) (SBAR (IN because) (S (NP (PRP they)) (ADVP (RB directly)) (VP (VP (VBP optimize) (NP (DT the) (JJ cumulative) (NN reward))) (CC and) (VP (MD can) (ADVP (RB straightforwardly)) (VP (VB be) (VP (VBN used) (PP (IN with) (NP (NP (JJ nonlinear) (NN function) (NNS approximators)) (PP (JJ such) (IN as) (NP (JJ neural) (NNS networks)))))))))))) (. .))
(S (NP (DT The) (CD two) (JJ main) (NNS challenges)) (VP (VBP are) (NP (NP (DT the) (JJ large) (NN number)) (PP (IN of) (NP (NP (NP (NNS samples)) (VP (ADVP (RB typically)) (VBN required))) (, ,) (CC and) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (S (VP (VBG obtaining) (NP (ADJP (JJ stable) (CC and) (JJ steady)) (NN improvement)) (PP (IN despite) (NP (NP (DT the) (NN nonstationarity)) (PP (IN of) (NP (DT the) (JJ incoming) (NNS data))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP address) (NP (DT the) (JJ first) (NN challenge)) (PP (IN by) (S (VP (VBG using) (SBAR (S (NP (NN value)) (VP (VBZ functions) (PP (IN to) (S (ADVP (RB substantially)) (VP (VB reduce) (SBAR (S (NP (NP (DT the) (NN variance)) (PP (IN of) (NP (NN policy) (NN gradient)))) (VP (VBZ estimates) (PP (IN at) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (DT some) (NN bias))))) (, ,) (PP (IN with) (NP (NP (DT an) (ADJP (RB exponentially) (HYPH -) (VBN weighted)) (NN estimator)) (PP (IN of) (NP (NP (DT the) (NN advantage) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ analogous) (PP (IN to) (NP (NN TD))))))))))))))))))))))) (PRN (-LRB- -LRB-) (NP (NN lambda)) (-RRB- -RRB-))) (. .))
(S (NP (PRP We)) (VP (VBP address) (NP (DT the) (JJ second) (NN challenge)) (PP (IN by) (S (VP (VBG using) (NP (NP (NP (NN trust) (NN region) (NN optimization) (NN procedure)) (PP (IN for) (NP (CC both) (NP (DT the) (NN policy)) (CC and) (NP (DT the) (NN value) (NN function))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN represented) (PP (IN by) (NP (JJ neural) (NNS networks)))))))))))) (. .))
(NP (NP (NP (PRP$ Our) (NN approach) (NNS yields)) (NP (NP (JJ strong) (JJ empirical) (NNS results)) (PP (IN on) (NP (ADJP (RB highly) (JJ challenging)) (NN 3D) (NN locomotion) (NNS tasks))))) (, ,) (VP (VBG learning) (S (VP (VP (VBG running) (NP (NP (NNS gaits)) (PP (IN for) (NP (ADJP (JJ bipedal) (CC and) (JJ quadrupedal)) (JJ simulated) (NNS robots))))) (, ,) (CC and) (VP (VBG learning) (NP (DT a) (NN policy)) (PP (IN for) (S (VP (VBG getting) (NP (DT the) (NN biped)) (S (VP (TO to) (VP (VB stand) (PRT (RP up)) (PP (IN from) (S (VP (VBG starting) (PRT (RP out)) (S (VP (VBG lying) (PP (IN on) (NP (DT the) (NN ground)))))))))))))))))) (. .))
(S (PP (IN In) (NP (NP (NN contrast)) (PP (IN to) (NP (NP (DT a) (NN body)) (PP (IN of) (NP (NP (JJ prior) (NN work)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (ADJP (NN hand) (HYPH -) (VBN crafted)) (NN policy) (NNS representations))))))))))) (, ,) (NP (PRP$ our) (NML (JJ neural) (NN network)) (NNS policies)) (VP (VBP map) (ADVP (RB directly)) (PP (IN from) (NP (JJ raw) (NNS kinematics))) (PP (IN to) (NP (JJ joint) (NNS torques)))) (. .))
(S (S (NP (PRP$ Our) (NN algorithm)) (VP (VBZ is) (ADJP (RB fully) (NP (JJ model) (HYPH -) (JJ free))))) (, ,) (CC and) (S (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NP (JJ simulated) (NN experience)) (VP (VBN required) (PP (IN for) (NP (DT the) (NN learning) (NNS tasks))) (PP (IN on) (NP (JJ 3D) (NNS bipeds))))))) (VP (VBZ corresponds) (PP (IN to) (NP (NP (QP (CD 1) (HYPH -) (CD 2)) (NNS weeks)) (PP (IN of) (NP (JJ real) (NN time))))))) (. .))
