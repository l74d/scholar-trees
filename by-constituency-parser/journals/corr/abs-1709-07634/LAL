(S (PP (IN For) (NP (JJS most) (JJ state-of-the-art) (NNS architectures))) (, ,) (NP (NP (VBD Rectified) (JJ Linear) (NNP Unit)) (PRN (-LRB- -LRB-) (NP (NNP ReLU)) (-RRB- -RRB-))) (VP (VBZ becomes) (NP (NP (DT a) (JJ standard) (NN component)) (VP (VBN accompanied) (PP (IN with) (NP (DT each) (NN layer)))))) (. .))
(S (SBAR (IN Although) (S (NP (NNP ReLU)) (VP (MD can) (VP (VB ease) (NP (DT the) (NN network) (NN training)) (PP (TO to) (NP (DT an) (NN extent))))))) (, ,) (NP (NP (DT the) (NN character)) (PP (IN of) (S (VP (VBG blocking) (NP (JJ negative) (NNS values)))))) (VP (VP (MD may) (VP (VB suppress) (NP (NP (DT the) (NN propagation)) (PP (IN of) (NP (JJ useful) (NN information)))))) (CC and) (VP (VBZ leads) (PP (TO to) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (S (VP (VBG optimizing) (NP (NP (ADJP (RB very) (JJ deep)) (NNP Convolutional) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP CNNs)) (-RRB- -RRB-)))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (S (VP (VBG stacking) (NP (NNS layers)) (PP (IN with) (NP (JJ nonlinear) (NNS activations))))) (VP (VBZ is) (ADJP (JJ hard)) (S (VP (TO to) (VP (VB approximate) (NP (NP (DT the) (JJ intrinsic) (JJ linear) (NNS transformations)) (PP (IN between) (NP (NN feature) (NNS representations)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP investigate) (NP (NP (DT the) (NN effect)) (PP (IN of) (S (VP (VBG erasing) (NP (NP (NNP ReLUs)) (PP (IN of) (NP (JJ certain) (NNS layers))))))))) (CC and) (VP (VB apply) (NP (PRP it)) (PP (TO to) (NP (NP (JJ various) (JJ representative) (NNS architectures)) (VP (VBG following) (NP (JJ deterministic) (NNS rules))))))) (. .))
(S (NP (PRP It)) (VP (MD can) (VP (VP (VB ease) (NP (DT the) (NN optimization))) (CC and) (VP (VB improve) (NP (DT the) (NN generalization) (NN performance))) (PP (IN for) (NP (ADJP (RB very) (JJ deep)) (NNP CNN) (NNS models))))) (. .))
(S (S (NP (PRP We)) (VP (VBP find) (S (S (NP (NP (CD two) (JJ key) (NNS factors))) (VP (VBG being) (ADJP (JJ essential) (PP (TO to) (NP (DT the) (NN performance) (NN improvement)))))) (: :) (NP (NP (CD 1) (-RRB- -RRB-) (NP (NP (DT the) (NN location)) (SBAR (WHADVP (WRB where)) (S (NP (NNP ReLU)) (VP (MD should) (VP (VB be) (VP (VBN erased) (PP (IN inside) (NP (DT the) (JJ basic) (NN module)))))))))) (: ;) (NP (CD 2) (-RRB- -RRB-) (NP (NP (DT the) (NN proportion)) (PP (IN of) (NP (JJ basic) (NNS modules))) (SBAR (S (VP (TO to) (VP (VB erase) (NP (NNP ReLU)))))))))))) (: ;) (S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG erasing) (NP (NP (DT the) (JJ last) (NNP ReLU) (NN layer)) (PP (IN of) (NP (NP (DT all) (JJ basic) (NNS modules)) (PP (IN in) (NP (DT a) (NN network)))))))) (ADVP (RB usually)) (VP (NNS yields) (NP (VBD improved) (NN performance))))))) (. .))
(S (S (PP (IN In) (NP (NNS experiments))) (, ,) (NP (PRP$ our) (NN approach)) (VP (ADVP (RB successfully)) (VBZ improves) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ various) (JJ representative) (NNS architectures)))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP report) (NP (NP (DT the) (JJ improved) (NNS results)) (PP (IN on) (NP (NP (NNP SVHN)) (, ,) (NP (NNP CIFAR-10/100)) (, ,) (CC and) (NP (NNP ImageNet))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (JJ competitive) (JJ single-model) (NN performance)) (PP (IN on) (NP (NNP CIFAR-100))) (PP (IN with) (NP (NP (ADJP (CD 16.53) (NN %)) (NN error) (NN rate)) (PP (VBN compared) (PP (TO to) (NP (NN state-of-the-art))))))) (. .))
