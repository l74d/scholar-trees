(S (NP (NNP Boosting)) (VP (VBZ is) (NP (NP (DT a) (JJ popular) (JJ ensemble) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ generates) (NP (ADJP (RBR more) (JJ powerful)) (NNS learners)) (PP (IN by) (S (VP (ADVP (JJ linearly)) (VBG combining) (NP (NP (NN base) (NNS models)) (PP (IN from) (NP (DT a) (NN simpler) (NN hypothesis) (NN class)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP investigate) (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (VBG adapting) (NP (NN batch) (NN gradient) (VBG boosting)) (PP (IN for) (S (VP (VBG minimizing) (NP (JJ convex) (NN loss) (NNS functions))))) (PP (TO to) (NP (NP (VB online) (VBG setting)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (NN loss)) (PP (IN at) (NP (DT each) (NN iteration)))) (VP (VBZ is) (VP (ADVP (JJ i.i.d)) (VBN sampled) (PP (IN from) (NP (DT an) (JJ unknown) (NN distribution)))))))))))))) (. .))
(S (S (VP (TO To) (VP (VB generalize) (PP (IN from) (NP (NN batch))) (PP (TO to) (NP (VB online)))))) (, ,) (NP (PRP we)) (ADVP (RB first)) (VP (VBP introduce) (NP (NP (DT the) (NN definition)) (PP (IN of) (NP (JJ online) (JJ weak) (NN learning) (NN edge))) (SBAR (WHPP (IN with) (WHNP (WDT which))) (S (PP (IN for) (NP (ADJP (RB strongly) (NNS convex) (CC and) (JJ smooth)) (NN loss) (NNS functions))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT an) (NN algorithm)) (, ,) (NP (NP (VBG Streaming) (NNP Gradient) (NNP Boosting)) (PRN (-LRB- -LRB-) (NP (NNP SGB)) (-RRB- -RRB-))) (PP (IN with) (NP (NP (JJ exponential) (NN shrinkage) (NNS guarantees)) (PP (IN in) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ weak) (NNS learners))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (VBP further)) (VP (JJ present) (NP (NP (DT an) (NN adaptation)) (PP (IN of) (NP (NNP SGB))) (SBAR (S (VP (TO to) (VP (VB optimize) (NP (NP (JJ non-smooth) (NN loss) (NNS functions)) (, ,) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBP derive) (NP (DT a) (NNP O) (PRN (-LRB- -LRB-) (JJ ln) (NNP N/N) (-RRB- -RRB-)) (NN convergence) (NN rate)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN analysis)) (VP (MD can) (VP (VB extend) (PP (TO to) (NP (JJ adversarial) (NN online) (VBG learning) (VBG setting))) (PP (IN under) (NP (DT a) (JJR stronger) (NN assumption) (SBAR (IN that) (S (NP (DT the) (JJ online) (JJ weak) (NN learning) (NN edge)) (VP (MD will) (VP (VB hold) (PP (IN in) (NP (JJ adversarial) (NN setting)))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB finally)) (VP (VBP demonstrate) (NP (NP (JJ experimental) (NNS results)) (VP (VBG showing) (SBAR (IN that) (S (PP (IN in) (NP (NN practice))) (NP (PRP$ our) (NN algorithms)) (VP (MD can) (VP (VB achieve) (NP (NP (JJ competitive) (NNS results)) (PP (IN as) (NP (JJ classic) (NN gradient) (VBG boosting)))) (SBAR (IN while) (S (VP (VBG using) (NP (JJR less) (NN computation)))))))))))) (. .))
