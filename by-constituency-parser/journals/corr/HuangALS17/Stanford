(S (NP (JJ Deep) (JJ neural) (NNS networks)) (VP (VBP are) (VP (VBN known) (S (VP (TO to) (VP (VB be) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB train) (ADJP (JJ due) (PP (IN to) (NP (NP (DT the) (NN instability)) (PP (IN of) (ADVP (RB back))) (PP (HYPH -) (NP (NN propagation))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (NP (NP (DT a) (ADJP (VBG boosting)) (NN theory)) (PP (IN for) (NP (DT the) (NNP ResNet) (NN architecture))))) (. .))
(S (S (NP (PRP We)) (VP (VB construct) (NP (ADJP (NP ($ $) (CD T$)) (JJ weak)) (NN module) (NNS classifiers)))) (, ,) (NP (DT each)) (VP (VBZ contains) (NP (NP (CD two)) (PP (IN of) (NP (DT the) (NML ($ $) (CD T$)) (NNS layers)))) (, ,) (SBAR (JJ such) (IN that) (S (NP (DT the) (VBN combined) (JJ strong) (NN learner)) (VP (VBZ is) (NP (DT a) (NNP ResNet)))))) (. .))
(S (NP (PRP$ Our) (VBN proposed) (NN algorithm)) (ADVP (RB merely)) (VP (VBZ requires) (NP (NP (NP (DT a) (JJ sequential) (NN training)) (PP (IN of) (NP (NP ($ $) (CD T$)) (`` ") (NP (JJ shallow) (NNS ResNets)) ('' ")))) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADJP (JJ inexpensive))))))) (. .))
(S (PP (IN In) (NP (JJ other) (NNS words))) (, ,) (NP (PRP we)) (VP (VP (VBP propose) (NP (DT a) (JJ weak) (NN learning) (NN condition))) (CC and) (VP (VB prove) (NP (DT a) (ADJP (VBG boosting)) (NN theory)) (PP (IN for) (NP (NNP ResNet))) (PP (IN under) (NP (DT the) (JJ weak) (NN learning) (NN condition))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP apply) (PP (IN to) (NP (JJ general) (NN multi-class) (NNS ResNets)))) (. .))
(S (NP (NP (DT A) (NN generalization) (NN error)) (VP (VBN bound) (PP (VBN based) (PP (IN on) (NP (NN margin) (NN theory)))))) (VP (VP (VBZ is) (VP (VBN proved))) (CC and) (VP (VBZ suggests) (NP (NP (NNP ResNet) (POS 's)) (ADJP (JJ resistant) (PP (IN to) (S (VP (VBG overfitting) (PP (IN under) (NP (NP (NN network)) (PP (IN with) (NP ($ $) (CD l_1))))) (NP (NP ($ $)) (SBAR (S (NP (NN norm)) (VP (VBD bounded))))))))) (NNS weights)))) (. .))
