(S (NP (NP (DT The) (NN performance) (CC and) (NN efficiency)) (PP (IN of) (NP (NP (JJ distributed) (NN training)) (PP (IN of) (NP (NNP Deep) (NNP Neural) (NNP Networks)))))) (VP (ADVP (RB highly)) (VBP depend) (PP (IN on) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NP (JJ gradient) (VBG averaging)) (PP (IN among) (NP (DT all) (VBG participating) (NNS nodes))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN bounded) (PP (IN by) (NP (NP (DT the) (NN communication)) (PP (IN between) (NP (NNS nodes)))))))))))) (. .))
(S (S (NP (EX There)) (VP (VBP are) (NP (NP (CD two) (JJ major) (NNS strategies)) (SBAR (S (VP (TO to) (VP (VB reduce) (NP (NN communication) (NN overhead))))))))) (: :) (S (S (NP (CD one)) (VP (VBZ is) (S (VP (TO to) (VP (VB hide) (NP (NN communication)) (PP (IN by) (S (VP (VBG overlapping) (NP (PRP it)) (PP (IN with) (NP (NN computation))))))))))) (, ,) (CC and) (S (NP (DT the) (JJ other)) (VP (VBZ is) (S (VP (TO to) (VP (VB reduce) (NP (NN message) (NNS sizes)))))))) (. .))
(S (S (NP (DT The) (JJ first) (NN solution)) (VP (VBZ works) (ADVP (RB well)) (PP (IN for) (NP (JJ linear) (JJ neural) (NNS architectures))))) (, ,) (CC but) (S (NP (NP (JJS latest) (NNS networks)) (PP (JJ such) (IN as) (NP (NP (NNP ResNet)) (CC and) (NP (NNP Inception))))) (VP (NN offer) (NP (NP (JJ limited) (NN opportunity)) (PP (IN for) (NP (DT this) (NN overlapping)))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (NNS researchers)) (VP (VBP have) (VP (VBN paid) (NP (JJR more) (NN attention)) (PP (TO to) (S (VP (VBG minimizing) (NP (NN communication))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ novel) (NN gradient) (NN compression) (NN framework)) (UCP (VP (VBN derived) (PP (IN from) (NP (NP (NNS insights)) (PP (IN of) (NP (JJ real) (JJ gradient) (NNS distributions)))))) (, ,) (CC and) (SBAR (WHNP (WDT which)) (S (VP (VBZ strikes) (NP (NP (DT a) (NN balance)) (PP (IN between) (NP (NP (NN compression) (NN ratio)) (, ,) (NP (NN accuracy)) (, ,) (CC and) (NP (JJ computational) (NN overhead))))))))))) (. .))
(S (NP (PRP$ Our) (NN framework)) (VP (VBZ has) (NP (NP (CD two) (JJ major) (JJ novel) (NNS components)) (: :) (NP (NP (NP (NN sparsification)) (PP (IN of) (NP (NP (NNS gradients)) (PP (IN in) (NP (DT the) (NN frequency) (NN domain)))))) (, ,) (CC and) (NP (NP (DT a) (JJ range-based) (NN floating) (NN point) (NN representation)) (SBAR (S (VP (TO to) (VP (VP (VB quantize)) (CC and) (VP (ADVP (JJR further)) (NN compress)) (NNS gradients) (NP (NNS frequencies)))))))))) (. .))
(S (NP (DT Both) (NNS components)) (VP (VBP are) (ADJP (JJ dynamic)) (, ,) (PP (IN with) (NP (NP (JJ tunable) (NNS parameters)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP achieve) (NP (NP (JJ different) (NN compression) (NN ratio)) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (NN accuracy) (NN requirement)) (CC and) (NP (NP (NNS systems) (POS â€º)) (NNS platforms))))))) (, ,) (CC and) (VP (VB achieve) (NP (NP (ADJP (RB very) (JJ high)) (NN throughput)) (PP (IN on) (NP (NNP GPUs))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (PRP$ our) (NNS techniques)) (VP (VBP guarantee) (NP (DT the) (NN convergence)) (PP (IN with) (NP (DT a) (VBG diminishing) (NN compression) (NN ratio))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN compression) (NN framework)) (VP (ADVP (RB effectively)) (VBZ improves) (NP (NP (DT the) (NN scalability)) (PP (IN of) (NP (NP (JJS most) (JJ popular) (JJ neural) (NNS networks)) (PP (IN on) (NP (DT a) (CD 32) (NNP GPU) (NN cluster)))))) (PP (TO to) (NP (NP (DT the) (NN baseline)) (PP (IN of) (NP (DT no) (NN compression))))) (, ,) (PP (IN without) (S (VP (VBG compromising) (NP (DT the) (NX (NX (NN accuracy)) (CC and) (NX (NN convergence) (NN speed))))))))))) (. .))
