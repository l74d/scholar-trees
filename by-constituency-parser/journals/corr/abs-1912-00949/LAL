(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN approach)) (SBAR (S (VP (TO to) (VP (VB address) (NP (NP (CD one) (NN aspect)) (PP (IN of) (NP (NP (DT the) (NN non-stationarity) (NN problem)) (PP (IN in) (NP (NP (JJ multi-agent) (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (JJ other) (NNS agents)) (VP (MD may) (VP (VB alter) (NP (PRP$ their) (NNS policies)) (ADVP (JJ due) (PP (TO to) (NP (NP (NN environment) (NNS changes)) (PP (IN during) (NP (NN execution))))))))))))))))))) (. .))
(S (NP (DT This)) (VP (VP (VBZ violates) (NP (NP (DT the) (NNP Markov) (NN assumption)) (SBAR (WHNP (IN that)) (S (VP (VBZ governs) (NP (RBS most) (JJ single-agent) (NNP RL) (NNS methods))))))) (CC and) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (JJ key) (NNS challenges)) (PP (IN in) (NP (JJ multi-agent) (NNP RL)))))))) (. .))
(S (S (VP (TO To) (VP (VB tackle) (NP (DT this))))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VP (VB train) (NP (JJ multiple) (NNS policies)) (PP (IN for) (NP (DT each) (NN agent)))) (CC and) (VP (VB postpone) (NP (NP (DT the) (NN selection)) (PP (IN of) (NP (DT the) (JJS best) (NN policy))) (PP (IN at) (NP (NN execution) (NN time))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VP (VBP model) (NP (DT the) (NN environment) (NN non-stationarity)) (PP (IN with) (NP (NP (DT a) (JJ finite) (NN set)) (PP (IN of) (NP (NNS scenarios)))))) (CC and) (VP (VB train) (NP (NP (NNS policies)) (VP (VBG fitting) (NP (DT each) (NN scenario)))))) (. .))
(S (PP (IN In) (NP (NP (NN addition)) (PP (TO to) (NP (VB multiple) (NNS policies))))) (, ,) (NP (DT each) (NN agent)) (ADVP (RB also)) (VP (VBZ learns) (NP (DT a) (NN policy) (NN predictor)) (S (VP (TO to) (VP (VB determine) (SBAR (WHNP (WDT which) (NN policy)) (S (VP (VBZ is) (NP (DT the) (JJS best)) (PP (IN with) (NP (PRP$ its) (JJ local) (NN information)))))))))) (. .))
(S (S (PP (IN By) (S (VP (VBG doing) (ADVP (RB so))))) (, ,) (NP (DT each) (NN agent)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB adapt) (NP (PRP$ its) (NN policy)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN environment)) (VP (NNS changes)))))))))) (CC and) (S (ADVP (RB consequentially)) (NP (DT the) (JJ other) (NNS agents)) (VP (VBP alter) (NP (PRP$ their) (NNS policies)) (PP (IN during) (NP (NN execution))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB empirically)) (VBD evaluated) (NP (PRP$ our) (NN method)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NP (JJ common) (NN benchmark) (NNS problems)) (VP (VBN proposed) (PP (IN for) (NP (JJ multi-agent) (JJ deep) (NNP RL))) (PP (IN in) (NP (DT the) (NN literature))))))))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NNS agents)) (VP (VBN trained) (PP (IN by) (NP (PRP$ our) (NNS algorithm))))) (VP (VP (VBP have) (NP (NP (JJR better) (NN adaptiveness)) (PP (IN in) (NP (VBG changing) (NNS environments))))) (CC and) (VP (VB outperform) (NP (DT the) (JJ state-of-the-art) (NNS methods)) (PP (IN in) (NP (PDT all) (DT the) (JJ tested) (NNS environments)))))))) (. .))
