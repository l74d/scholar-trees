(S (PP (IN With) (NP (NP (DT the) (NN development)) (PP (IN of) (NP (NN convolution) (JJ neural) (NN network))))) (, ,) (NP (ADJP (JJR more) (CC and) (JJR more)) (NNS researchers)) (VP (VBP focus) (NP (PRP$ their) (NN attention)) (PP (IN on) (NP (NP (DT the) (NN advantage)) (PP (IN of) (NP (NNP CNN))) (PP (IN for) (NP (NN face) (NN recognition) (NN task)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ deep) (NN convolution) (NN network)) (PP (IN for) (S (VP (VBG learning) (NP (DT a) (JJ robust) (NN face) (NN representation))))))) (. .))
(S (NP (DT The) (JJ deep) (NN convolution) (NN net)) (VP (VBZ is) (VP (VBN constructed) (PP (IN by) (NP (NP (NP (CD 4) (NN convolution) (NNS layers)) (, ,) (NP (CD 4) (NN max) (VBG pooling) (NNS layers)) (CC and) (NP (CD 2) (ADJP (RB fully) (VBN connected)) (NNS layers))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (ADVP (RB totally)) (VBZ contains) (NP (QP (IN about) (CD 4M)) (NNS parameters))))))))) (. .))
(S (NP (DT The) (NNP Max-Feature-Map) (NN activation) (NN function)) (VP (VBZ is) (VP (VBN used) (PP (RB instead) (IN of) (NP (NNP ReLU))) (SBAR (IN because) (S (NP (DT the) (NNP ReLU)) (VP (MD might) (VP (VB lead) (PP (TO to) (NP (NP (DT the) (NN loss)) (PP (IN of) (NP (NN information))) (PP (JJ due) (PP (TO to) (NP (DT the) (NN sparsity)))))) (SBAR (IN while) (S (NP (DT the) (NNP Max-Feature-Map)) (VP (MD can) (VP (VB get) (NP (DT the) (ADJP (NN compact) (CC and) (JJ discriminative)) (NN feature) (NNS vectors)))))))))))) (. .))
(S (NP (DT The) (NN model)) (VP (VBZ is) (VP (VP (VBN trained) (PP (IN on) (NP (NNP CASIA-WebFace) (NN dataset)))) (CC and) (VP (VBN evaluated) (PP (IN on) (NP (NNP LFW) (NN dataset)))))) (. .))
(S (NP (NP (DT The) (NN result)) (PP (IN on) (NP (NNP LFW)))) (VP (VBZ achieves) (NP (CD 97.77) (NN %)) (PP (IN on) (NP (NP (JJ unsupervised) (NN setting)) (PP (IN for) (NP (JJ single) (NN net)))))) (. .))
