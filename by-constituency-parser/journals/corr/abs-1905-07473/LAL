(S (NP (NP (NP (VBN Truncated) (NN backpropagation)) (PP (IN through) (NP (NN time)))) (PRN (-LRB- -LRB-) (NP (NNP TBPTT)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (DT a) (JJ popular) (NN method)) (PP (IN for) (S (VP (VBG learning) (PP (IN in) (NP (NP (JJ recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ saves) (NP (NN computation) (CC and) (NN memory)) (PP (IN at) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (NN bias))))) (PP (IN by) (S (VP (VBG truncating) (NP (NN backpropagation)) (PP (IN after) (NP (NP (DT a) (JJ fixed) (NN number)) (PP (IN of) (NP (NNS lags))))))))))))) (. .))
(S (S (PP (IN In) (NP (NN practice))) (, ,) (S (VP (VBG choosing) (NP (DT the) (JJ optimal) (NN truncation) (NN length)))) (VP (VBZ is) (ADJP (JJ difficult)))) (: :) (S (NP (NNP TBPTT)) (VP (VP (MD will) (RB not) (VP (VB converge) (SBAR (IN if) (S (NP (DT the) (NN truncation) (NN length)) (VP (VBZ is) (ADJP (RB too) (JJ small))))))) (, ,) (CC or) (VP (MD will) (VP (VB converge) (ADVP (RB slowly)) (SBAR (IN if) (S (NP (PRP it)) (VP (VBZ is) (ADJP (RB too) (JJ large))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT an) (JJ adaptive) (NNP TBPTT) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (VBZ converts) (NP (NP (DT the) (NN problem)) (PP (IN from) (S (VP (VBG choosing) (NP (DT a) (JJ temporal) (NN lag)))))) (PP (TO to) (NP (NP (CD one)) (PP (IN of) (S (VP (VBG choosing) (NP (NP (DT a) (JJ tolerable) (NN amount)) (PP (IN of) (NP (NN gradient) (NN bias)))))))))))))) (. .))
(S (S (PP (IN For) (NP (JJ many) (JJ realistic) (NNP RNNs))) (, ,) (NP (DT the) (NNP TBPTT) (NNS gradients)) (VP (VBP decay) (ADVP (RB geometrically)) (PP (IN in) (NP (NP (NN expectation)) (PP (IN for) (NP (JJ large) (NNS lags))))))) (: ;) (S (PP (IN under) (NP (DT this) (NN condition))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB control) (NP (DT the) (NN bias)) (PP (IN by) (S (VP (VBG varying) (NP (DT the) (NN truncation) (NN length)) (ADVP (RB adaptively)))))))) (. .))
(S (PP (IN For) (NP (NP (NNP RNNs)) (PP (IN with) (NP (JJ smooth) (NN activation) (NNS functions))))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (DT this) (NN bias)) (VP (VBZ controls) (NP (NP (DT the) (NN convergence) (NN rate)) (PP (IN of) (NP (NNP SGD))) (PP (IN with) (NP (NP (JJ biased) (NNS gradients)) (PP (IN for) (NP (PRP$ our) (JJ non-convex) (NN loss)))))))))) (. .))
(S (S (VP (VBG Using) (NP (DT this) (NN theory)))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (DT a) (JJ practical) (NN method)) (PP (IN for) (S (VP (ADVP (RB adaptively)) (VBG estimating) (NP (DT the) (NN truncation) (NN length)) (PP (IN during) (NP (NN training)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (PRP$ our) (JJ adaptive) (NNP TBPTT) (NN method)) (PP (IN on) (NP (JJ synthetic) (NNS data) (CC and) (NN language) (NN modeling) (NNS tasks)))) (CC and) (VP (VB find) (SBAR (IN that) (S (NP (PRP$ our) (JJ adaptive) (NNP TBPTT)) (VP (VBZ ameliorates) (NP (NP (DT the) (JJ computational) (NNS pitfalls)) (PP (IN of) (NP (JJ fixed) (NNP TBPTT))))))))) (. .))
