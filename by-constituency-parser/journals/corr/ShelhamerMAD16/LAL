(S (NP (NNP Reinforcement) (VBG learning)) (VP (JJ optimizes) (NP (NNS policies)) (PP (IN for) (NP (VBN expected) (JJ cumulative) (NN reward)))) (. .))
(SQ (VB Need) (S (NP (DT the) (NN supervision)) (VP (VB be) (ADJP (RB so) (JJ narrow)))) (. ?))
(S (NP (NNP Reward)) (VP (VBZ is) (ADJP (VBN delayed) (CC and) (JJR sparse)) (PP (IN for) (NP (JJ many) (NNS tasks))) (, ,) (S (VP (VBG making) (S (NP (PRP it)) (NP (NP (DT a) (JJ difficult) (CC and) (JJ impoverished) (NN signal)) (PP (IN for) (NP (JJ end-to-end) (NN optimization)))))))) (. .))
(S (S (VP (TO To) (VP (VB augment) (NP (NN reward))))) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (NP (JJ self-supervised) (NNS tasks)) (SBAR (WHNP (WDT that)) (S (VP (VBP incorporate) (NP (NP (NP (NNS states)) (, ,) (NP (NNS actions)) (, ,) (CC and) (NP (NNS successors))) (SBAR (S (VP (TO to) (VP (VB provide) (NP (JJ auxiliary) (NNS losses)))))))))))))) (. .))
(S (NP (DT These) (NNS losses)) (VP (VBP offer) (NP (NP (ADJP (JJ ubiquitous) (CC and) (JJ instantaneous)) (NN supervision)) (PP (IN for) (NP (NN representation) (VBG learning)))) (PP (ADVP (RB even)) (IN in) (NP (NP (DT the) (NN absence)) (PP (IN of) (NP (NN reward)))))) (. .))
(S (SBAR (IN While) (S (NP (JJ current) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG learning) (PP (IN from) (NP (NN reward))) (ADVP (NN alone)))) (VP (VBZ is) (ADJP (JJ feasible)))))))) (, ,) (NP (JJ pure) (NN reinforcement) (VBG learning) (NNS methods)) (VP (VBP are) (VP (VBN constrained) (PP (IN by) (NP (NP (JJ computational) (CC and) (JJ data) (NN efficiency) (NNS issues)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN remedied) (PP (IN by) (NP (JJ auxiliary) (NNS losses)))))))))))) (. .))
(S (NP (NP (JJ Self-supervised) (NN pre-training)) (CC and) (NP (JJ joint) (NN optimization))) (VP (VB improve) (NP (NP (DT the) (NX (NX (NN data) (NN efficiency)) (CC and) (NX (NN policy) (NNS returns)))) (PP (IN of) (NP (JJ end-to-end) (NN reinforcement) (NN learning))))) (. .))
