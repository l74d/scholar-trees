(S (ADVP (RB Nowadays)) (NP (JJ deep) (NN learning)) (VP (VBZ is) (VP (VBG dominating) (NP (NP (DT the) (NN field)) (PP (IN of) (NP (NML (NML (NML (NN machine) (NN learning)) (PP (IN with) (NP (NN state)))) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN performance)))) (PP (IN in) (NP (JJ various) (NN application) (NNS areas))))) (. .))
(S (ADVP (RB Recently)) (, ,) (NP (VBG spiking) (JJ neural) (NNS networks) (PRN (-LRB- -LRB-) (NP (NNS SNNs)) (-RRB- -RRB-))) (VP (VBP have) (VP (VBN been) (VP (VBG attracting) (NP (NP (DT a) (JJ great) (NN deal)) (PP (IN of) (NP (NN attention)))) (, ,) (S (ADVP (RB notably)) (VP (VBG owning) (PP (IN to) (NP (NP (PRP$ their) (NN power) (NN efficiency)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (ADVP (RB potentially)) (VP (VB allow) (S (NP (PRP us)) (VP (TO to) (VP (VB implement) (NP (NP (DT a) (NML (JJ low) (HYPH -) (NN power)) (NML (JJ deep) (NN learning)) (NN engine)) (NP (ADJP (JJ suitable) (PP (IN for) (NP (JJ real) (HYPH -) (NN time) (HYPH /) (NN mobile)))) (NNS applications))))))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG implementing) (NP (ADJP (NP (NNP SNN)) (HYPH -) (VBN based)) (JJ deep) (NN learning)))) (VP (VBZ remains) (NP (NP (ADJP (ADJP (JJ challenging)) (, ,) (ADJP (NP (RB especially) (NN gradient)) (HYPH -) (VBN based))) (NN training)) (PP (IN of) (NP (NP (NNS SNNs)) (PP (IN by) (NP (NN error) (NN backpropagation))))))) (. .))
(S (NP (PRP We)) (VP (MD can) (RB not) (ADVP (RB simply)) (VP (VB propagate) (NP (NNS errors)) (PP (IN through) (NP (NP (NNS SNNs)) (PP (IN in) (NP (JJ conventional) (NN way))))) (PP (IN because) (IN of) (NP (NP (DT the) (NN property)) (PP (IN of) (NP (NP (NNS SNNs)) (SBAR (WHNP (WDT that)) (S (VP (VBP process) (NP (JJ discrete) (NNS data)) (PP (IN in) (NP (NP (DT the) (NN form)) (PP (IN of) (NP (DT a) (NN series)))))))))))))) (. .))
(S (ADVP (RB Consequently)) (, ,) (NP (NP (JJS most)) (PP (IN of) (NP (DT the) (JJ previous) (NNS studies)))) (VP (VBP employ) (NP (NP (DT a) (NN workaround) (NN technique)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB first)) (VP (VP (VBZ trains) (NP (DT a) (NML (ADJP (JJ conventional) (VBN weighted)) (HYPH -) (NN sum)) (NML (JJ deep) (JJ neural)) (NN network))) (CC and) (ADVP (RB then)) (VP (VBZ maps) (NP (DT the) (NN learning) (NNS weights)) (PP (PP (IN to) (NP (NP (DT the) (NNP SNN)) (PP (IN under) (NP (NN training))))) (, ,) (RB instead) (PP (IN of) (NP (NN training) (NN SNN) (NNS parameters)))) (ADVP (RB directly)))))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (VP (VB eliminate) (NP (DT this) (NN workaround))))))) (, ,) (NP (RB recently) (VBN proposed)) (VP (VBZ is) (NP (NP (DT a) (JJ new) (NN class)) (PP (IN of) (NP (NP (NNP SNN)) (VP (VBN named) (NP (NP (NP (JJ deep) (NN spiking) (NNS networks)) (-LRB- -LRB-) (NP (NNS DSNs)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN trained) (ADVP (RB directly)) (-LRB- -LRB-) (PP (IN without) (NP (NP (DT a) (NN mapping)) (PP (IN from) (NP (JJ conventional) (JJ deep) (NNS networks))))) (-RRB- -RRB-) (PP (IN by) (NP (NN error) (NN backpropagation))) (PP (IN with) (NP (JJ stochastic) (NN gradient) (NN descent)))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN initialization)) (PP (IN of) (NP (NP (DT the) (NN membrane) (NN potential)) (PP (IN on) (NP (DT the) (JJ backward) (NN path)))))) (VP (VBZ is) (NP (NP (DT an) (JJ important) (NN step)) (PP (IN in) (NP (NN DSN) (NN training)))) (, ,) (PP (IN through) (NP (NP (JJ diverse) (NNS experiments)) (VP (VBN performed) (PP (IN under) (NP (JJ various) (NNS conditions)))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (ADJP (JJ simple) (CC and) (JJ efficient)) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB improve) (NP (NN DSN) (NN training)) (PP (IN by) (S (VP (VBG controlling) (NP (DT the) (JJ initial) (NN membrane) (NN potential)) (PP (IN on) (NP (DT the) (JJ backward) (NN path)))))))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (NNS experiments))) (, ,) (S (VP (VBG adopting) (NP (DT the) (VBN proposed) (NN approach)))) (VP (VBD allowed) (NP (PRP us)) (S (VP (TO to) (VP (VB boost) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN DSN) (NN training)))) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (VBG converging) (NN time) (CC and) (NN accuracy))))))))) (. .))
