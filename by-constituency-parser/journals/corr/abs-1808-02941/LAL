(S (NP (DT This) (NN paper)) (VP (NNS studies) (NP (NP (DT a) (NN class)) (PP (IN of) (NP (NP (JJ adaptive) (ADJP (NN gradient) (VBN based)) (NN momentum) (NN algorithms)) (SBAR (WHNP (WDT that)) (S (VP (VBP update) (NP (DT the) (NX (NX (NN search) (NNS directions)) (CC and) (NX (VBG learning) (NNS rates)))) (ADVP (RB simultaneously)) (S (VP (VBG using) (NP (JJ past) (NNS gradients))))))))))) (. .))
(S (NP (NP (DT This) (NN class)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP refer) (PP (TO to)) (PP (IN as) (NP (DT the) (`` ``) (JJ Adam-type) ('' '')))))) (, ,)) (VP (VBZ includes) (NP (NP (DT the) (JJ popular) (NN algorithms)) (PP (JJ such) (IN as) (NP (DT the) (NNP Adam) (, ,) (NNP AMSGrad) (CC and) (NNP AdaGrad))))) (. .))
(S (PP (IN Despite) (NP (NP (PRP$ their) (NN popularity)) (PP (IN in) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks))))))) (, ,) (NP (NP (DT the) (NN convergence)) (PP (IN of) (NP (DT these) (NNS algorithms))) (PP (IN for) (S (VP (VBG solving) (NP (JJ nonconvex) (NNS problems)))))) (VP (VBZ remains) (NP (DT an) (JJ open) (NN question))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ provides) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (JJ mild) (JJ sufficient) (NNS conditions)) (SBAR (WHNP (WDT that)) (S (VP (VBP guarantee) (NP (DT the) (NN convergence)) (PP (IN for) (NP (DT the) (JJ Adam-type) (NNS methods)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (S (NP (DT the) (NNS conditions)) (VP (VBP are) (ADJP (JJ essential)) (PP (IN in) (NP (DT the) (NN sense) (SBAR (IN that) (S (S (VP (VBG violating) (NP (PRP them)))) (VP (MD may) (VP (VB make) (S (NP (DT the) (NN algorithm)) (VP (NN diverge))))))))))))) (. .))
(S (NP (PRP$ Our) (NN study)) (VP (MD could) (ADVP (RB also)) (VP (VB be) (VP (VBN extended) (PP (TO to) (NP (NP (DT a) (JJR broader) (NN class)) (PP (IN of) (NP (NP (JJ adaptive) (NN gradient) (NNS methods)) (PP (IN in) (NP (NP (NN machine) (NN learning)) (CC and) (NP (NN optimization))))))))))) (. .))
