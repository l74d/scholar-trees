(S (NP (NP (DT The) (NN process)) (PP (IN of) (NP (JJ neural) (NN network) (VBG pruning))) (PP (IN with) (NP (JJ suitable) (JJ fine-tuning) (CC and) (VBG retraining)))) (VP (MD can) (VP (VB yield) (NP (NP (NNS networks)) (PP (IN with) (NP (NP (ADJP (RB considerably) (JJR fewer)) (NNS parameters)) (PP (IN than) (NP (DT the) (JJ original))))) (PP (IN with) (NP (NP (JJ comparable) (NNS degrees)) (PP (IN of) (NP (NN accuracy)))))))) (. .))
(S (ADVP (RB Typically)) (, ,) (NP (VBG pruning) (NNS methods)) (VP (VBP require) (NP (JJ large) (, ,) (JJ pre-trained) (NNS networks)) (PP (IN as) (NP (NP (DT a) (VBG starting) (NN point)) (SBAR (WHPP (IN from) (WHNP (WDT which))) (S (NP (PRP they)) (VP (VBP perform) (NP (DT a) (JJ time-intensive) (JJ iterative) (NN pruning) (CC and) (VBG retraining) (NN algorithm)))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (VBG pruning) (JJ in-training) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ prunes) (NP (DT a) (NN network)) (ADVP (NN real-time)) (PP (IN during) (NP (NN training))) (, ,) (S (VP (VBG reducing) (NP (DT the) (JJ overall) (NN training) (NN time)) (S (VP (TO to) (VP (VB achieve) (NP (DT an) (NN optimal) (VBD compressed) (NN network)))))))))))) (. .))
(S (S (VP (TO To) (VP (VB do) (ADVP (RB so))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT an) (ADJP (NN activation) (NN density) (VBN based)) (NN analysis)) (SBAR (WHNP (WDT that)) (S (VP (VBZ identifies) (NP (NP (DT the) (JJ optimal) (JJ relative) (NN sizing) (CC or) (NN compression)) (PP (IN for) (NP (NP (DT each) (NN layer)) (PP (IN of) (NP (DT the) (NN network))))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VP (VBZ removes) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NN pre-training))))) (CC and) (VP (VBZ is) (ADJP (JJ architecture) (JJ agnostic))) (, ,) (S (VP (VBG allowing) (S (NP (PRP it)) (VP (TO to) (VP (VB be) (VP (VBN employed) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN variety)) (PP (IN of) (NP (NNS systems)))))))))))) (. .))
(S (PP (IN For) (NP (NP (NNP VGG-19) (CC and) (NNP ResNet18)) (PP (IN on) (NP (NP (NNP CIFAR-10)) (, ,) (NP (NNP CIFAR-100)) (, ,) (CC and) (NP (NNP TinyImageNet)))))) (, ,) (NP (PRP we)) (VP (VB obtain) (NP (NP (ADJP (RB exceedingly) (JJ sparse)) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NP (NP (QP (IN up) (TO to) (CD 200x)) (NN reduction)) (PP (IN in) (NP (NNS parameters)))) (CC and) (NP (NP (QP ($ >) (CD 60x)) (NN reduction)) (PP (IN in) (NP (NN inference) (NN compute) (NNS operations))) (PP (IN in) (NP (DT the) (JJS best) (NN case))))) (-RRB- -RRB-)) (PP (IN with) (NP (NP (JJ comparable) (NNS accuracies)) (PRN (-LRB- -LRB-) (NP (NP (ADJP (QP (IN up) (TO to) (CD 2) (NN %) (CD -3) (NN %))) (NN loss)) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (DT the) (NN baseline) (NN network)))))) (-RRB- -RRB-)))))) (. .))
(S (PP (IN By) (S (VP (VBG reducing) (NP (DT the) (NN network) (NN size)) (ADVP (RB periodically)) (PP (IN during) (NP (NN training)))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (JJ total) (NN training) (NNS times)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (ADJP (JJR shorter)) (PP (IN than) (NP (NP (DT those)) (PP (IN of) (NP (ADJP (RB previously) (VBN proposed)) (NN pruning) (NNS methods))))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (S (VP (VBG training) (NP (VBN compressed) (NNS networks)) (PP (IN at) (NP (JJ different) (NN epochs))) (PP (IN with) (NP (PRP$ our) (VBN proposed) (NN method))))) (VP (NNS yields) (ADVP (ADJP (NP (JJ considerable) (NN reduction)) (PP (IN in) (NP (VBG training) (JJ compute) (NN complexity))) (PRN (-LRB- -LRB-) (ADJP (NP (CD 1.6x) (NNP -3.2x)) (JJR lower)) (-RRB- -RRB-)) (PP (IN at) (NP (JJ near) (NN iso-accuracy))))) (PP (IN as) (PP (VBN compared) (PP (TO to) (NP (NP (DT a) (NN baseline) (NN network)) (VP (VBD trained) (PP (ADVP (RB entirely)) (IN from) (NP (NN scratch))))))))) (. .))
