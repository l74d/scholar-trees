(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ practical) (NN method)) (PP (IN for) (NP (NP ($ $) (CD L_0)) (FRAG (FRAG (NP ($ $)) (NP (NN norm) (NN regularization)) (PP (IN for) (NP (JJ neural) (NNS networks)))) (: :) (NP (NP (NN pruning)) (NP (DT the) (NN network))))))) (PP (IN during) (NP (NN training))) (PP (IN by) (S (VP (VBG encouraging) (NP (NNS weights)) (S (VP (TO to) (VP (VB become) (NP (RB exactly) (CD zero))))))))) (. .))
(S (S (NP (JJ Such) (NN regularization)) (VP (VBZ is) (ADJP (JJ interesting) (PP (IN since) (NP (NP (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (SBAR (S (NP (PRP it)) (VP (MD can) (ADVP (RB greatly)) (VP (VB speed) (PRT (RP up)) (NP (NN training) (CC and) (NN inference))))))))))) (, ,) (CC and) (S (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (NP (PRP it)) (VP (MD can) (VP (VB improve) (NP (NN generalization))))) (. .))
(S (NP (NP (NN AIC) (CC and) (NN BIC)) (, ,) (NP (ADJP (RB well) (HYPH -) (VBN known)) (NML (NN model) (NN selection)) (NNS criteria)) (, ,)) (VP (VBP are) (NP (NP (JJ special) (NNS cases)) (PP (IN of) (NP (NP ($ $) (CD L_0)) (NP ($ $) (CD regularization)))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (IN since) (S (NP (NP (DT the) (NML (FRAG (NP ($ $) (CD L_0)) (NP ($ $)))) (NN norm)) (PP (IN of) (NP (NNS weights)))) (VP (VBZ is) (ADJP (JJ non-differentiable))))) (, ,) (NP (PRP we)) (VP (MD can) (RB not) (VP (VB incorporate) (NP (PRP it)) (ADVP (RB directly)) (PP (IN as) (NP (NP (DT a) (NN regularization) (NN term)) (PP (IN in) (NP (DT the) (JJ objective) (NN function))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (NN solution)) (PP (IN through) (NP (NP (NP (DT the) (NN inclusion)) (PP (IN of) (NP (NP (DT a) (NN collection)) (PP (IN of) (NP (JJ non-negative) (JJ stochastic) (NNS gates)))))) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB collectively)) (VP (VBP determine) (SBAR (WHNP (WDT which) (NNS weights)) (S (VP (TO to) (VP (VB set) (PP (IN to) (NP (CD zero))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (, ,) (ADVP (ADVP (RB somewhat) (RB surprisingly)) (, ,) (PP (IN for) (NP (NP (JJ certain) (NNS distributions)) (PP (IN over) (NP (DT the) (NNS gates)))))) (, ,) (NP (NP (DT the) (VBN expected) (NML (FRAG (NP ($ $) (CD L_0)) (NP ($ $)))) (NN norm)) (PP (IN of) (NP (NP (DT the)) (VP (VBG resulting) (NP (VBN gated) (NNS weights)))))) (VP (VBZ is) (ADJP (JJ differentiable) (PP (IN with) (NP (NN respect)))) (PP (IN to) (NP (DT the) (NN distribution) (NNS parameters))))))) (. .))
(S (NP (NP (DT The) (NNS parameters)) (PP (IN of) (NP (NP (DT the) (NN distribution)) (PP (IN over) (NP (DT the) (NNS gates)))))) (VP (MD can) (ADVP (RB then)) (VP (VB be) (ADVP (RB jointly)) (VP (VBN optimized) (PP (IN with) (NP (DT the) (JJ original) (NN network) (NNS parameters)))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (NP (PRP$ our) (NN method)) (VP (VP (VBZ allows) (PP (IN for) (NP (NP (ADJP (JJ straightforward) (CC and) (JJ efficient)) (NN learning)) (PP (IN of) (NP (NN model) (NNS structures))))) (PP (IN with) (NP (JJ stochastic) (NN gradient) (NN descent)))) (CC and) (VP (VBZ allows) (PP (IN for) (NP (NP (JJ conditional) (NN computation)) (PP (IN in) (NP (DT a) (JJ principled) (NN way))))))) (. .))
(S (NP (PRP We)) (VP (VBP perform) (NP (JJ various) (NNS experiments)) (S (VP (TO to) (VP (VB demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NP (DT the) (VBG resulting) (NN approach)) (CC and) (NP (NN regularizer))))))))) (. .))
