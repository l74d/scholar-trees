(S (NP (NNP Reinforcement) (NN learning)) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (ADJP (RBS most) (JJ popular)) (NNS approaches)) (PP (IN for) (NP (JJ automated) (NN game) (NN playing))))))) (. .))
(S (NP (DT This) (NN method)) (VP (VBZ allows) (S (NP (DT an) (NN agent)) (VP (TO to) (VP (VB estimate) (NP (NP (DT the) (JJ expected) (NN utility)) (PP (IN of) (NP (PRP$ its) (NN state)))) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB make) (NP (JJ optimal) (NNS actions)) (PP (IN in) (NP (DT an) (JJ unknown) (NN environment))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP seek) (S (VP (TO to) (VP (VB apply) (NP (JJ reinforcement) (VBG learning) (NN algorithms)) (PP (TO to) (NP (NP (DT the) (NN game)) (NP (NNP Flappy) (NNP Bird)))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NNP SARSA) (CC and) (NNP Q-Learning)) (VP (VBP outperform) (NP (DT the) (NN baseline)) (, ,) (S (VP (ADVP (RB regularly)) (VBG achieving) (NP (NP (NNS scores)) (PP (IN of) (NP (CD 1400+)))))) (, ,) (PP (IN with) (NP (NP (DT the) (JJS highest) (JJ in-game) (NN score)) (PP (IN of) (NP (CD 2069))))))))) (. .))
