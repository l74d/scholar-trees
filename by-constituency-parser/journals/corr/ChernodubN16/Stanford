(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN activation) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (VBZ implements) (NP (JJ piece-wise) (JJ orthogonal) (JJ non-linear) (NNS mappings)) (PP (VBN based) (PP (IN on) (NP (NNS permutations))))))))) (. .))
(S (S (NP (PRP It)) (VP (VBZ is) (ADJP (ADJP (JJ straightforward) (S (VP (TO to) (VP (VB implement))))) (, ,) (CC and) (ADJP (RB very) (ADVP (RB computationally)) (JJ efficient))))) (, ,) (S (ADVP (RB also)) (NP (PRP it)) (VP (VBZ has) (NP (JJ little) (NN memory) (NNS requirements)))) (. .))
(S (S (NP (PRP We)) (VP (VBD tested) (NP (PRP it)) (PP (IN on) (NP (NP (CD two) (NN toy) (NNS problems)) (PP (IN for) (NP (UCP (NP (NN feedforward)) (CC and) (ADJP (JJ recurrent))) (NNS networks))))))) (, ,) (NP (PRP it)) (VP (VBZ shows) (NP (JJ similar) (NN performance)) (PP (IN to) (NP (NN tanh) (CC and) (NN ReLU)))) (. .))
(S (S (NP (NN OPLU) (NN activation) (NN function)) (VP (VBZ ensures) (NP (NP (NN norm) (NN preservance)) (PP (IN of) (NP (DT the) (JJ backpropagated) (NNS gradients)))))) (, ,) (S (ADVP (RB therefore)) (NP (PRP it)) (VP (VBZ is) (ADJP (RB potentially) (JJ good) (PP (IN for) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ deep) (, ,) (JJ extra) (ADJP (JJ deep) (, ,) (CC and) (JJ recurrent)) (JJ neural) (NNS networks)))))))) (. .))
