(S (NP (ADJP (NN State) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (JJ deep) (NML (NN model) (NN compression)) (NNS methods)) (VP (VBP exploit) (NP (NP (DT the) (NML (JJ low) (HYPH -) (NN rank)) (NN approximation)) (CC and) (NP (NN sparsity) (NN pruning))) (S (VP (TO to) (VP (VB remove) (NP (JJ redundant) (NNS parameters)) (PP (IN from) (NP (NP (DT a)) (VP (VBN learned) (NP (JJ hidden) (NN layer))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP they)) (VP (VP (VBP process) (NP (DT each) (JJ hidden) (NN layer)) (ADVP (RB individually)) (SBAR (IN while) (S (VP (VBG neglecting) (NP (DT the) (JJ common) (NNS components)) (PP (IN across) (NP (NNS layers))))))) (, ,) (CC and) (ADVP (RB thus)) (VP (VBP are) (RB not) (ADJP (JJ able) (S (VP (TO to) (ADVP (RB fully)) (VP (VB exploit) (NP (DT the) (JJ potential) (NN redundancy) (NN space)) (PP (IN for) (NP (NN compression))))))))) (. .))
(S (S (VP (TO To) (VP (VP (VB solve) (NP (DT the) (JJ above) (NN problem))) (CC and) (VP (VB enable) (NP (NP (JJ further) (NN compression)) (PP (IN of) (NP (DT a) (NN model)))) (, ,) (S (VP (VP (VBG removing) (NP (DT the) (JJ cross-layer) (NN redundancy))) (CC and) (VP (VBG mining) (NP (DT the) (JJ layer-wise) (NN inheritance) (NN knowledge))))))))) (VP (VBZ is) (ADJP (JJ necessary))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP introduce) (S (NP (NP (DT a) (JJ holistic) (NML (NN model) (NN compression)) (NN framework)) (, ,) (VP (ADVP (RB namely)) (VBG MIning) (NP (ADJP (NP (NN Cross-layer)) (JJ Inherent)) (NN similarity) (NN Knowledge) (PRN (-LRB- -LRB-) (NP (NN MICIK)) (-RRB- -RRB-)))) (, ,)) (VP (TO to) (ADVP (RB fully)) (VP (VB excavate) (NP (DT the) (JJ potential) (NN redundancy) (NN space)))))) (. .))
(S (NP (NP (NP (DT The) (VBN proposed) (NN MICIK) (NN framework)) (ADVP (RB simultaneously))) (, ,) (NP (LST (-LRB- -LRB-) (LS 1) (-RRB- -RRB-)) (NP (NP (NML (S (VP (VBZ learns) (NP (DT the) (ADJP (JJ common) (CC and) (JJ unique)) (NN weight))))) (NNS components)) (PP (IN across) (NP (JJ deep) (NML (JJ neural) (NN network)) (NNS layers)))) (S (VP (TO to) (VP (VB increase) (NP (NN compression) (NN rate)))))) (: ;)) (VP (VP (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (VBZ preserves) (NP (NP (DT the) (JJ inherent) (NN similarity) (NN knowledge)) (PP (IN of) (NP (NP (JJ nearby) (NNS layers)) (CC and) (NP (JJ distant) (NNS layers)))) (S (VP (TO to) (VP (VB minimize) (NP (DT the) (NN accuracy) (NN loss))))))) (CC and) (FRAG (SBAR (LST (-LRB- -LRB-) (LS 3) (-RRB- -RRB-)) (S (VP (MD can) (VP (VB be) (ADJP (JJ complementary) (PP (IN to) (NP (NP (JJ other) (VBG existing) (NN compression) (NNS techniques)) (PP (JJ such) (IN as) (NP (NN knowledge)))))))) (NP (NN distillation)))))) (. .))
(SINV (S (NP (NP (JJ Extensive) (NNS experiments)) (PP (IN on) (NP (NML (JJ large) (HYPH -) (NN scale)) (JJ convolutional) (JJ neural) (NNS networks)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NNP MICIK)) (VP (VBZ is) (ADJP (JJ superior) (PP (IN over) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN model) (NN compression))))))))) (VP (VBZ approaches) (PP (PP (IN with) (NP (NP (NN 16X) (NN parameter) (NN reduction)) (PP (IN on) (NP (NN VGG) (HYPH -) (CD 16))))) (CC and) (PP (NP (CD 6X)) (IN on)))) (NP (NP (NNP GoogLeNet)) (, ,) (NP (NP (DT all)) (PP (IN without) (NP (NN accuracy) (NN loss))))) (. .))
