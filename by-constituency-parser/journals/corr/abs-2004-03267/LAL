(S (NP (JJ Reinforcement-based) (NN training) (NNS methods)) (VP (VBP have) (VP (VBN emerged) (PP (IN as) (NP (NP (DT the) (ADJP (RBS most) (JJ popular)) (NN choice)) (SBAR (S (VP (TO to) (VP (VB train) (NP (DT an) (ADJP (NN efficient) (CC and) (JJ effective)) (NN dialog) (NN policy)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT these) (NNS methods)) (VP (VBP are) (VP (VBG suffering) (PP (IN from) (NP (NP (ADJP (NN sparse) (CC and) (JJ unstable)) (NN reward) (NNS signals)) (VP (ADVP (RB usually)) (VBN returned) (PP (IN from) (NP (DT the) (NN user) (NN simulator))) (PP (IN at) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (DT the) (NN dialog)))))))))) (. .))
(S (ADVP (IN Besides)) (, ,) (NP (DT the) (JJ reward) (NN signal)) (VP (VBZ is) (VP (ADVP (RB manually)) (VBN designed) (PP (IN by) (NP (NN human) (NNS experts))) (SBAR (WHNP (WDT which)) (S (VP (VBZ requires) (NP (NN domain) (NN knowledge))))))) (. .))
(S (NP (NP (DT A) (NN number)) (PP (IN of) (NP (JJ adversarial) (VBG learning) (NNS methods)))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (S (VP (TO to) (VP (VB learn) (NP (DT the) (NN reward) (NN function)) (ADVP (RB together) (PP (IN with) (NP (DT the) (NN dialog) (NN policy)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (TO to) (ADVP (RB alternatively)) (VP (VB update) (NP (NP (DT the) (NN dialog) (NN policy)) (CC and) (NP (DT the) (NN reward) (NN model))) (PP (IN on) (NP (DT the) (NN fly)))))) (, ,) (NP (NP (DT the) (NN algorithms)) (SBAR (S (VP (TO to) (VP (VB update) (NP (DT the) (NN dialog) (NN policy))))))) (VP (VBP are) (VP (VBN limited) (PP (TO to) (NP (NP (NN policy) (JJ gradient-based) (NN algorithms)) (, ,) (PP (JJ such) (IN as) (NP (NNP REINFORCE) (CC and) (NNP PPO))))))) (. .))
(S (ADVP (IN Besides)) (, ,) (NP (NP (DT the) (JJ alternative) (NN training)) (PP (IN of) (NP (NP (DT the) (NN dialog) (NN agent)) (CC and) (NP (DT the) (NN reward) (NN model))))) (VP (MD can) (VP (VP (ADVP (RB easily)) (VB get) (ADJP (VBN stuck) (PP (IN in) (NP (JJ local) (NN optimum))))) (CC or) (VP (NN result) (PP (IN in) (NP (NN mode) (NN collapse)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB decompose) (NP (DT the) (JJ previous) (JJ adversarial) (NN training)) (PP (IN into) (NP (CD two) (JJ different) (NNS steps))))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (RB first)) (VBP train) (NP (DT the) (NN discriminator)) (PP (IN with) (NP (DT an) (JJ auxiliary) (NN dialog) (NN generator)))) (CC and) (ADVP (RB then)) (VP (VB incorporate) (NP (DT this) (JJ trained) (NN reward) (NN model)) (PP (TO to) (NP (DT a) (JJ common) (NN reinforcement) (VBG learning) (NN method))) (S (VP (TO to) (VP (VB train) (NP (DT a) (NN high-quality) (NN dialog) (NN agent))))))) (. .))
(S (NP (DT This) (NN approach)) (VP (VBZ is) (ADJP (JJ applicable) (PP (TO to) (NP (ADJP (DT both) (JJ on-policy) (CC and) (JJ off-policy)) (NN reinforcement) (VBG learning) (NNS methods))))) (. .))
(S (PP (IN By) (S (VP (VBG conducting) (NP (JJ several) (NNS experiments))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (S (NP (DT the) (VBN proposed) (NNS methods)) (VP (MD can) (VP (VB achieve) (NP (NP (JJ remarkable) (NN task) (NN success)) (CC and) (NP (PRP$ its) (JJ potential) (S (VP (TO to) (VP (VB transfer) (NP (NN knowledge)) (PP (IN from) (NP (VBG existing) (NNS domains))) (PP (TO to) (NP (DT a) (JJ new) (NN domain))))))))))))) (. .))
