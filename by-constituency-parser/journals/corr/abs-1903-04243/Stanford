(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (NN static) (NN loop) (NN vectorization) (NN optimization)) (PP (IN on) (NP (NP (NN top)) (PP (IN of) (NP (NP (NML (JJ high) (NN level)) (NN dataflow) (NN IR)) (VP (VBN used) (PP (IN by) (NP (NP (NNS frameworks)) (PP (IN like) (NP (NNP TensorFlow)))))))))))) (. .))
(S (NP (NP (DT A) (JJ new)) (VP (ADVP (RB statically)) (VBN vectorized) (NP (NP (JJ parallel)) (HYPH -) (PP (IN for) (NP (NN abstraction)))))) (VP (VBZ is) (VP (VP (VBN provided) (PP (IN on) (NP (NP (NN top)) (PP (IN of) (NP (NNP TensorFlow)))))) (, ,) (CC and) (VP (VBN used) (PP (IN for) (NP (NP (NNS applications)) (VP (VBG ranging) (PP (IN from) (NP (NML (NML (NN auto) (HYPH -) (NN batching)) (CC and) (NML (PP (IN per) (HYPH -) (NP (NN example))))) (NNS gradients))) (, ,) (PP (IN to) (NP (NP (JJ jacobian) (NN computation)) (, ,) (NP (VBN optimized) (NN map) (NNS functions)) (CC and) (NP (NN input) (NN pipeline) (NN optimization)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP report) (NP (JJ huge) (NNS speedups)) (PP (VBN compared) (PP (IN to) (NP (NP (ADJP (NP (DT both) (NN loop)) (VBN based)) (NNS implementations)) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NP (NML (NN run) (HYPH -) (NN time)) (NN batching)) (VP (VBN adopted) (PP (IN by) (NP (DT the) (NNP DyNet) (NN framework))))))))) (. .))
