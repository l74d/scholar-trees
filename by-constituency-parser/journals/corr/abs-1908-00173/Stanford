(S (S (NP (NN Sparsification)) (VP (VBZ is) (NP (DT an) (JJ efficient) (NN approach) (S (VP (TO to) (VP (VB accelerate) (NP (NNP CNN) (NN inference)))))))) (, ,) (CC but) (S (NP (PRP it)) (VP (VBZ is) (VP (VBG challenging) (S (VP (TO to) (VP (VB take) (NP (NP (NN advantage)) (PP (IN of) (NP (NN sparsity)))) (PP (IN in) (NP (NN training) (NN procedure))) (SBAR (IN because) (S (NP (DT the) (JJ involved) (NNS gradients)) (VP (VBP are) (ADVP (RB dynamically)) (VP (VBN changed))))))))))) (. .))
(S (ADVP (RB Actually)) (, ,) (NP (DT an) (JJ important) (NN observation)) (VP (VBZ shows) (SBAR (IN that) (S (NP (NP (JJS most)) (PP (IN of) (NP (NP (DT the) (NN activation) (NNS gradients)) (PP (IN in) (NP (NP (RB back) (HYPH -) (NN propagation)) (SBAR (S (VP (VBP are) (ADJP (RB very) (JJ close)) (PP (IN to) (NP (QP (CD zero) (CC and) (RB only)))))))))))) (VP (VBP have) (NP (NP (DT a) (JJ tiny) (NN impact)) (PP (IN on) (NP (NN weight) (HYPH -) (NN updating)))))))) (. .))
(S (ADVP (RB Hence)) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (NN pruning)) (NP (NP (DT these) (ADJP (RB very) (JJ small)) (NNS gradients)) (ADVP (RB randomly)) (S (VP (TO to) (VP (VB accelerate) (NP (NNP CNN) (NN training)) (PP (VBG according) (PP (IN to) (NP (NP (DT the) (JJ statistical) (NN distribution)) (PP (IN of) (NP (NN activation) (NNS gradients))))))))))) (. .))
(S (ADVP (RB Meanwhile)) (, ,) (NP (PRP we)) (ADVP (RB theoretically)) (VP (VB analyze) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (NN pruning) (NN algorithm)))) (PP (IN on) (NP (DT the) (NN convergence)))) (. .))
