(S (S (NP (NN Sparsification)) (VP (VBZ is) (NP (NP (DT an) (JJ efficient) (NN approach)) (SBAR (S (VP (TO to) (VP (VB accelerate) (NP (NNP CNN) (NN inference))))))))) (, ,) (CC but) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (VBG challenging)) (S (VP (TO to) (VP (VB take) (NP (NN advantage)) (PP (IN of) (NP (NN sparsity))) (PP (IN in) (NP (NN training) (NN procedure)))))) (SBAR (IN because) (S (NP (DT the) (JJ involved) (NNS gradients)) (VP (VBP are) (VP (ADVP (RB dynamically)) (VBN changed))))))) (. .))
(S (ADVP (RB Actually)) (, ,) (NP (DT an) (JJ important) (NN observation)) (VP (NNS shows) (SBAR (IN that) (S (NP (NP (JJS most)) (PP (IN of) (NP (NP (DT the) (NN activation) (NNS gradients)) (PP (IN in) (NP (NN back-propagation)))))) (VP (VP (VBP are) (ADJP (RB very) (RB close) (PP (TO to) (NP (CD zero))))) (CC and) (VP (ADVP (RB only)) (VB have) (NP (NP (DT a) (JJ tiny) (NN impact)) (PP (IN on) (NP (NN weight-updating))))))))) (. .))
(S (ADVP (RB Hence)) (, ,) (NP (PRP we)) (VP (VBP consider) (S (VP (VBG pruning) (NP (DT these) (ADJP (RB very) (JJ small)) (NNS gradients)) (ADVP (RB randomly)) (S (VP (TO to) (VP (VB accelerate) (NP (NNP CNN) (VBG training)) (PP (VBG according) (PP (TO to) (NP (NP (DT the) (JJ statistical) (NN distribution)) (PP (IN of) (NP (NN activation) (NNS gradients)))))))))))) (. .))
(S (ADVP (RB Meanwhile)) (, ,) (NP (PRP we)) (VP (ADVP (RB theoretically)) (VBP analyze) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (VBG pruning) (NN algorithm))) (PP (IN on) (NP (DT the) (NN convergence))))) (. .))
