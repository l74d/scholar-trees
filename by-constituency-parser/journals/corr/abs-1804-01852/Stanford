(S (NP (PRP We)) (VP (VBP address) (SBAR (S (NP (NP (DT the) (NN issue)) (PP (IN of) (S (VP (VBG speeding) (PRT (RP up)) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ convolutional) (JJ neural) (NNS networks)))) (PP (IN by) (S (VP (VBG studying) (NP (DT a) (VBN distributed) (NN method))))))))) (VP (VBD adapted) (PP (IN to) (NP (JJ stochastic) (NN gradient) (NN descent))))))) (. .))
(S (NP (PRP$ Our) (JJ parallel) (NN optimization) (NN setup)) (VP (VBZ uses) (NP (NP (JJ several) (NNS threads)) (, ,) (NP (NP (DT each)) (VP (VBG applying) (NP (JJ individual) (NN gradient) (NNS descents)) (PP (IN on) (NP (DT a) (JJ local) (NN variable))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN way)) (PP (IN of) (S (VP (VBG sharing) (NP (NP (NN information)) (PP (IN between) (NP (JJ different) (NNS threads)))) (PP (VBN based) (PP (IN on) (NP (NP (NN gossip) (NNS algorithms)) (SBAR (WHNP (WDT that)) (S (VP (VBP show) (NP (JJ good) (NN consensus) (NN convergence) (NNS properties))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NN method)) (VP (VBN called) (NP (NNP GoSGD)))) (VP (VBZ has) (NP (DT the) (NN advantage) (S (VP (TO to) (VP (VB be) (ADJP (RB fully) (JJ asynchronous) (CC and) (JJ decentralized))))))) (. .))
