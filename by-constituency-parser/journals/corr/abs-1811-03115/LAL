(S (NP (JJ Deep) (JJ autoregressive) (NN sequence-to-sequence) (NNS models)) (VP (VBP have) (VP (VBN demonstrated) (NP (JJ impressive) (NN performance)) (PP (IN across) (NP (NP (DT a) (JJ wide) (NN variety)) (PP (IN of) (NP (NNS tasks))))) (PP (IN in) (NP (JJ recent) (NNS years))))) (. .))
(S (SBAR (IN While) (S (NP (NP (JJ common) (NN architecture) (NNS classes)) (PP (JJ such) (IN as) (NP (NN recurrent) (, ,) (JJ convolutional) (, ,) (CC and) (NN self-attention) (NNS networks)))) (VP (VBP make) (NP (NP (JJ different) (NNS trade-offs)) (PP (IN between) (NP (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NN computation))) (VP (VBN needed) (PP (IN per) (NP (NN layer))))) (CC and) (NP (NP (DT the) (NN length)) (PP (IN of) (NP (DT the) (JJ critical) (NN path))) (PP (IN at) (NP (NN training) (NN time)))))))))) (, ,) (NP (NN generation)) (ADVP (RB still)) (VP (VBZ remains) (NP (DT an) (ADJP (RB inherently) (JJ sequential)) (NN process))) (. .))
(S (S (VP (TO To) (VP (VB overcome) (NP (DT this) (NN limitation))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN blockwise) (NN parallel) (VBG decoding) (NN scheme)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBP make) (NP (NNS predictions)) (PP (IN for) (NP (NP (JJ multiple) (NN time) (NNS steps)) (PP (IN in) (NP (NN parallel))))) (RB then) (ADVP (ADVP (RB back) (IN off)) (PP (TO to) (NP (NP (DT the) (JJS longest) (NN prefix)) (VP (VBN validated) (PP (IN by) (NP (DT a) (JJ scoring) (NN model)))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ allows) (PP (IN for) (NP (NP (JJ substantial) (JJ theoretical) (NNS improvements)) (PP (IN in) (NP (NN generation) (NN speed))))) (SBAR (WHADVP (WRB when)) (S (VP (VBN applied) (PP (TO to) (NP (NP (NNS architectures)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB process) (NP (NN output) (NNS sequences)) (PP (IN in) (NP (NN parallel))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP verify) (NP (PRP$ our) (NN approach)) (ADVP (RB empirically)) (PP (IN through) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (NP (NNS experiments)) (VP (VBG using) (NP (NP (JJ state-of-the-art) (NN self-attention) (NNS models)) (PP (IN for) (NP (NP (NN machine) (NN translation)) (CC and) (NP (NN image) (NN super-resolution)))))))))) (, ,) (S (VP (VBG achieving) (NP (NP (NN iteration) (NNS reductions)) (PP (IN of) (NP (QP (IN up) (TO to) (CD 2x)))) (PP (IN over) (NP (DT a) (JJ baseline) (NN greedy) (NN decoder))) (PP (IN with) (NP (NP (DT no) (NN loss)) (PP (IN in) (NP (NN quality))))) (, ,) (CC or) (VP (NP (QP (RB up) (TO to) (CD 7x))) (PP (IN in) (NP (NP (NN exchange)) (PP (IN for) (NP (NP (DT a) (JJ slight) (NN decrease)) (PP (IN in) (NP (NN performance)))))))))))) (. .))
(S (PP (IN In) (NP (NP (NNS terms)) (PP (IN of) (NP (NN wall-clock) (NN time))))) (, ,) (NP (PRP$ our) (JJS fastest) (NNS models)) (VP (VBP exhibit) (NP (NP (JJ real-time) (NNS speedups)) (PP (IN of) (NP (QP (IN up) (TO to) (CD 4x)))) (PP (IN over) (NP (JJ standard) (NN greedy) (NN decoding))))) (. .))
