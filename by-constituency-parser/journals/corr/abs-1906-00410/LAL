(S (NP (NP (NNP Domain) (NN randomization)) (PRN (-LRB- -LRB-) (NP (NNP DR)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (DT a) (JJ successful) (NN technique)) (PP (IN for) (S (VP (VBG learning) (NP (NP (JJ robust) (NNS policies)) (PP (IN for) (NP (JJ robot) (NNS systems)))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (DT the) (NN target) (NN robot) (NN system)))) (VP (VBP are) (ADJP (JJ unknown)))))))))) (. .))
(S (NP (NP (DT The) (NN success)) (PP (IN of) (NP (NP (NNS policies)) (VP (VBN trained) (PP (IN with) (NP (NN domain) (NN randomization))))))) (ADVP (RB however)) (, ,) (VP (VBZ is) (ADJP (RB highly) (JJ dependent) (PP (IN on) (NP (NP (DT the) (JJ correct) (NN selection)) (PP (IN of) (NP (DT the) (NN randomization) (NN distribution))))))) (. .))
(S (NP (NP (DT The) (NN majority)) (PP (IN of) (NP (NN success) (NNS stories)))) (ADVP (RB typically)) (VP (VBP use) (NP (ADJP (JJ real) (NN world)) (NNS data)) (SBAR (SBAR (IN in) (NN order) (S (VP (TO to) (VP (ADVP (RB carefully)) (VB select) (NP (DT the) (NNP DR) (NN distribution)))))) (, ,) (CC or) (VP (VB incorporate) (NP (ADJP (JJ real) (NN world)) (NNS trajectories)) (S (VP (TO to) (VP (ADVP (VB better)) (NN estimate) (NP (JJ appropriate) (NN randomization) (NNS distributions)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (VBG finding) (NP (NP (JJ good) (NN domain) (NN randomization) (NNS parameters)) (PP (IN for) (NP (NN simulation)))) (, ,) (PP (IN without) (NP (NP (JJ prior) (NN access)) (PP (TO to) (NP (NP (NNS data)) (PP (IN from) (NP (DT the) (NN target) (NN system)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP explore) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ gradient-based) (NN search) (NNS methods))) (S (VP (TO to) (VP (VB learn) (NP (DT a) (NN domain) (NN randomization)))))) (PP (IN with) (NP (NP (DT the) (VBG following) (NNS properties)) (: :) (S (SBAR (LST (CD 1) (-RRB- -RRB-)) (NP (DT The) (JJ trained) (NN policy)) (VP (MD should) (VP (VB be) (ADJP (JJ successful)) (PP (IN in) (NP (NP (NNS environments)) (VP (VBN sampled) (PP (IN from) (NP (DT the) (NN domain) (NN randomization) (NN distribution))))))))) (PRN (CD 2) (-RRB- -RRB-)) (S (NP (DT The) (NN domain) (NN randomization) (NN distribution)) (VP (MD should) (VP (VB be) (ADJP (JJ wide) (RB enough) (SBAR (IN so) (IN that) (S (NP (NP (DT the) (NN experience)) (ADJP (JJ similar) (PP (TO to) (NP (DT the) (NN target) (NN robot) (NN system))))) (VP (VBZ is) (VP (VBN observed) (PP (IN during) (NP (NN training)))))))) (, ,) (SBAR (IN while) (S (VP (VBG addressing) (NP (NP (DT the) (NN practicality)) (PP (IN of) (S (VP (VBG training) (NP (JJ finite) (NN capacity) (NNS models)))))))))))))))) (. .))
(S (NP (DT These) (CD two) (NNS properties)) (VP (VBP aim) (S (VP (TO to) (VP (VB ensure) (SBAR (S (NP (NP (DT the) (NNS trajectories)) (VP (VBN encountered) (PP (IN in) (NP (DT the) (NN target) (NN system))))) (VP (VBP are) (ADJP (JJ close) (PP (TO to) (NP (NP (DT those)) (VP (VBN observed) (PP (IN during) (NP (NN training)))))))))) (, ,) (SBAR (IN as) (S (NP (NP (VBG existing) (NNS methods)) (PP (IN in) (NP (NN machine) (NN learning)))) (VP (VBP are) (ADJP (RB better) (VBN suited) (PP (IN for) (NP (NN interpolation))) (PP (IN than) (NP (NN extrapolation))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (S (VP (VBG adapting) (NP (DT the) (NN domain) (NN randomization) (NN distribution)) (SBAR (IN while) (S (VP (VBG training) (NP (JJ context-conditioned) (NNS policies))))))) (VP (NNS results) (PP (IN in) (NP (NP (NNS improvements)) (PP (IN on) (NP (NN jump-start) (CC and) (JJ asymptotic) (NN performance))) (SBAR (WHADVP (WRB when)) (S (VP (VBG transferring) (NP (DT a) (JJ learned) (NN policy)) (PP (TO to) (NP (DT the) (NN target) (NN environment)))))))))))) (. .))
