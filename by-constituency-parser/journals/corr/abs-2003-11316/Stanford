(S (S (NP (NNP Network) (NN pruning)) (VP (VBZ is) (NP (NP (DT an) (JJ effective) (NN methodology)) (PP (IN to) (S (VP (VB compress) (NP (JJ large) (JJ neural) (NNS networks)))))))) (, ,) (CC and) (S (NP (NP (JJ sparse) (JJ neural) (NNS networks)) (VP (VBN obtained) (PP (IN by) (NP (NN pruning))))) (VP (MD can) (VP (VB benefit) (PP (IN from) (NP (NP (PRP$ their) (VBN reduced) (NN memory)) (CC and) (NP (NP (JJ computational) (NNS costs)) (PP (IN at) (NP (NN use))))))))) (. .))
(S (ADVP (RB Notably)) (, ,) (NP (JJ recent) (NNS studies)) (VP (VBP have) (VP (VBN found) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ possible) (S (VP (TO to) (VP (VB find) (NP (DT a) (ADJP (JJ trainable)) (JJ sparse) (JJ neural) (NN network)) (ADVP (RB even)) (PP (IN at) (NP (NP (JJ random) (NN initialization)) (PP (JJ prior) (IN to) (NP (NN training)))))))))))))) (. .))
(S (SBAR (IN While) (S (NP (NP (DT this) (NN approach)) (PP (IN of) (NP (NP (NN pruning)) (PP (IN at) (NP (NN initialization)))))) (VP (VBD turned) (PRT (RP out)) (S (VP (TO to) (VP (VB be) (ADJP (RB highly) (JJ effective)))))))) (, ,) (NP (EX there)) (VP (VBZ has) (VP (VBN been) (NP (NP (JJ little) (NN study)) (PP (VBG concerning) (NP (NP (DT the) (JJ subsequent) (NN training)) (PP (IN of) (NP (DT these) (JJ sparse) (JJ neural) (NNS networks)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP focus) (PP (IN on) (S (VP (VBG studying) (NP (NP (NP (DT the) (NNS effects)) (PP (IN of) (NP (NNS data) (NN parallelism)))) (CC and) (NP (NP (NN sparsity)) (PP (IN on) (NP (JJ neural) (NN network) (NN training))))))))) (. .))
(S (PP (IN For) (NP (NNS data) (NN parallelism))) (, ,) (NP (DT this)) (VP (ADVP (RB usually)) (VBZ means) (NP (NML (NN processing) (NN training)) (NNS data)) (PP (IN in) (NP (NP (NN parallel)) (VP (VP (VBG using) (NP (VBN distributed) (NNS systems))) (, ,) (CC or) (ADVP (RB equivalently)) (VP (VBG increasing) (NP (NN batch) (NN size)))))) (, ,) (SBAR (IN so) (IN that) (S (NP (DT the) (NN training) (NN process)) (VP (MD can) (VP (VB be) (VP (VBN accelerated))))))) (. .))
(S (PP (IN To) (NP (DT this) (NN end))) (, ,) (NP (PRP we)) (ADVP (RB first)) (VP (VB measure) (NP (DT the) (NNS effects)) (PP (IN for) (NP (NP (JJ different) (NN study) (NNS cases)) (PP (IN of) (NP (NP (NN batch) (NN size)) (CC and) (NP (NN sparsity) (NN level)))))) (SBAR (IN while) (S (VP (VBG tuning) (NP (NP (DT all) (NNS metaparameters)) (VP (VBN involved) (PP (IN in) (NP (DT the) (NN optimization))))))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (NP (PRP we)) (VP (VBP find) (PP (IN across) (NP (NP (JJ various) (NNS workloads)) (PP (IN of) (NP (NP (NP (NNS data)) (VP (VBN set))) (, ,) (NP (NN network) (NN model)) (, ,) (CC and) (NP (NP (NN optimization) (NNS algorithms)) (SBAR (IN that) (S (NP (EX there)) (VP (VBZ exists) (NP (NP (DT a) (JJ general) (NN scaling) (NN trend)) (PP (IN in) (NP (NP (DT the) (NN relationship)) (PP (IN between) (NP (NN batch) (NN size) (CC and) (NN number))))) (PP (IN of) (NP (NN training) (NNS steps)))) (PP (IN to) (NP (NP (NN convergence)) (PP (IN for) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NNS data) (NN parallelism))))))))))))))) (, ,) (ADVP (RB irrespective) (PP (IN of) (NP (NN sparsity) (NNS levels))))) (. .))
(S (ADVP (RB Also)) (, ,) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NP (NNS data) (NN parallelism)) (PP (IN in) (NP (NN training) (JJ sparse) (NNS networks)))))) (VP (VP (VBZ turns) (PRT (RP out)) (S (VP (TO to) (VP (VB be) (ADJP (DT no) (JJR worse)))))) (, ,) (CC or) (VP (MD can) (VP (VB be) (ADJP (RB even) (JJR better)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN training)) (VP (VBZ is) (VP (VBN done) (PP (IN by) (NP (NP (DT a) (NN momentum)) (VP (VBN based) (NP (NN optimizer)) (, ,) (SBAR (IN than) (S (NP (NP (DT that)) (PP (IN in) (NP (NN training)))) (ADVP (RB densely)) (VP (VBD parameterized) (NP (NNS networks)) (, ,) (PP (IN despite) (NP (NP (DT the) (JJ general) (NN difficulty)) (PP (IN of) (NP (NN training) (JJ sparse) (NNS networks)))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VBP provide) (NP (JJ theoretical) (NNS insights)) (PP (PP (VBN based) (PP (IN on) (NP (NP (DT the) (NN convergence) (NNS properties)) (PP (IN of) (NP (NP (JJ stochastic) (NN gradient) (NNS methods)) (CC and) (NP (DT a) (NN smoothness) (NN analysis))))))) (, ,) (CONJP (RB so) (IN as)) (PP (IN to) (S (S (ADVP (RB precisely)) (VP (VB illustrate) (NP (PRP$ our) (JJ empirical) (NNS findings)))) (CC and) (S (ADVP (RB hence)) (VP (TO to) (VP (VB develop) (NP (NP (DT a) (JJR better) (NN account)) (PP (IN of) (NP (NP (NP (DT the) (NNS effects)) (PP (IN of) (NP (NNS data) (NN parallelism)))) (CC and) (NP (NP (NN sparsity)) (PP (IN on) (NP (JJ neural) (NN network) (NN training)))))))))))))) (. .))
