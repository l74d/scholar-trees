(S (S (NP (NNP Network) (NN pruning)) (VP (VBZ is) (NP (NP (DT an) (JJ effective) (NN methodology)) (SBAR (S (VP (TO to) (VP (VB compress) (NP (JJ large) (JJ neural) (NNS networks))))))))) (, ,) (CC and) (S (NP (NP (JJ sparse) (JJ neural) (NNS networks)) (VP (VBN obtained) (PP (IN by) (NP (VBG pruning))))) (VP (MD can) (VP (VB benefit) (PP (IN from) (NP (NP (PRP$ their) (VBN reduced) (NN memory) (CC and) (JJ computational) (NNS costs)) (PP (IN at) (NP (NN use)))))))) (. .))
(S (ADVP (RB Notably)) (, ,) (NP (JJ recent) (NNS studies)) (VP (VBP have) (VP (VBN found) (SBAR (IN that) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (JJ possible)) (S (VP (TO to) (VP (VB find) (NP (DT a) (JJ trainable) (NN sparse) (JJ neural) (NN network)) (PP (ADVP (RB even)) (IN at) (NP (JJ random) (NN initialization))) (ADVP (RB prior) (PP (TO to) (NP (NN training)))))))))))) (. .))
(S (SBAR (IN While) (S (NP (NP (DT this) (NN approach)) (PP (IN of) (S (VP (VBG pruning) (PP (IN at) (NP (NN initialization))))))) (VP (VBD turned) (PRT (RP out)) (S (VP (TO to) (VP (VB be) (ADJP (RB highly) (JJ effective)))))))) (, ,) (NP (EX there)) (VP (VBZ has) (VP (VBN been) (NP (NP (JJ little) (NN study)) (VP (VBG concerning) (NP (NP (DT the) (JJ subsequent) (NN training)) (PP (IN of) (NP (DT these) (JJ sparse) (JJ neural) (NNS networks)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP focus) (PP (IN on) (S (VP (VBG studying) (NP (NP (DT the) (NNS effects)) (PP (IN of) (NP (NNS data) (NN parallelism) (CC and) (NN sparsity))) (PP (IN on) (NP (JJ neural) (NN network) (NN training)))))))) (. .))
(S (PP (IN For) (NP (NNS data) (NN parallelism))) (, ,) (NP (DT this)) (ADVP (RB usually)) (VP (VBZ means) (S (VP (VP (VBG processing) (NP (VBG training) (NNS data)) (PP (IN in) (NP (JJ parallel))) (S (VP (VBG using) (NP (JJ distributed) (NNS systems))))) (, ,) (CC or) (VP (ADVP (RB equivalently)) (VBG increasing) (NP (NN batch) (NN size)) (, ,) (SBAR (IN so) (IN that) (S (NP (DT the) (NN training) (NN process)) (VP (MD can) (VP (VB be) (VP (VBN accelerated)))))))))) (. .))
(S (PP (TO To) (NP (DT this) (NN end))) (, ,) (NP (PRP we)) (ADVP (RB first)) (VP (VBD measure) (NP (NP (DT the) (NNS effects)) (PP (IN for) (NP (JJ different) (NN study) (NNS cases))) (PP (IN of) (NP (NP (NN batch) (NN size)) (CC and) (NP (NN sparsity) (NN level))))) (SBAR (IN while) (S (VP (VBG tuning) (NP (NP (DT all) (NNS metaparameters)) (VP (VBN involved) (PP (IN in) (NP (DT the) (NN optimization))))))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (NP (PRP we)) (VP (VBP find) (PP (IN across) (NP (NP (JJ various) (NNS workloads)) (PP (IN of) (NP (NNS data) (NN set) (, ,) (NN network) (NN model) (, ,) (CC and) (NP (NN optimization) (VBP algorithms)))))) (SBAR (IN that) (S (NP (EX there)) (VP (VBZ exists) (NP (NP (DT a) (JJ general) (NN scaling) (NN trend)) (PP (IN in) (NP (NP (DT the) (NN relationship)) (PP (IN between) (NP (NP (NP (NN batch) (NN size)) (CC and) (NP (NP (NN number)) (PP (IN of) (NP (VBG training) (NNS steps))))) (PP (TO to) (NP (VB convergence))))))) (PP (IN for) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NNS data) (NN parallelism)))))) (, ,) (ADVP (NN irrespective) (PP (IN of) (NP (NN sparsity) (NNS levels)))))))) (. .))
(S (ADVP (RB Also)) (, ,) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NNS data) (NN parallelism))) (PP (IN in) (S (VP (VBG training) (NP (JJ sparse) (NNS networks)))))) (VP (VBZ turns) (PRT (RP out)) (S (VP (VP (TO to) (VP (VB be) (ADJP (DT no) (JJR worse)))) (, ,) (CC or) (VP (MD can) (VP (VB be) (ADJP (RB even) (RBR better)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN training)) (VP (VBZ is) (VP (VBN done) (PP (IN by) (NP (DT a) (ADJP (NN momentum) (VBN based)) (NN optimizer))))))))) (, ,) (PP (IN than) (NP (NP (DT that)) (PP (IN in) (S (VP (VBG training) (NP (ADJP (RB densely) (VBN parameterized)) (NNS networks))))))))) (, ,) (PP (IN despite) (NP (NP (DT the) (JJ general) (NN difficulty)) (PP (IN of) (S (VP (VBG training) (NP (JJ sparse) (NNS networks)))))))) (. .))
(S (NP (PRP We)) (ADVP (VBP further)) (VP (RB provide) (NP (NP (JJ theoretical) (NNS insights)) (VP (VBN based) (PP (IN on) (NP (NP (DT the) (NN convergence) (NNS properties)) (PP (IN of) (NP (NP (JJ stochastic) (NN gradient) (NNS methods)) (CC and) (NP (DT a) (JJ smoothness) (NN analysis)))))))) (, ,) (SBAR (RB so) (IN as) (S (VP (VP (TO to) (VP (ADVP (RB precisely)) (VB illustrate) (NP (PRP$ our) (JJ empirical) (NNS findings)))) (CC and) (ADVP (NN hence)) (VP (TO to) (VP (VB develop) (NP (NP (DT a) (JJR better) (NN account)) (PP (IN of) (NP (NP (DT the) (NNS effects)) (PP (IN of) (NP (NNS data) (NN parallelism) (CC and) (NN sparsity))) (PP (IN on) (NP (JJ neural) (NN network) (NN training)))))))))))) (. .))
