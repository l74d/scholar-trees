(S (NP (NNP Reinforcement) (NN learning)) (VP (VBZ is) (VP (VBN concerned) (PP (IN with) (S (VP (VBG identifying) (NP (JJ reward-maximizing) (NN behaviour) (NNS policies)) (PP (IN in) (NP (NP (NNS environments)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADVP (RB initially)) (ADJP (JJ unknown)))))))))))) (. .))
(S (NP (NP (JJ State-of-the-art) (NN reinforcement) (NN learning) (NNS approaches)) (, ,) (PP (JJ such) (IN as) (NP (JJ deep) (NNS Q-networks))) (, ,)) (VP (VP (VBP are) (ADJP (JJ model-free))) (CC and) (VP (VB learn) (S (VP (TO to) (VP (VB act) (ADVP (RB effectively)) (PP (IN across) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NP (NNS environments)) (PP (JJ such) (IN as) (NP (NNP Atari) (NNS games))))))))))) (, ,) (CC but) (VP (VBP require) (NP (NP (JJ huge) (NNS amounts)) (PP (IN of) (NP (NNS data)))))) (. .))
(S (NP (JJ Model-based) (NNS techniques)) (VP (VP (VBP are) (ADJP (RBR more) (JJ data-efficient))) (, ,) (CC but) (VP (VBP need) (S (VP (TO to) (VP (VB acquire) (NP (NP (JJ explicit) (NN knowledge)) (PP (IN about) (NP (DT the) (NN environment))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP take) (NP (NP (DT a) (NN step)) (PP (IN towards) (S (VP (VBG using) (NP (JJ model-based) (NNS techniques)) (PP (IN in) (NP (NP (NNS environments)) (PP (IN with) (NP (DT a) (JJ high-dimensional) (JJ visual) (NN state) (NN space))))))))) (PP (IN by) (S (VP (VBG demonstrating) (SBAR (IN that) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (JJ possible)) (S (VP (TO to) (VP (VB learn) (NP (NP (NN system) (NNS dynamics)) (CC and) (NP (DT the) (NN reward) (NN structure))) (ADVP (RB jointly)))))))))))) (. .))
(S (NP (PRP$ Our) (NN contribution)) (VP (VBZ is) (S (VP (TO to) (VP (VB extend) (NP (NP (DT a) (ADJP (RB recently) (VBN developed)) (JJ deep) (JJ neural) (NN network)) (PP (IN for) (NP (NP (NN video) (NN frame) (NN prediction)) (PP (IN in) (NP (NNP Atari) (NNS games)))))) (S (VP (TO to) (VP (VB enable) (NP (NN reward) (NN prediction)) (ADVP (IN as) (RB well))))))))) (. .))
(S (PP (TO To) (NP (DT this) (NN end))) (, ,) (NP (PRP we)) (VP (VP (VBP phrase) (NP (NP (DT a) (JJ joint) (NN optimization) (NN problem)) (PP (IN for) (S (VP (VBG minimizing) (NP (DT both) (NN video) (NN frame) (CC and) (JJ reward) (NN reconstruction) (NN loss))))))) (, ,) (CC and) (VP (JJ adapt) (NP (NN network) (NNS parameters)) (ADVP (RB accordingly)))) (. .))
(S (NP (NP (JJ Empirical) (NNS evaluations)) (PP (IN on) (NP (CD five) (NNP Atari) (NNS games)))) (VP (VBP demonstrate) (NP (NP (JJ accurate) (JJ cumulative) (NN reward) (NN prediction)) (PP (IN of) (NP (QP (IN up) (TO to) (CD 200)) (NNS frames))))) (. .))
(S (NP (PRP We)) (VP (VBP consider) (NP (DT these) (NNS results)) (PP (IN as) (S (VP (VBG opening) (PRT (RP up)) (NP (NP (JJ important) (NNS directions)) (PP (IN for) (NP (NP (JJ model-based) (NN reinforcement) (NN learning)) (PP (IN in) (NP (JJ complex) (, ,) (ADJP (RB initially) (JJ unknown)) (NNS environments)))))))))) (. .))
