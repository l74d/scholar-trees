(S (S (NP (JJ Deep) (NN learning) (NNS algorithms)) (VP (VBP have) (VP (VBN shown) (NP (JJ tremendous) (NN success)) (PP (IN in) (NP (JJ many) (NN recognition) (NNS tasks)))))) (: ;) (S (ADVP (RB however)) (, ,) (NP (DT these) (NNS algorithms)) (ADVP (RB typically)) (VP (VBP include) (NP (NP (DT a) (NML (NML (JJ deep) (JJ neural) (NN network)) (-LRB- -LRB-) (NML (NN DNN)) (-RRB- -RRB-)) (NN structure)) (CC and) (NP (NP (DT a) (JJ large) (NN number)) (PP (IN of) (NP (NP (NNS parameters)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (NP (PRP it)) (ADJP (JJ challenging) (S (VP (TO to) (VP (VB implement) (NP (PRP them)) (PP (IN on) (NP (ADJP (NP (NN power) (HYPH /) (NN area)) (HYPH -) (VBN constrained)) (VBN embedded) (NNS platforms))))))))))))))))) (. .))
(FRAG (S (VP (TO To) (VP (VB reduce) (NP (NP (DT the) (NN network) (NN size)) (, ,) (NP (NP (JJ several) (NNS studies)) (VP (VBN investigated) (NP (NN compression)) (PP (IN by) (S (VP (VBG introducing) (NP (NN element-wise) (CC or) (NN row))))))))))) (NP (NP (NML (SYM -) (HYPH /) (NN column)) (NML (SYM -) (HYPH /) (NN block-wise)) (NN sparsity)) (PP (IN via) (NP (NN pruning) (CC and) (NN regularization)))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (JJ many) (JJ recent) (NNS works)) (VP (VBP have) (VP (VBN focused) (PP (IN on) (S (VP (VBG reducing) (NP (NP (NN precision)) (PP (IN of) (NP (NNS activations) (CC and) (NNS weights)))) (PP (IN with) (NP (NP (DT some)) (VP (VBG reducing) (PRT (RP down)) (PP (IN to) (NP (DT a) (JJ single) (NN bit))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG combining) (NP (JJ various) (NN sparsity) (NNS structures)) (PP (IN with) (NP (NP (VBN binarized)) (CC or) (NP (RB very) (HYPH -) (JJ low) (HYPH -) (NN precision)) (PRN (-LRB- -LRB-) (NP (QP (CD 2) (SYM -) (CD 3)) (NN bit)) (-RRB- -RRB-)))))) (NP (JJ neural) (NNS networks)) (VP (VBP have) (RB not) (VP (VBN been) (ADVP (RB comprehensively)) (VP (VBN explored)))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NN design) (NNS techniques)) (PP (IN for) (NP (NML (NML (JJ minimum) (HYPH -) (NN area)) (HYPH /) (PP (SYM -) (NP (NN energy) (NN DNN)))) (NN hardware)))) (PP (IN with) (NP (NP (JJ minimal) (NN degradation)) (PP (IN in) (NP (NN accuracy)))))) (. .))
(S (PP (IN During) (NP (NN training))) (, ,) (NP (NP (CC both) (NP (NN binarization) (HYPH /) (JJ low) (HYPH -) (NN precision)) (CC and)) (VP (VBN structured) (NP (NN sparsity)))) (VP (VBP are) (VP (VBN applied) (PP (IN as) (NP (NNS constraints))) (S (VP (TO to) (VP (VB find) (NP (NP (DT the) (JJS smallest) (NN memory) (NN footprint)) (PP (IN for) (NP (DT a) (VBN given) (NML (JJ deep) (NN learning)) (NN algorithm))))))))) (. .))
(S (NP (NP (DT The) (NN DNN) (NN model)) (PP (IN for) (NP (NP (NML (NN CIFAR) (HYPH -) (CD 10)) (NN dataset)) (PP (IN with) (NP (NP (NML (NN weight) (NN memory)) (NN reduction)) (PP (IN of) (NP (NN 50X)))))))) (VP (VBZ exhibits) (S (NP (NN accuracy)) (ADJP (JJ comparable) (PP (IN to) (NP (NP (DT that)) (PP (IN of) (NP (DT the) (NML (VBG floating) (HYPH -) (NN point)) (NN counterpart)))))))) (. .))
(S (NP (NP (NN Area) (, ,) (NN performance) (CC and) (NN energy) (NNS results)) (PP (IN of) (NP (NP (NNP DNN) (NN hardware)) (PP (IN in) (NP (JJ 40nm) (NNS CMOS)))))) (VP (VBP are) (VP (VBN reported) (PP (IN for) (NP (DT the) (NN MNIST) (NN dataset))))) (. .))
(S (NP (NP (DT The) (VBN optimized) (NN DNN)) (SBAR (WHNP (WDT that)) (S (VP (VBZ combines) (NP (NP (NN 8X)) (VP (VBN structured) (NP (NML (NML (NN compression)) (CC and) (NML (CD 3) (HYPH -) (NN bit))) (NN weight) (NN precision)))))))) (VP (VBD showed) (NP (CD 98.4) (NN %)) (NP (NP (NN accuracy)) (PP (IN at) (NP (NP (NN 20nJ)) (PP (IN per) (NP (NN classification))))))) (. .))
