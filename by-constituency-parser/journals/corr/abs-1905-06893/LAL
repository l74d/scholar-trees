(S (NP (DT The) (NN ability) (S (VP (TO to) (VP (VB discover) (NP (ADJP (RB approximately) (JJ optimal)) (NNS policies)) (PP (IN in) (NP (NP (NNS domains)) (PP (IN with) (NP (JJ sparse) (NNS rewards))))))))) (VP (VBZ is) (ADJP (JJ crucial) (PP (TO to) (S (VP (VBG applying) (NP (NP (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-))) (PP (IN in) (NP (JJ many) (JJ real-world) (NNS scenarios)))))))) (. .))
(S (NP (NP (NNS Approaches)) (PP (JJ such) (IN as) (NP (NP (JJ neural) (NN density) (NNS models)) (CC and) (NP (NP (JJ continuous) (NN exploration)) (PRN (-LRB- -LRB-) (NP (JJ e.g.)) (, ,) (NP (NNP Go-Explore)) (-RRB- -RRB-)))))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (S (VP (TO to) (VP (VB maintain) (NP (NP (DT the) (JJ high) (NN exploration) (NN rate)) (ADJP (JJ necessary) (S (VP (TO to) (VP (VB find) (NP (ADJP (ADJP (JJ high) (NN performing)) (CC and) (ADJP (JJ generalizable))) (NNS policies))))))))))))) (. .))
(S (NP (NP (JJ Soft) (JJ actor-critic)) (PRN (-LRB- -LRB-) (NP (NNP SAC)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (DT another) (NN method)) (PP (IN for) (S (VP (VBG improving) (NP (NN exploration))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ aims) (S (VP (TO to) (VP (VB combine) (NP (JJ efficient) (VBG learning)) (PP (IN via) (NP (NN off-policy) (NNS updates))) (SBAR (IN while) (S (VP (VBG maximizing) (NP (DT the) (NN policy) (NN entropy))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VP (VBP extend) (NP (NNP SAC)) (PP (TO to) (NP (NP (DT a) (JJR richer) (NN class)) (PP (IN of) (NP (NN probability) (NNS distributions))) (PRN (-LRB- -LRB-) (INTJ (NN e.g.)) (, ,) (ADJP (NN multimodal)) (-RRB- -RRB-)))) (PP (IN through) (S (VP (NN normalizing) (NP (NP (NNS flows)) (PRN (-LRB- -LRB-) (NP (NNP NF)) (-RRB- -RRB-))))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (DT this)) (VP (ADVP (RB significantly)) (VBZ improves) (NP (NN performance)) (PP (IN by) (S (VP (VBG accelerating) (NP (NP (DT the) (NN discovery)) (PP (IN of) (NP (JJ good) (NNS policies)))) (SBAR (IN while) (S (VP (VBG using) (NP (ADJP (JJ much) (JJR smaller)) (NN policy) (NNS representations))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NN approach)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP call) (S (NP (JJ SAC-NF)))))) (, ,)) (VP (VBZ is) (NP (NP (DT a) (JJ simple) (, ,) (JJ efficient) (, ,) (JJ easy-to-implement) (NN modification) (CC and) (NX (NN improvement))) (PP (TO to) (NP (NNP SAC))) (PP (IN on) (NP (NP (JJ continuous) (NN control) (NNS baselines)) (PP (JJ such) (IN as) (NP (NP (NNP MuJoCo)) (CC and) (NP (NNP PyBullet) (NNP Roboschool) (NNS domains)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (NNP SAC-NF)) (VP (VBZ does) (NP (DT this)) (SBAR (IN while) (S (VP (VBG being) (ADJP (RB significantly) (RBR parameter) (JJ efficient))))) (, ,) (S (VP (VBG using) (NP (NP (QP (QP (RB as) (JJ few) (IN as) (CD 5.5)) (NN %)) (DT the) (NNS parameters)) (PP (IN for) (NP (DT an) (JJ equivalent) (NNP SAC) (NN model))))))) (. .))
