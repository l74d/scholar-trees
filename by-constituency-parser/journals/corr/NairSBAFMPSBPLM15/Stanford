(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT the) (JJ first) (ADJP (ADVP (RB massively)) (VBN distributed)) (NN architecture)) (PP (IN for) (NP (JJ deep) (NN reinforcement) (NN learning))))) (. .))
(S (NP (DT This) (NN architecture)) (VP (VBZ uses) (NP (NP (NP (CD four) (JJ main) (NNS components)) (: :) (NP (NP (JJ parallel) (NNS actors)) (SBAR (WHNP (WDT that)) (S (VP (VBP generate) (NP (JJ new) (NN behaviour))))))) (: ;) (NP (NP (JJ parallel) (NNS learners)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (VBN trained) (PP (IN from) (NP (VBN stored) (NN experience)))))))) (: ;) (NP (NP (DT a) (VBN distributed) (JJ neural) (NN network) (S (VP (TO to) (VP (VB represent) (NP (DT the) (NN value) (NN function)))))) (CC or) (NP (NN behaviour) (NN policy))) (: ;) (CC and) (NP (NP (DT a) (VBN distributed) (NN store)) (PP (IN of) (NP (NN experience)))))) (. .))
(S (NP (PRP We)) (VP (VBD used) (NP (PRP$ our) (NN architecture) (S (VP (TO to) (VP (VB implement) (NP (DT the) (JJ Deep) (NML (NN Q) (HYPH -) (NN Network)) (NN algorithm)))))) (PRN (-LRB- -LRB-) (NP (NN DQN)) (-RRB- -RRB-))) (. .))
(S (NP (PRP$ Our) (VBN distributed) (NN algorithm)) (VP (VBD was) (VP (VBN applied) (PP (IN to) (NP (NP (CD 49) (NNS games)) (PP (IN from) (NP (NNP Atari))))) (PP (NP (CD 2600) (NNS games)) (IN from) (NP (DT the) (NNP Arcade) (NNP Learning) (NNP Environment))) (, ,) (S (VP (VBG using) (NP (JJ identical) (NNS hyperparameters)))))) (. .))
(S (NP (PRP$ Our) (NN performance)) (VP (VP (VBD surpassed) (NP (JJ non-distributed) (NN DQN)) (PP (IN in) (NP (NP (CD 41)) (PP (IN of) (NP (DT the) (CD 49) (NNS games)))))) (CC and) (VP (ADVP (RB also)) (VBD reduced) (NP (NP (DT the) (NN wall) (HYPH -) (NN time)) (VP (VBN required) (S (VP (TO to) (VP (VB achieve) (NP (DT these) (NNS results)) (PP (IN by) (NP (NP (DT an) (NN order)) (PP (IN of) (NP (NN magnitude))))) (PP (IN on) (NP (JJS most) (NNS games)))))))))) (. .))
