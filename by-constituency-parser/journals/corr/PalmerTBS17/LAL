(S (NP (NP (JJ Much)) (PP (IN of) (NP (NP (DT the) (NN success)) (PP (IN of) (NP (NP (JJ single) (NN agent) (JJ deep) (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP DRL)) (-RRB- -RRB-)))) (PP (IN in) (NP (JJ recent) (NNS years)))))) (VP (MD can) (VP (VB be) (VP (VBN attributed) (PP (TO to) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (NN experience) (NN replay) (NNS memories)) (PRN (-LRB- -LRB-) (NP (NNP ERM)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP allow) (S (NP (NP (JJ Deep) (NNP Q-Networks)) (PRN (-LRB- -LRB-) (NP (NNP DQNs)) (-RRB- -RRB-))) (VP (TO to) (VP (VB be) (VP (VBN trained) (ADVP (RB efficiently)) (PP (IN through) (S (VP (VBG sampling) (NP (VBN stored) (NN state) (NNS transitions))))))))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NN care)) (VP (VBZ is) (VP (VBN required) (SBAR (WHADVP (WRB when)) (S (VP (VBG using) (NP (NNP ERMs)) (PP (IN for) (NP (NP (JJ multi-agent) (JJ deep) (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP MA-DRL)) (-RRB- -RRB-))))))) (, ,) (SBAR (IN as) (S (NP (JJ stored) (NNS transitions)) (VP (MD can) (VP (VP (VB become) (ADJP (JJ outdated)) (SBAR (IN because) (S (NP (NNS agents)) (VP (VBP update) (NP (PRP$ their) (NNS policies)) (PP (IN in) (NP (JJ parallel))))))) (PRN ($ -LSB-) (CD 11) (NN -RSB-)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (NP (PRP we)) (VP (VBP apply) (NP (NP (JJ leniency)) (PRN ($ -LSB-) (CD 23) (NN -RSB-))) (PP (TO to) (NP (NNP MA-DRL)))) (. .))
(S (NP (JJ Lenient) (NNS agents)) (VP (JJ map) (NP (JJ state-action) (NNS pairs)) (PP (TO to) (NP (NP (VBG decaying) (NN temperature) (NNS values)) (SBAR (WHNP (WDT that)) (S (VP (VBP control) (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NN leniency))) (VP (VBN applied) (PP (NNS towards) (NP (NP (JJ negative) (NN policy) (NNS updates)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (VBN sampled) (PP (IN from) (NP (DT the) (NNP ERM))))))))))))))))) (. .))
(S (NP (DT This)) (VP (VP (VBZ introduces) (NP (NN optimism)) (PP (IN in) (NP (DT the) (NN value-function) (NN update)))) (, ,) (CC and) (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB facilitate) (NP (NP (NN cooperation)) (PP (IN in) (NP (JJ tabular) (JJ fully-cooperative) (JJ multi-agent) (NN reinforcement) (VBG learning) (NNS problems))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (PRP$ our) (NNP Lenient-DQN) (PRN (-LRB- -LRB-) (NP (NNP LDQN)) (-RRB- -RRB-))) (ADVP (RB empirically)) (PP (IN against) (NP (NP (NP (DT the) (JJ related) (NNP Hysteretic-DQN) (PRN (-LRB- -LRB-) (NNP HDQN) (-RRB- -RRB-)) (VBP algorithm)) ($ -LSB-) (CD 22) (NN -RSB-)) (CONJP (RB as) (RB well) (IN as)) (NP (NP (DT a) (JJ modified) (NN version)) (SBAR (S (NP (PRP we)) (VP (VBP call) (S (NP (JJ scheduled-HDQN)))))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (JJ average) (NN reward) (NN learning)) (PP (IN near) (NP (JJ terminal) (NNS states)))))))))) (. .))
(S (NP (NNS Evaluations)) (VP (VBP take) (NP (NN place)) (PP (IN in) (NP (NP (JJ extended) (NNS variations)) (PP (IN of) (NP (NP (DT the) (NNP Coordinated) (NNP Multi-Agent) (NNP Object) (NNP Transportation) (NNP Problem)) (PRN (-LRB- -LRB-) (NP (NNP CMOTP)) (-RRB- -RRB-)) (VBD -LSB-) (CD 8) (NN -RSB-))) (SBAR (WHNP (WDT which)) (S (VP (VBP include) (NP (NP (JJ fully-cooperative) (NNS sub-tasks)) (CC and) (NP (JJ stochastic) (NNS rewards))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NNP LDQN) (NNS agents)) (VP (VBP are) (ADJP (RBR more) (JJ likely) (S (VP (TO to) (VP (VB converge) (PP (TO to) (NP (DT the) (JJ optimal) (NN policy))) (PP (IN in) (NP (DT a) (JJ stochastic) (NN reward) (NNP CMOTP))))))) (PP (VBN compared) (PP (TO to) (NP (ADJP (VB standard) (CC and) (JJ scheduled-HDQN)) (NNS agents)))))))) (. .))
