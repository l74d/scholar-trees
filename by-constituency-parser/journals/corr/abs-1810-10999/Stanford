(S (NP (NP (JJ Recurrent) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (VP (VP (VBP provide) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NN performance)) (PP (IN in) (S (VP (VBG processing) (NP (JJ sequential) (NNS data)))))) (CC but) (VP (VBP are) (ADJP (ADJP (NN memory) (JJ intensive)) (S (VP (TO to) (VP (VB train) (, ,) (S (VP (VBG limiting) (NP (NP (DT the) (NN flexibility)) (PP (IN of) (NP (NP (NN RNN) (NNS models)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN trained))))))))))))))))) (. .))
(NP (NP (JJ Reversible) (NNS RNNs)) (, ---) (NP (NP (NNS RNNs)) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (S (NP (DT the) (ADJP (ADJP (JJ hidden) (HYPH -) (PP (TO to))) (HYPH -) (VBN hidden)) (NN transition)) (VP (MD can) (VP (VB be) (VP (VBN reversed))))) (NFP ---) (S (S (VP (VB offer) (NP (DT a) (NN path)) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN memory) (NNS requirements)) (PP (IN of) (NP (NN training))))))) (, ,) (SBAR (IN as) (S (NP (JJ hidden) (NNS states)) (VP (VBP need) (RB not) (VP (VB be) (VP (VBN stored)))))))) (CC and) (S (ADVP (RB instead)) (VP (MD can) (VP (VB be) (VP (VBN recomputed) (PP (IN during) (NP (NN backpropagation))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB first)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (ADJP (RB perfectly) (JJ reversible)) (NNS RNNs)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP require) (NP (NP (DT no) (NN storage)) (PP (IN of) (NP (DT the) (JJ hidden) (NNS activations))))))) (, ,)) (VP (VBP are) (ADJP (RB fundamentally) (JJ limited) (SBAR (IN because) (S (NP (PRP they)) (VP (MD can) (RB not) (VP (VB forget) (NP (NN information)) (PP (IN from) (NP (PRP$ their) (JJ hidden) (NN state)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VBP provide) (NP (DT a) (NN scheme)) (PP (IN for) (S (VP (VBG storing) (NP (NP (DT a) (JJ small) (NN number)) (PP (IN of) (NP (NP (NNS bits)) (PP (IN in) (NP (NN order)))))) (S (VP (TO to) (VP (VB allow) (NP (JJ perfect) (NN reversal)) (PP (IN with) (S (VP (VBG forgetting))))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ achieves) (NP (JJ comparable) (NN performance)) (PP (IN to) (NP (JJ traditional) (NNS models)) (PP (IN while) (S (VP (VBG reducing) (NP (DT the) (NML (NN activation) (NN memory)) (NN cost)) (PP (IN by) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (CD 10)))))))) (: --) (NP (CD 15)))) (. .))
(S (NP (PRP We)) (VP (VBP extend) (NP (PRP$ our) (NN technique)) (PP (IN to) (NP (NP (ADJP (NN attention) (HYPH -) (VBN based)) (NML (NN sequence) (HYPH -) (IN to) (HYPH -) (NN sequence)) (NNS models)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP it)) (VP (VBZ maintains) (NP (NN performance)) (PP (IN while) (S (VP (VBG reducing) (NP (NML (NN activation) (NN memory)) (NN cost)) (PP (IN by) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (NP (NP (CD 5) (: --) (CD 10)) (PP (IN in) (NP (DT the) (NN encoder)))) (, ,) (CC and) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (NP (CD 10) (: --) (CD 15)) (PP (IN in) (NP (DT the) (NN decoder))))))))))))))))))) (. .))
