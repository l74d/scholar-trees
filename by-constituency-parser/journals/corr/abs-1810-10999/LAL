(S (NP (NP (JJ Recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))) (VP (VP (VBP provide) (NP (JJ state-of-the-art) (NN performance)) (PP (IN in) (S (VP (VBG processing) (NP (JJ sequential) (NNS data)))))) (CC but) (VP (VBP are) (JJ memory) (JJ intensive) (S (VP (TO to) (VP (VB train)))) (, ,) (S (VP (VBG limiting) (NP (NP (DT the) (NN flexibility)) (PP (IN of) (NP (NP (NNP RNN) (NNS models)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN trained))))))))))))) (. .))
(S (NP (NP (JJ Reversible) (NNP RNNs)) (PRN (: —) (NP (NP (NN -RNNs)) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (DT the) (JJ hidden-to-hidden) (NN transition)) (VP (MD can) (VP (VB be) (VP (VBN reversed))))))) (: —))) (VP (VB -offer) (NP (NP (DT a) (NN path)) (SBAR (S (VP (TO to) (VB reduce) (NP (NP (DT the) (NN memory) (NNS requirements)) (PP (IN of) (NP (NN training)))))))) (, ,) (SBAR (IN as) (S (NP (JJ hidden) (NNS states)) (VP (VP (VBP need) (S (RB not) (VP (VB be) (VP (VBN stored))))) (CC and) (VP (ADVP (RB instead)) (MD can) (VP (VB be) (VP (VBN recomputed) (PP (IN during) (NP (NN backpropagation)))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB first)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (ADJP (RB perfectly) (JJ reversible)) (NNP RNNs)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP require) (NP (NP (DT no) (NN storage)) (PP (IN of) (NP (DT the) (JJ hidden) (NNS activations))))))) (, ,)) (VP (VBP are) (ADJP (RB fundamentally) (VBN limited)) (SBAR (IN because) (S (NP (PRP they)) (VP (MD can) (RB not) (VP (VB forget) (NP (NP (NN information)) (PP (IN from) (NP (PRP$ their) (JJ hidden) (NN state)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VB provide) (NP (NP (DT a) (NN scheme)) (PP (IN for) (S (VP (VBG storing) (NP (NP (DT a) (JJ small) (NN number)) (PP (IN of) (NP (NNS bits)))) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB allow) (NP (NP (JJ perfect) (NN reversal)) (PP (IN with) (NP (NN forgetting))))))))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ achieves) (NP (NP (JJ comparable) (NN performance)) (PP (TO to) (NP (JJ traditional) (NNS models)))) (SBAR (IN while) (S (VP (VBG reducing) (NP (DT the) (NN activation) (NN memory) (NN cost)) (PP (IN by) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (QP (CD 10) (: —) (CD 15)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP extend) (NP (PRP$ our) (NN technique)) (PP (TO to) (NP (NP (JJ attention-based) (NN sequence-to-sequence) (NNS models)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP it)) (VP (VBZ maintains) (NP (NN performance)) (SBAR (IN while) (S (VP (VBG reducing) (NP (JJ activation) (NN memory) (NN cost)) (PP (IN by) (NP (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (QP (CD 5) (: —) (CD 10)))) (PP (IN in) (NP (DT the) (NN encoder)))) (, ,) (CC and) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (QP (CD 10) (: —) (CD 15)))) (PP (IN in) (NP (DT the) (NN decoder))))))))))))))) (. .))
