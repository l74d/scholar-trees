(SBARQ (PP (VBN Given) (NP (NP (CD two) (NNS networks)) (PP (IN with) (NP (NP (DT the) (JJ same) (NN training) (NN loss)) (PP (IN on) (NP (DT a) (NN dataset))))))) (, ,) (WHADVP (WRB when)) (SQ (MD would) (NP (PRP they)) (VP (VB have) (NP (NP (ADJP (RB drastically) (JJ different)) (NN test) (NNS losses)) (CC and) (NP (NNS errors))))) (. ?))
(S (S (ADJP (RBR Better))) (NP (NP (NN understanding)) (PP (IN of) (NP (NP (DT this) (NN question)) (PP (IN of) (NP (NN generalization)))))) (VP (MD may) (VP (VB improve) (NP (NP (JJ practical) (NNS applications)) (PP (IN of) (NP (JJ deep) (NNS networks)))))) (. .))
(S (S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (PP (IN with) (NP (JJ cross-entropy) (NN loss))) (NP (PRP it)) (VP (VBZ is) (ADJP (RB surprisingly) (JJ simple)) (S (VP (TO to) (VP (VB induce) (NP (ADJP (RB significantly) (JJ different)) (NN generalization) (NNS performances)) (PP (IN for) (NP (NP (CD two) (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (NP (NP (DT the) (JJ same) (NN architecture)) (, ,) (NP (DT the) (JJ same) (NN meta) (NNS parameters)) (CC and) (NP (DT the) (JJ same) (NN training) (NN error)))))))))))))))) (: :) (S (NP (CD one)) (VP (MD can) (VP (CC either) (VP (VB pretrain) (NP (DT the) (NNS networks)) (PP (IN with) (NP (NP (JJ different) (NNS levels)) (PP (IN of) (NP (`` ") (JJ corrupted) ('' ") (NNS data)))))) (CC or) (ADVP (RB simply)) (VP (VB initialize) (NP (DT the) (NNS networks)) (PP (IN with) (NP (NP (NNS weights)) (PP (IN of) (NP (JJ different) (JJ Gaussian) (JJ standard) (NNS deviations))))))))) (. .))
(S (NP (NP (DT A) (NN corollary)) (PP (IN of) (NP (NP (JJ recent) (JJ theoretical) (NNS results)) (PP (IN on) (NP (NN overfitting)))))) (VP (VBZ shows) (SBAR (IN that) (S (NP (DT these) (NNS effects)) (VP (VBP are) (ADJP (JJ due) (PP (IN to) (NP (NP (DT an) (JJ intrinsic) (NN problem)) (PP (IN of) (S (VP (VBG measuring) (NP (NN test) (NN performance)) (PP (IN with) (NP (NP (DT a) (NML (ADJP (NP (NN cross) (HYPH -) (NN entropy)) (HYPH /) (JJ exponential)) (HYPH -) (NN type)) (NN loss)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN decomposed) (PP (IN into) (NP (CD two) (NNS components))) (NP (NP (NP (DT both)) (VP (VBN minimized) (PP (IN by) (NP (NNP SGD))))) (: --) (SBAR (WHNP (NP (CD one)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBZ is) (RB not) (VP (VBN related) (PP (IN to) (NP (VBN expected) (NN classification) (NN performance))))))))))))))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (IN if) (S (NP (PRP we)) (VP (VBP factor) (PRT (RP out)) (NP (NP (DT this) (NN component)) (PP (IN of) (NP (DT the) (NN loss))))))) (, ,) (NP (DT a) (JJ linear) (NN relationship)) (VP (VBZ emerges) (PP (IN between) (NP (NML (NN training) (CC and) (NN test)) (NNS losses)))) (. .))
(S (S (PP (IN Under) (NP (DT this) (NN transformation))) (, ,) (NP (JJ classical) (NN generalization) (NNS bounds)) (VP (VBP are) (ADJP (RB surprisingly) (JJ tight)))) (: :) (S (NP (DT the) (NML (JJ empirical) (HYPH /) (NN training)) (NN loss)) (VP (VBZ is) (ADJP (RB very) (JJ close) (PP (IN to) (NP (DT the) (NML (VBN expected) (HYPH /) (NN test)) (NN loss)))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (DT the) (UCP (NP (NP (JJ empirical) (NN relation)) (PP (IN between) (NP (NN classification) (NN error)))) (CC and) (VP (VBN normalized) (S (ADJP (JJ cross-entropy))))) (NN loss)) (VP (VBP seem) (S (VP (TO to) (VP (VB be) (ADJP (RB approximately) (JJ monotonic)))))))
