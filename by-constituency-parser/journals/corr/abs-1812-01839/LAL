(S (NP (NP (NNP Deep) (JJ neural) (NN network) (NN compression) (NNS techniques)) (PP (JJ such) (IN as) (NP (NP (NN pruning)) (CC and) (NP (NN weight) (NN tensor) (NN decomposition))))) (ADVP (RB usually)) (VP (VBP require) (NP (JJ fine-tuning)) (S (VP (TO to) (VP (VB recover) (NP (DT the) (NN prediction) (NN accuracy)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN compression) (NN ratio)) (VP (VBZ is) (ADJP (JJ high))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (JJ conventional) (JJ fine-tuning)) (VP (NNS suffers) (PP (IN from) (NP (NP (NP (DT the) (NN requirement)) (PP (IN of) (NP (DT a) (JJ large) (NN training) (NN set)))) (CC and) (NP (DT the) (JJ time-consuming) (NN training) (NN procedure))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (JJ novel) (NN solution)) (PP (IN for) (NP (NP (NN knowledge) (NN distillation)) (PP (IN from) (NP (JJ label-free) (JJ few) (NNS samples))))) (SBAR (S (VP (TO to) (VP (VB realize) (NP (DT both) (NP (NNS data) (NN efficiency)) (CC and) (NP (VBG training/processing) (NN efficiency))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP treat) (NP (DT the) (JJ original) (NN network)) (PP (IN as) (`` ``) (NP (JJ teacher-net)) ('' ''))) (CC and) (VP (NP (DT the) (JJ compressed) (NN network)) (PP (IN as) (`` ``) (NP (JJ student-net)) ('' '')))) (. .))
(S (S (NP (DT A) (CD 1x1) (NN convolution) (NN layer)) (VP (VBZ is) (VP (VBN added) (PP (IN at) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NP (DT each) (NN layer) (NN block)) (PP (IN of) (NP (DT the) (NN student-net)))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP fit) (NP (NP (DT the) (JJ block-level) (NNS outputs)) (PP (IN of) (NP (DT the) (NN student-net)))) (PP (TO to) (NP (DT the) (NN teacher-net))) (PP (IN by) (S (VP (VBG estimating) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (DT the) (JJ added) (NNS layers))))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (DT the) (JJ added) (NN layer)) (VP (MD can) (VP (VB be) (VP (VBN merged) (PP (IN without) (S (VP (VBG adding) (NP (JJ extra) (NX (NX (NNS parameters)) (CC and) (NX (NN computation) (NN cost)))) (PP (IN during) (NP (NN inference)))))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (JJ multiple) (NX (NX (NNS datasets)) (CC and) (NX (NN network) (NNS architectures)))))) (VP (VBP verify) (NP (NP (NP (DT the) (NN method) (POS 's)) (NN effectiveness)) (PP (IN on) (NP (NP (NNS student-nets)) (VP (VBN obtained) (PP (IN by) (NP (JJ various) (NN network) (NN pruning) (CC and) (JJ weight) (NN decomposition) (NNS methods)))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (MD can) (VP (VB recover) (NP (NP (NN student-net) (POS 's)) (NN accuracy)) (PP (TO to) (NP (NP (DT the) (JJ same) (NN level)) (PP (IN as) (NP (JJ conventional) (JJ fine-tuning) (NNS methods))))) (PP (IN in) (NP (NNS minutes))) (SBAR (IN while) (S (VP (VBG using) (NP (NP (ADJP (QP (RB only) (CD 1)) (NN %)) (JJ label-free) (NN data)) (PP (IN of) (NP (DT the) (JJ full) (NN training) (NNS data))))))))) (. .))
