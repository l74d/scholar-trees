(S (NP (NNP Error) (NN backpropagation)) (VP (VBZ is) (NP (NP (DT a) (ADJP (RB highly) (JJ effective)) (NN mechanism)) (PP (IN for) (S (VP (VBG learning) (NP (NP (JJ high-quality) (JJ hierarchical) (NNS features)) (PP (IN in) (NP (JJ deep) (NNS networks))))))))) (. .))
(S (S (VP (VBG Updating) (NP (NP (DT the) (NNS features) (CC or) (NNS weights)) (PP (IN in) (NP (CD one) (NN layer)))))) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ requires) (S (VP (VBG waiting) (PP (IN for) (NP (NP (DT the) (NN propagation)) (PP (IN of) (NP (NN error) (NNS signals))) (PP (IN from) (NP (JJR higher) (NNS layers)))))))) (. .))
(S (NP (NP (VBG Learning)) (VP (VBG using) (NP (ADJP (VBN delayed) (CC and) (JJ non-local)) (NNS errors)))) (VP (VBZ makes) (S (NP (NP (PRP it))) (ADJP (JJ hard)) (S (VP (TO to) (VP (VB reconcile) (NP (NN backpropagation)) (PP (IN with) (NP (NP (DT the) (VBG learning) (NNS mechanisms)) (VP (VBN observed) (PP (IN in) (NP (JJ biological) (JJ neural) (NNS networks)))))))))) (SBAR (IN as) (S (NP (PRP it)) (VP (VBZ requires) (S (NP (DT the) (NNS neurons)) (VP (TO to) (VP (VB maintain) (NP (NP (DT a) (NN memory)) (PP (IN of) (NP (DT the) (NN input)))) (ADVP (RB long) (RB enough) (SBAR (IN until) (S (NP (DT the) (JJ higher-layer) (NNS errors)) (VP (VBP arrive)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (JJ alternative) (NN learning) (NN mechanism)) (SBAR (WHADVP (WRB where)) (S (NP (NNS errors)) (VP (VBP are) (VP (VBN generated) (ADVP (RB locally)) (PP (IN in) (NP (DT each) (NN layer))) (S (VP (VBG using) (NP (VBN fixed) (, ,) (JJ random) (JJ auxiliary) (NNS classifiers)))))))))) (. .))
(S (S (NP (JJR Lower) (NNS layers)) (VP (MD could) (ADVP (RB thus)) (VP (VB be) (VP (VBN trained) (ADVP (RB independently) (PP (IN of) (NP (JJR higher) (NNS layers)))))))) (CC and) (S (NP (NN training)) (VP (MD could) (VP (VB either) (VP (VB proceed) (NP (NP (NN layer)) (PP (IN by) (NP (NN layer))))) (, ,) (CC or) (VP (ADVP (RB simultaneously)) (PP (IN in) (NP (DT all) (NNS layers))) (S (VP (VBG using) (NP (JJ local) (NN error) (NN information)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP address) (NP (NP (JJ biological) (NN plausibility) (NNS concerns)) (PP (JJ such) (IN as) (NP (NN weight) (NN symmetry) (NNS requirements))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (VBN proposed) (NN learning) (NN mechanism)) (VP (VBN based) (PP (IN on) (NP (NP (ADJP (JJ fixed) (, ,) (JJ broad) (, ,) (CC and) (JJ random)) (NN tuning)) (PP (IN of) (NP (DT each) (NN neuron))) (PP (TO to) (NP (DT the) (NN classification) (NNS categories))))))) (VP (VBZ outperforms) (NP (NP (DT the) (ADJP (JJ biologically-motivated)) (NN feedback) (NN alignment) (VBG learning) (NN technique)) (PP (IN on) (NP (DT the) (NP (ADJP (NNP MNIST) (, ,) (NNP CIFAR10) (, ,) (CC and))) (NNP SVHN) (NNS datasets)))) (, ,) (S (VP (VBG approaching) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ standard) (NN backpropagation))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ highlights) (NP (NP (DT a) (JJ potential) (JJ biological) (NN mechanism)) (PP (IN for) (NP (NP (DT the) (ADJP (JJ supervised) (, ,) (CC or) (NN task-dependent) (, ,)) (NN learning)) (PP (IN of) (NP (NN feature) (NNS hierarchies))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (RB well) (VBN suited) (PP (IN for) (S (VP (VBG learning) (NP (JJ deep) (NNS networks)) (PP (IN in) (NP (NN custom) (NN hardware))) (SBAR (WHADVP (WRB where)) (S (NP (PRP it)) (VP (MD can) (ADVP (RB drastically)) (VP (VB reduce) (NP (NP (NN memory) (NN traffic)) (CC and) (NP (NNS data) (NN communication) (NNS overheads))))))))))))))) (. .))
