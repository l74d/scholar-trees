(S (NP (NP (NP (DT The) (NN use)) (PP (IN of) (NP (JJ low) (HYPH -) (NN precision)))) (NP (NML (VBN fixed) (HYPH -) (NN point)) (NN arithmetic))) (ADVP (IN along) (PP (IN with) (NP (JJ stochastic) (NN rounding)))) (VP (VBZ has) (VP (VBN been) (VP (VBN proposed) (PP (IN as) (NP (NP (DT a) (JJ promising) (NN alternative)) (PP (IN to) (NP (DT the) (ADJP (RB commonly) (VBN used)) (NML (CD 32) (HYPH -) (NN bit)) (JJ floating) (NN point) (NN arithmetic))))) (S (VP (TO to) (VP (VB enhance) (NP (NP (NN training) (JJ neural) (NNS networks)) (VP (VBG training) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NML (NN performance) (CC and) (NN energy)) (NN efficiency))))))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (JJ first) (NN part)) (PP (IN of) (NP (DT this) (NN paper))))) (, ,) (NP (NP (DT the) (NN behaviour)) (PP (IN of) (NP (NP (DT the) (NML (CD 12) (HYPH -) (NN bit)) (NML (JJ fixed) (HYPH -) (NN point)) (NN arithmetic)) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (DT a) (JJ convolutional) (JJ neural) (NN network)) (PP (IN with) (NP (DT the) (NML (NN CIFAR) (HYPH -) (CD 10)) (NN dataset))))))))) (VP (VBZ is) (VP (VBN analysed) (, ,) (S (VP (VBG showing) (SBAR (IN that) (S (NP (JJ such) (NN arithmetic)) (VP (VBZ is) (RB not) (NP (DT the) (ADJP (RBS most) (JJ appropriate) (PP (IN for) (NP (DT the) (NN training)))) (NN phase))))))))) (. .))
(S (PP (IN After) (NP (DT that))) (, ,) (NP (DT the) (NN paper)) (VP (VBZ presents) (CC and) (VBZ evaluates) (, ,) (PP (IN under) (S (NP (NP (DT the) (JJ same) (NNS conditions)) (, ,) (NP (JJ alternative) (NML (JJ low) (HYPH -) (NN precision)) (NNS arithmetics)) (, ,)) (VP (VBG starting) (PP (IN with) (NP (DT the) (NML (CD 12) (HYPH -) (NN bit)) (NML (JJ floating) (HYPH -) (NN point)) (NN arithmetic))))))) (. .))
(S (NP (DT These) (CD two) (NNS representations)) (VP (VP (VBP are) (ADVP (RB then)) (ADJP (VBN leveraged) (S (VP (VBG using) (NP (JJ local) (NN scaling)) (PP (IN in) (NP (NN order))) (S (VP (TO to) (VP (VB increase) (NP (NN accuracy))))))))) (CC and) (VP (VBP get) (ADJP (ADJP (JJR closer)) (PP (IN to) (NP (DT the) (NN baseline) (NML (CD 32) (HYPH -) (NN bit)) (NML (JJ floating) (HYPH -) (NN point)) (NN arithmetic)))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (DT the) (NN paper)) (VP (VBZ introduces) (NP (NP (DT a) (VBN simplified) (NN model)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (CC both) (NP (DT the) (NNS outputs)) (CC and) (NP (NP (DT the) (NNS gradients)) (PP (IN of) (NP (DT the) (JJ neural) (NNS networks))))) (VP (VBP are) (VP (VBN constrained) (PP (IN to) (NP (NML (NML (NN power)) (HYPH -) (PP (IN of) (HYPH -) (NP (CD two)))) (NNS values))) (, ,) (S (ADVP (RB just)) (VP (VBG using) (NP (NP (CD 7) (NNS bits)) (PP (IN for) (NP (PRP$ their) (NN representation)))))))))))) (. .))
(S (S (NP (DT The) (NN evaluation)) (VP (VBZ demonstrates) (NP (NP (DT a) (JJ minimal) (NN loss)) (PP (IN in) (NP (NN accuracy)))) (PP (IN for) (NP (NP (DT the) (VBN proposed) (NN Power)) (HYPH -) (PP (IN of) (HYPH -) (NP (CD Two) (JJ neural) (NN network))))))) (, ,) (S (S (VP (VBG avoiding) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NNS multiplications) (CC and) (NNS divisions)))))) (CC and) (FRAG (ADVP (RB thereby)) (, ,) (ADVP (RB significantly)) (VP (VBG reducing) (NP (NP (DT the) (NN training) (NN time)) (CONJP (RB as) (RB well) (IN as)) (NP (DT the) (NN energy)) (NML (NML (NN consumption)) (CC and) (NML (NN memory) (NNS requirements)))) (PP (IN during) (NP (NP (DT the) (NN training)) (CC and) (NP (NN inference) (NNS phases))))))) (. .))
