(S (NP (JJ Traditional) (JJ model-based) (NN reinforcement) (VBG learning) (NNS approaches)) (VP (VBP learn) (NP (NP (DT a) (NN model)) (PP (IN of) (NP (DT the) (NN environment) (NNS dynamics)))) (PP (IN without) (S (VP (ADVP (RB explicitly)) (VBG considering) (SBAR (WHADVP (WRB how)) (S (NP (PRP it)) (VP (MD will) (VP (VB be) (VP (VBN used) (PP (IN by) (NP (DT the) (NN agent)))))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (JJ misspecified) (NN model) (NNS classes))))) (, ,) (NP (DT this)) (VP (MD can) (VP (VB lead) (PP (TO to) (NP (JJ poor) (NNS estimates))) (, ,) (SBAR (IN as) (S (NP (DT some) (JJ relevant) (JJ available) (NN information)) (VP (VBZ is) (VP (VBN ignored))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ novel) (JJ model-based) (NN policy) (NN search) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ exploits) (NP (NP (DT the) (NN knowledge)) (PP (IN of) (NP (DT the) (JJ current) (NN agent) (NN policy)))) (S (VP (TO to) (VP (VB learn) (NP (DT an) (JJ approximate) (NN transition) (NN model)) (, ,) (S (VP (VBG focusing) (PP (IN on) (NP (NP (DT the) (NNS portions)) (PP (IN of) (NP (DT the) (NN environment))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RBS most) (JJ relevant) (PP (IN for) (NP (NN policy) (NN improvement))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP leverage) (NP (NP (DT a) (NN weighting) (NN scheme)) (, ,) (VP (VBN derived) (PP (IN from) (NP (NP (DT the) (NN minimization)) (PP (IN of) (NP (NP (DT the) (NN error)) (PP (IN on) (NP (DT the) (JJ model-based) (NN policy) (NN gradient) (NN estimator)))))))) (, ,)) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB define) (NP (NP (DT a) (JJ suitable) (JJ objective) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (VBN optimized) (PP (IN for) (S (VP (VBG learning) (NP (DT the) (JJ approximate) (NN transition) (NN model))))))))))))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (PRP we)) (VP (VBP integrate) (NP (DT this) (NN procedure)) (PP (IN into) (NP (NP (DT a) (NN batch) (NN policy) (NN improvement) (NN algorithm)) (, ,) (VP (VBN named) (S (NP (NP (NNP Gradient-Aware) (JJ Model-based) (NNP Policy) (NNP Search)) (PRN (-LRB- -LRB-) (NP (NNP GAMPS)) (-RRB- -RRB-))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (ADVP (RB iteratively)) (VBZ learns) (NP (DT a) (NN transition) (NN model))) (CC and) (VP (VBZ uses) (NP (PRP it)) (, ,) (ADVP (RB together) (PP (IN with) (NP (DT the) (JJ collected) (NNS trajectories)))) (, ,) (S (VP (TO to) (VP (VB compute) (NP (DT the) (JJ new) (NN policy) (NNS parameters)))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (ADVP (RB empirically)) (VBP validate) (NP (NNP GAMPS)) (PP (IN on) (NP (NP (NN benchmark) (NNS domains)) (VP (VBG analyzing) (CC and) (VBG discussing) (NP (PRP$ its) (NNS properties)))))) (. .))
