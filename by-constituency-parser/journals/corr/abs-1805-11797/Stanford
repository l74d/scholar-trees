(S (NP (NML (JJ Long) (JJ short) (HYPH -) (NN term)) (NN memory) (PRN (-LRB- -LRB-) (NP (NN LSTM)) (-RRB- -RRB-))) (VP (VBZ has) (VP (VBN been) (ADVP (RB widely)) (VP (VBN used) (PP (IN for) (NP (JJ sequential) (NNS data) (NN modeling)))))) (. .))
(S (NP (NNS Researchers)) (VP (VBP have) (VP (VBN increased) (NP (NNP LSTM) (NN depth)) (PP (IN by) (S (VP (VBG stacking) (NP (NN LSTM) (NNS cells)) (S (VP (TO to) (VP (VB improve) (NP (NN performance)))))))))) (. .))
(S (NP (DT This)) (VP (VP (VBZ incurs) (NP (NN model) (NN redundancy))) (, ,) (VP (VBZ increases) (NP (NML (NN run) (HYPH -) (NN time)) (NN delay))) (, ,) (CC and) (VP (VBZ makes) (S (NP (DT the) (NNPS LSTMs)) (ADJP (RBR more) (JJ prone) (PP (IN to) (S (VP (VBG overfitting)))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS problems))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NML (JJ hidden) (HYPH -) (NN layer)) (NN LSTM) (PRN (-LRB- -LRB-) (NP (NN H) (HYPH -) (NN LSTM)) (-RRB- -RRB-))) (SBAR (WHNP (WDT that)) (S (VP (VBZ adds) (NP (JJ hidden) (NNS layers)) (PP (IN to) (NP (NP (NNP LSTM) (POS 's)) (JJ original) (NML (CD one) (NN level)) (JJ non-linear) (NN control) (NNS gates)))))))) (. .))
(FRAG (NP (NML (NN H) (HYPH -) (NN LSTM)) (NNS increases)) (NP (NN accuracy)) (SBAR (IN while) (S (S (VP (VBG employing) (NP (NP (JJR fewer) (JJ external)) (VP (VBN stacked) (NP (NNS layers)) (, ,) (S (ADVP (RB thus)) (VP (VBG reducing) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS parameters)))))))))) (CC and) (S (VP (VB run) (HYPH -) (NP (NN time) (NN latency)) (ADVP (RB significantly)))))) (. .))
(S (NP (PRP We)) (VP (VBP employ) (S (VP (VB grow) (HYPH -) (CC and) (HYPH -) (VB prune)) (NP (NP (-LRB- -LRB-) (NNP GP) (-RRB- -RRB-)) (NP (NN training)))) (PP (IN to) (S (ADVP (RB iteratively)) (VP (VB adjust) (NP (NP (DT the) (ADJP (NP (NP (JJ hidden) (NNS layers)) (PP (IN through) (NP (NN gradient)))) (HYPH -) (VBN based)) (ADJP (NP (NN growth) (CC and) (NN magnitude)) (HYPH -) (VBN based)) (NN pruning)) (PP (IN of) (NP (NNS connections)))))))) (. .))
(S (NP (DT This)) (VP (VBZ learns) (NP (CC both) (NP (DT the) (NNS weights)) (CC and) (NP (NP (DT the) (JJ compact) (NN architecture)) (PP (IN of) (NP (NML (NN H) (HYPH -) (NN LSTM)) (NN control) (NNS gates)))))) (. .))
(S (NP (PRP We)) (VP (VBP have) (NP (NP (ADJP (NNP GP) (HYPH -) (VBN trained)) (NML (NN H) (HYPH -)) (NNS LSTMs)) (PP (IN for) (NP (NML (NML (NN image) (NN captioning)) (CC and) (NML (NN speech) (NN recognition))) (NNS applications))))) (. .))
(S (PP (IN For) (NP (NP (DT the) (NNP NeuralTalk) (NN architecture)) (PP (IN on) (NP (DT the) (NNP MSCOCO) (NN dataset))))) (, ,) (NP (PRP$ our) (CD three) (NNS models)) (VP (VBP reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS parameters)))) (UCP (PP (IN by) (NP (NP (CD 38.7) (NN x)) (-LRB- [) (NP (NP (NP (NML (VBG floating) (HYPH -) (NN point)) (NNS operations)) (-LRB- -LRB-) (NP (NNS FLOPs)) (-RRB- -RRB-)) (PP (IN by) (NP (QP (CD 45.5) (SYM x))))) (-RRB- ]))) (, ,) (S (VP (VB run) (HYPH -) (NP (NN time) (NN latency)) (PP (IN by) (NP (CD 4.5) (NN x)))) (, ,) (CC and) (VP (VB improve) (NP (DT the) (NN CIDEr) (NN score)) (PP (IN by) (NP (CD 2.6))))))) (. .))
(S (PP (IN For) (NP (NP (DT the) (NN DeepSpeech2) (NN architecture)) (PP (IN on) (NP (DT the) (NN AN4) (NN dataset))))) (, ,) (NP (PRP$ our) (CD two) (NNS models)) (VP (VBP reduce) (NP (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS parameters)) (PP (IN by) (NP (QP (CD 19.4) (SYM x))))))) (-LRB- -LRB-) (NP (NP (NNS FLOPs)) (PP (IN by) (NP (CD 23.5))) (NP (LST (LS x) (-RRB- -RRB-)) (, ,) (NP (NP (ADJP (VB run) (HYPH -) (NN time)) (NN latency)) (PP (IN by) (NP (CD 15.7) (NN %)))))) (, ,) (CC and) (NP (NP (DT the) (NN word) (NN error) (NN rate)) (PP (IN from) (NP (QP (CD 12.9) (NN %) (IN to) (CD 8.7) (NN %))))))) (. .))
(S (ADVP (RB Thus)) (, ,) (NP (ADJP (NNP GP) (HYPH -) (VBN trained)) (NML (NN H) (HYPH -)) (NNS LSTMs)) (VP (MD can) (VP (VB be) (VP (VP (VBN seen) (S (VP (TO to) (VP (VB be) (ADJP (JJ compact)) (, ,) (ADVP (RB fast)))))) (, ,) (CC and) (VP (ADJP (JJ accurate)))))) (. .))
