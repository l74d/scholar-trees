(S (NP (DT This) (NN paper)) (VP (VBZ describes) (NP (NP (DT an) (NN improvement)) (PP (IN in) (NP (NP (JJ Deep) (NML (NN Q) (HYPH -) (NN learning))) (VP (VBN called) (NP (NP (NNP Reverse) (NML (NML (NNP Experience) (NNP Replay)) (-LRB- -LRB-) (RRC (ADVP (RB also)) (NP (NNP RER))) (-RRB- -RRB-))) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ solves) (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (JJ sparse) (NNS rewards))))) (CC and) (VP (VBZ helps) (S (VP (TO to) (VP (VB deal) (PP (IN with) (NP (NN reward))) (S (VP (VBG maximizing) (NP (NNS tasks)) (PP (IN by) (NP (NN sampling) (NNS transitions))) (PP (ADVP (RB successively)) (IN in) (NP (JJ reverse) (NN order)))))))))))))))))) (. .))
(S (PP (IN On) (NP (NP (NNS tasks)) (PP (IN with) (NP (NP (NP (JJ enough) (NN experience)) (PP (IN for) (NP (NN training)))) (CC and) (NP (NP (JJ enough) (NN Experience)) (NP (NML (NNP Replay) (NN memory)) (NN capacity))))))) (, ,) (NP (NP (JJ Deep) (NML (NN Q) (HYPH -) (NML (VBG learning) (NNP Network)))) (PP (IN with) (NP (NNP Reverse) (NML (NNP Experience) (NNP Replay))))) (VP (VBZ shows) (NP (NP (JJ competitive) (NNS results)) (PP (IN against) (NP (DT both) (JJ Double) (NN DQN)))) (, ,) (PP (IN with) (NP (DT a) (JJ standard) (NN Experience) (NML (NML (NNP Replay)) (, ,) (CC and) (NML (NN vanilla))) (NN DQN)))) (. .))
(S (ADVP (RB Also)) (, ,) (NP (NNP RER)) (VP (VBZ achieves) (NP (NP (ADJP (RB significantly) (VBN increased)) (NNS results)) (PP (IN in) (NP (NP (NNS tasks)) (PP (IN with) (NP (NP (NP (DT a) (NN lack)) (PP (IN of) (NP (NN experience)))) (CC and) (NP (NML (NNP Replay) (NN memory)) (NN capacity)))))))) (. .))
