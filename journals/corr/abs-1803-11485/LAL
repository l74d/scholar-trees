(S (PP (IN In) (NP (JJ many) (JJ real-world) (NNS settings))) (, ,) (NP (NP (DT a) (NN team)) (PP (IN of) (NP (NNS agents)))) (VP (MD must) (VP (VB coordinate) (NP (PRP$ their) (NN behaviour)) (SBAR (IN while) (S (VP (VBG acting) (PP (IN in) (NP (DT a) (JJ decentralised) (NN way)))))))) (. .))
(S (PP (IN At) (NP (DT the) (JJ same) (NN time))) (, ,) (NP (NP (PRP it))) (VP (VBZ is) (ADVP (RB often)) (ADJP (JJ possible)) (S (VP (TO to) (VP (VB train) (NP (DT the) (NNS agents)) (PP (IN in) (NP (DT a) (JJ centralised) (NN fashion))) (PP (IN in) (NP (NP (DT a) (ADJP (JJ simulated) (CC or) (JJ laboratory)) (NN setting)) (, ,) (SBAR (WHADVP (WRB where)) (S (S (NP (JJ global) (NN state) (NN information)) (VP (VBZ is) (ADJP (JJ available)))) (CC and) (S (NP (NN communication) (NNS constraints)) (VP (VBP are) (VP (VBN lifted)))))))))))) (. .))
(S (S (S (VP (VBG Learning) (NP (NP (JJ joint) (NNS action-values)) (VP (VBN conditioned) (PP (IN on) (NP (JJ extra) (NN state) (NN information))))))) (VP (VBZ is) (NP (NP (DT an) (JJ attractive) (NN way)) (SBAR (S (VP (TO to) (VP (VB exploit) (NP (JJ centralised) (NN learning))))))))) (, ,) (CC but) (S (NP (NP (DT the) (JJS best) (NN strategy)) (PP (IN for) (S (ADVP (RB then)) (VP (VBG extracting) (NP (VBN decentralised) (NNS policies)))))) (VP (VBZ is) (ADJP (JJ unclear)))) (. .))
(S (NP (PRP$ Our) (NN solution)) (VP (VBZ is) (NP (NP (NNP QMIX)) (, ,) (NP (NP (DT a) (JJ novel) (JJ value-based) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB train) (NP (JJ decentralised) (NNS policies)) (PP (IN in) (NP (DT a) (JJ centralised) (JJ end-to-end) (NN fashion)))))))))) (. .))
(S (NP (NNP QMIX)) (VP (VBZ employs) (NP (NP (DT a) (NN network)) (SBAR (WHNP (WDT that)) (S (VP (VBZ estimates) (NP (JJ joint) (NNS action-values)) (PP (IN as) (NP (NP (DT a) (JJ complex) (JJ non-linear) (NN combination)) (PP (IN of) (NP (NP (JJ per-agent) (NNS values)) (SBAR (WHNP (IN that)) (S (VP (NN condition) (PP (ADVP (RB only)) (IN on) (NP (JJ local) (NNS observations))))))))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB structurally)) (VBP enforce) (SBAR (IN that) (S (NP (DT the) (NN joint-action) (NN value)) (VP (VBZ is) (ADJP (JJ monotonic)) (PP (IN in) (NP (DT the) (JJ per-agent) (NNS values)))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ allows) (NP (NP (JJ tractable) (NN maximisation)) (PP (IN of) (NP (DT the) (JJ joint) (JJ action-value))) (PP (IN in) (NP (NN off-policy) (NN learning))))) (, ,) (CC and) (VP (NNS guarantees) (NP (NP (VBP consistency)) (PP (IN between) (NP (DT the) (ADJP (JJ centralised) (CC and) (JJ decentralised)) (NNS policies))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (NNP QMIX)) (PP (IN on) (NP (NP (DT a) (JJ challenging) (NN set)) (PP (IN of) (NP (NNP StarCraft) (NNP II) (NN micromanagement) (NNS tasks)))))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (NNP QMIX)) (VP (ADVP (RB significantly)) (VBZ outperforms) (NP (VBG existing) (JJ value-based) (JJ multi-agent) (NN reinforcement) (VBG learning) (NNS methods))))))) (. .))
