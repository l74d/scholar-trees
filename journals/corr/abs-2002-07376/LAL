(S (S (NP (NN Overparameterization)) (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB benefit) (NP (NP (DT both) (DT the) (NN optimization) (CC and) (NN generalization)) (PP (IN of) (NP (JJ neural) (NNS networks))))))))))) (, ,) (CC but) (S (NP (JJ large) (NNS networks)) (VP (VBP are) (ADJP (JJ resource) (NN hungry)) (PP (IN at) (NP (DT both) (NN training) (CC and) (NN test) (NN time))))) (. .))
(S (NP (NNP Network) (VBG pruning)) (VP (VP (MD can) (VP (VB reduce) (NP (JJ test-time) (NN resource) (NNS requirements)))) (, ,) (CC but) (VP (VP (VBZ is) (ADVP (RB typically)) (VP (VBN applied) (PP (TO to) (NP (VBN trained) (NNS networks))))) (CC and) (ADVP (RB therefore)) (VP (MD can) (RB not) (VP (VB avoid) (NP (DT the) (JJ expensive) (NN training) (NN process)))))) (. .))
(S (NP (PRP We)) (VP (VBP aim) (S (VP (TO to) (VP (VB prune) (NP (NNS networks)) (PP (IN at) (NP (NN initialization))) (, ,) (S (ADVP (RB thereby)) (VP (VBG saving) (NP (NNS resources)) (PP (IN at) (NP (NN training) (NN time))) (ADVP (IN as) (RB well)))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP argue) (SBAR (IN that) (S (NP (JJ efficient) (NN training)) (VP (VBZ requires) (S (VP (VBG preserving) (NP (NP (DT the) (NN gradient) (NN flow)) (PP (IN through) (NP (DT the) (NN network)))))))))) (. .))
(S (NP (DT This)) (VP (VBZ leads) (PP (TO to) (NP (NP (DT a) (ADJP (JJ simple) (CC but) (JJ effective)) (NN pruning) (NN criterion)) (SBAR (S (NP (PRP we)) (VP (NN term) (S (NP (S (NP (NNP Gradient) (NNP Signal) (NNP Preservation))) (PRN (-LRB- -LRB-) (NP (NNP GraSP)) (-RRB- -RRB-)))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB empirically)) (VBP investigate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (DT the) (VBN proposed) (NN method)))) (PP (IN with) (NP (NP (JJ extensive) (NNS experiments)) (PP (IN on) (NP (NP (NNP CIFAR-10)) (, ,) (NP (NNP CIFAR-100)) (, ,) (NP (NNP Tiny-ImageNet)) (CC and) (NP (NNP ImageNet)))) (, ,) (S (VP (VBG using) (NP (NNP VGGNet) (CC and) (NNP ResNet) (NNS architectures))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (MD can) (VP (VB prune) (NP (NP (CD 80) (NN %)) (PP (IN of) (NP (NP (DT the) (NNS weights)) (PP (IN of) (NP (NP (DT a) (NNP VGG-16) (NN network)) (PP (IN on) (NP (NNP ImageNet)))))))) (PP (IN at) (NP (NN initialization))) (, ,) (PP (IN with) (NP (NP (RB only) (DT a) (ADJP (CD 1.6) (NN %)) (NN drop)) (PP (IN in) (NP (JJ top-1) (NN accuracy))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP$ our) (NN method)) (VP (VBZ achieves) (NP (NP (ADJP (RB significantly) (JJR better)) (NN performance)) (PP (IN than) (NP (DT the) (NN baseline)))) (PP (IN at) (NP (JJ extreme) (NN sparsity) (NNS levels)))) (. .))
