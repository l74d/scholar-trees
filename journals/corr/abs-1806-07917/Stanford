(S (NP (NP (DT The) (NN scope)) (PP (IN of) (NP (DT the) (NNP Baldwin) (NN effect)))) (VP (VBD was) (ADVP (RB recently)) (VP (VBN called) (PP (IN into) (NP (NN question))) (PP (IN by) (NP (NP (CD two) (NNS papers)) (SBAR (WHNP (WDT that)) (S (ADVP (RB closely)) (VP (VBD examined) (NP (NP (DT the) (JJ seminal) (NN work)) (PP (IN of) (NP (NNP Hinton) (CC and) (NNP Nowlan))))))))))) (. .))
(S (PP (IN To) (NP (DT this) (NN date))) (NP (RB there)) (VP (VBZ has) (VP (VBN been) (NP (NP (DT no) (NN demonstration)) (PP (IN of) (NP (PRP$ its) (NN necessity)))) (PP (IN in) (NP (ADJP (ADVP (RB empirically)) (JJ challenging)) (NNS tasks))))) (. .))
(S (ADVP (RB Here)) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NNP Baldwin) (NN effect)) (VP (VBZ is) (NP (ADJP (JJ capable) (PP (IN of) (S (VP (VP (VBG evolving) (ADJP (NP (JJ few) (HYPH -) (NN shot)) (JJ supervised))) (CC and) (VP (NN reinforcement) (VBG learning)))))) (NNS mechanisms))))) (, ,) (PP (IN by) (S (VP (VBG shaping) (NP (NP (DT the) (NNS hyperparameters)) (CC and) (NP (NP (DT the) (JJ initial) (NNS parameters)) (PP (IN of) (NP (NML (JJ deep) (NN learning)) (NNS algorithms))))))))) (. .))
(S (ADVP (RB Furthermore)) (NP (PRP it)) (VP (MD can) (ADVP (RB genetically)) (VP (VB accommodate) (NP (JJ strong) (NN learning) (NNS biases)) (PP (IN on) (NP (NP (DT the) (JJ same) (NN set)) (PP (IN of) (NP (NNS problems))))) (PP (IN as) (NP (NP (DT a) (JJ recent) (NN machine)) (VP (VBG learning) (NP (NP (NN algorithm)) (VP (VBN called) (NP (NP (NNP MAML) (`` ") (NNP Model) (NNP Agnostic) (NNP Meta) (HYPH -) (NNP Learning) ('' ")) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NP (NML (RB second) (HYPH -) (NN order)) (NNS gradients)) (PP (RB instead) (IN of) (NP (NN evolution)))) (S (VP (TO to) (VP (VB learn) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NP (NN reference) (NNS parameters)) (-LRB- -LRB-) (NP (JJ initial) (NNS weights)) (-RRB- -RRB-)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB allow) (NP (JJ rapid) (NN adaptation)) (PP (IN to) (NP (NP (NNS tasks)) (VP (VBN sampled) (PP (IN from) (NP (DT a) (NN distribution))))))))))))))))))))))))))) (. .))
(S (SBAR (IN Whilst) (S (PP (IN in) (NP (JJ simple) (NNS cases))) (NP (NNP MAML)) (VP (VBZ is) (ADVP (RBR more) (NP (NNS data))) (ADJP (JJ efficient) (PP (IN than) (NP (DT the) (NNP Baldwin) (NN effect))))))) (, ,) (NP (DT the) (NNP Baldwin) (NN effect)) (VP (VBZ is) (ADJP (RBR more) (JJ general) (PP (IN in) (SBAR (IN that) (S (NP (PRP it)) (VP (VP (VBZ does) (RB not) (VP (VB require) (NP (NNS gradients)) (S (VP (TO to) (VP (VB be) (VP (VBN backpropagated) (PP (IN to) (NP (DT the) (NN reference) (NNS parameters) (CC or) (NNS hyperparameters))))))))) (, ,) (CC and) (VP (VBZ permits) (ADVP (RB effectively)) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (NP (NN gradient) (NNS updates)) (PP (IN in) (NP (DT the) (JJ inner) (NN loop))))))))))))) (. .))
(S (NP (DT The) (NNP Baldwin) (NN effect)) (VP (VBZ learns) (NP (NP (JJ strong) (ADJP (NN learning) (JJ dependent)) (NNS biases)) (, ,) (CONJP (RB rather) (IN than)) (NP (ADVP (RB purely)) (NP (ADJP (RB genetically) (VBG accommodating)) (VBN fixed) (NNS behaviours)) (PP (IN in) (NP (DT a) (NN learning) (JJ independent) (NN manner)))))) (. .))
