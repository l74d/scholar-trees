(S (NP (NP (DT The) (NN scope)) (PP (IN of) (NP (DT the) (NNP Baldwin) (NN effect)))) (VP (VBD was) (ADVP (RB recently)) (VP (VBN called) (PP (IN into) (NP (NN question))) (PP (IN by) (NP (NP (CD two) (NNS papers)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB closely)) (VBD examined) (NP (NP (DT the) (JJ seminal) (NN work)) (PP (IN of) (NP (NNP Hinton) (CC and) (NNP Nowlan))))))))))) (. .))
(S (PP (TO To) (NP (DT this) (NN date))) (NP (EX there)) (VP (VBZ has) (VP (VBN been) (NP (NP (DT no) (NN demonstration)) (PP (IN of) (NP (NP (PRP$ its) (NN necessity)) (PP (IN in) (NP (ADJP (RB empirically) (VBG challenging)) (NNS tasks)))))))) (. .))
(S (ADVP (RB Here)) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NNP Baldwin) (NN effect)) (VP (VBZ is) (ADJP (JJ capable) (PP (IN of) (S (VP (VBG evolving) (NP (ADJP (JJ few-shot) (VBN supervised) (CC and) (JJ reinforcement)) (NN learning) (NNS mechanisms)) (, ,) (PP (IN by) (S (VP (VBG shaping) (NP (NP (NP (DT the) (NNS hyperparameters)) (CC and) (NP (DT the) (JJ initial) (NNS parameters))) (PP (IN of) (NP (JJ deep) (NN learning) (NN algorithms))))))))))))))) (. .))
(S (ADVP (IN Furthermore)) (NP (PRP it)) (VP (MD can) (VP (ADVP (RB genetically)) (VB accommodate) (NP (NP (JJ strong) (NN learning) (NNS biases)) (PP (IN on) (NP (NP (DT the) (JJ same) (NN set)) (PP (IN of) (NP (NNS problems))) (PP (IN as) (NP (NP (DT a) (JJ recent) (NN machine) (VBG learning) (NN algorithm)) (VP (VBN called) (S (NP (NNP MAML) (`` ``) (NNP Model) (NNP Agnostic) (NNP Meta-Learning) ('' '')))) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NN second-order) (NNS gradients)) (PP (RB instead) (IN of) (NP (NN evolution))) (S (VP (TO to) (VP (VB learn) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NN reference) (NNS parameters)) (PRN (-LRB- -LRB-) (NP (JJ initial) (NNS weights)) (-RRB- -RRB-)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB allow) (NP (NP (JJ rapid) (NN adaptation)) (PP (TO to) (NP (NP (NNS tasks)) (VP (VBN sampled) (PP (IN from) (NP (DT a) (NN distribution))))))))))))))))))))))))))) (. .))
(S (SBAR (NNP Whilst) (S (PP (IN in) (NP (JJ simple) (NNS cases))) (NP (NNP MAML)) (VP (VBZ is) (ADJP (ADJP (JJR more) (NNS data) (NN efficient)) (PP (IN than) (NP (DT the) (NNP Baldwin) (NN effect))))))) (, ,) (NP (DT the) (NNP Baldwin) (NN effect)) (VP (VBZ is) (ADJP (RBR more) (JJ general)) (SBAR (IN in) (DT that) (S (NP (PRP it)) (VP (VP (VBZ does) (RB not) (VP (VB require) (S (NP (NNS gradients)) (VP (TO to) (VP (VB be) (VP (VBN backpropagated) (PP (TO to) (NP (DT the) (NN reference) (NNS parameters) (CC or) (NNS hyperparameters))))))))) (, ,) (CC and) (VP (NNS permits) (ADVP (RB effectively)) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (JJ gradient) (NNS updates))) (PP (IN in) (NP (DT the) (JJ inner) (NN loop))))))))) (. .))
(S (NP (DT The) (NNP Baldwin) (NN effect)) (VP (VBZ learns) (NP (NP (JJ strong) (ADJP (VBG learning) (JJ dependent)) (NNS biases)) (, ,) (PP (RB rather) (IN than) (S (VP (ADVP (RB purely) (RB genetically)) (VBG accommodating) (NP (VBN fixed) (NNS behaviours)) (PP (IN in) (NP (DT a) (ADJP (JJ learning) (JJ independent)) (NN manner)))))))) (. .))
