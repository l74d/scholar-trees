(S (NP (NNP Cross) (NN entropy)) (VP (VBZ is) (NP (NP (DT the) (ADJP (RBS most) (RB widely) (JJ used)) (NN loss) (NN function)) (PP (IN for) (NP (NP (JJ supervised) (NN training)) (PP (IN of) (NP (NML (NN image) (NN classification)) (NNS models))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN training) (NN methodology)) (SBAR (WHNP (WDT that)) (S (ADVP (RB consistently)) (VP (VBZ outperforms) (NP (NP (NN cross) (NN entropy)) (PP (IN on) (NP (JJ supervised) (NML (NML (NN learning) (NNS tasks)) (PP (IN across) (NP (JJ different) (NNS architectures) (CC and) (NNS data)))) (NNS augmentations))))))))) (. .))
(S (NP (PRP We)) (VP (VBP modify) (NP (NP (DT the) (NN batch) (JJ contrastive) (NN loss)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (ADVP (RB recently)) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (RB very) (JJ effective) (PP (IN at) (S (VP (VBG learning) (NP (JJ powerful) (NNS representations)) (PP (IN in) (NP (DT the) (ADJP (NN self) (HYPH -) (JJ supervised)) (NN setting))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP are) (ADVP (RB thus)) (ADJP (JJ able) (S (VP (TO to) (VP (VB leverage) (NP (NN label) (NN information)) (ADVP (ADVP (RBR more) (RB effectively)) (SBAR (IN than) (S (VP (VB cross) (NP (NN entropy))))))))))) (. .))
(S (NP (NP (NNS Clusters)) (PP (IN of) (NP (NP (NNS points)) (VP (VBG belonging) (PP (IN to) (NP (DT the) (JJ same) (NN class))))))) (VP (VBP are) (VP (VBN pulled) (ADVP (RB together)) (PP (IN in) (NP (VBG embedding) (NN space))) (, ,) (SBAR (IN while) (S (ADVP (RB simultaneously)) (VP (VBG pushing) (PRT (RB apart)) (NP (NP (NNS clusters)) (PP (IN of) (NP (NP (NNS samples)) (PP (IN from) (NP (JJ different) (NNS classes))))))))))) (. .))
(S (PP (IN In) (NP (NP (NN addition)) (PP (IN to) (NP (DT this))))) (, ,) (NP (PRP we)) (VP (VP (VBP leverage) (NP (NP (JJ key) (NNS ingredients)) (PP (JJ such) (IN as) (NP (JJ large) (NN batch) (NNS sizes))))) (CC and) (VP (VBN normalized) (NP (NP (NNS embeddings)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB benefit) (NP (ADJP (NN self) (HYPH -) (JJ supervised)) (NN learning))))))))))))) (. .))
(S (PP (IN On) (NP (DT both) (NML (NML (NNP ResNet) (HYPH -) (CD 50)) (CC and) (NML (NNP ResNet) (HYPH -) (CD 200))))) (, ,) (NP (PRP we)) (VP (VBP outperform) (NP (NN cross) (NN entropy)) (PP (IN by) (NP (IN over) (CD 1) (NN %))) (, ,) (S (VP (VBG setting) (NP (NP (DT a) (JJ new) (NN state)) (PP (IN of) (NP (NP (DT the) (NN art) (NN number)) (PP (IN of) (NP (CD 78.8) (NN %)))))) (PP (IN among) (NP (NP (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (NML (NNP AutoAugment) (NNS data)) (NN augmentation)))))))))) (. .))
(S (NP (DT The) (NN loss)) (ADVP (RB also)) (VP (VBZ shows) (NP (NP (JJ clear) (NNS benefits)) (PP (IN for) (NP (NN robustness)))) (PP (IN to) (NP (NP (JJ natural) (NNS corruptions)) (PP (IN on) (NP (NP (JJ standard) (NNS benchmarks)) (PP (IN on) (NP (DT both) (NN calibration) (CC and) (NN accuracy)))))))) (. .))
(S (PP (VBN Compared) (SBAR (S (VP (TO to) (VP (VB cross) (NP (NN entropy))))))) (, ,) (NP (PRP$ our) (JJ supervised) (JJ contrastive) (NN loss)) (VP (VBZ is) (ADJP (ADJP (RBR more) (JJ stable)) (PP (IN to) (NP (NP (NN hyperparameter) (NNS settings)) (PP (JJ such) (IN as) (NP (NP (NNS optimizers)) (CC or) (NP (NNS data) (NNS augmentations)))))))) (. .))
