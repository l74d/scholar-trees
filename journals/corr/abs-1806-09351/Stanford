(S (NP (NP (DT The) (ADJP (RBS most) (NN data) (HYPH -) (JJ efficient)) (NNS algorithms)) (PP (IN for) (NP (NP (NN reinforcement) (NN learning)) (PP (IN in) (NP (NNS robotics)))))) (VP (VBP are) (NP (ADJP (NP (NN model)) (HYPH -) (VBN based)) (NN policy) (NN search) (NNS algorithms) (, ,) (SBAR (WHNP (WDT which)) (S (NP (NP (NN alternate)) (PP (IN between) (S (VP (VP (VBG learning) (NP (NP (DT a) (JJ dynamical) (NN model)) (PP (IN of) (NP (DT the) (NN robot))))) (CC and) (VP (VBG optimizing) (NP (DT a) (NN policy))))))) (VP (TO to) (VP (VB maximize) (NP (DT the) (VBN expected) (NN return)) (PP (VBN given) (NP (NP (DT the) (NN model)) (CC and) (NP (PRP$ its) (NNS uncertainties)))))))))) (. .))
(S (S (ADVP (RB However)) (, ,) (NP (DT the) (JJ current) (NNS algorithms)) (VP (VBP lack) (NP (DT an) (JJ effective) (NN exploration) (NN strategy)) (S (VP (TO to) (VP (VB deal) (PP (IN with) (NP (ADJP (JJ sparse) (CC or) (JJ misleading)) (NN reward) (NNS scenarios)))))))) (: :) (S (SBAR (IN if) (S (NP (PRP they)) (VP (VBP do) (RB not) (VP (VB experience) (NP (NP (DT any) (NN state)) (PP (IN with) (NP (DT a) (JJ positive) (NN reward)))) (PP (IN during) (NP (DT the) (JJ initial) (JJ random) (NN exploration))))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (RB very) (JJ unlikely)) (S (VP (TO to) (VP (VB solve) (NP (DT the) (NN problem))))))) (. .))
(S (ADVP (RB Here)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (ADJP (NP (JJ novel) (NN model)) (HYPH -) (VBN based)) (NML (NN policy) (NN search)) (NN algorithm)) (, ,) (NP (NN Multi-DEX))) (, ,) (SBAR (IN that) (S (VP (VBZ leverages) (NP (NP (DT a)) (VP (VBN learned) (NP (JJ dynamical) (NN model)) (S (VP (TO to) (ADVP (RB efficiently)) (VP (VP (VB explore) (NP (DT the) (NN task) (NN space))) (CC and) (VP (VB solve) (NP (NNS tasks)) (PP (IN with) (NP (NP (JJ sparse) (NNS rewards)) (PP (IN in) (NP (DT a) (JJ few) (NNS episodes))))))))))))))) (. .))
(S (S (VP (TO To) (VP (VB achieve) (NP (DT this))))) (, ,) (NP (PRP we)) (VP (VBP frame) (NP (NP (DT the) (NML (NN policy) (NN search)) (NN problem)) (PP (IN as) (NP (NP (DT a) (JJ multi-objective) (, ,) (ADJP (NP (NN model)) (HYPH -) (VBN based)) (NML (NN policy) (NN optimization)) (NN problem)) (PP (IN with) (NP (CD three) (NNS objectives)))))) (: :) (S (S (LST (-LRB- -LRB-) (LS 1) (-RRB- -RRB-)) (VP (VB generate) (ADVP (RB maximally)) (NP (JJ novel) (NN state) (NNS trajectories)))) (, ,) (S (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (VP (VP (VB maximize) (NP (DT the) (VBN expected) (NN return))) (CC and) (VP (LST (-LRB- -LRB-) (LS 3) (-RRB- -RRB-)) (VB keep) (NP (NP (DT the) (NN system)) (PP (IN in) (NP (NML (NN state) (HYPH -) (NN space)) (NNS regions))))) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (DT the) (NN model)) (VP (VBZ is) (ADJP (ADJP (IN as) (JJ accurate)) (PP (IN as) (ADJP (JJ possible))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VBP optimize) (NP (DT these) (NNS objectives)) (S (VP (VBG using) (NP (DT a) (ADJP (NP (NN Pareto)) (HYPH -) (VBN based)) (JJ multi-objective) (NN optimization) (NN algorithm))))) (. .))
(S (NP (DT The) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP Multi-DEX)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB solve) (NP (NP (JJ sparse) (NN reward) (NNS scenarios)) (-LRB- -LRB-) (PP (IN with) (NP (DT a) (JJ simulated) (JJ robotic) (NN arm))) (-RRB- -RRB-)) (PP (IN in) (NP (ADJP (RB much) (JJR lower)) (NN interaction) (NN time))) (PP (IN than) (NP (NML (NML (NN VIME)) (, ,) (NML (NN TRPO)) (, ,) (NML (NN GEP) (HYPH -) (NN PG)) (, ,) (NML (NN CMA) (HYPH -) (NN ES)) (CC and) (NML (JJ Black))) (HYPH -) (NN DROPS))))))))))) (. .))
