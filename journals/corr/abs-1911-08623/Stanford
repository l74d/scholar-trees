(S (SBAR (IN Although) (S (NP (JJ deep) (NN learning)) (VP (VBZ has) (VP (VBN been) (VP (VBN applied) (S (VP (TO to) (ADVP (RB successfully)) (VP (VB address) (NP (JJ many) (NML (NNS data) (NN mining)) (NNS problems)))))))))) (, ,) (NP (ADJP (RB relatively) (JJ limited)) (NN work)) (VP (VBZ has) (VP (VBN been) (VP (VBN done) (PP (IN on) (NP (NP (JJ deep) (NN learning)) (PP (IN for) (NP (NN anomaly) (NN detection)))))))) (. .))
(S (NP (NP (VBG Existing) (NML (JJ deep) (NN anomaly) (NN detection)) (NNS methods)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP focus) (PP (IN on) (S (VP (VBG learning) (NP (JJ new) (NN feature) (NNS representations)) (S (VP (TO to) (VP (VB enable) (NP (JJ downstream) (NN anomaly) (NN detection) (NNS methods))))))))))) (, ,)) (VP (VB perform) (NP (NP (NP (JJ indirect) (NN optimization)) (PP (IN of) (NP (NN anomaly) (NNS scores)))) (, ,) (VP (VBG leading) (PP (IN to) (NP (NP (ADJP (NN data) (HYPH -) (JJ inefficient)) (NN learning)) (CC and) (NP (JJ suboptimal) (NN anomaly) (NN scoring))))))) (. .))
(S (ADVP (RB Also)) (, ,) (NP (PRP they)) (VP (VBP are) (ADVP (RB typically)) (VP (VBN designed) (PP (IN as) (NP (JJ unsupervised) (NN learning))) (PP (IN due) (IN to) (NP (NP (DT the) (NN lack)) (PP (IN of) (NP (NML (JJ large) (HYPH -) (NN scale)) (VBN labeled) (NN anomaly) (NNS data))))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (NP (PRP they)) (VP (VBP are) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB leverage) (NP (NP (NP (JJ prior) (NN knowledge)) (-LRB- -LRB-) (NP (ADVP (FW e.g.)) (, ,) (NP (NP (QP (DT a) (JJ few))) (VP (VBN labeled) (NP (NNS anomalies))))) (-RRB- -RRB-)) (SBAR (WHADVP (WRB when)) (S (NP (JJ such) (NN information)) (VP (VBZ is) (ADJP (JJ available) (PP (IN as) (PP (IN in) (NP (JJ many) (NML (JJ real) (HYPH -) (NN world)) (NN anomaly) (NN detection) (NNS applications)))))))))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ introduces) (NP (NP (DT a) (JJ novel) (NN anomaly) (NN detection) (NN framework)) (CC and) (NP (PRP$ its) (NN instantiation))) (S (VP (TO to) (VP (VB address) (NP (DT these) (NNS problems)))))) (. .))
(S (PP (RB Instead) (PP (IN of) (NP (NN representation) (NN learning)))) (, ,) (NP (PRP$ our) (NN method)) (VP (VBZ fulfills) (NP (NP (DT an) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NN learning)) (PP (IN of) (NP (NN anomaly) (NNS scores)))) (PP (IN by) (NP (NP (DT a) (NML (JJ neural) (NN deviation)) (NN learning)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBP leverage) (NP (NP (DT a) (ADJP (JJ few) (PRN (-LRB- -LRB-) (FRAG (ADVP (FW e.g.)) (, ,) (ADJP (JJ multiple) (PP (IN to) (NP (NNS dozens))))) (-RRB- -RRB-))) (VBN labeled) (NNS anomalies)) (CC and) (NP (DT a) (JJ prior) (NN probability) (S (VP (TO to) (VP (VB enforce) (NP (NP (ADJP (RB statistically) (JJ significant)) (NNS deviations)) (PP (IN of) (NP (NP (DT the) (NN anomaly) (NNS scores)) (PP (IN of) (NP (NNS anomalies)))))) (PP (IN from) (NP (NP (DT that)) (PP (IN of) (NP (NP (JJ normal) (NNS data) (NNS objects)) (PP (IN in) (NP (DT the) (JJ upper) (NN tail)))))))))))))))))) (. .))
(S (NP (JJ Extensive) (NNS results)) (VP (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (MD can) (VP (VB be) (VP (VBN trained) (NP (ADJP (RB substantially) (RBR more)) (NML (NML (NNS data)) (HYPH -) (ADVP (RB efficiently)))))))))) (CC and) (VP (VBZ achieves) (NP (NP (ADJP (RB significantly) (JJR better)) (NN anomaly) (NN scoring)) (PP (IN than) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (VBG competing) (NNS methods)))))) (. .))
