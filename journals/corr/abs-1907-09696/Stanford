(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT the) (NN trainability)) (PP (IN of) (NP (NML (NML (VBN rectified) (JJ linear) (NN unit)) (-LRB- -LRB-) (NML (NN ReLU))) (-RRB- -RRB-) (NNS networks))))) (. .))
(S (NP (DT A) (NN ReLU) (NN neuron)) (VP (VBZ is) (VP (VBN said) (S (VP (TO to) (VP (VB be) (ADJP (JJ dead) (SBAR (IN if) (FRAG (NP (PRP it)) (NP (NP (JJ only) (NNS outputs)) (NP (DT a) (JJ constant))) (PP (IN for) (NP (DT any) (NN input))))))))))) (. .))
(S (NP (NP (CD Two) (NN death) (NNS states)) (PP (IN of) (NP (NNS neurons)))) (VP (VBP are) (VP (VBN introduced) (: ;) (UCP (ADJP (JJ tentative)) (CC and) (NP (JJ permanent) (NN death))))) (. .))
(S (NP (DT A) (NN network)) (VP (VBZ is) (ADVP (RB then)) (VP (VBN said) (S (VP (TO to) (VP (VB be) (ADJP (JJ trainable)) (SBAR (IN if) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (ADJP (RB permanently) (JJ dead)) (NNS neurons)))) (VP (VBZ is) (ADJP (RB sufficiently) (JJ small) (PP (IN for) (NP (DT a) (NN learning) (NN task)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP refer) (PP (IN to) (NP (NP (DT the) (NN probability)) (PP (IN of) (NP (NP (DT a) (NN network)) (VP (VBG being) (ADJP (JJ trainable) (PP (IN as) (NP (NN trainability)))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT a) (NN network)) (VP (VBG being) (ADJP (JJ trainable)))) (VP (VBZ is) (NP (NP (DT a) (JJ necessary) (NN condition)) (PP (IN for) (NP (JJ successful) (NN training))))))))) (CC and) (S (NP (DT the) (NN trainability)) (VP (VBZ serves) (PP (IN as) (NP (NP (DT an) (JJ upper) (VBN bound)) (PP (IN of) (NP (JJ successful) (NN training) (NNS rates))))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (VP (VB quantify) (NP (DT the) (NN trainability))))))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT the) (NN probability) (NN distribution)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ active) (NNS neurons)))))) (PP (IN at) (NP (DT the) (NN initialization)))) (. .))
(S (PP (IN In) (NP (JJ many) (NNS applications))) (, ,) (S (VP (VBN over-specified) (CC or) (VBN over-parameterized) (NP (JJ neural) (NNS networks)))) (VP (VBP are) (ADVP (RB successfully)) (VP (VBN employed) (CC and) (VBN shown) (S (VP (TO to) (VP (VB be) (VP (VBN trained) (ADVP (RB effectively)))))))) (. .))
(S (PP (IN With) (NP (NP (DT the) (NN notion)) (PP (IN of) (NP (NN trainability))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NN over-parameterization)) (VP (VBZ is) (NP (CC both) (NP (DT a) (JJ necessary)) (CC and) (NP (DT a) (JJ sufficient) (NN condition))) (PP (IN for) (S (VP (VBG minimizing) (NP (DT the) (NN training) (NN loss))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (ADJP (NN data) (HYPH -) (JJ dependent)) (NN initialization) (NN method)) (PP (IN in) (NP (DT the) (JJ over-parameterized) (NN setting))))) (. .))
(S (NP (NNP Numerical) (NNS examples)) (VP (VBP are) (VP (VBN provided) (S (VP (TO to) (VP (VB demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NP (DT the) (NN method)) (CC and) (NP (PRP$ our) (JJ theoretical) (NNS findings)))))))))) (. .))
