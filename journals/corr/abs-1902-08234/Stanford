(S (NP (NP (DT The) (NN choice)) (PP (IN of) (NP (NP (NN batch) (HYPH -) (NN size)) (PP (IN in) (NP (DT a) (JJ stochastic) (NN optimization) (NN algorithm)))))) (VP (VBZ plays) (NP (NP (DT a) (JJ substantial) (NN role)) (PP (IN for) (NP (DT both) (NN optimization) (CC and) (NN generalization))))) (. .))
(S (S (VP (VBG Increasing) (NP (NP (DT the) (NN batch) (HYPH -) (NN size)) (VP (VBN used) (ADVP (RB typically)))))) (VP (VP (VBZ improves) (NP (NN optimization))) (CC but) (VP (VBZ degrades) (NP (NN generalization)))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (VBG improving) (NP (NN generalization)) (PP (IN while) (S (VP (VBG maintaining) (NP (JJ optimal) (NN convergence)) (PP (IN in) (NP (NML (JJ large) (HYPH -) (NN batch)) (NN training))))))))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB add) (NP (NN covariance) (NN noise)) (PP (IN to) (NP (DT the) (NNS gradients))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT the) (NN learning) (NN performance)) (PP (IN of) (NP (PRP$ our) (NN method)))) (VP (VBZ is) (ADVP (RBR more) (RB accurately)) (VP (VBN captured) (PP (PP (IN by) (NP (NP (DT the) (NN structure)) (PP (IN of) (NP (NP (DT the) (NN covariance) (NN matrix)) (PP (IN of) (NP (DT the) (NN noise))))))) (CONJP (RB rather) (IN than)) (PP (IN by) (NP (NP (DT the) (NN variance)) (PP (IN of) (NP (NNS gradients))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (PP (IN over) (NP (DT the) (NN convex) (HYPH -) (JJ quadratic))) (, ,) (NP (PRP we)) (VP (VBP prove) (PP (IN in) (NP (NN theory))) (SBAR (IN that) (S (NP (PRP it)) (VP (MD can) (VP (VB be) (VP (VBN characterized) (PP (IN by) (NP (NP (DT the) (NNP Frobenius) (NN norm)) (PP (IN of) (NP (DT the) (NN noise) (NN matrix))))))))))) (. .))
(S (S (NP (NP (PRP$ Our) (JJ empirical) (NNS studies)) (PP (IN with) (NP (NP (JJ standard) (NML (JJ deep) (NN learning)) (NN model) (HYPH -) (NNS architectures)) (CC and) (NP (NNS datasets))))) (VP (VBZ shows) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (CONJP (RB not) (RB only)) (VP (VBZ improves) (NP (NP (NN generalization) (NN performance)) (PP (IN in) (NP (NML (JJ large) (HYPH -) (NN batch)) (NN training))))) (, ,) (CC but) (VP (ADVP (RB furthermore)) (, ,) (VBZ does) (ADVP (RB so)) (PP (IN in) (NP (NP (DT a) (NN way)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN optimization) (NN performance)) (VP (VBZ remains) (ADJP (JJ desirable))))))))))))) (CC and) (S (NP (DT the) (NN training) (NN duration)) (VP (VBZ is) (RB not) (ADJP (VBN elongated)))) (. .))
