(S (NP (JJ Adaptive) (NN gradient)) (VP (VBZ approaches) (SBAR (IN that) (S (S (ADVP (RB automatically)) (VP (VB adjust) (NP (DT the) (NN learning) (NN rate)) (PP (IN on) (NP (DT a) (NML (PP (IN per) (HYPH -) (NP (NN feature)))) (NN basis))))) (VP (VBP have) (VP (VBN been) (ADJP (RB very) (JJ popular) (PP (IN for) (S (VP (VBG training) (NP (JJ deep) (NNS networks))))))))))) (. .))
(S (NP (NP (DT This) (JJ rich) (NN class)) (PP (IN of) (NP (NNS algorithms)))) (VP (VBZ includes) (NP (NP (NNP Adagrad)) (, ,) (NP (NNP RMSprop)) (, ,) (NP (NNP Adam)) (, ,) (CC and) (NP (JJ recent) (NNS extensions)))) (. .))
(S (NP (PDT All) (DT these) (NNS algorithms)) (VP (VBP have) (VP (VBN adopted) (NP (JJ diagonal) (NN matrix) (NN adaptation)) (, ,) (PP (IN due) (IN to) (NP (NP (DT the) (ADJP (JJ prohibitive) (JJ computational)) (NN burden)) (PP (IN of) (S (VP (VBG manipulating) (NP (JJ full) (NNS matrices)) (PP (IN in) (NP (JJ high) (HYPH -) (NNS dimensions)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NN block) (HYPH -) (JJ diagonal) (NN matrix)) (NP (NN adaptation))) (VP (MD can) (VP (VB be) (NP (NP (DT a) (ADJP (JJ practical) (CC and) (JJ powerful)) (NN solution)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (ADVP (RB effectively)) (VP (VP (VB utilize) (NP (NP (JJ structural) (NNS characteristics)) (PP (IN of) (NP (NML (JJ deep) (NN learning)) (NNS architectures))))) (, ,) (CC and) (ADVP (RB significantly)) (VP (VB improve) (NP (NP (NN convergence)) (CC and) (NP (NML (PP (ADVP (IN out)) (HYPH -) (IN of) (HYPH -) (NP (NN sample)))) (NN generalization)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (DT a) (JJ general) (NN framework)) (PP (IN with) (NP (NP (NN block)) (HYPH -) (NP (NP (JJ diagonal) (NN matrix) (NNS updates)) (PP (IN via) (NP (NP (NN coordinate) (NN grouping)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ includes) (NP (NP (NNS counterparts)) (PP (IN of) (NP (DT the) (JJ aforementioned) (NNS algorithms)))) (, ,) (S (VP (VB prove) (NP (PRP$ their) (NN convergence)) (PP (IN in) (NP (JJ non-convex) (NN optimization))) (, ,) (S (VP (VBG highlighting) (NP (NNS benefits)) (PP (VBN compared) (PP (IN to) (NP (JJ diagonal) (NNS versions))))))))))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (ADJP (NP (JJ efficient) (NN spectrum)) (HYPH -) (VBG clipping)) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (VBZ benefits) (PP (IN from) (NP (NP (JJ superior) (NN generalization) (NN performance)) (PP (IN of) (NP (NNP Sgd)))))))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP reveal) (SBAR (IN that) (S (NP (NP (NN block)) (HYPH -) (NP (JJ diagonal) (NNS approaches))) (VP (VP (VBP achieve) (NP (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS results)) (PP (IN on) (NP (JJ several) (NML (JJ deep) (NN learning)) (NNS tasks))))) (, ,) (CC and) (VP (MD can) (VP (VB outperform) (NP (NP (NP (JJ adaptive) (JJ diagonal) (NNS methods)) (, ,) (NP (NN vanilla) (NNP Sgd))) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NP (DT a) (VBN modified) (NN version)) (PP (IN of) (NP (NP (NML (JJ full) (HYPH -) (NN matrix)) (NN adaptation)) (VP (VBN proposed) (ADVP (RB very) (RB recently))))))))))))) (. .))
