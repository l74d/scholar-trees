(S (NP (NNP Depthwise) (NNS convolutions)) (VP (VBP provide) (NP (JJ significant) (NN performance) (NNS benefits)) (PP (VBG owing) (PP (TO to) (NP (NP (DT the) (NN reduction)) (PP (IN in) (NP (DT both) (NNS parameters) (CC and) (NNS mult-adds))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG training) (NP (NN depthwise) (NN convolution) (NNS layers)) (PP (IN with) (NP (NNP GPUs))))) (VP (VBZ is) (ADJP (JJ slow)) (PP (IN in) (NP (JJ current) (JJ deep) (NN learning) (NNS frameworks))) (SBAR (IN because) (S (NP (PRP$ their) (NNS implementations)) (VP (MD can) (RB not) (VP (ADVP (RB fully)) (VB utilize) (NP (DT the) (NNP GPU) (NN capacity))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this) (NN problem))))) (, ,) (PP (IN in) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBD present) (NP (NP (DT an) (JJ efficient) (NN method)) (PRN (-LRB- -LRB-) (VP (VBN called) (S (NP (NN diagonalwise) (NN refactorization)))) (-RRB- -RRB-)) (PP (IN for) (S (VP (VBG accelerating) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (NN depthwise) (NN convolution) (NNS layers))))))))) (. .))
(S (NP (PRP$ Our) (JJ key) (NN idea)) (VP (VBZ is) (S (VP (TO to) (VP (VB rearrange) (NP (NP (DT the) (NN weight) (NNS vectors)) (PP (IN of) (NP (DT a) (NN depthwise) (NN convolution)))) (PP (IN into) (NP (DT a) (JJ large) (JJ diagonal) (NN weight) (NNS matrix))) (SBAR (RB so) (IN as) (S (VP (TO to) (VP (VB convert) (NP (DT the) (NN depthwise) (NN convolution)) (PP (IN into) (NP (NP (CD one) (JJ single) (NN standard) (NN convolution)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (ADVP (RB well)) (VBN supported) (PP (IN by) (NP (NP (DT the) (NN cuDNN) (NN library)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ highly-optimized) (PP (IN for) (NP (NNP GPU) (NNS computations))))))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP have) (VP (VBN implemented) (NP (PRP$ our) (NN training) (NN method)) (PP (IN in) (NP (CD five) (JJ popular) (NN deep) (NN learning) (NNS frameworks))))) (. .))
