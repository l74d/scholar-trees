(S (NP (NN Optimization) (NNS techniques)) (VP (VBP are) (PP (IN of) (NP (JJ great) (NN importance))) (PP (IN to) (ADVP (RB effectively) (CC and) (RB efficiently)) (VP (VB train) (NP (DT a) (JJ deep) (JJ neural) (NN network)) (PRN (-LRB- -LRB-) (NP (NN DNN)) (-RRB- -RRB-))))) (. .))
(S (NP (PRP It)) (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (SBAR (IN that) (S (S (VP (VBG using) (NP (DT the) (ADJP (JJ first) (CC and) (JJ second)) (NN order) (NNS statistics) (PRN (-LRB- -LRB-) (NP (ADVP (FW e.g.)) (, ,) (NN mean) (CC and) (NN variance)) (-RRB- -RRB-))) (S (VP (TO to) (VP (VB perform) (NP (NP (NML (NN Z) (HYPH -) (NN score)) (NN standardization)) (PP (IN on) (NP (NP (NN network) (NNS activations)) (CC or) (NP (NN weight) (NNS vectors)))) (, ,) (PP (JJ such) (IN as) (NP (NP (NN batch) (NN normalization) (PRN (-LRB- -LRB-) (NP (NN BN)) (-RRB- -RRB-))) (CC and) (NP (NN weight) (NN standardization) (PRN (-LRB- -LRB-) (NP (NN WS)) (-RRB- -RRB-))))))))))) (, ,) (VP (MD can) (VP (VB improve) (NP (DT the) (NN training) (NN performance))))))))) (. .))
(S (NP (NP (JJ Different)) (PP (IN from) (NP (NP (DT these) (VBG existing) (NNS methods)) (SBAR (WHNP (WDT that)) (S (ADVP (RB mostly)) (VP (VBP operate) (PP (IN on) (NP (NNS activations) (CC or) (NNS weights))))))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NP (DT a) (JJ new) (NN optimization) (NN technique)) (, ,) (RRC (ADVP (RB namely)) (NP (NN gradient) (NN centralization))) (PRN (-LRB- -LRB-) (NP (NN GC)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ operates) (ADVP (RB directly)) (PP (IN on) (NP (NNS gradients))))))) (PP (IN by) (S (VP (VBG centralizing) (NP (DT the) (NN gradient) (NNS vectors)) (S (VP (TO to) (VP (VB have) (NP (CD zero) (NN mean))))))))) (. .))
(S (NP (NN GC)) (VP (MD can) (VP (VB be) (VP (VBN viewed) (PP (IN as) (NP (NP (DT a) (VBN projected) (NN gradient) (NN descent) (NN method)) (PP (IN with) (NP (DT a) (ADJP (JJ constrained)) (NN loss) (NN function)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NN GC)) (VP (MD can) (VP (VB regularize) (NP (CC both) (NP (DT the) (NN weight) (NN space)) (CC and) (NP (NN output) (NN feature) (NN space))) (SBAR (IN so) (IN that) (S (NP (PRP it)) (VP (MD can) (VP (VB boost) (NP (NP (DT the) (NN generalization) (NN performance)) (PP (IN of) (NP (NNS DNNs))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NN GC)) (VP (VBZ improves) (NP (NP (DT the) (NN Lipschitzness)) (PP (IN of) (NP (NP (DT the) (NN loss) (NN function)) (CC and) (NP (PRP$ its) (NN gradient))))) (SBAR (IN so) (IN that) (S (NP (DT the) (NN training) (NN process)) (VP (VBZ becomes) (ADJP (RBR more) (JJ efficient) (CC and) (JJ stable)))))) (. .))
(S (NP (NN GC)) (VP (VP (VBZ is) (ADJP (RB very) (JJ simple) (S (VP (TO to) (VP (VB implement)))))) (CC and) (VP (MD can) (VP (VB be) (ADVP (RB easily)) (VP (VBN embedded) (PP (IN into) (NP (NP (VBG existing) (NN gradient)) (VP (VBN based) (NP (NNP DNN) (NNS optimizers)) (PP (IN with) (NP (NP (RB only) (CD one) (NN line)) (PP (IN of) (NP (NN code)))))))))))) (. .))
(S (NP (PRP It)) (VP (MD can) (ADVP (RB also)) (VP (VB be) (ADVP (RB directly)) (VP (VBN used) (PP (IN to) (NP (NP (JJ fine) (HYPH -) (NN tune)) (NP (DT the) (JJ pre-trained) (NNS DNNs))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (PP (IN on) (NP (JJ various) (NNS applications))) (, ,) (PP (VBG including) (NP (NML (NML (JJ general) (NN image) (NN classification)) (, ,) (NML (ADJP (JJ fine) (HYPH -) (JJ grained)) (NN image) (NN classification)) (, ,)) (NN detection) (CC and) (NN segmentation))) (, ,)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NN GC)) (VP (MD can) (ADVP (RB consistently)) (VP (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN DNN) (NN learning))))))))) (. .))
(S (NP (NP (DT The) (NN code)) (PP (IN of) (NP (NN GC)))) (VP (MD can) (VP (VB be) (VP (VBN found) (PP (IN at) (NP (NP (DT this)) (SBAR (S (VP (VBZ https) (NP (NN URL)))))))))))
