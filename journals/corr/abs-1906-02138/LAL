(S (NP (DT This) (NN paper)) (VP (VBZ investigates) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ intrinsic) (NN reward))) (S (VP (TO to) (VP (VB guide) (NP (NN exploration)) (PP (IN in) (NP (JJ multi-agent) (NN reinforcement) (NN learning)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP discuss) (NP (NP (DT the) (NNS challenges)) (PP (IN in) (S (VP (VBG applying) (NP (JJ intrinsic) (NN reward)) (PP (TO to) (NP (VB multiple) (JJ collaborative) (NNS agents)))))))) (CC and) (VP (VB demonstrate) (SBAR (WHADVP (WRB how)) (S (NP (JJ unreliable) (NN reward)) (VP (MD can) (VP (VB prevent) (NP (JJ decentralized) (NNS agents)) (PP (IN from) (S (VP (VBG learning) (NP (DT the) (JJ optimal) (NN policy))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP address) (NP (DT this) (NN problem)) (PP (IN with) (NP (NP (DT a) (JJ novel) (NN framework)) (, ,) (NP (NP (NNP Independent) (JJ Centrally-assisted) (NNP Q-learning)) (PRN (-LRB- -LRB-) (NP (NNP ICQL)) (-RRB- -RRB-))) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (VBD decentralized) (NNS agents)) (VP (NN share) (NP (NP (NN control)) (CC and) (NP (DT an) (NN experience) (NN replay) (NN buffer))) (PP (IN with) (NP (DT a) (JJ centralized) (NN agent))))))))) (. .))
(S (S (NP (RB Only) (DT the) (JJ centralized) (NN agent)) (VP (VBZ is) (VP (ADVP (RB intrinsically)) (VBN rewarded)))) (, ,) (CC but) (S (NP (DT the) (JJ decentralized) (NNS agents)) (ADVP (RB still)) (VP (VBP benefit) (PP (IN from) (NP (VBN improved) (NN exploration))) (, ,) (PP (IN without) (NP (NP (DT the) (NN distraction)) (PP (IN of) (NP (JJ unreliable) (NNS incentives))))))) (. .))
