(S (NP (DT This) (NN paper)) (VP (VBZ investigates) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ intrinsic) (NN reward)))) (S (VP (TO to) (VP (VB guide) (NP (NN exploration)) (PP (IN in) (NP (JJ multi-agent) (NN reinforcement) (NN learning))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP discuss) (NP (DT the) (NNS challenges)) (PP (IN in) (S (VP (VBG applying) (NP (JJ intrinsic) (NN reward)) (PP (IN to) (NP (JJ multiple) (JJ collaborative) (NNS agents))))))) (CC and) (VP (VBP demonstrate) (SBAR (WHADVP (WRB how)) (S (NP (ADJP (JJ unreliable)) (NN reward)) (VP (MD can) (VP (VB prevent) (NP (JJ decentralized) (NNS agents)) (PP (IN from) (S (VP (VBG learning) (NP (DT the) (JJ optimal) (NN policy))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP address) (NP (DT this) (NN problem)) (PP (IN with) (NP (NP (NP (DT a) (JJ novel) (NN framework)) (, ,) (NP (NP (ADJP (NP (NP (NNP Independent)) (ADVP (RB Centrally))) (HYPH -) (VBN assisted)) (NML (NN Q) (HYPH -) (NN learning))) (-LRB- -LRB-) (NP (NN ICQL)) (-RRB- -RRB-))) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (JJ decentralized) (NNS agents)) (VP (VBP share) (NP (NP (NN control)) (CC and) (NP (DT an) (NN experience) (NN replay) (NN buffer))) (PP (IN with) (NP (DT a) (JJ centralized) (NN agent))))))))) (. .))
(S (S (NP (RB Only) (DT the) (JJ centralized) (NN agent)) (VP (VBZ is) (ADJP (RB intrinsically) (VBN rewarded)))) (, ,) (CC but) (S (NP (DT the) (JJ decentralized) (NNS agents)) (ADVP (RB still)) (VP (VBP benefit) (PP (IN from) (NP (NP (VBN improved) (NN exploration)) (, ,) (PP (IN without) (NP (NP (DT the) (NN distraction)) (PP (IN of) (NP (ADJP (JJ unreliable)) (NNS incentives))))))))) (. .))
