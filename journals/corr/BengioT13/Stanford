(S (NP (PRP We)) (VP (VBP introduce) (NP (DT a) (JJ novel) (NN training) (NN principle)) (PP (IN for) (NP (NP (JJ probabilistic) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (NP (NP (DT an) (NN alternative)) (PP (IN to) (NP (JJ maximum) (NN likelihood)))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NML (NNP Generative) (NNP Stochastic) (NNP Networks) (-LRB- -LRB-) (NNP GSN) (-RRB- -RRB-)) (NN framework)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (S (VP (VBG learning) (NP (NP (NP (DT the) (NN transition) (NN operator)) (PP (IN of) (NP (DT a) (NNP Markov) (NN chain)))) (SBAR (WHNP (WP$ whose)) (S (NP (JJ stationary) (NN distribution)) (VP (VBZ estimates) (NP (DT the) (NNS data) (NN distribution))))))))))) (. .))
(S (S (NP (NP (DT The) (NN transition) (NN distribution)) (PP (IN of) (NP (DT the) (NNP Markov) (NN chain)))) (VP (VBZ is) (ADJP (JJ conditional) (PP (IN on) (NP (DT the) (JJ previous) (NN state)))) (, ,) (S (ADVP (RB generally)) (VP (VBG involving) (NP (DT a) (JJ small) (NN move)))))) (, ,) (S (ADVP (RB so)) (NP (DT this) (JJ conditional) (NN distribution)) (VP (VBZ has) (NP (JJR fewer) (JJ dominant) (NNS modes)))) (, ,) (S (VP (VBG being) (ADJP (JJ unimodal) (PP (IN in) (NP (NP (DT the) (NN limit)) (PP (IN of) (NP (JJ small) (NNS moves)))))))) (. .))
(S (ADVP (RB Thus)) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJR easier)) (S (VP (TO to) (VP (VB learn) (SBAR (IN because) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJR easier)) (S (VP (TO to) (VP (VB approximate) (NP (PRP$ its) (NN partition) (NN function)) (, ,) (PP (ADVP (RBR more)) (IN like) (S (VP (VBG learning) (S (VP (TO to) (VP (VB perform) (NP (JJ supervised) (NN function) (NN approximation)))))))) (, ,) (PP (IN with) (NP (NP (NNS gradients)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN obtained) (PP (IN by) (NP (NN backprop)))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (NP (NNS theorems)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP generalize) (NP (JJ recent) (NN work)) (PP (IN on) (NP (NP (DT the) (JJ probabilistic) (NN interpretation)) (PP (IN of) (NP (NN denoising) (NNS autoencoders)))))) (CC and) (VP (VB obtain) (PP (IN along) (NP (DT the) (NN way))) (NP (NP (DT an) (JJ interesting) (NN justification)) (PP (IN for) (NP (NP (NN dependency) (NNS networks)) (CC and) (NP (VBN generalized) (NN pseudolikelihood)))))))))) (, ,) (PP (IN along) (IN with) (NP (NP (DT a) (NN definition)) (PP (IN of) (NP (NP (DT an) (JJ appropriate) (JJ joint) (NML (NN distribution) (CC and) (NN sampling)) (NN mechanism)) (SBAR (WHADVP (RB even) (WRB when)) (S (NP (DT the) (NNS conditionals)) (VP (VBP are) (RB not) (ADJP (JJ consistent)))))))))) (. .))
(S (NP (NNS GSNs)) (VP (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN with) (NP (VBG missing) (NNS inputs)))))) (CC and) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB sample) (NP (NP (NNS subsets)) (PP (IN of) (NP (NP (NNS variables)) (VP (VBN given) (NP (DT the) (NN rest))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP validate) (NP (NP (DT these) (JJ theoretical) (NNS results)) (PP (IN with) (NP (NNS experiments)))) (PP (IN on) (NP (CD two) (NN image) (NNS datasets))) (VP (VBG using) (NP (NP (DT an) (NN architecture)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ mimics) (NP (DT the) (JJ Deep) (NNP Boltzmann) (NNP Machine) (NNP Gibbs) (NN sampler))) (CC but) (VP (VBZ allows) (NP (NN training)) (S (VP (TO to) (VP (VB proceed) (PP (IN with) (NP (JJ simple) (NN backprop)))))))))))) (, ,) (PP (IN without) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NN layerwise) (NN pretraining)))))) (. .))
