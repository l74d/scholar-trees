(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (ADJP (JJ stackable) (JJ recurrent)) (NN cell)) (-LRB- -LRB-) (NP (NNP STAR)) (-RRB- -RRB-)) (PP (IN for) (NP (NP (NP (ADJP (JJ recurrent)) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (NP (ADJP (RB significantly) (JJR less)) (NNS parameters)) (PP (IN than) (ADVP (RB widely))) (VP (VBN used) (NP (NNP LSTM) (CC and) (NNP GRU)) (PP (IN while) (S (VP (VBG being) (ADJP (RBR more) (JJ robust) (PP (IN against) (NP (NP (VBG vanishing)) (CC or) (NP (VBG exploding) (NNS gradients))))))))))))))) (. .))
(SINV (VP (VBG Stacking) (NP (NP (JJ multiple) (NNS layers)) (PP (IN of) (NP (ADJP (JJ recurrent)) (NNS units))))) (VP (VBZ has) (NP (NP (CD two) (JJ major) (NNS drawbacks)) (: :) (S (LST (LS i) (-RRB- -RRB-)) (S (NP (ADJP (JJ many) (JJ recurrent)) (NNS cells) (PRN (-LRB- -LRB-) (NP (ADVP (FW e.g.)) (, ,) (NML (NN LSTM)) (NNS cells)) (-RRB- -RRB-))) (VP (VBP are) (ADJP (RB extremely) (JJ eager) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (NNS parameters)) (CC and) (NP (NN computation) (NNS resources))))))))) (, ,) (S (LST (LS ii) (-RRB- -RRB-)) (NP (JJ deep) (NNS RNNs)) (VP (VBP are) (ADJP (JJ prone) (PP (IN to) (NP (VBG vanishing) (CC or) (VBG exploding))))))))) (NP (NP (NNS gradients)) (PP (IN during) (NP (NN training)))) (. .))
(S (NP (PRP We)) (VP (VBP investigate) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ multi-layer) (NNS RNNs)))) (CC and) (VBP examine) (NP (NP (DT the) (NN magnitude)) (PP (IN of) (NP (NP (DT the) (NNS gradients)) (SBAR (IN as) (S (NP (PRP they)) (VP (VBP propagate) (PP (IN through) (NP (NP (DT the) (NN network)) (PP (IN in) (NP (DT the) (`` ") (JJ vertical) ('' ") (NN direction)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (, ,) (PP (VBG depending) (PP (IN on) (NP (NP (DT the) (NN structure)) (PP (IN of) (NP (DT the) (ADJP (JJ basic) (JJ recurrent)) (NN unit)))))) (, ,) (NP (DT the) (NNS gradients)) (VP (VBP are) (ADVP (RB systematically)) (NP (VBN attenuated) (CC or) (VBN amplified)))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (PRP$ our) (NN analysis)))) (NP (PRP we)) (VP (VBP design) (NP (NP (DT a) (JJ new) (NN type)) (PP (IN of) (NP (NP (VBN gated) (NN cell)) (SBAR (WHNP (WDT that)) (S (ADVP (RB better)) (VP (VBZ preserves) (NP (NN gradient) (NN magnitude))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP validate) (NP (PRP$ our) (NN design)) (PP (IN on) (NP (NP (DT a) (JJ large) (NN number)) (PP (IN of) (NP (NML (NN sequence) (NN modelling)) (NNS tasks)))))) (CC and) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NNP STAR) (NN cell)) (VP (VBZ allows) (S (VP (TO to) (VP (VP (VB build)) (CC and) (VP (VB train) (NP (ADJP (JJR deeper) (JJ recurrent)) (NNS architectures)) (, ,) (S (ADVP (RB ultimately)) (VP (VBG leading) (PP (IN to) (NP (VBN improved) (NN performance))))) (SBAR (IN while) (S (VP (VBG being) (ADVP (RB computationally)) (ADJP (JJ efficient)))))))))))))) (. .))
