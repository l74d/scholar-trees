(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (JJ several) (JJ new) (NML (JJ black) (HYPH -) (NN box)) (NNS reductions)) (SBAR (WHNP (WDT that)) (S (ADVP (RB significantly)) (VP (VBP improve) (NP (NP (DT the) (NN design)) (PP (IN of) (NP (ADJP (NP (NP (JJ adaptive)) (CC and) (NP (NN parameter))) (HYPH -) (JJ free)) (NML (NN online) (NN learning)) (NNS algorithms)))) (PP (IN by) (S (VP (VP (VBG simplifying) (NP (NN analysis))) (, ,) (VP (VBG improving) (NP (NN regret) (NNS guarantees))) (, ,) (CC and) (ADVP (RB sometimes)) (VP (ADVP (RB even)) (VBG improving) (NP (NN runtime))))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP reduce) (NP (NP (NN parameter) (HYPH -) (JJ free) (NN online) (NN learning)) (PP (IN to) (NP (JJ online) (NML (NN exp) (HYPH -) (NN concave)) (NN optimization)))))) (, ,) (S (NP (PRP we)) (VP (VBP reduce) (NP (NP (NN optimization)) (PP (IN in) (NP (DT a) (NNP Banach) (NN space)))) (PP (IN to) (NP (ADJP (CD one) (HYPH -) (JJ dimensional)) (NN optimization))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP reduce) (NP (NP (NN optimization)) (PP (IN over) (NP (DT a) (ADJP (JJ constrained) (NN domain) (PP (IN to) (ADJP (JJ unconstrained)))) (NN optimization)))))) (. .))
(S (NP (NP (DT All)) (PP (IN of) (NP (PRP$ our) (NNS reductions)))) (VP (VBP run) (ADVP (RB as) (RB fast)) (PP (IN as) (NP (JJ online) (NN gradient) (NN descent)))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (PRP$ our) (JJ new) (NNS techniques)) (S (VP (TO to) (VP (VP (VB improve) (PP (IN upon) (NP (NP (DT the) (ADJP (RB previously) (JJS best)) (NN regret) (NNS bounds)) (PP (IN for) (NP (NN parameter) (HYPH -) (JJ free) (NN learning)))))) (, ,) (CC and) (VP (VB do) (ADVP (RB so)) (PP (IN for) (NP (JJ arbitrary) (NNS norms)))))))) (. .))
