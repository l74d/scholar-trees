(S (NP (JJ Recurrent) (JJ neural) (NNS networks)) (VP (VBP are) (ADVP (RB nowadays)) (ADVP (RB successfully)) (VP (VBN used) (PP (IN in) (NP (NP (DT an) (NN abundance)) (PP (IN of) (NP (NNS applications))))) (, ,) (S (VP (VBG going) (PP (IN from) (NP (NN text) (, ,) (NN speech) (CC and) (NN image))) (NP (NP (NN processing)) (PP (IN to) (NP (NN recommender) (NNS systems)))))))) (. .))
(S (NP (NP (NN Backpropagation)) (PP (IN through) (NP (NN time)))) (VP (VBZ is) (NP (NP (DT the) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADVP (RB commonly)) (VP (VBN used) (S (VP (TO to) (VP (VB train) (NP (DT these) (NNS networks)) (PP (IN on) (NP (JJ specific) (NNS tasks)))))))))))) (. .))
(S (NP (JJ Many) (NML (JJ deep) (NN learning)) (NNS frameworks)) (VP (VBP have) (NP (NP (PRP$ their) (JJ own) (NN implementation)) (PP (IN of) (NP (NML (NN training) (CC and) (NN sampling)) (NNS procedures)))) (PP (IN for) (NP (ADJP (JJ recurrent)) (JJ neural) (NNS networks))) (, ,) (SBAR (IN while) (S (NP (EX there)) (VP (VBP are) (PP (IN in) (NP (NN fact) (JJ multiple) (JJ other) (NNS possibilities))) (S (VP (TO to) (VP (VP (VB choose) (PP (IN from))) (CC and) (VP (NP (JJ other) (NNS parameters)) (PP (IN to) (NP (NN tune))))))))))) (. .))
(S (PP (IN In) (NP (VBG existing) (NN literature))) (NP (DT this)) (VP (VBZ is) (ADVP (RB very) (RB often)) (VP (VBN overlooked) (CC or) (VBN ignored))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (ADVP (RB therefore)) (VP (VBP give) (NP (NP (DT an) (NN overview)) (PP (IN of) (NP (NP (JJ possible) (NML (NN training) (CC and) (NN sampling)) (NNS schemes)) (PP (IN for) (NP (ADJP (NP (NN character) (HYPH -) (NN level)) (JJ recurrent)) (JJ neural) (NNS networks)))))) (S (VP (TO to) (VP (VB solve) (NP (NP (DT the) (NN task)) (PP (IN of) (S (VP (VBG predicting) (NP (NP (DT the) (JJ next) (NN token)) (PP (IN in) (NP (DT a) (VBN given) (NN sequence)))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP test) (NP (DT these) (JJ different) (NNS schemes)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NP (NNS datasets)) (, ,) (NP (JJ neural) (NN network) (NNS architectures)) (CC and) (NP (NN parameter) (NNS settings))))))) (, ,) (CC and) (VP (VB formulate) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (NML (NN take) (HYPH -) (NN home)) (NNS recommendations)))))) (. .))
(S (NP (NP (DT The) (NN choice)) (PP (IN of) (NP (NML (NN training) (CC and) (NN sampling)) (NN scheme)))) (VP (VP (VBZ turns) (PRT (RP out)) (S (VP (TO to) (VP (VB be) (ADJP (JJ subject) (PP (IN to) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (NN trade) (HYPH -) (NNS offs))) (, ,) (PP (JJ such) (IN as) (NP (NML (NML (NN training) (NN stability)) (, ,) (NML (NN sampling) (NN time)) (, ,) (NML (NN model) (NN performance)) (CC and) (NML (NN implementation))) (NN effort)))))))))) (, ,) (CC but) (VP (VBZ is) (ADJP (RB largely) (JJ independent) (PP (IN of) (NP (DT the) (NNS data)))))) (. .))
(S (ADVP (RB Perhaps)) (NP (DT the) (ADJP (RBS most) (JJ surprising)) (NN result)) (VP (VBZ is) (SBAR (IN that) (S (S (VP (VBG transferring) (NP (JJ hidden) (NNS states)) (PP (IN for) (S (ADVP (RB correctly)) (VP (VBG initializing) (NP (DT the) (NN model)) (PP (IN on) (NP (NNS subsequences)))))))) (ADVP (RB often)) (VP (VBZ leads) (PP (IN to) (NP (JJ unstable) (NN training) (NN behavior))) (PP (VBG depending) (PP (IN on) (NP (DT the) (NN dataset)))))))) (. .))
