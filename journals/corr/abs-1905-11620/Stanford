(S (NP (NP (NN Convergence)) (PP (IN of) (NP (DT the) (NN gradient) (NN descent) (NN algorithm)))) (VP (VBZ has) (VP (VBN been) (VP (VBG attracting) (NP (VBN renewed) (NN interest)) (PP (IN due) (PP (IN to) (NP (NP (PRP$ its) (NN utility)) (PP (IN in) (NP (NML (JJ deep) (NN learning)) (NNS applications))))))))) (. .))
(S (SBAR (RB Even) (IN as) (S (NP (NP (JJ multiple) (NNS variants)) (PP (IN of) (NP (NN gradient) (NN descent)))) (VP (VBD were) (VP (VBN proposed))))) (, ,) (NP (NP (DT the) (NN assumption)) (SBAR (IN that) (S (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (DT the) (NN objective)))) (VP (VBZ is) (NP (NNP Lipschitz) (JJ continuous)))))) (VP (VBD remained) (NP (NP (DT an) (JJ integral) (NN part)) (PP (IN of) (NP (DT the) (NN analysis)))) (PP (IN until) (ADVP (RB recently)))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP look) (PP (IN at) (NP (NN convergence) (NN analysis))) (PP (IN by) (S (VP (VBG focusing) (PP (IN on) (NP (NP (DT a) (NN property)) (SBAR (WHNP (WDT that)) (S (NP (PRP we)) (VP (VBP term) (PP (PP (IN as) (NP (NN concavifiability))) (, ,) (RB instead) (PP (IN of) (NP (NP (NNP Lipschitz) (NN continuity)) (PP (IN of) (NP (NNS gradients))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NN concavifiability)) (VP (VBZ is) (NP (DT a) (ADJP (JJ necessary) (CC and) (JJ sufficient)) (NN condition) (S (VP (TO to) (VP (VB satisfy) (NP (NP (DT the) (JJ upper) (JJ quadratic) (NN approximation)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ key) (PP (IN in) (S (VP (VBG proving) (SBAR (IN that) (S (NP (DT the) (JJ objective) (NN function)) (VP (VBZ decreases) (PP (IN after) (NP (DT every) (NN gradient) (NN descent) (NN update)))))))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (DT any) (NN gradient) (NNP Lipschitz) (NN function)) (VP (VBZ satisfies) (NP (NN concavifiability)))))) (. .))
(S (NP (DT A) (JJ constant) (ADJP (VBN known) (PP (IN as) (NP (DT the) (NN concavifier)))) (ADJP (JJ analogous) (PP (IN to) (NP (DT the) (NN gradient)))) (NNP Lipschitz)) (ADJP (JJ constant) (SBAR (S (VP (VBZ is) (VP (VBN derived) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ indicative) (PP (IN of) (NP (DT the) (JJ optimal) (NN step) (NN size)))))))))))) (. .))
(S (PP (IN As) (NP (DT an) (NN application))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (NP (DT the) (NN utility)) (PP (IN of) (S (VP (VBG finding) (NP (DT the) (NN concavifier)) (PP (DT the) (IN in) (NP (NP (NN convergence)) (PP (IN of) (NP (NN gradient) (NN descent))))) (PP (IN through) (NP (NP (DT an) (NN example)) (VP (VBN inspired) (PP (IN by) (NP (JJ neural) (NNS networks))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP derive) (NP (NNS bounds)) (PP (IN on) (NP (DT the) (NN concavifier) (S (VP (TO to) (VP (VB obtain) (NP (DT a) (JJ fixed) (NN step) (NN size)) (PP (IN for) (NP (DT a) (JJ single) (NML (JJ hidden) (NN layer)) (NN ReLU) (NN network))))))))) (. .))
