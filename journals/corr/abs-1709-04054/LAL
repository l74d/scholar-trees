(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ simple) (NN extension)) (PP (TO to) (NP (NP (DT the) (NNP ReLU-family)) (PP (IN of) (NP (NN activation) (NNS functions))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ allows) (S (NP (PRP them)) (VP (TO to) (VP (VB shift) (NP (DT the) (JJ mean) (NN activation)) (PP (IN across) (NP (DT a) (NN layer))) (PP (IN towards) (NP (NN zero))))))))))) (. .))
(S (S (VP (VBN Combined) (PP (IN with) (NP (JJ proper) (NN weight) (NN initialization))))) (, ,) (NP (DT this)) (VP (VBZ alleviates) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NN normalization) (NNS layers))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP explore) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (NP (JJ deep) (NN vanilla) (JJ recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-)) (PP (IN with) (NP (QP (IN up) (TO to) (CD 144)) (NNS layers))))))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (JJ bipolar) (NN activation) (NNS functions)) (VP (VBP help) (NP (VBG learning)) (PP (IN in) (NP (DT this) (NN setting)))))))) (. .))
(S (PP (IN On) (NP (DT the) (NNP Penn) (NNP Treebank) (CC and) (NNP Text8) (NN language) (VBG modeling) (NNS tasks))) (NP (PRP we)) (VP (VB obtain) (NP (JJ competitive) (NNS results)) (, ,) (S (VP (VBG improving) (PP (IN on) (NP (NP (DT the) (JJS best) (VBD reported) (NNS results)) (PP (IN for) (NP (JJ non-gated) (NNS networks)))))))) (. .))
(S (PP (IN In) (NP (NP (NNS experiments)) (PP (IN with) (NP (NP (JJ convolutional) (JJ neural) (NNS networks)) (PP (IN without) (NP (NN batch) (NN normalization))))))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (JJ bipolar) (NNS activations)) (VP (VP (VBP produce) (NP (NP (DT a) (JJR faster) (NN drop)) (PP (IN in) (NP (VBG training) (NN error))))) (, ,) (CC and) (VP (NNS results) (PP (IN in) (NP (NP (DT a) (JJR lower) (NN test) (NN error)) (PP (IN on) (NP (DT the) (NNP CIFAR-10) (NN classification) (NN task)))))))))) (. .))
