(S (S (SBAR (IN As) (S (NP (JJ deep) (JJ neural) (NNS networks)) (VP (VBP are) (ADVP (RB increasingly)) (VP (VBN used) (PP (IN in) (NP (NP (NNS applications)) (VP (VBN suited) (PP (IN for) (NP (JJR low-power) (NNS devices)))))))))) (, ,) (NP (DT a) (JJ fundamental) (NN dilemma)) (VP (VBZ becomes) (ADJP (JJ apparent)))) (: :) (S (S (NP (DT the) (NN trend)) (VP (VBZ is) (S (VP (TO to) (VP (VB grow) (NP (NNS models)) (S (VP (TO to) (VP (VB absorb) (NP (NP (VBG increasing) (NNS data)) (SBAR (WHNP (WDT that)) (S (VP (VBZ gives) (NP (NN rise)) (PP (TO to) (NP (NN memory) (JJ intensive))))))))))))))) (: ;) (S (ADVP (RB however)) (NP (JJR low-power) (NNS devices)) (VP (VBP are) (VP (VBN designed) (PP (IN with) (NP (NP (ADJP (RB very) (JJ limited)) (NN memory)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (RB not) (VP (VB store) (NP (JJ large) (NNS models)))))))))))) (. .))
(S (NP (NNS Parameters) (VBG pruning)) (VP (VBZ is) (ADJP (JJ critical)) (PP (IN for) (NP (NP (JJ deep) (NN model) (NN deployment)) (PP (IN on) (NP (JJR low-power) (NNS devices)))))) (. .))
(S (NP (VBG Existing) (NNS efforts)) (ADVP (RB mainly)) (VP (VBP focus) (PP (IN on) (S (VP (VP (VBG designing) (NP (ADJP (RB highly) (JJ efficient)) (NNS structures))) (CC or) (VP (VBG pruning) (NP (NP (JJ redundant) (NNS connections)) (PP (IN for) (NP (NNS networks))))))))) (. .))
(S (NP (PRP They)) (VP (VP (VBP are) (ADVP (RB usually)) (ADJP (JJ sensitive) (PP (TO to) (NP (DT the) (NNS tasks))))) (CC or) (VP (VB relay) (PP (IN on) (NP (ADJP (JJ dedicated) (CC and) (JJ expensive)) (NN hashing) (NN storage) (NNS strategies))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ novel) (NN approach)) (PP (IN for) (S (VP (VBG achieving) (NP (DT a) (JJ lightweight) (NN model))))) (PP (IN from) (NP (NP (DT the) (NNS views)) (PP (IN of) (NP (VBG reconstructing) (NP (NP (NP (DT the) (NN structure)) (PP (IN of) (NP (JJ convolutional) (NNS kernels)))) (CC and) (NP (JJ efficient) (NN storage))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VP (VBZ transforms) (NP (DT a) (JJ traditional) (NN square) (NN convolution) (NNS kernel)) (PP (TO to) (NP (NN line) (NNS segments)))) (, ,) (CC and) (VP (ADVP (RB automatically)) (VB learn) (NP (NP (DT a) (JJ proper) (NN strategy)) (PP (IN for) (S (VP (VBG equipping) (NP (DT these) (NN line) (NNS segments)) (S (VP (TO to) (VP (VB model) (NP (JJ diverse) (NNS features))))))))))) (. .))
(S (NP (DT The) (JJ experimental) (NNS results)) (VP (VBP indicate) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (MD can) (VP (ADVP (RB massively)) (VB reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NP (NNS parameters)) (PRN (-LRB- -LRB-) (S (VP (VBN pruned) (NP (CD 69) (NN %)) (PP (IN on) (NP (NNP DenseNet-40))))) (-RRB- -RRB-))) (CC and) (NP (NP (NNS calculations)) (PRN (-LRB- -LRB-) (S (VP (VBN pruned) (NP (CD 59) (NN %)) (PP (IN on) (NP (NNP DenseNet-40))))) (-RRB- -RRB-)))))) (SBAR (IN while) (S (VP (VBG maintaining) (NP (JJ acceptable) (NN performance)) (PRN (-LRB- -LRB-) (S (VP (ADVP (RB only)) (RB lose) (NP (ADJP (QP (JJR less) (IN than) (CD 2)) (NN %)) (NN accuracy)))) (-RRB- -RRB-)))))))))) (. .))
