(S (NP (DT This) (NN work)) (VP (VBZ aims) (S (VP (TO to) (VP (VB enable) (NP (NP (JJ on-device) (NN training)) (PP (IN of) (NP (NP (JJ convolutional) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP CNNs)) (-RRB- -RRB-))))) (PP (IN by) (S (VP (VBG reducing) (NP (DT the) (NN computation) (NN cost)) (PP (IN at) (NP (NN training) (NN time)))))))))) (. .))
(S (S (NP (NNP CNN) (NNS models)) (VP (VBP are) (ADVP (RB usually)) (VP (VBN trained) (PP (IN on) (NP (NN high-performance) (NNS computers)))))) (CC and) (S (NP (RB only) (DT the) (JJ trained) (NNS models)) (VP (VBP are) (VP (VBN deployed) (PP (TO to) (NP (VB edge) (NNS devices)))))) (. .))
(S (CC But) (NP (DT the) (ADJP (RB statically) (JJ trained)) (NN model)) (VP (VP (MD can) (RB not) (VP (VB adapt) (ADVP (RB dynamically)) (PP (IN in) (NP (DT a) (JJ real) (NN environment))))) (CC and) (VP (MD may) (VP (VB result) (PP (IN in) (NP (NP (JJ low) (NN accuracy)) (PP (IN for) (NP (JJ new) (NNS inputs)))))))) (. .))
(S (NP (NP (JJ On-device) (NN training)) (PP (IN by) (S (VP (VBG learning) (PP (IN from) (NP (NP (DT the) (NN real-world) (NNS data)) (PP (IN after) (NP (NN deployment))))))))) (VP (MD can) (ADVP (RB greatly)) (VP (VB improve) (NP (NN accuracy)))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT the) (JJ high) (NN computation) (NN cost)) (VP (VBZ makes) (S (NP (VBG training)) (ADJP (JJ prohibitive) (PP (IN for) (NP (JJ resource-constrained) (NNS devices)))))) (. .))
(S (S (VP (TO To) (VP (VB tackle) (NP (DT this) (NN problem))))) (, ,) (NP (PRP we)) (VP (VP (VBP explore) (NP (NP (DT the) (JJ computational) (NNS redundancies)) (PP (IN in) (NP (NN training))))) (CC and) (VP (VB reduce) (NP (DT the) (NN computation) (NN cost)) (PP (IN by) (NP (NP (CD two) (JJ complementary) (NNS approaches)) (: :) (NP (NP (NP (JJ self-supervised) (JJ early) (NN instance) (VBG filtering)) (PP (IN on) (NP (NNS data) (NN level)))) (CC and) (NP (NP (NN error) (NN map) (VBG pruning)) (PP (IN on) (NP (DT the) (JJ algorithm) (NN level))))))))) (. .))
(S (NP (DT The) (JJ early) (NN instance) (NN filter)) (VP (VP (NNS selects) (NP (JJ important) (NNS instances)) (PP (IN from) (NP (DT the) (NN input) (NN stream))) (S (VP (TO to) (VP (VB train) (NP (DT the) (NN network)))))) (CC and) (VP (VBZ drops) (NP (JJ trivial) (NNS ones)))) (. .))
(S (NP (DT The) (NN error) (NN map) (VBG pruning)) (ADVP (JJ further)) (VP (NNS prunes) (PRT (RP out)) (NP (JJ insignificant) (NNS computations)) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (PP (IN with) (NP (DT the) (VBN selected) (NNS instances))))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NN computation) (NN cost)) (VP (VBZ is) (VP (ADVP (RB substantially)) (VBN reduced) (PP (PP (IN without) (NP (DT any))) (CC or) (PP (IN with) (NP (JJ marginal) (NN accuracy) (NN loss))))))))) (. .))
(S (PP (IN For) (NP (NN example))) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (NNP ResNet-110)) (PP (IN on) (NP (NNP CIFAR-10)))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (ADJP (CD 68) (NN %)) (NN computation) (VBG saving)) (SBAR (SBAR (IN while) (S (VP (VBG preserving) (NP (JJ full) (NN accuracy))))) (CC and) (NP (NP (ADJP (CD 75) (NN %)) (NN computation) (VBG saving)) (PP (IN with) (NP (NP (DT a) (JJ marginal) (NN accuracy) (NN loss)) (PP (IN of) (NP (CD 1.3) (NN %)))))))) (. .))
(S (NP (NP (JJ Aggressive) (NN computation) (VBG saving)) (PP (IN of) (NP (CD 96) (NN %)))) (VP (VBZ is) (VP (VBN achieved) (PP (IN with) (NP (ADJP (QP (JJR less) (IN than) (CD 0.1)) (NN %)) (NN accuracy) (NN loss))) (SBAR (WHADVP (WRB when)) (S (NP (NN quantization)) (VP (VBZ is) (VP (VBN integrated) (PP (IN into) (NP (DT the) (VBN proposed) (NNS approaches))))))))) (. .))
(S (ADVP (IN Besides)) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (NNP LeNet)) (PP (IN on) (NP (NNP MNIST)))))) (, ,) (NP (PRP we)) (VP (VBP save) (NP (ADJP (CD 79) (NN %)) (NN computation)) (SBAR (IN while) (S (VP (VBG boosting) (NP (NN accuracy)) (PP (IN by) (NP (CD 0.2) (NN %))))))) (. .))
