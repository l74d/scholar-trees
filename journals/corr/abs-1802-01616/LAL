(S (NP (DT This) (NN paper)) (VP (VBZ addresses) (NP (NP (DT the) (NN topic)) (PP (IN of) (S (VP (VBG sparsifying) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP DNN) (POS 's)) (-RRB- -RRB-)))))))) (. .))
(S (SBAR (IN While) (S (NP (NNP DNN) (POS 's)) (VP (VBP are) (NP (NP (JJ powerful) (NNS models)) (SBAR (WHNP (IN that)) (S (VP (VBP achieve) (NP (JJ state-of-the-art) (NN performance)) (PP (IN on) (NP (NP (DT a) (JJ large) (NN number)) (PP (IN of) (NP (NNS tasks)))))))))))) (, ,) (NP (NP (DT the) (JJ large) (NN number)) (PP (IN of) (NP (NN model) (NNS parameters)))) (VP (VBP poses) (NP (JJ serious) (NN storage) (CC and) (JJ computational) (NNS challenges))) (. .))
(S (S (VP (TO To) (VP (VB combat) (NP (DT these) (NNS difficulties))))) (, ,) (NP (NP (DT a) (VBG growing) (NN line)) (PP (IN of) (NP (NN work)))) (VP (NNS focuses) (PP (IN on) (S (VP (VBG pruning) (NP (NN network) (NNS weights)) (PP (IN without) (S (VP (VBG sacrificing) (NP (NN performance))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ general) (NN affine) (VBG scaling) (NN transformation) (PRN (-LRB- -LRB-) (NNP AST) (-RRB- -RRB-)) (NN algorithm)) (SBAR (S (VP (TO to) (VP (VB sparsify) (NP (NNP DNN) (POS 's)))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ follows) (PP (IN in) (NP (NP (DT the) (NNS footsteps)) (PP (IN of) (NP (NP (JJ popular) (JJ sparse) (NN recovery) (NNS techniques)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (ADVP (RB yet)) (S (VP (TO to) (VP (VB be) (VP (VBN explored) (PP (IN in) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (NNP DNN) (POS 's))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP describe) (NP (NP (DT a) (JJ principled) (NN framework)) (PP (IN for) (S (VP (VBG transforming) (NP (ADJP (RB densely) (VBN connected)) (NNP DNN) (POS 's)) (PP (IN into) (NP (ADJP (RB sparsely) (VBN connected)) (NNS ones))) (PP (IN without) (S (VP (VBG sacrificing) (NP (NN network) (NN performance)))))))))) (. .))
(S (PP (IN Unlike) (NP (VBG existing) (NNS methods))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB learn) (NP (NP (JJ sparse) (NNS connections)) (PP (IN at) (NP (DT each) (NN layer)))) (ADVP (RB simultaneously))))))) (, ,) (CC and) (VP (VBZ achieves) (NP (JJ comparable) (VBG pruning) (NNS results)) (PP (IN on) (NP (NP (DT the) (NN architecture)) (VP (VBD tested)))))) (. .))
