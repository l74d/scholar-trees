(S (NP (NP (JJ Multi-sample) (, ,) (JJ importance-weighted) (JJ variational) (NNS autoencoders)) (PRN (-LRB- -LRB-) (NP (NNP IWAE)) (-RRB- -RRB-))) (VP (VBP give) (NP (NP (NP (JJR tighter) (NNS bounds)) (CC and) (NP (ADJP (JJR more) (JJ accurate)) (NN uncertainty) (NNS estimates))) (PP (IN than) (NP (NP (NP (JJ variational) (NNS autoencoders)) (PRN (-LRB- -LRB-) (NP (NNP VAE)) (-RRB- -RRB-))) (VP (VBD trained) (PP (IN with) (NP (DT a) (JJ standard) (JJ single-sample) (NN objective)))))))) (. .))
(S (S (ADVP (RB However)) (, ,) (NP (NNP IWAEs)) (VP (VBD scale) (ADVP (RB poorly)))) (: :) (S (SBAR (IN as) (S (NP (DT the) (JJ latent) (NN dimensionality)) (VP (NNS grows)))) (, ,) (NP (PRP they)) (VP (VBP require) (NP (ADJP (RB exponentially) (JJ many)) (NNS samples)) (S (VP (TO to) (VP (VB retain) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (NP (NN importance) (NN weighting))))))))) (. .))
(S (SBAR (IN While) (S (NP (NP (JJ sequential) (NNP Monte-Carlo)) (PRN (-LRB- -LRB-) (NP (NNP SMC)) (-RRB- -RRB-))) (VP (MD can) (VP (VB address) (NP (DT this) (NN problem)))))) (, ,) (S (NP (PRP it)) (VP (VBZ is) (ADJP (RB prohibitively) (JJ slow)) (SBAR (IN because) (S (NP (DT the) (JJ resampling) (NN step)) (VP (VBZ imposes) (NP (NP (JJ sequential) (NN structure)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (RB not) (VP (VB be) (VP (VBN parallelised)))))))))))) (, ,) (CC and) (S (ADVP (RB moreover)) (, ,) (NP (VBG resampling)) (VP (VBZ is) (ADJP (JJ non-differentiable)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ problematic)) (SBAR (WHADVP (WRB when)) (S (VP (VBG learning) (NP (JJ approximate) (NNS posteriors)))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS issues))))) (, ,) (NP (PRP we)) (VP (VBD developed) (NP (NP (VB tensor) (NNP Monte-Carlo)) (PRN (-LRB- -LRB-) (NP (NNP TMC)) (-RRB- -RRB-)) (SBAR (WHNP (WDT which)) (S (VP (VBZ gives) (NP (ADJP (RB exponentially) (JJ many)) (NN importance) (NNS samples)) (PP (IN by) (S (VP (VP (ADVP (RB separately)) (VBG drawing) (NP (ADJP ($ $) (NNP K) ($ $)) (NNS samples)) (PP (IN for) (NP (NP (DT each)) (PP (IN of) (NP (DT the) (ADJP ($ $) (JJ n) ($ $)) (JJ latent) (NNS variables)))))) (, ,) (ADVP (RB then)) (VP (VBG averaging) (PP (IN over) (NP (DT all) (ADJP (QP ($ $) (NNP K^n) ($ $))) (JJ possible) (NNS combinations)))))))))))) (. .))
(S (SBAR (IN While) (S (NP (NP (DT the) (NN sum)) (PP (IN over) (NP (ADJP (RB exponentially) (JJ many)) (NNS terms)))) (VP (MD might) (VP (VB seem) (S (VP (TO to) (VP (VB be) (ADJP (JJ intractable))))))))) (, ,) (PP (IN in) (NP (JJ many) (NNS cases))) (NP (PRP it)) (VP (MD can) (VP (VB be) (VP (VBN computed) (ADVP (RB efficiently)) (PP (IN as) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (JJ tensor) (NNS inner-products)))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP TMC)) (VP (VBZ is) (ADJP (JJ superior) (PP (TO to) (NP (NNP IWAE)))) (PP (IN on) (NP (NP (DT a) (JJ generative) (NN model)) (PP (IN with) (NP (NP (JJ multiple) (JJ stochastic) (NNS layers)) (VP (VBD trained) (PP (IN on) (NP (DT the) (NNP MNIST) (NN handwritten) (JJ digit) (NN database))))))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP TMC)) (VP (MD can) (VP (VB be) (VP (VBN combined) (PP (IN with) (NP (JJ standard) (NN variance) (NN reduction) (NNS techniques)))))))))) (. .))
