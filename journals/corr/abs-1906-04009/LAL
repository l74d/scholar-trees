(S (NP (NP (JJ Soft) (NNP Actor-Critic)) (PRN (-LRB- -LRB-) (NP (NNP SAC)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (DT an) (JJ off-policy) (JJ actor-critic) (JJ deep) (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NNP DRL) (-RRB- -RRB-)) (VBP algorithm)) (VP (VBN based) (PP (IN on) (NP (JJ maximum) (JJ entropy) (NN reinforcement) (NN learning)))))) (. .))
(S (PP (IN By) (S (VP (VBG combining) (NP (NN off-policy) (NNS updates)) (PP (IN with) (NP (DT an) (JJ actor-critic) (NN formulation)))))) (, ,) (NP (NNP SAC)) (VP (VBZ achieves) (NP (NP (JJ state-of-the-art) (NN performance)) (PP (IN on) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (NN continuous-action) (NN benchmark) (NNS tasks)))))) (, ,) (S (VP (VBG outperforming) (NP (JJ prior) (UCP (NN on-policy) (CC and) (NN off-policy)) (NNS methods))))) (. .))
(S (NP (NP (DT The) (NN off-policy) (NN method)) (VP (VBN employed) (PP (IN by) (NP (NNP SAC))))) (VP (NNS samples) (NP (NNS data)) (ADVP (RB uniformly)) (PP (IN from) (NP (JJ past) (NN experience))) (SBAR (WHADVP (WRB when)) (S (VP (VBG performing) (NP (NN parameter) (NNS updates)))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (VP (S (VP (S (VP (VBG Emphasizing) (NP (NNP Recent) (NNP Experience)))) (PRN (-LRB- -LRB-) (NP (NNP ERE)) (-RRB- -RRB-)))) (, ,) (NP (NP (DT a) (ADJP (JJ simple) (CC but) (JJ powerful)) (JJ off-policy) (NN sampling) (NN technique)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ emphasizes) (NP (ADJP (RB recently) (VBN observed)) (NNS data)) (SBAR (IN while) (S (RB not) (VP (VBG forgetting) (NP (DT the) (NN past)))))))))))) (. .))
(S (NP (DT The) (NNP ERE) (NN algorithm)) (VP (VP (VBZ samples) (ADVP (RBR more) (RB aggressively)) (PP (IN from) (NP (JJ recent) (NN experience)))) (, ,) (CC and) (ADVP (RB also)) (VP (NNS orders) (NP (DT the) (NNS updates)) (S (VP (TO to) (VP (VB ensure) (SBAR (DT that) (S (NP (NP (VBZ updates)) (PP (IN from) (NP (JJ old) (NNS data)))) (VP (VBP do) (RB not) (VP (VB overwrite) (NP (NP (NNS updates)) (PP (IN from) (NP (JJ new) (NNS data))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP compare) (NP (NP (JJ vanilla) (NNP SAC)) (CC and) (NP (NNP SAC+ERE)))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (NNP ERE)) (VP (VBZ is) (ADJP (ADJP (RBR more) (JJ sample) (NN efficient)) (PP (IN than) (NP (NN vanilla) (NNP SAC)))) (PP (IN for) (NP (NN continuous-action) (NNP Mujoco) (NNS tasks)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP consider) (S (VP (VBG combining) (NP (NNP SAC)) (PP (IN with) (NP (NP (NNP Priority) (NNP Experience) (NNP Replay)) (PRN (-LRB- -LRB-) (NP (NNP PER)) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (NN scheme)) (VP (ADVP (RB originally)) (VBN proposed) (PP (IN for) (NP (JJ deep) (NNP Q-learning)))) (SBAR (WHNP (WDT which)) (S (VP (VBZ prioritizes) (NP (DT the) (NNS data)) (PP (VBN based) (PP (IN on) (NP (NN temporal-difference) (PRN (-LRB- -LRB-) (NNP TD) (-RRB- -RRB-)) (NN error))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP SAC+PER)) (VP (MD can) (VP (ADVP (RB marginally)) (VB improve) (NP (NP (DT the) (JJ sample) (NN efficiency) (NN performance)) (PP (IN of) (NP (NNP SAC)))) (, ,) (CC but) (ADVP (ADVP (RB much) (JJR less) (RB so)) (PP (IN than) (NP (NNP SAC+ERE))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VP (VBP propose) (NP (NP (DT an) (NN algorithm)) (SBAR (WHNP (WDT which)) (S (VP (VBZ integrates) (NP (NNP ERE) (CC and) (NNP PER))))))) (CC and) (VP (VB show) (SBAR (IN that) (S (NP (DT this) (JJ hybrid) (NN algorithm)) (VP (MD can) (VP (VB give) (NP (DT the) (JJS best) (NNS results)) (PP (IN for) (NP (NP (DT some)) (PP (IN of) (NP (DT the) (NNP Mujoco) (NNS tasks))))))))))) (. .))
