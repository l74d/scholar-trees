(S (NP (PRP We)) (VP (VBP propose) (NP (DT an) (NN algorithm)) (PP (IN for) (NP (NP (DT a) (NN family)) (PP (IN of) (NP (NN optimization) (NNS problems))))) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN objective)) (VP (MD can) (VP (VB be) (VP (VBN decomposed) (PP (IN as) (NP (NP (DT a) (NN sum)) (PP (IN of) (NP (NNS functions))))) (PP (IN with) (NP (NN monotonicity) (NNS properties))))))))) (. .))
(S (NP (DT The) (VBG motivating) (NN problem)) (VP (VBZ is) (NP (NP (NN optimization)) (PP (IN of) (NP (NP (NP (NNS hyperparameters)) (PP (IN of) (NP (NML (NN machine) (NN learning)) (NNS algorithms)))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP argue) (SBAR (IN that) (S (NP (NP (DT the) (NN objective)) (, ,) (NP (NN validation) (NN error)) (, ,)) (VP (MD can) (VP (VB be) (VP (VBN decomposed) (PP (IN as) (NP (NP (JJ monotonic) (NNS functions)) (PP (IN of) (NP (DT the) (NNS hyperparameters))))))))))))))))) (. .))
(S (NP (PRP$ Our) (VBN proposed) (NN algorithm)) (VP (VBZ adapts) (NP (NML (JJ Bayesian) (NN optimization)) (NNS methods)) (S (VP (TO to) (VP (VB incorporate) (NP (DT the) (NN monotonicity) (NNS constraints)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP illustrate) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (S (VP (VBG exploiting) (NP (NN monotonicity)) (S (VP (VBG using) (NP (JJ illustrative) (NNS examples))))))))) (CC and) (VP (VBP demonstrate) (NP (NP (DT the) (NNS improvements)) (PP (IN in) (NP (NN optimization) (NN efficiency)))) (PP (IN for) (NP (NP (DT some) (NN machine)) (VP (VBG learning) (NP (NN hyperparameter) (NN tuning) (NNS applications))))))) (. .))
