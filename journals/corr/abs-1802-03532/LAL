(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT an) (NN algorithm)) (PP (IN for) (NP (NP (DT a) (NN family)) (PP (IN of) (NP (NN optimization) (NNS problems))) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN objective)) (VP (MD can) (VP (VB be) (VP (VBN decomposed) (PP (IN as) (NP (NP (DT a) (NN sum)) (PP (IN of) (NP (NP (NNS functions)) (PP (IN with) (NP (NN monotonicity) (NNS properties)))))))))))))))) (. .))
(S (NP (DT The) (NN motivating) (NN problem)) (VP (VBZ is) (NP (NP (NN optimization)) (PP (IN of) (NP (NP (NNS hyperparameters)) (PP (IN of) (NP (NN machine) (VBG learning) (NN algorithms))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP argue) (SBAR (IN that) (S (NP (NP (DT the) (NN objective)) (, ,) (NP (NN validation) (NN error)) (, ,)) (VP (MD can) (VP (VB be) (VP (VBN decomposed) (PP (IN as) (NP (NP (JJ monotonic) (NNS functions)) (PP (IN of) (NP (DT the) (NNS hyperparameters))))))))))))))) (. .))
(S (NP (PRP$ Our) (VBN proposed) (NN algorithm)) (VP (VBZ adapts) (NP (JJ Bayesian) (NN optimization) (NNS methods)) (S (VP (TO to) (VP (VB incorporate) (NP (DT the) (NN monotonicity) (NNS constraints)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP illustrate) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (S (VP (VBG exploiting) (NP (NN monotonicity)))))) (S (VP (VBG using) (NP (JJ illustrative) (NNS examples))))) (CC and) (VP (VB demonstrate) (NP (NP (DT the) (NNS improvements)) (PP (IN in) (NP (NN optimization) (NN efficiency))) (PP (IN for) (NP (DT some) (NN machine) (VBG learning) (NN hyperparameter) (VBG tuning) (NNS applications)))))) (. .))
