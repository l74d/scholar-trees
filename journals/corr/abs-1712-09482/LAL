(S (PP (IN In) (NP (NP (JJ many) (NNS applications)) (PP (IN of) (NP (NN classifier) (NN learning))))) (, ,) (NP (VBG training) (NNS data)) (VP (NNS suffers) (PP (IN from) (NP (JJ label) (NN noise)))) (. .))
(S (NP (JJ Deep) (NNS networks)) (VP (VBP are) (VP (VBN learned) (S (VP (VBG using) (NP (JJ huge) (NN training) (NNS data)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (NN noisy) (NNS labels)))) (VP (VBZ is) (ADJP (RB particularly) (JJ relevant))))))))) (. .))
(S (NP (NP (DT The) (JJ current) (NNS techniques)) (VP (VBN proposed) (PP (IN for) (S (VP (VBG learning) (NP (JJ deep) (NNS networks)) (PP (IN under) (NP (NN label) (NN noise)))))))) (VP (NN focus) (PP (PP (IN on) (S (VP (VBG modifying) (NP (DT the) (NN network) (NN architecture))))) (CC and) (PP (IN on) (NP (NP (NN algorithms)) (PP (IN for) (S (VP (VBG estimating) (NP (JJ true) (NNS labels)) (PP (IN from) (NP (JJ noisy) (NNS labels)))))))))) (. .))
(S (NP (DT An) (JJ alternate) (NN approach)) (VP (MD would) (VP (VB be) (S (VP (TO to) (VP (VB look) (PP (IN for) (NP (NP (NN loss) (NNS functions)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RB inherently) (JJ noise-tolerant)))))))))))) (. .))
(S (PP (IN For) (NP (JJ binary) (NN classification))) (NP (EX there)) (VP (JJ exist) (NP (NP (JJ theoretical) (NNS results)) (PP (IN on) (NP (NN loss) (NNS functions))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ robust) (PP (TO to) (NP (VB label) (NN noise))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP provide) (NP (NP (DT some) (JJ sufficient) (NNS conditions)) (PP (IN on) (NP (DT a) (NN loss) (NN function)))) (SBAR (IN so) (DT that) (S (NP (NP (NN risk) (NN minimization)) (PP (IN under) (NP (DT that) (NN loss) (NN function)))) (VP (MD would) (VP (VB be) (ADJP (RB inherently) (JJ tolerant) (PP (TO to) (NP (VB label) (NN noise)))) (PP (IN for) (NP (NN multiclass) (NN classification) (NNS problems)))))))) (. .))
(S (NP (DT These) (NNS results)) (VP (VBP generalize) (NP (NP (DT the) (VBG existing) (NNS results)) (PP (IN on) (NP (NP (JJ noise-tolerant) (NN loss) (NNS functions)) (PP (IN for) (NP (JJ binary) (NN classification))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP study) (NP (NP (DT some)) (PP (IN of) (NP (NP (DT the) (ADJP (RB widely) (VBN used)) (NN loss) (NNS functions)) (PP (IN in) (NP (JJ deep) (NNS networks))))))) (CC and) (VP (NN show) (SBAR (IN that) (S (NP (NP (DT the) (NN loss) (NN function)) (VP (VBN based) (PP (IN on) (NP (NP (JJ mean) (JJ absolute) (NN value)) (PP (IN of) (NP (NN error))))))) (VP (VBZ is) (ADJP (RB inherently) (JJ robust) (PP (TO to) (NP (VB label) (NN noise))))))))) (. .))
(S (ADVP (RB Thus)) (NP (JJ standard) (RP back) (NN propagation)) (VP (VBZ is) (ADJP (JJ enough) (S (VP (TO to) (VP (VB learn) (NP (DT the) (JJ true) (NN classifier)) (PP (ADVP (RB even)) (IN under) (NP (NN label) (NN noise)))))))) (. .))
(S (PP (IN Through) (NP (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP illustrate) (NP (NP (DT the) (NN robustness)) (PP (IN of) (NP (NN risk) (NN minimization))) (PP (IN with) (NP (JJ such) (NN loss) (NNS functions))) (PP (IN for) (NP (VBG learning) (JJ neural) (NNS networks))))) (. .))
