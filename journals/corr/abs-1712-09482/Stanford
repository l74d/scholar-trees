(S (PP (IN In) (NP (NP (JJ many) (NNS applications)) (PP (IN of) (NP (NN classifier) (NN learning))))) (, ,) (NP (NN training) (NNS data)) (VP (VBZ suffers) (PP (IN from) (NP (NN label) (NN noise)))) (. .))
(S (NP (JJ Deep) (NNS networks)) (VP (VBP are) (VP (VBN learned) (S (VP (VBG using) (NP (NP (JJ huge) (NN training) (NNS data)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (JJ noisy) (NNS labels)))) (VP (VBZ is) (ADJP (RB particularly) (JJ relevant)))))))))) (. .))
(S (NP (DT The) (JJ current) (NNS techniques)) (VP (VBN proposed) (PP (IN for) (S (VP (VBG learning) (NP (JJ deep) (NNS networks)) (PP (IN under) (NP (NN label) (NN noise) (NN focus))) (PP (PP (IN on) (S (VP (VBG modifying) (NP (DT the) (NN network) (NN architecture))))) (CC and) (PP (IN on) (NP (NP (NNS algorithms)) (PP (IN for) (S (VP (VBG estimating) (NP (JJ true) (NNS labels)) (PP (IN from) (NP (JJ noisy) (NNS labels))))))))))))) (. .))
(S (NP (DT An) (JJ alternate) (NN approach)) (VP (MD would) (VP (VB be) (S (VP (TO to) (VP (VB look) (PP (IN for) (NP (NP (NN loss) (NNS functions)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RB inherently) (RB noise) (HYPH -) (JJ tolerant)))))))))))) (. .))
(S (PP (IN For) (NP (JJ binary) (NN classification))) (NP (RB there)) (VP (VBP exist) (NP (JJ theoretical) (NNS results)) (PP (IN on) (NP (NP (NN loss) (NNS functions)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ robust) (PP (IN to) (NP (NN label) (NN noise)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP provide) (NP (DT some) (JJ sufficient) (NNS conditions)) (PP (IN on) (NP (DT a) (NN loss) (NN function))) (SBAR (IN so) (IN that) (S (NP (NP (NN risk) (NN minimization)) (PP (IN under) (NP (DT that) (NN loss) (NN function)))) (VP (MD would) (VP (VB be) (ADJP (RB inherently) (JJ tolerant) (PP (IN to) (NP (NP (NN label) (NN noise)) (PP (IN for) (NP (NN multiclass) (NN classification) (NNS problems))))))))))) (. .))
(S (NP (DT These) (NNS results)) (VP (VB generalize) (NP (DT the) (VBG existing) (NNS results)) (PP (IN on) (NP (ADJP (NP (NN noise)) (HYPH -) (JJ tolerant)) (NN loss) (NNS functions))) (PP (IN for) (NP (JJ binary) (NN classification)))) (. .))
(S (NP (PRP We)) (VP (VP (VBP study) (NP (NP (DT some)) (PP (IN of) (NP (NP (DT the) (ADJP (RB widely) (JJ used)) (NN loss) (NNS functions)) (PP (IN in) (NP (JJ deep) (NNS networks))))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN loss) (NN function)) (PP (VBN based) (PP (IN on) (NP (NP (JJ mean) (JJ absolute) (NN value)) (PP (IN of) (NP (NN error))))))) (VP (VBZ is) (ADJP (RB inherently) (JJ robust) (PP (IN to) (NP (NN label) (NN noise))))))))) (. .))
(S (ADVP (RB Thus)) (NP (JJ standard) (NML (ADVP (RB back))) (NN propagation)) (VP (VBZ is) (ADJP (JJ enough) (S (VP (TO to) (VP (VB learn) (NP (DT the) (JJ true) (NN classifier)) (ADVP (RB even)) (PP (IN under) (NP (NN label) (NN noise)))))))) (. .))
(S (PP (IN Through) (NP (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP illustrate) (NP (NP (DT the) (NN robustness)) (PP (IN of) (NP (NN risk) (NN minimization)))) (PP (IN with) (NP (NP (JJ such) (NN loss) (NNS functions)) (PP (IN for) (S (VP (VBG learning) (NP (JJ neural) (NNS networks)))))))) (. .))
