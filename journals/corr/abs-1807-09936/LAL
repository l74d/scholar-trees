(S (NP (NNP Imitation) (VBG learning) (NNS algorithms)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB learn) (NP (DT a) (NN policy)) (PP (IN from) (NP (JJ expert) (NNS demonstrations))) (PP (IN without) (NP (NP (NN access)) (PP (TO to) (NP (DT a) (JJ reward) (NN signal))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (JJS most) (JJ existing) (NNS approaches)) (VP (VBP are) (RB not) (JJ applicable) (PP (IN in) (NP (JJ multi-agent) (NNS settings))) (PP (JJ due) (TO to) (NP (NP (DT the) (NN existence)) (PP (IN of) (NP (NP (NN multiple) (PRN (-LRB- -LRB-) (NNP Nash) (-RRB- -RRB-)) (NN equilibria)) (CC and) (NP (JJ non-stationary) (NNS environments))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NP (DT a) (JJ new) (NN framework)) (PP (IN for) (NP (JJ multi-agent) (NN imitation) (VBG learning))) (PP (IN for) (NP (JJ general) (NNP Markov) (NNS games)))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP build) (PP (IN upon) (NP (NP (DT a) (JJ generalized) (NN notion)) (PP (IN of) (NP (JJ inverse) (NN reinforcement) (NN learning)))))))))) (. .))
(S (NP (PRP We)) (ADVP (VBP further)) (VP (VB introduce) (NP (NP (DT a) (JJ practical) (JJ multi-agent) (JJ actor-critic) (NN algorithm)) (PP (IN with) (NP (JJ good) (JJ empirical) (NN performance))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB imitate) (NP (JJ complex) (NNS behaviors)) (PP (IN in) (NP (NP (JJ high-dimensional) (NNS environments)) (PP (IN with) (NP (JJ multiple) (ADJP (JJ cooperative) (CC or) (VBG competing)) (NNS agents))))))))))) (. .))
