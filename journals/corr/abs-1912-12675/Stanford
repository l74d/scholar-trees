(S (NP (NP (DT The) (NN growth)) (PP (IN in) (NP (NP (DT the) (NN complexity)) (PP (IN of) (NP (NNP Convolutional) (JJ Neural) (NNS Networks) (PRN (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-))))))) (VP (VBZ is) (VP (VBG increasing) (NP (NN interest)) (PP (IN in) (S (VP (VP (VBG partitioning) (NP (NP (DT a) (NN network)) (PP (IN across) (NP (JJ multiple) (NNS accelerators)))) (PP (IN during) (NP (NN training)))) (CC and) (VP (VBG pipelining) (NP (NP (DT the) (NN backpropagation) (NNS computations)) (PP (IN over) (NP (DT the) (NNS accelerators)))))))))) (. .))
(S (NP (VBG Existing) (NNS approaches)) (VP (VP (VB avoid)) (CC or) (VP (VB limit) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ stale) (NNS weights)))) (PP (IN through) (NP (NP (NNS techniques)) (PP (JJ such) (IN as) (NP (NP (NN micro-batching)) (CC or) (NP (NN weight) (NN stashing)))))))) (. .))
(S (NP (DT These) (NNS techniques)) (ADVP (CC either)) (VP (VB underutilize) (PP (IN of) (NP (NP (NNS accelerators)) (CC or) (NP (NN increase) (NN memory) (NN footprint))))) (. .))
(S (NP (PRP We)) (VP (VBP explore) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (JJ stale) (NNS weights)))) (PP (IN on) (NP (NP (DT the) (JJ statistical) (NN efficiency) (CC and) (NN performance)) (PP (IN in) (NP (NP (DT a) (ADJP (JJ pipelined)) (NN backpropagation) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ maximizes) (NP (NN accelerator) (NN utilization))) (CC and) (VP (VBZ keeps) (NP (NN memory) (JJ overhead)) (S (ADJP (JJ modest)))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP use) (NP (CD 4) (NNS CNNs) (PRN (-LRB- -LRB-) (NP (NP (NNP LeNet) (HYPH -) (CD 5)) (, ,) (NP (NNP AlexNet)) (, ,) (NP (NNP VGG) (CC and) (NNP ResNet))) (-RRB- -RRB-)))) (CC and) (VP (VB show) (SBAR (IN that) (S (SBAR (WHADVP (WRB when)) (S (NP (VBG pipelining)) (VP (VBZ is) (VP (VBN limited) (PP (IN to) (NP (NP (JJ early) (NNS layers)) (PP (IN in) (NP (DT a) (NN network))))))))) (, ,) (NP (NP (NN training)) (PP (IN with) (NP (JJ stale) (NNS weights)))) (VP (VBZ converges) (CC and) (VBZ results) (PP (IN in) (NP (NP (NNS models)) (PP (IN with) (NP (JJ comparable) (NN inference) (NNS accuracies))))))))) (PP (IN to) (NP (NP (DT those)) (VP (VBG resulting) (PP (IN from) (NP (NP (JJ non-pipelined) (NN training)) (PP (IN on) (NP (NP (NML (NML (NN MNIST)) (CC and) (NML (NN CIFAR) (HYPH -) (CD 10))) (NNS datasets)) (: ;) (NP (NP (DT a) (NN drop)) (PP (IN in) (NP (NP (NN accuracy)) (PP (IN of) (NP (CD 0.4) (NN %)))))) (, ,) (NP (CD 4) (NN %)) (, ,) (NP (NP (QP (CD 0.83) (NN %) (CC and) (CD 1.45) (NN %))) (PP (IN for) (NP (DT the) (CD 4) (NNS networks)))) (, ,) (ADVP (RB respectively)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (VBG pipelining)) (VP (VBZ is) (ADJP (ADJP (JJR deeper)) (PP (IN in) (NP (DT the) (NN network))))))) (, ,) (NP (NN inference) (NNS accuracies)) (VP (VBP drop) (ADVP (RB significantly))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (VP (VBG combining) (NP (NP (ADJP (JJ pipelined) (CC and) (JJ non-pipelined)) (NN training)) (PP (IN in) (NP (DT a) (NN hybrid) (NN scheme)))) (S (VP (TO to) (VP (VB address) (NP (DT this) (NN drop)))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN implementation) (CC and) (NN performance)) (PP (IN of) (NP (NP (PRP$ our) (JJ pipelined) (NN backpropagation)) (PP (IN in) (NP (NNP PyTorch)))))) (PP (IN on) (NP (CD 2) (NNS GPUs))) (VP (VBG using) (NP (NNP ResNet))) (, ,) (S (VP (VBG achieving) (NP (NP (NNS speedups)) (PP (IN of) (NP (NP (QP (RB up) (IN to) (CD 1.8)) (NN X)) (PP (IN over) (NP (DT a) (NML (CD 1) (HYPH -) (NN GPU)) (NN baseline)))))) (, ,) (PP (IN with) (NP (NP (DT a) (JJ small) (NN drop)) (PP (IN in) (NP (NN inference) (NN accuracy)))))))) (. .))
