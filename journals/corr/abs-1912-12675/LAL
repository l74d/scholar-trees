(S (NP (NP (DT The) (NN growth)) (PP (IN in) (NP (NP (DT the) (NN complexity)) (PP (IN of) (NP (NP (NNP Convolutional) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP CNNs)) (-RRB- -RRB-))))))) (VP (VBZ is) (VP (VBG increasing) (NP (NP (NN interest)) (PP (IN in) (S (VP (VP (VBG partitioning) (NP (DT a) (NN network)) (PP (IN across) (NP (JJ multiple) (NNS accelerators))) (PP (IN during) (NP (NN training)))) (CC and) (VP (VBG pipelining) (NP (DT the) (NN backpropagation) (NNS computations)) (PP (IN over) (NP (DT the) (NNS accelerators)))))))))) (. .))
(S (NP (VBG Existing) (NNS approaches)) (VP (VBP avoid) (CC or) (VBP limit) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ stale) (NNS weights)))) (PP (IN through) (NP (NP (NNS techniques)) (PP (JJ such) (IN as) (NP (NP (NN micro-batching)) (CC or) (NP (NN weight) (NN stashing))))))) (. .))
(S (NP (DT These) (NNS techniques)) (VP (CC either) (VP (VP (NN underutilize) (PP (IN of) (NP (NNS accelerators)))) (CC or) (VP (VB increase) (NP (NN memory) (NN footprint))))) (. .))
(S (NP (PRP We)) (VP (VBP explore) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (JJ stale) (NNS weights))) (PP (IN on) (NP (DT the) (JJ statistical) (NN efficiency) (CC and) (NN performance))) (PP (IN in) (NP (NP (DT a) (JJ pipelined) (NN backpropagation) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ maximizes) (NP (NN accelerator) (NN utilization))) (CC and) (VP (VBZ keeps) (S (NP (NN memory) (JJ overhead)) (ADJP (JJ modest))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP use) (NP (NP (CD 4) (NNP CNNs)) (PRN (-LRB- -LRB-) (NP (NP (NNP LeNet-5)) (, ,) (NP (NNP AlexNet)) (, ,) (NP (NNP VGG)) (CC and) (NP (NNP ResNet))) (-RRB- -RRB-)))) (CC and) (VP (VBP show) (SBAR (IN that) (S (SBAR (WHADVP (WRB when)) (S (NP (NN pipelining)) (VP (VBZ is) (VP (VBN limited) (PP (TO to) (NP (NP (JJ early) (NNS layers)) (PP (IN in) (NP (DT a) (NN network))))))))) (, ,) (NP (NP (VBG training)) (PP (IN with) (NP (JJ stale) (NNS weights)))) (VP (VP (NNS converges)) (CC and) (VP (NNS results) (PP (IN in) (NP (NP (NNS models)) (PP (IN with) (NP (NP (NP (JJ comparable) (NN inference) (NNS accuracies)) (PP (TO to) (NP (NP (DT those)) (VP (VBG resulting) (PP (IN from) (NP (NP (JJ non-pipelined) (NN training)) (PP (IN on) (NP (NNP MNIST) (CC and) (NNP CIFAR-10) (NNS datasets))))))))) (: ;) (NP (NP (DT a) (NN drop)) (PP (IN in) (NP (NN accuracy))) (PP (IN of) (NP (NP (NP (CD 0.4) (NN %)) (, ,) (NP (CD 4) (NN %)) (, ,) (NP (CD 0.83) (NN %)) (CC and) (NP (CD 1.45) (NN %))) (PP (IN for) (NP (DT the) (CD 4) (NNS networks))) (, ,) (ADVP (RB respectively))))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NN pipelining)) (VP (VBZ is) (ADVP (RBR deeper) (PP (IN in) (NP (DT the) (NN network))))))) (, ,) (NP (NN inference) (NNS accuracies)) (VP (VBP drop) (ADVP (RB significantly))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (VP (VBG combining) (NP (VBN pipelined) (CC and) (JJ non-pipelined) (NN training)) (PP (IN in) (NP (DT a) (JJ hybrid) (NN scheme))) (S (VP (TO to) (VP (VB address) (NP (DT this) (NN drop)))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN implementation) (CC and) (NN performance)) (PP (IN of) (NP (NP (PRP$ our) (JJ pipelined) (NN backpropagation)) (PP (IN in) (NP (NNP PyTorch)))))) (PP (IN on) (NP (CD 2) (NNP GPUs))) (S (VP (VBG using) (NP (NNP ResNet)))) (, ,) (S (VP (VBG achieving) (NP (NP (NNS speedups)) (PP (IN of) (NP (QP (IN up) (TO to) (CD 1.8X)))) (PP (IN over) (NP (DT a) (JJ 1-GPU) (NN baseline)))) (, ,) (PP (IN with) (NP (NP (DT a) (JJ small) (NN drop)) (PP (IN in) (NP (NN inference) (NN accuracy)))))))) (. .))
