(S (NP (NP (JJ Deep) (JJ Neural) (NN Network)) (-LRB- -LRB-) (NP (NN DNN)) (-RRB- -RRB-)) (VP (VBZ is) (ADJP (ADJP (JJ powerful)) (CC but) (ADVP (RB computationally)) (ADJP (JJ expensive)) (CC and) (ADJP (NN memory) (JJ intensive))) (, ,) (S (ADVP (RB thus)) (VP (VBG impeding) (NP (PRP$ its) (JJ practical) (NN usage)) (PP (IN on) (NP (ADJP (NP (NN resource)) (HYPH -) (VBN constrained)) (NML (NN front) (HYPH -) (NN end)) (NNS devices)))))) (. .))
(S (NP (NN DNN) (NN pruning)) (VP (VBZ is) (NP (NP (DT an) (NN approach)) (PP (IN for) (NP (NP (JJ deep) (NN model) (NN compression)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ aims) (PP (IN at) (S (VP (VBG eliminating) (NP (DT some) (NNS parameters)) (PP (IN with) (NP (ADJP (JJ tolerable)) (NN performance) (NN degradation))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (JJ novel) (ADJP (NP (NN momentum) (HYPH -) (NN SGD)) (HYPH -) (VBN based)) (NN optimization) (NN method)) (S (VP (TO to) (VP (VB reduce) (NP (DT the) (NN network) (NN complexity)) (PP (IN by) (NP (NML (PP (IN on) (HYPH -) (NP (DT the) (HYPH -) (NN fly)))) (NN pruning))))))) (. .))
(S (ADVP (RB Concretely)) (, ,) (PP (VBN given) (NP (DT a) (NML (JJ global) (NN compression)) (NN ratio))) (, ,) (NP (PRP we)) (VP (VBP categorize) (NP (PDT all) (DT the) (NNS parameters)) (PP (IN into) (NP (NP (CD two) (NNS parts)) (PP (IN at) (NP (NP (DT each) (NN training) (NN iteration)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN updated) (S (VP (VBG using) (NP (JJ different) (NNS rules))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN way))) (, ,) (NP (PRP we)) (ADVP (RB gradually)) (VP (VB zero) (PRT (RP out)) (NP (DT the) (JJ redundant) (NNS parameters)) (, ,) (SBAR (IN as) (S (NP (PRP we)) (VP (VBP update) (S (NP (PRP them)) (VP (VBG using) (NP (RB only) (NP (DT the) (JJ ordinary) (NN weight) (NN decay)) (CC but) (NP (NP (DT no) (NNS gradients)) (VP (VBN derived) (PP (IN from) (NP (DT the) (JJ objective) (NN function)))))))))))) (. .))
(S (PP (IN As) (NP (NP (DT a) (NN departure)) (PP (IN from) (NP (NP (JJ prior) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP require) (NP (JJ heavy) (JJ human) (NNS works)) (PP (IN to) (S (VP (VP (VB tune) (NP (DT the) (NN layer-wise) (NN sparsity) (NNS ratios))) (, ,) (VP (VB prune) (PP (IN by) (S (VP (VBG solving) (NP (JJ complicated) (JJ non-differentiable) (NNS problems)))))) (CC or) (VP (VB finetune) (NP (DT the) (NN model)) (PP (IN after) (NP (NN pruning)))))))))))))) (, ,) (NP (PRP$ our) (NN method)) (VP (VBZ is) (VP (VBN characterized) (PP (IN by) (NP (NP (NML (NML (CD 1)) (-RRB- -RRB-) (JJ global)) (NN compression)) (SBAR (WHNP (WDT that)) (S (ADVP (RB automatically)) (VP (VBZ finds) (NP (NP (NP (NP (DT the) (JJ appropriate) (NML (IN per) (HYPH -) (NN layer)) (NN sparsity) (NNS ratios)) (: ;) (LST (LS 2) (-RRB- -RRB-))) (SBAR (S (VP (VB end) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN training))))))) (: ;) (NP (LST (LS 3) (-RRB- -RRB-)) (NP (DT no) (NN need)) (PP (IN for) (NP (NP (DT a) (ADJP (NN time) (HYPH -) (VBG consuming)) (NN re-training) (NN process)) (PP (IN after) (NP (NN pruning)))))) (: ;) (CC and) (NP (LST (LS 4) (-RRB- -RRB-)) (NP (JJ superior) (NN capability) (S (VP (TO to) (VP (VB find) (NP (JJR better)))))) (S (VP (VBG winning) (NP (NP (NNS tickets)) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (VP (VBN won) (NP (DT the) (NN initialization) (NN lottery)))))))))))))))))) (. .))
