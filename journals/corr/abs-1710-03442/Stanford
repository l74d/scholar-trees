(S (NP (NP (JJ Monotonic) (NN policy) (NN improvement)) (CC and) (NP (ADJP (IN off) (HYPH -) (NN policy)) (NN learning))) (VP (VBP are) (NP (NP (CD two) (JJ main) (JJ desirable) (NNS properties)) (PP (IN for) (S (VP (NN reinforcement) (VBG learning) (NP (NNS algorithms))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (PP (IN by) (NP (NP (JJR lower)) (VP (VBG bounding) (NP (NP (DT the) (NN performance) (NN difference)) (PP (IN of) (NP (CD two) (NNS policies))))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (JJ monotonic) (NN policy) (NN improvement)) (VP (VBZ is) (VP (VBN guaranteed) (PP (IN from)) (PP (IN on) (HYPH -) (NP (NP (QP (CC and) (RB off))) (PP (HYPH -) (NP (NN policy) (NN mixture) (NNS samples)))))))))) (. .))
(S (NP (NP (DT An) (NN optimization) (NN procedure)) (SBAR (WHNP (WDT which)) (S (VP (VBZ applies) (NP (NP (DT the) (VBN proposed)) (VP (VBN bound))))))) (VP (MD can) (VP (VB be) (VP (VBN regarded) (PP (IN as) (NP (DT an) (NML (NN off) (HYPH -) (NN policy)) (NML (JJ natural) (NN policy) (NN gradient)) (NN method)))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (VP (VB support) (NP (DT the) (JJ theoretical) (NN result))))))) (, ,) (NP (PRP we)) (VP (VP (VBP provide) (NP (NP (DT a) (NN trust) (NN region) (NN policy) (NN optimization) (NN method)) (VP (VBG using) (NP (NN experience) (NN replay)))) (SBAR (IN as) (S (NP (NP (DT a) (JJ naive) (NN application)) (PP (IN of) (NP (PRP$ our)))) (ADJP (JJ bound)))) (, ,)) (CC and) (VP (VB evaluate) (NP (PRP$ its) (NN performance)) (PP (IN in) (NP (CD two) (JJ classical) (NN benchmark) (NNS problems))))) (. .))
