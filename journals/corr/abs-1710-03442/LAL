(S (NP (NP (JJ Monotonic) (NN policy) (NN improvement)) (CC and) (NP (NN off-policy) (NN learning))) (VP (VBP are) (NP (NP (CD two) (JJ main) (JJ desirable) (NNS properties)) (PP (IN for) (NP (NN reinforcement) (NN learning) (NN algorithms))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (PP (IN by) (S (VP (ADVP (JJR lower)) (VBG bounding) (NP (NP (DT the) (NN performance) (NN difference)) (PP (IN of) (NP (CD two) (NNS policies))))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (JJ monotonic) (NN policy) (NN improvement)) (VP (VBZ is) (VP (VBN guaranteed) (PP (IN from) (NP (ADJP (JJ on-) (CC and) (JJ off-policy)) (NN mixture) (NNS samples)))))))) (. .))
(S (NP (NP (DT An) (NN optimization) (NN procedure)) (SBAR (WHNP (WDT which)) (S (VP (VBZ applies) (NP (DT the) (VBN proposed) (NN bound)))))) (VP (MD can) (VP (VB be) (VP (VBN regarded) (PP (IN as) (NP (DT an) (JJ off-policy) (JJ natural) (NN policy) (NN gradient) (NN method)))))) (. .))
(S (SBAR (IN In) (NN order) (S (VP (TO to) (VP (VB support) (NP (DT the) (JJ theoretical) (NN result)))))) (, ,) (NP (PRP we)) (VP (VP (VBP provide) (NP (NP (DT a) (JJ trust) (NN region) (NN policy) (NN optimization) (NN method)) (VP (VBG using) (NP (NN experience) (NN replay)) (PP (IN as) (NP (NP (DT a) (JJ naive) (NN application)) (PP (IN of) (NP (PRP$ our) (NN bound)))))))) (, ,) (CC and) (VP (VB evaluate) (NP (PRP$ its) (NN performance)) (PP (IN in) (NP (CD two) (JJ classical) (NN benchmark) (NNS problems))))) (. .))
