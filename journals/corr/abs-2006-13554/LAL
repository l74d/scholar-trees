(S (NP (JJ Robust) (NN loss) (NNS functions)) (VP (VBP are) (ADJP (JJ essential) (PP (IN for) (S (VP (VBG training) (NP (NP (JJ accurate) (JJ deep) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP DNNs)) (-RRB- -RRB-))) (PP (IN in) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (NN noisy) (PRN (-LRB- -LRB-) (JJ incorrect) (-RRB- -RRB-)) (NNS labels)))))))))) (. .))
(S (NP (PRP It)) (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (SBAR (IN that) (S (NP (DT the) (ADJP (RB commonly) (VBN used)) (NNP Cross) (NNP Entropy) (PRN (-LRB- -LRB-) (NNP CE) (-RRB- -RRB-)) (NN loss)) (VP (VBZ is) (RB not) (ADJP (JJ robust) (PP (TO to) (NP (DT noisy) (NNS labels)))))))))) (. .))
(S (SBAR (NNP Whilst) (S (NP (JJ new) (NN loss) (NNS functions)) (VP (VBP have) (VP (VBN been) (VP (VBN designed)))))) (, ,) (NP (PRP they)) (VP (VBP are) (ADJP (ADVP (RB only) (RB partially)) (JJ robust))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (ADVP (RB theoretically)) (VP (VBP show) (PP (IN by) (S (VP (VBG applying) (NP (DT a) (JJ simple) (NN normalization))))) (SBAR (IN that) (: :) (S (NP (DT any) (NN loss)) (VP (MD can) (VP (VB be) (VP (VBN made) (S (ADJP (JJ robust) (PP (TO to) (NP (DT noisy) (NNS labels))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (NN practice))) (, ,) (S (ADVP (RB simply)) (VP (VBG being) (ADJP (NN robust)))) (VP (VBZ is) (RB not) (ADJP (JJ sufficient) (SBAR (IN for) (S (NP (DT a) (NN loss) (NN function)) (VP (TO to) (VP (VB train) (NP (JJ accurate) (NNP DNNs)))))))) (. .))
(S (PP (IN By) (S (VP (VBG investigating) (NP (JJ several) (JJ robust) (NN loss) (NNS functions))))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP suffer) (PP (IN from) (NP (NP (DT a) (NN problem)) (PP (IN of) (NP (NN underfitting))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (DT a) (NN framework)) (SBAR (S (VP (TO to) (VP (VB build) (NP (JJ robust) (NN loss) (NNS functions))))))) (VP (VBD called) (S (NP (S (NP (NNP Active) (NNP Passive) (NNP Loss))) (PRN (-LRB- -LRB-) (NP (NNP APL)) (-RRB- -RRB-))))))) (. .))
(S (NP (NNP APL)) (VP (NNS combines) (NP (NP (CD two) (JJ robust) (NN loss) (NNS functions)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB mutually)) (VBP boost) (NP (DT each) (JJ other))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NN benchmark) (NNS datasets)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT the) (NN family)) (PP (IN of) (NP (JJ new) (NN loss) (NNS functions))) (VP (VBN created) (PP (IN by) (NP (PRP$ our) (NNP APL) (NN framework))))) (VP (MD can) (VP (ADVP (RB consistently)) (VB outperform) (NP (JJ state-of-the-art) (NNS methods)) (PP (IN by) (NP (JJ large) (NNS margins))) (, ,) (PP (ADVP (RB especially)) (IN under) (NP (NP (JJ large) (NN noise) (NNS rates)) (PP (JJ such) (IN as) (NP (ADJP (CD 60) (NN %) (CC or) (CD 80) (NN %)) (JJ incorrect) (NNS labels)))))))))) (. .))
