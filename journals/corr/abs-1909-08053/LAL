(S (NP (NP (JJ Recent) (NN work)) (PP (IN in) (NP (NN language) (NN modeling)))) (VP (VBZ demonstrates) (SBAR (IN that) (S (S (VP (VBG training) (NP (JJ large) (NN transformer) (NNS models)))) (VP (VBZ advances) (NP (NP (DT the) (NN state)) (PP (IN of) (NP (DT the) (NN art))) (PP (IN in) (NP (NNP Natural) (NNP Language) (NNP Processing) (NNS applications)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (ADJP (RB very) (JJ large)) (NNS models)) (VP (MD can) (VP (VB be) (ADJP (RB quite) (JJ difficult) (SBAR (S (VP (TO to) (VP (VB train)))))) (PP (JJ due) (PP (TO to) (NP (NN memory) (NNS constraints)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VP (VBP present) (NP (NP (PRP$ our) (NNS techniques)) (PP (IN for) (S (VP (VBG training) (NP (ADJP (RB very) (JJ large)) (NN transformer) (NNS models))))))) (CC and) (VP (VB implement) (NP (NP (DT a) (NN simple) (, ,) (JJ efficient) (JJ intra-layer) (NN model) (JJ parallel) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (S (VP (VBG training) (NP (NP (JJ transformer) (NNS models)) (PP (IN with) (NP (NP (NNS billions)) (PP (IN of) (NP (NNS parameters)))))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VP (VBZ does) (RB not) (VP (VB require) (NP (DT a) (JJ new) (NN compiler) (CC or) (JJ library) (NNS changes)))) (, ,) (VP (VBZ is) (ADJP (JJ orthogonal) (CC and) (JJ complimentary) (PP (TO to) (NP (NN pipeline) (NN model) (NN parallelism))))) (, ,) (CC and) (VP (MD can) (VP (VB be) (VP (ADVP (RB fully)) (VBN implemented) (PP (IN with) (NP (NP (DT the) (NN insertion)) (PP (IN of) (NP (DT a) (JJ few) (NN communication) (NNS operations))) (PP (IN in) (NP (JJ native) (NNP PyTorch))))))))) (. .))
(S (NP (PRP We)) (VP (VBP illustrate) (NP (DT this) (NN approach)) (PP (IN by) (S (VP (VBG converging) (NP (ADJP (NN transformer) (VBN based)) (NNS models)) (PP (IN up) (PP (TO to) (NP (QP (CD 8.3) (CD billion)) (NNS parameters)))) (S (VP (VBG using) (NP (CD 512) (NNP GPUs)))))))) (. .))
(S (NP (PRP We)) (VP (VBP sustain) (NP (CD 15.1) (NNP PetaFLOPs)) (PP (IN across) (NP (DT the) (JJ entire) (NN application))) (PP (IN with) (NP (ADJP (CD 76) (NN %)) (NN scaling) (NN efficiency))) (SBAR (WHADVP (WRB when)) (S (VP (VBN compared) (PP (TO to) (NP (NP (DT a) (JJ strong) (JJ single) (NNP GPU) (NN baseline)) (SBAR (WHNP (WDT that)) (S (VP (VBZ sustains) (NP (NP (CD 39) (NNP TeraFLOPs)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (CD 30) (NN %)) (PP (IN of) (NP (JJ peak) (NNP FLOPs))))))))))))))))) (. .))
(S (S (VP (TO To) (VP (VB demonstrate) (SBAR (DT that) (S (NP (JJ large) (NN language) (NNS models)) (VP (MD can) (VP (ADVP (RB further)) (VB advance) (NP (NP (NP (DT the) (NN state)) (PP (IN of) (NP (DT the) (NN art)))) (PRN (-LRB- -LRB-) (NP (NNP SOTA)) (-RRB- -RRB-)))))))))) (, ,) (NP (PRP we)) (VP (VBP train) (NP (NP (NP (DT an) (QP (CD 8.3) (CD billion)) (NN parameter) (NN transformer) (NN language) (NN model)) (ADJP (JJ similar) (PP (TO to) (NP (NNP GPT-2))))) (CC and) (NP (NP (DT a) (QP (CD 3.9) (CD billion)) (NN parameter) (NN model)) (ADJP (JJ similar) (PP (TO to) (NP (NNP BERT))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (DT that) (S (NP (NP (JJ careful) (NN attention)) (PP (TO to) (NP (NP (DT the) (NN placement)) (PP (IN of) (NP (NN layer) (NN normalization))) (PP (IN in) (NP (NNP BERT-like) (NNS models)))))) (VP (VBZ is) (ADJP (JJ critical) (PP (TO to) (S (VP (VBG achieving) (NP (JJ increased) (NN performance)) (SBAR (IN as) (S (NP (DT the) (NN model) (NN size)) (VP (NNS grows)))))))))))) (. .))
(S (S (VP (VBG Using) (NP (DT the) (JJ GPT-2) (NN model)))) (NP (PRP we)) (VP (VBP achieve) (NP (JJ SOTA) (NNS results)) (PP (IN on) (NP (DT the) (NX (NX (NNP WikiText103)) (PRN (-LRB- -LRB-) (NP (NP (CD 10.8)) (PP (VBN compared) (PP (TO to) (NP (NP (NNP SOTA) (NN perplexity)) (PP (IN of) (NP (CD 15.8))))))) (-RRB- -RRB-))) (CC and) (NNP LAMBADA) (PRN (-LRB- -LRB-) (NP (NP (CD 66.5) (NN %)) (PP (VBN compared) (PP (TO to) (NP (NP (NNP SOTA) (NN accuracy)) (PP (IN of) (NP (CD 63.2) (NN %))))))) (-RRB- -RRB-)) (NNS datasets)))) (. .))
(S (NP (PRP$ Our) (NNP BERT) (NN model)) (VP (NNS achieves) (NP (NP (NP (NNP SOTA) (NNS results)) (PP (IN on) (NP (DT the) (NNP RACE) (NN dataset)))) (PRN (-LRB- -LRB-) (NP (NP (CD 90.9) (NN %)) (PP (VBN compared) (PP (TO to) (NP (NP (NNP SOTA) (NN accuracy)) (PP (IN of) (NP (CD 89.4) (NN %))))))) (-RRB- -RRB-)))) (. .))
