(S (NP (NP (DT The) (JJ large) (NN memory) (NNS requirements)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))) (VP (VBP limit) (NP (NP (PRP$ their) (NN deployment) (CC and) (NN adoption)) (PP (IN on) (NP (JJ many) (NNS devices))))) (. .))
(S (NP (NNP Model) (NN compression) (NNS methods)) (VP (ADVP (RB effectively)) (VB reduce) (NP (NP (DT the) (NN memory) (NNS requirements)) (PP (IN of) (NP (DT these) (NNS models)))) (, ,) (PP (ADVP (RB usually)) (IN through) (S (VP (VBG applying) (NP (NP (NNS transformations)) (PP (JJ such) (IN as) (NP (NP (NN weight) (NN pruning)) (CC or) (NP (NN quantization))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ novel) (NN scheme)) (PP (IN for) (NP (JJ lossy) (NN weight) (VBG encoding))) (SBAR (WHNP (WDT which)) (S (VP (VBZ complements) (NP (JJ conventional) (NN compression) (NNS techniques))))))) (. .))
(S (NP (DT The) (NN encoding)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (NP (DT the) (NNP Bloomier) (NN filter)) (, ,) (NP (NP (DT a) (JJ probabilistic) (NN data) (NN structure)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB save) (NP (NN space)) (PP (IN at) (NP (NP (DT the) (NN cost)) (PP (IN of) (S (VP (VBG introducing) (NP (JJ random) (NNS errors)))))))))))))))) (. .))
(S (PP (S (VP (VBG Leveraging) (NP (NP (DT the) (NN ability)) (PP (IN of) (NP (JJ neural) (NNS networks))) (S (VP (TO to) (VP (VB tolerate) (NP (DT these) (NNS imperfections)))))))) (CC and) (PP (IN by) (S (VP (VBG re-training) (PP (IN around) (NP (DT the) (NNS errors))))))) (, ,) (NP (NP (DT the) (VBN proposed) (NN technique)) (, ,) (NP (NNP Weightless)) (, ,)) (VP (MD can) (VP (VB compress) (NP (NNP DNN) (NNS weights)) (PP (IN by) (NP (QP (IN up) (TO to) (CD 496x)))) (PP (IN with) (NP (DT the) (JJ same) (NN model) (NN accuracy))))) (. .))
(S (NP (DT This)) (VP (NNS results) (PP (IN in) (NP (RB up) (PP (TO to) (NP (NP (DT a) (CD 1.51x) (NN improvement)) (PP (IN over) (NP (DT the) (JJ state-of-the-art)))))))) (. .))
