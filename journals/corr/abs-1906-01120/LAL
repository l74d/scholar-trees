(S (PP (IN In) (NP (DT a) (JJ conventional) (JJ supervised) (VBG learning) (NN setting))) (, ,) (NP (DT a) (NN machine) (VBG learning) (NN model)) (VP (VBZ has) (NP (NP (NN access)) (PP (TO to) (NP (NP (NNS examples)) (PP (IN of) (NP (NP (DT all) (JJ object) (NNS classes)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (VBN desired) (S (VP (TO to) (VP (VB be) (VP (VBN recognized) (PP (IN during) (NP (DT the) (NN inference) (NN stage))))))))))))))))) (. .))
(S (NP (DT This)) (VP (NNS results) (PP (IN in) (NP (NP (DT a) (JJ fixed) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (VBZ lacks) (NP (NP (DT the) (NN flexibility)) (SBAR (S (VP (TO to) (VP (VB adapt) (PP (TO to) (NP (JJ new) (VBG learning) (NNS tasks)))))))))))))) (. .))
(S (PP (IN In) (NP (JJ practical) (NNS settings))) (, ,) (S (NP (VBG learning) (NNS tasks)) (ADVP (RB often)) (VP (VBP arrive) (PP (IN in) (NP (DT a) (NN sequence))))) (CC and) (S (NP (DT the) (NNS models)) (VP (MD must) (ADVP (RB continually)) (VP (VB learn) (S (VP (TO to) (VP (VB increment) (NP (PRP$ their) (ADJP (RB previously) (VBN acquired)) (NN knowledge)))))))) (. .))
(S (NP (VBG Existing) (JJ incremental) (NN learning) (NNS approaches)) (VP (VBP fall) (PP (ADVP (RB well)) (IN below) (NP (NP (DT the) (JJ state-of-the-art) (JJ cumulative) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (DT all) (NN training) (NNS classes)) (PP (IN at) (NP (RB once))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ random) (NN path) (NN selection) (NN algorithm)) (, ,) (VP (VBD called) (S (NP (JJ Adaptive) (NNP RPS-Net)))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB progressively)) (VBZ chooses) (NP (NP (JJ optimal) (NNS paths)) (PP (IN for) (NP (DT the) (JJ new) (NNS tasks)))) (SBAR (IN while) (S (VP (VBG encouraging) (NP (NP (NN parameter) (VBG sharing)) (PP (IN between) (NP (NNS tasks)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (JJ new) (NN network) (NN capacity) (NN measure)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (S (NP (PRP us)) (VP (TO to) (ADVP (RB automatically)) (VP (VB switch) (NP (NNS paths)) (SBAR (IN if) (S (NP (DT the) (ADJP (RB already) (JJ used)) (NNS resources)) (VP (VBP are) (VP (VBN saturated))))))))))))) (. .))
(S (SBAR (IN Since) (S (NP (DT the) (VBN proposed) (NN path-reuse) (NN strategy)) (VP (VBZ ensures) (NP (RB forward) (NN knowledge) (NN transfer))))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VP (VBZ is) (ADJP (JJ efficient))) (CC and) (VP (VBZ has) (NP (ADJP (RB considerably) (JJR less)) (NN computation) (NN overhead)))) (. .))
(S (PP (IN As) (NP (DT an) (JJ added) (NN novelty))) (, ,) (NP (DT the) (VBN proposed) (NN model)) (VP (VBZ integrates) (NP (JJ knowledge) (NN distillation) (CC and) (NN retrospection)) (PP (IN along) (PP (IN with) (NP (DT the) (NN path) (NN selection) (NN strategy)))) (S (VP (TO to) (VP (VB overcome) (NP (JJ catastrophic) (NN forgetting)))))) (. .))
(S (SBAR (IN In) (NN order) (S (VP (TO to) (VP (VB maintain) (NP (NP (DT an) (NN equilibrium)) (PP (IN between) (NP (ADJP (ADJP (JJ previous)) (CC and) (ADJP (RB newly) (VBN acquired))) (NN knowledge)))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ simple) (NN controller)) (SBAR (S (VP (TO to) (VP (ADVP (RB dynamically)) (VB balance) (NP (DT the) (NN model) (NN plasticity)))))))) (. .))
(S (PP (IN Through) (NP (JJ extensive) (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (SBAR (IN that) (S (NP (DT the) (NNP Adaptive) (NNP RPS-Net) (NN method)) (VP (VBZ surpasses) (NP (NP (DT the) (JJ state-of-the-art) (NN performance)) (PP (IN for) (NP (JJ incremental) (NN learning))))))) (CC and) (S (PP (IN by) (S (VP (VBG utilizing) (NP (JJ parallel) (NN computation))))) (NP (DT this) (NN method)) (VP (MD can) (VP (VB run) (PP (IN in) (NP (JJ constant) (NN time))) (PP (IN with) (NP (NP (RB nearly) (DT the) (JJ same) (NN efficiency)) (PP (IN as) (NP (DT a) (JJ conventional) (JJ deep) (JJ convolutional) (JJ neural) (NN network)))))))))) (. .))
