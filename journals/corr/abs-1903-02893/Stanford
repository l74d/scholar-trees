(S (NP (PRP We)) (VP (VBP study) (NP (NP (DT the) (NN emergence)) (PP (IN of) (NP (NP (JJ sparse) (NNS representations)) (PP (IN in) (NP (JJ neural) (NNS networks))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (PP (IN in) (NP (NP (JJ unsupervised) (NNS models)) (PP (IN with) (NP (NN regularization))))) (, ,) (NP (NP (DT the) (NN emergence)) (PP (IN of) (NP (NN sparsity)))) (VP (VBZ is) (NP (NP (DT the) (NN result)) (PP (IN of) (NP (NP (DT the) (NML (NN input) (NN data)) (NNS samples)) (VP (VBG being) (VP (VBN distributed) (PP (IN along) (NP (ADJP (RB highly) (JJ non-linear) (CC or) (JJ discontinuous)) (NN manifold)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP derive) (NP (DT a) (JJ similar) (NN argument)) (PP (IN for) (NP (NP (ADJP (RB discriminatively) (VBN trained)) (NNS networks)) (CC and) (NP (JJ present) (NNS experiments)))) (S (VP (TO to) (VP (VB support) (NP (DT this) (NN hypothesis)))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (NP (PRP$ our) (NN study)) (PP (IN of) (NP (NN sparsity)))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ new) (NN loss) (NN function)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN as) (NP (NN regularization) (NN term))) (PP (IN for) (NP (NP (NNS models)) (PP (IN like) (NP (NNS autoencoders) (CC and) (NNS MLPs)))))))))))) (. .))
(S (ADVP (RB Further)) (, ,) (NP (DT the) (JJ same) (NN loss) (NN function)) (VP (MD can) (ADVP (RB also)) (VP (VB be) (VP (VBN used) (PP (IN as) (NP (DT a) (NN cost) (NN function))) (PP (IN for) (NP (NP (DT an) (JJ unsupervised) (NML (ADJP (JJ single) (HYPH -) (JJ layered)) (JJ neural) (NN network)) (NN model)) (PP (IN for) (NP (NN learning) (JJ efficient) (NNS representations)))))))) (. .))
