(S (NP (NP (JJ Recurrent) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (VP (VBP are) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB train) (PP (IN on) (NP (NML (NN sequence) (NN processing)) (NNS tasks))))))) (, ,) (SBAR (CONJP (RB not) (RB only)) (SBAR (IN because) (S (NP (NN input) (NN noise)) (VP (MD may) (VP (VB be) (VP (VBN amplified) (PP (IN through) (NP (NN feedback)))))))) (, ,) (CONJP (CC but) (RB also)) (SBAR (IN because) (S (NP (NP (DT any) (NN inaccuracy)) (PP (IN in) (NP (DT the) (NNS weights)))) (VP (VBZ has) (NP (NP (JJ similar) (NNS consequences)) (PP (IN as) (NP (NN input) (NN noise))))))))) (. .))
(S (NP (PRP We)) (VP (VBP describe) (NP (DT a) (NN method)) (PP (IN for) (S (VP (VBG denoising) (NP (DT the) (JJ hidden) (NN state)) (PP (IN during) (NP (NN training))) (S (VP (TO to) (VP (VB achieve) (S (NP (ADJP (RBR more) (JJ robust)) (NNS representations)) (ADVP (RB thereby)) (VP (VBG improving) (NP (NN generalization) (NN performance))))))))))) (. .))
(S (NP (NN Attractor) (NNS dynamics)) (VP (VBP are) (VP (VBN incorporated) (PP (IN into) (NP (DT the) (JJ hidden) (NN state))) (PP (IN to) (NP (NP (`` `) (ADJP (JJ clean) (ADVP (RP up))) ('' ') (NNS representations)) (PP (IN at) (NP (NP (DT each) (NN step)) (PP (IN of) (NP (DT a) (NN sequence))))))))) (. .))
(S (NP (DT The) (NN attractor) (NNS dynamics)) (VP (VBP are) (VP (VBN trained) (PP (IN through) (NP (DT an) (JJ auxillary) (NN denoising) (NN loss))) (S (VP (TO to) (VP (VB recover) (NP (ADJP (RB previously) (JJ experienced)) (JJ hidden) (NNS states)) (PP (IN from) (NP (NP (JJ noisy) (NNS versions)) (PP (IN of) (NP (DT those) (NNS states)))))))))) (. .))
(S (NP (NP (NP (DT This) (NN state)) (HYPH -) (VP (VBN denoised) (S (ADJP (JJ recurrent))))) (NP (JJ neural) (NN network) (-LRB- {) (NN SDRNN) (-RRB- }))) (VP (VBZ performs) (NP (NP (JJ multiple) (NNS steps)) (PP (IN of) (NP (NP (JJ internal) (NN processing)) (PP (IN for) (NP (DT each) (JJ external) (NN sequence) (NN step))))))) (. .))
(S (PP (IN On) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (NNS tasks))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NNP SDRNN)) (VP (VBZ outperforms) (NP (DT a) (JJ generic) (NN RNN)) (PP (CONJP (RB as) (RB well) (IN as) (NP (NP (DT a) (NN variant)) (PP (IN of) (NP (DT the) (NN SDRNN))))) (PP (IN with) (NP (NP (NN attractor) (NNS dynamics)) (PP (IN on) (NP (DT the) (JJ hidden) (NN state))))) (CC but) (PP (IN without) (NP (DT the) (JJ auxillary) (NN loss)))))))) (. .))
(S (NP (PRP We)) (VP (VBP argue) (SBAR (IN that) (S (NP (NP (NN attractor) (NNS dynamics)) (, ---) (CC and) (NP (VBG corresponding) (NN connectivity) (NNS constraints))) (, ---) (VP (VP (VBP are) (NP (NP (DT an) (JJ essential) (NN component)) (PP (IN of) (NP (DT the) (NML (JJ deep) (NN learning)) (NN arsenal))))) (CC and) (VP (MD should) (VP (VB be) (VP (VBN invoked) (PP (CONJP (RB not) (RB only)) (PP (IN for) (NP (ADJP (JJ recurrent)) (NNS networks))) (CONJP (CC but) (RB also)) (PP (IN for) (S (VP (VBG improving) (NP (NP (JJ deep) (NN feedforward) (NNS nets)) (CC and) (NP (NN intertask) (NN transfer)))))))))))))) (. .))
