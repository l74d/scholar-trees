(S (NP (DT This) (NN paper)) (VP (VBZ presents) (NP (DT a) (JJ new) (NN method)) (PP (IN for) (S (VP (VBG pre-training) (NP (NP (JJ neural) (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB decrease) (NP (NP (DT the) (JJ total) (NN training) (NN time)) (PP (IN for) (NP (DT a) (JJ neural) (NN network)))) (PP (IN while) (S (VP (VBG maintaining) (NP (NP (DT the) (JJ final) (NN performance)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ motivates) (NP (PRP$ its) (NN use)) (PP (IN on) (NP (JJ deep) (JJ neural) (NNS networks))))))))))))))))))) (. .))
(S (PP (IN By) (S (VP (VBG partitioning) (NP (NP (DT the) (NN training) (NN task)) (PP (IN in) (NP (JJ multiple) (NN training) (NNS subtasks)))) (PP (IN with) (NP (NP (NNS sub-models)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN performed) (UCP (ADVP (RB independently)) (CC and) (PP (IN in) (NP (NN parallel)))))))))))))) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBN shown) (SBAR (IN that) (S (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT the) (NNS sub-models)))) (VP (VBZ reduces) (ADVP (RB almost)) (ADVP (RB quadratically)) (PP (IN with) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS subtasks)) (VP (VBN created))))))))) (, ,) (S (ADVP (RB quickly)) (VP (VBG scaling) (PRT (RP down)) (NP (NP (DT the) (NNS sub-models)) (VP (VBN used) (PP (IN for) (NP (DT the) (NN pre-training))))))))) (. .))
(S (NP (DT The) (NNS sub-models)) (VP (VBP are) (ADVP (RB then)) (VP (VBN merged) (S (VP (TO to) (VP (VB provide) (NP (NP (DT a) (JJ pre-trained) (JJ initial) (NN set)) (PP (IN of) (NP (NP (NNS weights)) (PP (IN for) (NP (DT the) (JJ original) (NN model))))))))))) (. .))
(S (NP (DT The) (JJ proposed) (NN method)) (VP (VBZ is) (ADJP (JJ independent) (PP (IN of) (NP (NP (DT the) (JJ other) (NNS aspects)) (PP (IN of) (NP (NP (DT the) (NN training)) (, ,) (PP (JJ such) (IN as) (NP (NP (NN architecture)) (PP (IN of) (NP (NP (DT the) (JJ neural) (NN network)) (, ,) (NP (NN training) (NN method)) (, ,) (CC and) (NP (NN objective)))))) (, ,)))))) (S (VP (VBG making) (S (NP (PRP it)) (ADJP (JJ compatible) (PP (IN with) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (VBG existing) (NNS approaches)))))))))) (. .))
(S (NP (NP (DT The) (NN speedup)) (PP (IN without) (NP (NP (NN loss)) (PP (IN of) (NP (NN performance)))))) (VP (VBZ is) (VP (VBN validated) (ADVP (RB experimentally)) (PP (PP (IN on) (NP (NNP MNIST))) (CC and) (PP (IN on) (NP (NML (NN CIFAR10) (NNS data)) (NNS sets)))) (, ,) (S (ADVP (RB also)) (VP (VBG showing) (SBAR (IN that) (S (S (ADVP (RB even)) (VP (VBG performing) (NP (DT the) (NNS subtasks)) (ADVP (RB sequentially)))) (VP (MD can) (VP (VB decrease) (NP (DT the) (NN training) (NN time)))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (JJR larger) (NNS models)) (VP (MD may) (VP (VB present) (NP (JJR higher) (NNS speedups) (CC and) (NN conjecture)) (PP (IN about) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (NP (NP (DT the) (NN method)) (PP (IN in) (NP (VBN distributed) (NN learning) (NNS systems)))))))))))) (. .))
