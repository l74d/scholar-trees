(S (NP (PRP We)) (VP (VBP consider) (NP (NP (DT a) (JJ new) (NN form)) (PP (IN of) (NP (JJ model-based) (NN reinforcement) (VBG learning) (NNS methods))) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB directly)) (VBZ learns) (NP (DT the) (JJ optimal) (NN control) (NNS parameters)) (, ,) (PP (RB instead) (IN of) (S (VP (VBG learning) (NP (DT the) (VBG underlying) (JJ dynamical) (NN system)))))))))) (. .))
(S (NP (DT This)) (VP (VBZ includes) (NP (NP (DT a) (NN form)) (PP (IN of) (NP (NN exploration) (CC and) (NN exploitation))) (PP (IN in) (S (VP (NN learning) (CC and) (VBG applying) (NP (DT the) (JJ optimal) (NN control) (NNS parameters)) (PP (IN over) (NP (NN time)))))))) (. .))
(S (NP (DT This)) (ADVP (RB also)) (VP (VBZ includes) (NP (NP (DT a) (JJ general) (NN framework)) (SBAR (SBAR (WHNP (WDT that)) (S (VP (VBZ manages) (NP (NP (DT a) (NN collection)) (PP (IN of) (NP (JJ such) (JJ control-model-based) (NN reinforcement) (VBG learning) (NNS methods))) (VP (VBG running) (PP (IN in) (NP (NN parallel)))))))) (CC and) (SBAR (WHNP (DT that)) (S (VP (VBZ selects) (NP (DT the) (JJS best) (NN decision)) (PP (IN from) (PP (IN among) (NP (DT these) (NNS parallel) (NNS methods)))) (PP (IN with) (S (NP (DT the) (JJ different) (NNS methods)) (VP (ADVP (RB interactively)) (VBG learning) (ADVP (RB together))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP derive) (NP (NP (JJ theoretical) (NNS results)) (PP (IN for) (NP (NP (DT the) (JJ optimal) (NN control)) (PP (IN of) (NP (NP (ADJP (JJ linear) (CC and) (JJ nonlinear)) (NNS instances)) (PP (IN of) (NP (DT the) (JJ new) (JJ control-model-based) (NN reinforcement) (VBG learning) (NNS methods))))))))) (. .))
(S (NP (PRP$ Our) (JJ empirical) (NNS results)) (VP (NN demonstrate) (CC and) (VB quantify) (NP (NP (DT the) (JJ significant) (NNS benefits)) (PP (IN of) (NP (PRP$ our) (NN approach))))) (. .))
