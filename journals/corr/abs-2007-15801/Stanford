(S (NP (PRP We)) (VP (VBP perform) (NP (NP (DT a) (ADJP (JJ careful) (, ,) (JJ thorough) (, ,) (CC and) (JJ large)) (NN scale) (JJ empirical) (NN study)) (PP (IN of) (NP (NP (DT the) (NN correspondence)) (PP (IN between) (NP (NP (JJ wide) (JJ neural) (NNS networks)) (CC and) (NP (NN kernel) (NNS methods)))))))) (. .))
(S (PP (IN By) (S (VP (VBG doing) (ADVP (RB so))))) (, ,) (NP (PRP we)) (VP (VBP resolve) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NP (JJ open) (NNS questions)) (VP (VBN related) (PP (IN to) (NP (NP (DT the) (NN study)) (PP (IN of) (NP (ADJP (RB infinitely) (JJ wide)) (JJ neural) (NNS networks)))))))))) (. .))
(S (S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP include))) (: :) (S (NP (NN kernel) (NNS methods)) (VP (VP (VBP outperform) (NP (ADJP (RB fully) (HYPH -) (VBN connected)) (NML (NN finite) (HYPH -) (NN width)) (NNS networks))) (, ,) (CC but) (VP (VBP underperform) (NP (JJ convolutional) (JJ finite) (NN width) (NNS networks))))) (: ;) (S (NP (NML (JJ neural) (NN network)) (JJ Gaussian) (NML (NN process) (-LRB- -LRB-) (NN NNGP) (-RRB- -RRB-)) (NNS kernels)) (ADVP (RB frequently)) (VP (VBP outperform) (NP (NML (NML (JJ neural) (NN tangent)) (-LRB- -LRB-) (NML (NN NT)) (-RRB- -RRB-)) (NNS kernels)))) (: ;) (S (S (VP (VBN centered) (CC and) (VBN ensembled) (NP (JJ finite) (NNS networks)))) (VP (VP (VBP have) (VP (VBN reduced) (NP (JJ posterior) (NN variance)))) (CC and) (VP (VB behave) (NP (JJR more)) (ADVP (RB similarly)) (PP (IN to) (NP (JJ infinite) (NNS networks)))))) (: ;) (S (NP (NP (NN weight) (NN decay)) (CC and) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (DT a) (NML (JJ large) (NN learning)) (NN rate))))) (VP (VB break) (NP (NP (DT the) (NN correspondence)) (PP (IN between) (NP (NP (NN finite)) (CC and) (NP (JJ infinite) (NNS networks))))))) (: ;) (S (NP (DT the) (NNP NTK) (NN parameterization)) (VP (VBZ outperforms) (NP (NP (DT the) (JJ standard) (NN parameterization)) (PP (IN for) (NP (JJ finite) (NN width) (NNS networks)))))) (: ;) (S (NP (NP (JJ diagonal) (NN regularization)) (PP (IN of) (NP (NNS kernels)))) (VP (VBZ acts) (ADVP (RB similarly)) (PP (IN to) (NP (NP (JJ early) (NN stopping)) (: ;) (NP (NP (NML (VBG floating) (NN point)) (NN precision) (NNS limits)) (NP (NP (NN kernel) (NN performance)) (PP (IN beyond) (NP (DT a) (JJ critical) (NN dataset) (NN size))))))))) (: ;) (S (NP (VBN regularized) (NN ZCA) (NN whitening)) (VP (VBZ improves) (NP (NN accuracy)))) (: ;) (S (NP (JJ finite) (NN network) (NN performance)) (VP (VBZ depends) (ADVP (RB non-monotonically)) (PP (IN on) (NP (NP (NN width)) (PP (IN in) (NP (NP (NNS ways)) (VP (RB not) (VBN captured) (PP (IN by) (NP (JJ double) (NN descent) (NN phenomena)))))))))) (: ;) (S (NP (NP (NN equivariance)) (PP (IN of) (NP (NNS CNNs)))) (VP (VBZ is) (ADJP (RB only) (JJ beneficial) (PP (IN for) (NP (JJ narrow) (NNS networks)))) (ADVP (RB far) (PP (IN from) (NP (DT the) (NN kernel) (NN regime)))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (ADVP (RB additionally)) (VP (VBP motivate) (NP (DT an) (JJ improved) (JJ layer-wise) (NN scaling)) (PP (IN for) (NP (NP (NN weight) (NN decay)) (SBAR (WHNP (WDT which)) (S (VP (VBZ improves) (NP (NP (NN generalization)) (PP (IN in) (NP (NML (NN finite) (HYPH -) (NN width)) (NNS networks)))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (JJ improved) (JJS best) (NNS practices)) (PP (IN for) (S (VP (VBG using) (NP (NP (NML (NN NNGP) (CC and) (NN NT)) (NNS kernels)) (PP (IN for) (NP (NN prediction))) (, ,) (PP (VBG including) (NP (DT a) (JJ novel) (NN ensembling) (NN technique))))))))) (. .))
(S (S (VP (VBG Using) (NP (NP (DT these) (JJS best) (NNS practices)) (SBAR (S (NP (PRP we)) (VP (VBP achieve) (NP (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS results)) (PP (IN on) (NP (NML (NN CIFAR) (HYPH -) (CD 10)) (NN classification)))) (PP (IN for) (NP (NP (NNS kernels)) (VP (VBG corresponding) (PP (IN to) (NP (DT each) (NN architecture) (NN class)))))))))))) (NP (PRP we)) (VP (VBP consider)) (. .))
