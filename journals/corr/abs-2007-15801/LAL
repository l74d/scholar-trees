(S (NP (PRP We)) (VP (VBP perform) (NP (NP (DT a) (ADJP (ADJP (JJ careful)) (, ,) (ADJP (JJ thorough)) (, ,) (CC and) (ADJP (JJ large) (NN scale))) (JJ empirical) (NN study)) (PP (IN of) (NP (NP (DT the) (NN correspondence)) (PP (IN between) (NP (NP (JJ wide) (JJ neural) (NNS networks)) (CC and) (NP (NNS kernel) (NNS methods)))))))) (. .))
(S (PP (IN By) (S (VP (VBG doing) (ADVP (RB so))))) (, ,) (NP (PRP we)) (VP (VBP resolve) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NP (JJ open) (NNS questions)) (VP (VBN related) (PP (TO to) (NP (NP (DT the) (NN study)) (PP (IN of) (NP (ADJP (RB infinitely) (JJ wide)) (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP include) (: :) (S (S (NP (NNS kernel) (NNS methods)) (VP (VP (RB outperform) (NP (JJ fully-connected) (JJ finite-width) (NNS networks))) (, ,) (CC but) (VP (JJ underperform) (NP (JJ convolutional) (NN finite) (NN width) (NNS networks))))) (: ;) (S (NP (JJ neural) (NN network) (JJ Gaussian) (NN process) (PRN (-LRB- -LRB-) (NNP NNGP) (-RRB- -RRB-)) (VBZ kernels)) (ADVP (RB frequently)) (VP (JJ outperform) (NP (JJ neural) (NN tangent) (PRN (-LRB- -LRB-) (NNP NT) (-RRB- -RRB-)) (NNS kernels)))) (: ;) (S (NP (ADJP (VBN centered) (CC and) (VBN ensembled)) (JJ finite) (NNS networks)) (VP (VBP have) (VP (VP (VBN reduced) (NP (JJ posterior) (NN variance))) (CC and) (VP (VB behave) (ADVP (JJR more) (RB similarly) (PP (TO to) (NP (VB infinite) (NNS networks)))))))) (: ;) (S (NP (NP (VBN weight) (NN decay)) (CC and) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (DT a) (JJ large) (VBG learning) (NN rate))))) (VP (VB break) (NP (NP (DT the) (NN correspondence)) (PP (IN between) (NP (ADJP (NN finite) (CC and) (JJ infinite)) (NNS networks)))))) (: ;) (S (NP (DT the) (NNP NTK) (NN parameterization)) (VP (VBZ outperforms) (NP (NP (DT the) (JJ standard) (NN parameterization)) (PP (IN for) (NP (JJ finite) (JJ width) (NNS networks)))))) (: ;) (S (NP (NP (JJ diagonal) (NN regularization)) (PP (IN of) (NP (NNS kernels)))) (VP (NNS acts) (ADVP (RB similarly) (PP (TO to) (NP (JJ early) (NN stopping)))))) (: ;) (S (NP (VBG floating) (NN point) (NN precision)) (VP (NNS limits) (NP (VBP kernel) (NN performance)) (PP (IN beyond) (NP (DT a) (JJ critical) (NN dataset) (NN size))))) (: ;) (S (NP (VBN regularized) (NNP ZCA) (VBG whitening)) (VP (NNS improves) (NP (NN accuracy)))) (: ;) (S (NP (JJ finite) (NN network) (NN performance)) (VP (VBZ depends) (ADVP (RB non-monotonically)) (PP (IN on) (NP (NN width))) (PP (IN in) (NP (NP (NNS ways)) (VP (RB not) (VBN captured) (PP (IN by) (NP (JJ double) (JJ descent) (NN phenomena)))))))) (: ;)) (S (NP (NP (NN equivariance)) (PP (IN of) (NP (NNP CNNs)))) (VP (VBZ is) (ADVP (RB only)) (JJ beneficial) (PP (IN for) (NP (NP (JJ narrow) (NNS networks)) (ADVP (RB far) (PP (IN from) (NP (DT the) (NN kernel) (NN regime))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (ADVP (RB additionally)) (VP (VBP motivate) (NP (NP (DT an) (JJ improved) (NN layer-wise) (NN scaling)) (PP (IN for) (NP (NN weight) (NN decay))) (SBAR (WHNP (WDT which)) (S (VP (VBZ improves) (NP (NP (NN generalization)) (PP (IN in) (NP (JJ finite-width) (NNS networks))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (JJ improved) (JJS best) (NNS practices)) (PP (IN for) (S (VP (VBG using) (NP (NNP NNGP) (CC and) (NNP NT) (NNS kernels)) (PP (IN for) (NP (NN prediction)))))) (, ,) (PP (VBG including) (NP (DT a) (JJ novel) (NN ensembling) (NN technique))))) (. .))
(S (S (VP (VBG Using) (NP (DT these) (JJS best) (NNS practices)))) (NP (PRP we)) (VP (VBP achieve) (NP (NP (JJ state-of-the-art) (NNS results)) (PP (IN on) (NP (NP (NNP CIFAR-10) (NN classification)) (PP (IN for) (NP (NP (NNS kernels)) (VP (VBG corresponding) (PP (TO to) (NP (NP (DT each) (NN architecture) (NN class)) (SBAR (S (NP (PRP we)) (VP (VBP consider))))))))))))) (. .))
