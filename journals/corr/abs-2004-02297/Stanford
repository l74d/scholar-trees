(S (NP (DT This) (NN paper)) (VP (VBZ reduces) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (NP (NNS DNNs)) (VP (VBG training) (PP (IN by) (S (VP (VBG decreasing) (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NNS data) (NN movement)))) (PP (IN across) (NP (NP (JJ heterogeneous) (NNS architectures)) (VP (VBN composed) (PP (IN of) (NP (NP (JJ several) (NNS GPUs)) (CC and) (NP (JJ multicore) (NN CPU) (NNS devices))))))))))))))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (NP (DT this) (NN paper)) (VP (VBZ proposes) (NP (DT an) (NN algorithm) (S (VP (TO to) (ADVP (RB dynamically)) (VP (VB adapt) (NP (NP (DT the) (NNS data) (NN representation) (NN format)) (PP (IN of) (NP (NN network) (NNS weights)))) (PP (IN during) (NP (NN training)))))))) (. .))
(S (NP (DT This) (NN algorithm)) (VP (VBZ drives) (NP (NP (DT a) (NN compression) (NN procedure)) (SBAR (WHNP (WDT that)) (S (VP (VBZ reduces) (NP (NNS data)) (NP (NN size)) (PP (IN before) (S (VP (VBG sending) (NP (PRP them)) (PP (IN over) (NP (DT the) (JJ parallel) (NN system))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP run) (NP (NP (NP (DT an) (JJ extensive) (NN evaluation) (NN campaign)) (PP (VBG considering) (NP (JJ several) (NML (PP (ADVP (IN up)) (HYPH -) (IN to) (HYPH -) (NP (NN date)))) (NML (JJ deep) (JJ neural) (NN network)) (NNS models)))) (CC and) (NP (NP (CD two) (NML (JJ high) (HYPH -) (NN end)) (JJ parallel) (NNS architectures)) (VP (VBN composed) (PP (IN of) (NP (NP (JJ multiple) (NNS GPUs)) (CC and) (NP (NN CPU) (NN multicore) (NNS chips)))))))) (. .))
