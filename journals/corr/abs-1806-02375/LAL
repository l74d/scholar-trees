(S (NP (NP (NN Batch) (NN normalization)) (PRN (-LRB- -LRB-) (NP (NNP BN)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (DT a) (NN technique)) (SBAR (S (VP (TO to) (VP (VB normalize) (NP (NP (NNS activations)) (PP (IN in) (NP (NP (JJ intermediate) (NNS layers)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))))))))))) (. .))
(S (NP (PRP$ Its) (NN tendency) (S (VP (TO to) (VP (VP (VB improve) (NP (NN accuracy))) (CC and) (VP (VB speed) (PRT (RP up)) (NP (VBG training))))))) (VP (VB have) (VP (VBN established) (NP (NNP BN)) (PP (IN as) (NP (NP (DT a) (JJ favorite) (NN technique)) (PP (IN in) (NP (JJ deep) (NN learning))))))) (. .))
(S (ADVP (RB Yet)) (, ,) (PP (IN despite) (NP (PRP$ its) (JJ enormous) (NN success))) (, ,) (NP (EX there)) (VP (VBZ remains) (NP (NP (JJ little) (NN consensus)) (PP (IN on) (NP (NP (DT the) (JJ exact) (NN reason) (CC and) (NN mechanism)) (PP (IN behind) (NP (DT these) (NNS improvements))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP take) (NP (NP (DT a) (NN step)) (PP (IN towards) (NP (NP (DT a) (JJR better) (NN understanding)) (PP (IN of) (NP (NNP BN)))))) (, ,) (S (VP (VBG following) (NP (DT an) (JJ empirical) (NN approach))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP conduct) (NP (JJ several) (NNS experiments))) (, ,) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (NNP BN)) (ADVP (RB primarily)) (VP (VBZ enables) (NP (NP (VBG training)) (PP (IN with) (NP (NP (JJR larger) (NN learning) (NNS rates)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (DT the) (NN cause)) (PP (IN for) (NP (NP (JJR faster) (NN convergence)) (CC and) (NP (JJR better) (NN generalization)))))))))))))))) (. .))
(S (PP (IN For) (NP (NP (NNS networks)) (PP (IN without) (NP (NNP BN))))) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (WHADVP (WRB how)) (S (NP (JJ large) (NN gradient) (NNS updates)) (VP (MD can) (VP (VB result) (PP (IN in) (S (NP (VBG diverging) (NN loss) (CC and) (NNS activations)) (VP (VBG growing) (ADVP (RB uncontrollably)) (PP (IN with) (NP (NP (NN network) (NN depth)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ limits) (NP (JJ possible) (VBG learning) (NNS rates))))))))))))))) (. .))
(S (NP (NNP BN)) (VP (VBZ avoids) (NP (DT this) (NN problem)) (PP (IN by) (S (VP (VP (ADVP (RB constantly)) (VBG correcting) (NP (NNS activations)) (VP (TO to) (VP (VB be) (UCP (ADJP (JJ zero-mean)) (CC and) (PP (IN of) (NP (NN unit) (JJ standard) (NN deviation))))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ enables) (NP (JJR larger) (JJ gradient) (NNS steps))) (, ,) (VP (NNS yields) (NP (RBR faster) (NN convergence))) (CC and) (VP (MD may) (VP (VB help) (S (VP (VB bypass) (NP (JJ sharp) (JJ local) (NN minima))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (VBP further)) (VP (RB show) (NP (NP (JJ various) (NNS ways)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (NNS gradients) (CC and) (NNS activations)) (PP (IN of) (NP (JJ deep) (JJ unnormalized) (NNS networks)))) (VP (VBP are) (ADJP (JJ ill-behaved))))))) (. .))
(S (NP (PRP We)) (VP (VBP contrast) (NP (PRP$ our) (NNS results)) (PP (IN against) (NP (NP (JJ recent) (NNS findings)) (PP (IN in) (NP (JJ random) (NN matrix) (NN theory))))) (, ,) (S (VP (VBG shedding) (NP (JJ new) (NN light)) (PP (IN on) (NP (NP (JJ classical) (NN initialization) (NNS schemes)) (CC and) (NP (PRP$ their) (NNS consequences))))))) (. .))
