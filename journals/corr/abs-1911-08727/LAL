(S (S (VP (TO To) (VP (VB reduce) (NP (NP (DT the) (JJ long) (NN training) (NN time)) (PP (IN of) (NP (JJ large) (JJ deep) (JJ neural) (NN network) (PRN (-LRB- -LRB-) (NNP DNN) (-RRB- -RRB-)) (NNS models))))))) (, ,) (NP (NP (VBN distributed) (JJ synchronous) (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP S-SGD)) (-RRB- -RRB-))) (VP (VBZ is) (ADVP (RB commonly)) (VP (VBN used) (PP (IN on) (NP (NP (DT a) (NN cluster)) (PP (IN of) (NP (NNS workers))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN speedup)) (VP (VBN brought) (PP (IN by) (NP (JJ multiple) (NNS workers))))) (VP (VBZ is) (VP (VBN limited) (PP (IN by) (NP (DT the) (NN communication) (NN overhead))))) (. .))
(S (NP (NP (CD Two) (NNS approaches)) (, ,) (NP (ADVP (RB namely)) (NP (NP (VBG pipelining)) (CC and) (NP (JJ gradient) (NN sparsification)))) (, ,)) (VP (VBP have) (VP (VBN been) (ADVP (RB separately)) (VP (VBN proposed) (S (VP (TO to) (VP (VB alleviate) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (NN communication) (NNS overheads)))))))))) (. .))
(S (ADVP (RB Yet)) (, ,) (NP (DT the) (NN gradient) (NN sparsification) (NNS methods)) (VP (VP (MD can) (ADVP (RB only)) (VP (VB initiate) (NP (DT the) (NN communication)) (PP (IN after) (NP (DT the) (NN backpropagation))))) (, ,) (CC and) (VP (ADVP (RB hence)) (VB miss) (NP (DT the) (NN pipelining) (NN opportunity)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (VBN distributed) (NN optimization) (NN method)) (VP (VBN named) (S (NP (NNP LAGS-SGD)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ combines) (NP (NNP S-SGD)) (PP (IN with) (NP (DT a) (JJ novel) (JJ layer-wise) (JJ adaptive) (NN gradient) (NN sparsification) (PRN (-LRB- -LRB-) (NNP LAGS) (-RRB- -RRB-)) (NN scheme)))))))) (. .))
(S (PP (IN In) (NP (NNP LAGS-SGD))) (, ,) (NP (DT every) (NN worker)) (VP (VBZ selects) (NP (NP (NP (DT a) (JJ small) (NN set)) (PP (IN of) (NP (`` ``) (JJ significant) ('' '') (NNS gradients))) (PP (IN from) (NP (DT each) (NN layer))) (ADVP (RB independently)) (SBAR (WHNP (WP$ whose) (NN size)) (S (VP (MD can) (VP (VB be) (ADJP (JJ adaptive) (PP (TO to) (NP (NP (DT the) (NN communication-to-computation) (NN ratio)) (PP (IN of) (NP (DT that) (NN layer))))))))))))) (. .))
(S (NP (NP (DT The) (JJ layer-wise) (NN nature)) (PP (IN of) (NP (NNP LAGS-SGD)))) (VP (VBZ opens) (NP (NP (DT the) (NN opportunity)) (PP (IN of) (NP (NP (VBG overlapping) (NNS communications)) (PP (IN with) (NP (NNS computations)))))) (, ,) (SBAR (IN while) (S (NP (NP (DT the) (JJ adaptive) (NN nature)) (PP (IN of) (NP (NNP LAGS-SGD)))) (VP (VBZ makes) (S (NP (PRP it)) (ADJP (JJ flexible) (S (VP (TO to) (VP (VB control) (NP (DT the) (NN communication) (NN time))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (SBAR (DT that) (S (S (NP (NNP LAGS-SGD)) (VP (VBZ has) (NP (NN convergence) (NNS guarantees)))) (CC and) (S (NP (PRP it)) (VP (VBZ has) (NP (NP (DT the) (JJ same) (NN order)) (PP (IN of) (NP (NN convergence) (NN rate))) (PP (IN as) (NP (NN vanilla) (NNP S-SGD)))) (PP (IN under) (NP (DT a) (JJ weak) (JJ analytical) (NN assumption)))))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP are) (VP (VBN conducted) (S (VP (TO to) (VP (VB verify) (NP (NP (DT the) (JJ analytical) (NN assumption)) (CC and) (NP (NP (DT the) (NN convergence) (NN performance)) (PP (IN of) (NP (NNP LAGS-SGD)))))))))) (. .))
(S (NP (NP (JJ Experimental) (NNS results)) (PP (IN on) (NP (DT a) (JJ 16-GPU) (NN cluster)))) (VP (NN show) (SBAR (IN that) (S (NP (JJ LAGS-SGD)) (VP (NNS outperforms) (NP (NP (DT the) (JJ original) (NNP S-SGD)) (CC and) (NP (VBG existing) (VBN sparsified) (NNP S-SGD))) (PP (IN without) (S (VP (VBG losing) (NP (JJ obvious) (NN model) (NN accuracy))))))))) (. .))
