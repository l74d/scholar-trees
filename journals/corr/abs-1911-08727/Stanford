(S (S (VP (TO To) (VP (VB reduce) (NP (NP (NP (DT the) (NML (JJ long) (NN training)) (NN time)) (PP (IN of) (NP (JJ large) (NML (NML (JJ deep) (JJ neural) (NN network)) (-LRB- -LRB-) (NML (NN DNN)) (-RRB- -RRB-)) (NNS models)))) (, ,) (VP (VBN distributed) (NP (JJ synchronous) (JJ stochastic) (NN gradient) (NN descent)))) (PRN (-LRB- -LRB-) (NP (NN S) (HYPH -) (NN SGD)) (-RRB- -RRB-))))) (VP (VBZ is) (ADVP (RB commonly)) (VP (VBN used) (PP (IN on) (NP (NP (DT a) (NN cluster)) (PP (IN of) (NP (NNS workers))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN speedup)) (VP (VBN brought) (PP (IN by) (NP (JJ multiple) (NNS workers))))) (VP (VBZ is) (VP (VBN limited) (PP (IN by) (NP (DT the) (NN communication) (NN overhead))))) (. .))
(S (NP (CD Two) (NNS approaches)) (, ,) (S (UCP (S (ADVP (RB namely)) (VP (VBG pipelining))) (CC and) (NP (NN gradient) (NN sparsification)))) (, ,) (VP (VBP have) (VP (VBN been) (ADVP (RB separately)) (VP (VBN proposed) (S (VP (TO to) (VP (VB alleviate) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (NN communication) (NNS overheads)))))))))) (. .))
(S (ADVP (RB Yet)) (, ,) (NP (DT the) (NML (NN gradient) (NN sparsification)) (NNS methods)) (VP (VP (MD can) (ADVP (RB only)) (VP (VB initiate) (NP (DT the) (NN communication)) (PP (IN after) (NP (DT the) (NN backpropagation))))) (, ,) (CC and) (VP (ADVP (RB hence)) (VBP miss) (NP (DT the) (VBG pipelining) (NN opportunity)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (VBN distributed) (NN optimization) (NN method)) (VP (VBN named) (NP (NP (NN LAGS) (HYPH -) (NN SGD)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ combines) (NP (NML (NML (NN S) (HYPH -) (NN SGD)) (PP (IN with) (NP (DT a) (JJ novel) (JJ layer-wise) (JJ adaptive) (NN gradient) (NN sparsification) (-LRB- -LRB-) (NN LAGS) (-RRB- -RRB-)))) (NN scheme))))))))) (. .))
(S (PP (IN In) (NP (NN LAGS) (HYPH -) (NN SGD))) (, ,) (NP (DT every) (NN worker)) (VP (VBZ selects) (NP (NP (NP (DT a) (JJ small) (NN set)) (PP (IN of) (NP (NP (`` ") (JJ significant) ('' ") (NNS gradients)) (PP (IN from) (NP (NP (DT each) (NN layer)) (ADVP (RB independently))))))) (SBAR (WHNP (WP$ whose) (NN size)) (S (VP (MD can) (VP (VB be) (ADJP (JJ adaptive) (PP (IN to) (NP (NP (DT the) (NML (NML (NN communication)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN computation)))) (NN ratio)) (PP (IN of) (NP (DT that) (NN layer)))))))))))) (. .))
(S (NP (NP (DT The) (JJ layer-wise) (NN nature)) (PP (IN of) (NP (NN LAGS) (HYPH -) (NN SGD)))) (VP (VBZ opens) (NP (NP (DT the) (NN opportunity)) (PP (IN of) (NP (NP (VBG overlapping) (NNS communications)) (PP (IN with) (NP (NNS computations)))))) (, ,) (SBAR (IN while) (S (NP (NP (DT the) (JJ adaptive) (NN nature)) (PP (IN of) (NP (NN LAGS) (HYPH -) (NN SGD)))) (VP (VBZ makes) (S (NP (PRP it)) (ADJP (JJ flexible) (S (VP (TO to) (VP (VB control) (NP (DT the) (NN communication) (NN time))))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (NN LAGS) (HYPH -) (NN SGD)) (VP (VBZ has) (NP (NN convergence) (NNS guarantees))))))) (CC and) (S (NP (PRP it)) (VP (VBZ has) (NP (NP (DT the) (JJ same) (NN order)) (PP (IN of) (NP (NP (NN convergence) (NN rate)) (PP (IN as) (NP (NP (NML (NN vanilla) (NN S)) (HYPH -) (NN SGD)) (PP (IN under) (NP (DT a) (JJ weak) (JJ analytical) (NN assumption)))))))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP are) (VP (VBN conducted) (S (VP (TO to) (VP (VB verify) (NP (NP (DT the) (JJ analytical) (NN assumption)) (CC and) (NP (NP (DT the) (NN convergence) (NN performance)) (PP (IN of) (NP (NN LAGS) (HYPH -) (NN SGD)))))))))) (. .))
(S (NP (NP (JJ Experimental) (NNS results)) (PP (IN on) (NP (DT a) (NML (CD 16) (HYPH -) (NN GPU)) (NN cluster)))) (VP (VBP show) (SBAR (IN that) (S (NP (NN LAGS) (HYPH -) (NN SGD)) (VP (VBZ outperforms) (NP (NP (DT the) (JJ original) (NN S) (HYPH -) (NN SGD)) (CC and) (NP (NP (VBG existing)) (VP (VBN sparsified) (NP (NN S) (HYPH -) (NN SGD)) (PP (IN without) (S (VP (VBG losing) (NP (JJ obvious) (NN model) (NN accuracy)))))))))))) (. .))
