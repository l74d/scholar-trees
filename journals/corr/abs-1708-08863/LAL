(S (NP (NP (JJ Recurrent) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))) (VP (VBP achieve) (NP (JJ state-of-the-art) (NNS results)) (PP (IN in) (NP (JJ many) (JJ sequence-to-sequence) (NN modeling) (NNS tasks)))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NNP RNNs)) (VP (VP (VBP are) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB train))))))) (CC and) (VP (VB tend) (S (VP (TO to) (VP (VB suffer) (PP (IN from) (NP (VBG overfitting)))))))) (. .))
(S (S (VP (VBN Motivated) (PP (IN by) (NP (NP (DT the) (NNP Data) (NNP Processing) (NNP Inequality)) (PRN (-LRB- -LRB-) (NP (NNP DPI)) (-RRB- -RRB-)))))) (, ,) (NP (PRP we)) (VP (VBP formulate) (NP (DT the) (JJ multi-layered) (NN network)) (PP (IN as) (NP (DT a) (NNP Markov) (NN chain))) (, ,) (S (VP (VBG introducing) (NP (NP (DT a) (NN training) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ comprises) (S (VP (VP (VBG training) (NP (DT the) (NN network)) (ADVP (RB gradually))) (CC and) (VP (VBG using) (NP (JJ layer-wise) (NN gradient) (NN clipping)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBD found) (SBAR (IN that) (S (S (VP (VBG applying) (NP (NP (PRP$ our) (NNS methods)) (, ,) (VP (VBN combined) (PP (IN with) (NP (ADJP (RB previously) (VBN introduced)) (NN regularization) (CC and) (NN optimization) (NNS methods)))) (, ,)))) (VP (VBD resulted) (PP (IN in) (NP (NP (NNS improvements)) (PP (IN in) (NP (NP (JJ state-of-the-art) (NNS architectures)) (VP (VBG operating) (PP (IN in) (NP (NN language) (NN modeling) (NNS tasks)))))))))))) (. .))
