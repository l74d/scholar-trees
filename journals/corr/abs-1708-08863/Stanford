(S (NP (NP (JJ Recurrent) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (VP (VBP achieve) (NP (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS results)) (PP (IN in) (NP (JJ many) (NML (NML (NN sequence)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN sequence) (NN modeling)))) (NNS tasks))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NNS RNNs)) (VP (VBP are) (ADJP (JJ difficult) (S (VP (TO to) (VP (VP (VB train)) (CC and) (VP (VB tend) (S (VP (TO to) (VP (VB suffer) (PP (IN from) (S (VP (VBG overfitting))))))))))))) (. .))
(S (S (VP (VBN Motivated) (PP (IN by) (NP (DT the) (NNP Data) (NNP Processing) (NNP Inequality))) (PRN (-LRB- -LRB-) (NP (NNP DPI)) (-RRB- -RRB-)))) (, ,) (NP (PRP we)) (VP (VBP formulate) (NP (NP (DT the) (JJ multi-layered) (NN network)) (PP (IN as) (NP (DT a) (NNP Markov) (NN chain)))) (, ,) (S (VP (VBG introducing) (NP (NP (DT a) (NN training) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ comprises) (S (VP (VP (VBG training) (NP (DT the) (NN network)) (ADVP (RB gradually))) (CC and) (VP (VBG using) (NP (JJ layer-wise) (NN gradient)) (S (VP (VBG clipping))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBD found) (SBAR (IN that) (S (S (VP (VBG applying) (NP (PRP$ our) (NNS methods)))) (, ,) (PP (VBN combined) (PP (IN with) (NP (ADJP (RB previously) (VBN introduced)) (NML (NN regularization) (CC and) (NN optimization)) (NNS methods)))) (, ,) (VP (VBD resulted) (PP (IN in) (NP (NP (NNS improvements)) (PP (IN in) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS architectures))))) (S (VP (VBG operating) (PP (IN in) (NP (NML (NN language) (NN modeling)) (NNS tasks))))))))) (. .))
