(S (NP (NP (DT The) (NN choice)) (PP (IN of) (NP (NN activation) (NN function)))) (VP (MD can) (VP (ADVP (RB significantly)) (VB influence) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ neural) (NNS networks)))))) (. .))
(S (NP (NP (DT The) (NN lack)) (PP (IN of) (NP (NP (VBG guiding) (NNS principles)) (PP (IN for) (NP (NP (DT the) (NN selection)) (PP (IN of) (NP (NN activation) (NN function)))))))) (VP (VBZ is) (ADJP (JJ lamentable))) (. .))
(S (NP (PRP We)) (VP (VBP try) (S (VP (TO to) (VP (VB address) (NP (DT this) (NN issue)) (PP (IN by) (S (VP (VBG introducing) (NP (NP (PRP$ our) (JJ variational) (JJ neural) (NNS networks)) (, ,) (SBAR (WHADVP (WRB where)) (S (S (NP (DT the) (NN activation) (NN function)) (VP (VBZ is) (VP (VBN represented) (PP (IN as) (NP (NP (DT a) (JJ linear) (NN combination)) (PP (IN of) (NP (JJ possible) (NN candidate) (NNS functions)))))))) (, ,) (CC and) (S (NP (DT an) (JJ optimal) (NN activation)) (VP (VBZ is) (VP (VBN obtained) (PP (IN via) (NP (NP (NN minimization)) (PP (IN of) (NP (DT a) (NN loss) (NN function))) (S (VP (VBG using) (NP (JJ gradient) (NN descent) (NN method))))))))))))))))))) (. .))
(S (S (NP (NP (DT The) (NN gradient) (NN formulae)) (PP (IN for) (NP (NP (DT the) (NN loss) (NN function)) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (DT these) (NN expansion) (NNS coefficients)))))))) (VP (VBP are) (ADJP (JJ central) (PP (IN for) (NP (NP (DT the) (NN implementation)) (PP (IN of) (NP (JJ gradient) (NN descent) (NN algorithm)))))))) (, ,) (CC and) (S (ADVP (RB here)) (NP (PRP we)) (VP (VBP derive) (NP (DT these) (JJ gradient) (NN formulae)))) (. .))
