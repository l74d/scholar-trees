(S (NP (JJ Chinese) (NN text) (NN recognition)) (VP (VBZ is) (ADJP (ADJP (RBR more) (JJ challenging)) (PP (IN than) (NP (JJ Latin) (JJ text)))) (PP (JJ due) (TO to) (NP (NP (NP (DT the) (JJ large) (NN amount)) (PP (IN of) (NP (JJ fine-grained) (JJ Chinese) (NNS characters)))) (CC and) (NP (NP (DT the) (JJ great) (NN imbalance)) (PP (IN over) (NP (NNS classes))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ causes) (NP (DT a) (JJ serious) (NN overfitting) (NN problem))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (VP (TO to) (VP (VB apply) (NP (NNP Maximum) (NNP Entropy) (NNP Regularization)) (S (VP (TO to) (VP (VB regularize) (NP (NP (DT the) (NN training) (NN process)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (S (VP (TO to) (ADVP (RB simply)) (VP (VB add) (NP (DT a) (JJ negative) (JJ entropy) (NN term)) (PP (TO to) (NP (DT the) (JJ canonical) (JJ cross-entropy) (NN loss))) (PP (IN without) (NP (DT any) (NX (NX (JJ additional) (NNS parameters)) (CC and) (NX (NX (NN modification)) (PP (IN of) (NP (DT a) (NN model))))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (RB theoretically)) (VBP give) (NP (DT the) (NN convergence) (NN probability) (NN distribution))) (CC and) (VP (VB analyze) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN regularization)) (VP (NN influence) (NP (DT the) (NN learning) (NN process))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NP (JJ Chinese) (NN character) (NN recognition)) (, ,) (NP (NNP Chinese) (VBP text) (NN line) (NN recognition)) (CC and) (NP (JJ fine-grained) (NN image) (NN classification))))) (VP (VBP achieve) (NP (JJ consistent) (NN improvement)) (, ,) (S (VP (VBG proving) (SBAR (IN that) (S (NP (DT the) (NN regularization)) (VP (VBZ is) (ADJP (JJ beneficial) (PP (TO to) (NP (NP (NN generalization) (CC and) (NN robustness)) (PP (IN of) (NP (DT a) (NN recognition) (NN model)))))))))))) (. .))
