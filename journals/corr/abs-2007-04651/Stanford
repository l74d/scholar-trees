(S (NP (JJ Chinese) (NN text) (NN recognition)) (VP (VBZ is) (ADJP (ADJP (RBR more) (JJ challenging)) (PP (IN than) (NP (JJ Latin) (NN text)))) (PP (IN due) (IN to) (NP (NP (DT the) (JJ large) (NN amount)) (PP (IN of) (NP (NP (ADJP (JJ fine) (HYPH -) (JJ grained)) (JJ Chinese) (NNS characters)) (CC and) (NP (NP (DT the) (JJ great) (NN imbalance)) (PP (IN over) (NP (NP (NNS classes)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ causes) (NP (DT a) (JJ serious) (NN overfitting) (NN problem))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (VP (TO to) (VP (VB apply) (NP (NML (NNP Maximum) (NNP Entropy)) (NN Regularization)) (PP (IN to) (NP (NP (NML (S (VP (VB regularize) (NP (DT the) (NN training))))) (NN process)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (S (VP (TO to) (ADVP (RB simply)) (VP (VB add) (NP (DT a) (JJ negative) (NN entropy) (NN term)) (PP (IN to) (NP (NP (NP (DT the) (JJ canonical) (JJ cross-entropy) (NN loss)) (PP (IN without) (NP (DT any) (JJ additional) (NNS parameters)))) (CC and) (NP (NP (NN modification)) (PP (IN of) (NP (DT a) (NN model)))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB theoretically)) (VP (VP (VBP give) (NP (DT the) (NN convergence) (NN probability)) (NP (NN distribution))) (CC and) (VP (VB analyze) (SBAR (WHADVP (WRB how)) (FRAG (NP (NP (DT the) (NN regularization) (NN influence)) (NP (DT the) (NN learning) (NN process))))))) (. .))
(FRAG (NP (NNS Experiments)) (PP (IN on) (NP (NP (JJ Chinese) (NN character) (NN recognition)) (, ,) (NP (JJ Chinese) (NN text) (NN line) (NN recognition)) (CC and) (NP (ADJP (JJ fine) (HYPH -) (JJ grained)) (NN image) (NN classification)))) (S (VP (VB achieve) (NP (JJ consistent) (NN improvement)))) (, ,) (S (VP (VBG proving) (SBAR (IN that) (S (NP (DT the) (NN regularization)) (VP (VBZ is) (ADJP (JJ beneficial) (PP (IN to) (NP (NP (NN generalization) (CC and) (NN robustness)) (PP (IN of) (NP (DT a) (NN recognition) (NN model))))))))))) (. .))
