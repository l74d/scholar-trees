(S (NP (NP (NN Batch) (NNP Normalization)) (PRN (-LRB- -LRB-) (NP (NNP BatchNorm)) (-RRB- -RRB-))) (VP (VBZ is) (ADVP (RB commonly)) (VP (VBN used) (PP (IN in) (NP (NP (NNP Convolutional) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP CNNs)) (-RRB- -RRB-)))) (S (VP (TO to) (VP (VB improve) (NP (VBG training) (NN speed) (CC and) (NN stability))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (EX there)) (VP (VBZ is) (ADVP (RB still)) (NP (NP (JJ limited) (NN consensus)) (PP (IN on) (SBAR (WHADVP (WRB why)) (S (NP (DT this) (NN technique)) (VP (VBZ is) (ADJP (JJ effective)))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ uses) (NP (NP (NNS concepts)) (PP (IN from) (NP (DT the) (JJ traditional) (JJ adaptive) (NN filter) (NN domain)))) (S (VP (TO to) (VP (VB provide) (NP (NP (NN insight)) (PP (IN into) (NP (NP (DT the) (NX (NX (NNS dynamics)) (CC and) (NX (JJ inner) (NNS workings)))) (PP (IN of) (NP (NNP BatchNorm)))))))))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NN convolution) (NN weight) (NNS updates)) (VP (VBP have) (NP (NP (JJ natural) (NNS modes)) (SBAR (WHNP (WP$ whose) (NN stability) (CC and) (NN convergence) (NN speed)) (S (VP (VBP are) (VP (VBN tied) (PP (TO to) (NP (NP (DT the) (NNS eigenvalues)) (PP (IN of) (NP (NP (DT the) (NN input) (NN autocorrelation) (NNS matrices)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN controlled) (PP (IN by) (NP (NNP BatchNorm))) (PP (IN through) (NP (NP (DT the) (NN convolution) (NNS layers) (POS â€º)) (NN channel-wise) (NN structure)))))))))))))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP$ our) (NNS experiments)) (VP (VB demonstrate) (SBAR (IN that) (S (NP (DT the) (NN speed) (CC and) (NN stability) (NNS benefits)) (VP (VBP are) (NP (JJ distinct) (NNS effects)))))) (. .))
(S (PP (IN At) (NP (JJ low) (VBG learning) (NNS rates))) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (NP (NP (NNP BatchNorm) (POS 's)) (NN amplification)) (PP (IN of) (NP (DT the) (JJS smallest) (NNS eigenvalues)))) (SBAR (WHNP (WDT that)) (S (VP (VBZ improves) (NP (NN convergence) (NN speed))))) (, ,) (SBAR (IN while) (S (PP (IN at) (NP (JJ high) (VBG learning) (NNS rates))) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (NP (NP (NNP BatchNorm) (POS 's)) (NN suppression)) (PP (IN of) (NP (DT the) (JJS largest) (NNS eigenvalues)))) (SBAR (WHNP (WDT that)) (S (VP (VBZ ensures) (NP (NN stability))))))))) (. .))
(S (ADVP (RB Lastly)) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (PP (IN in) (NP (DT the) (JJ first) (NN training) (NN step))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NN normalization)) (VP (VBZ is) (VP (VBN needed) (ADVP (RBS most)))))) (, ,) (NP (NNP BatchNorm)) (VP (VBZ satisfies) (NP (NP (DT the) (JJ same) (NN optimization)) (PP (IN as) (NP (NP (NNP Normalized) (NNP Least) (NNP Mean) (NNP Square)) (PRN (-LRB- -LRB-) (NP (NNP NLMS)) (-RRB- -RRB-))))) (, ,) (SBAR (IN while) (S (NP (PRP it)) (VP (VBZ continues) (S (VP (TO to) (VP (VB approximate) (NP (DT this) (NN condition)) (PP (IN in) (NP (JJ subsequent) (NNS steps))))))))))))) (. .))
(S (NP (NP (DT The) (NNS analyses)) (VP (VBN provided) (PP (IN in) (NP (DT this) (NN paper))))) (VP (VBD lay) (NP (NP (DT the) (NN groundwork)) (PP (IN for) (S (VP (VBG gaining) (NP (NP (JJ further) (NN insight)) (PP (IN into) (NP (NP (DT the) (NN operation)) (PP (IN of) (NP (JJ modern) (JJ neural) (NN network) (NNS structures)))))) (S (VP (VBG using) (NP (JJ adaptive) (NN filter) (NN theory))))))))) (. .))
