(S (S (VP (VBG Going) (ADVP (NN deeper) (CC and) (NN wider)) (PP (IN in) (NP (JJ neural) (NNS architectures))))) (VP (VBZ improves) (NP (DT the) (NN accuracy)) (, ,) (SBAR (IN while) (S (NP (DT the) (JJ limited) (NNP GPU) (NNP DRAM)) (VP (VBZ places) (NP (DT an) (JJ undesired) (NN restriction)) (PP (IN on) (NP (DT the) (NN network) (NN design) (NN domain))))))) (. .))
(S (NP (JJ Deep) (NNP Learning) (PRN (-LRB- -LRB-) (NNP DL) (-RRB- -RRB-)) (NNS practitioners)) (VP (CC either) (VP (VBP need) (NP (NP (NN change)) (PP (TO to) (NP (ADJP (JJR less) (JJ desired)) (NN network) (NNS architectures))))) (, ,) (CC or) (VP (ADVP (RB nontrivially)) (VB dissect) (NP (DT a) (NN network)) (PP (IN across) (NP (NN multiGPUs))))) (. .))
(S (NP (DT These)) (VP (JJ distract) (NP (NNP DL) (NNS practitioners)) (PP (IN from) (S (VP (VBG concentrating) (PP (IN on) (NP (PRP$ their) (JJ original) (NN machine) (VBG learning) (NNS tasks))))))) (. .))
(S (NP (PRP We)) (VP (JJ present) (NP (NP (NNS SuperNeurons)) (: :) (NP (NP (DT a) (JJ dynamic) (NNP GPU) (NN memory) (VBG scheduling) (NN runtime)) (SBAR (S (VP (TO to) (VP (VB enable) (NP (DT the) (NN network) (NN training)) (PP (ADVP (RB far)) (IN beyond) (NP (DT the) (NNP GPU) (NNP DRAM) (NN capacity)))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP address) (NP (NP (DT the) (NN performance) (NNS issues)) (PP (IN in) (NP (DT those) (NN memory) (VBG saving) (NNS techniques))))) (. .))
(S (PP (VBN Given) (NP (DT the) (JJ limited) (NNP GPU) (NNP DRAM))) (, ,) (NP (NNP SuperNeurons)) (VP (CONJP (RB not) (RB only)) (VP (NNS provisions) (NP (DT the) (JJ necessary) (NN memory)) (PP (IN for) (NP (DT the) (NN training)))) (, ,) (CONJP (CC but) (RB also)) (VP (ADVP (RB dynamically)) (VBZ allocates) (NP (DT the) (NN memory)) (PP (IN for) (NP (NN convolution) (NNS workspaces))) (S (VP (TO to) (VP (VB achieve) (NP (DT the) (JJ high) (NN performance))))))) (. .))
(S (NP (NP (NNS Evaluations)) (PP (IN against) (NP (NNP Caffe) (, ,) (NNP Torch) (, ,) (NNP MXNet) (CC and) (NNP TensorFlow)))) (VP (VBP have) (VP (VBN demonstrated) (SBAR (IN that) (S (NP (NNP SuperNeurons)) (VP (NNS trains) (NP (ADVP (NP (ADJP (QP (IN at) (JJS least) (CD 3.2432)) (JJR deeper)) (NN network)) (PP (IN than) (NP (JJ current) (NNS ones)))) (PP (IN with) (NP (DT the) (VBG leading) (NN performance))))))))) (. .))
(S (ADVP (RB Particularly)) (, ,) (NP (NNS SuperNeurons)) (VP (MD can) (VP (VB train) (NP (NP (NNP ResNet2500)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (NP (ADJP ($ $) (CD 10^4) ($ $)) (JJ basic) (NN network) (NNS layers)) (PP (IN on) (NP (DT a) (CD 12GB) (NNP K40c))))))))) (. .))
