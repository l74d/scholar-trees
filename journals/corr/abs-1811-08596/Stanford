(S (NP (NP (DT The) (NN performance) (CC and) (NN efficiency)) (PP (IN of) (NP (NP (VBN distributed) (NN training)) (PP (IN of) (NP (JJ Deep) (JJ Neural) (NNS Networks)))))) (ADVP (RB highly)) (VP (VBP depend) (PP (IN on) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN gradient) (NN averaging))))) (PP (IN among) (NP (NP (DT all) (VBG participating) (NNS nodes)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN bounded) (PP (IN by) (NP (NP (DT the) (NN communication)) (PP (IN between) (NP (NNS nodes)))))))))))) (. .))
(S (S (NP (EX There)) (VP (VBP are) (NP (CD two) (JJ major) (NNS strategies) (S (VP (TO to) (VP (VB reduce) (NP (NN communication) (NN overhead)))))))) (: :) (S (S (NP (CD one)) (VP (VBZ is) (S (VP (TO to) (VP (VB hide) (NP (NN communication)) (PP (IN by) (S (VP (VBG overlapping) (NP (PRP it)) (PP (IN with) (NP (NN computation))))))))))) (, ,) (CC and) (S (NP (DT the) (JJ other)) (VP (VBZ is) (S (VP (TO to) (VP (VB reduce) (NP (NN message) (NNS sizes)))))))) (. .))
(S (S (NP (DT The) (JJ first) (NN solution)) (VP (VBZ works) (ADVP (RB well)) (PP (IN for) (NP (JJ linear) (JJ neural) (NNS architectures))))) (, ,) (CC but) (S (NP (NP (JJS latest) (NNS networks)) (PP (JJ such) (IN as) (NP (NNP ResNet) (CC and) (NNP Inception)))) (VP (VBP offer) (NP (NP (JJ limited) (NN opportunity)) (PP (IN for) (NP (DT this) (VBG overlapping)))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (NNS researchers)) (VP (VBP have) (VP (VBN paid) (NP (JJR more) (NN attention)) (PP (IN to) (S (VP (VBG minimizing) (NP (NN communication))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NP (DT a) (JJ novel) (NML (NN gradient) (NN compression)) (NN framework)) (VP (VBN derived) (PP (IN from) (NP (NP (NNS insights)) (PP (IN of) (NP (NML (JJ real) (NN gradient)) (NNS distributions))))))) (, ,) (CC and) (SBAR (WHNP (WDT which)) (S (VP (VBZ strikes) (NP (NP (DT a) (NN balance)) (PP (IN between) (NP (NP (NN compression) (NN ratio)) (, ,) (NP (NN accuracy)) (, ,) (CC and) (NP (JJ computational) (NN overhead)))))))))) (. .))
(S (NP (PRP$ Our) (NN framework)) (VP (VP (VBZ has) (NP (NP (NP (CD two) (JJ major) (JJ novel) (NNS components)) (: :) (NP (NP (NN sparsification)) (PP (IN of) (NP (NP (NNS gradients)) (PP (IN in) (NP (DT the) (NN frequency) (NN domain))))))) (, ,) (CC and) (NP (NP (DT a) (ADJP (NN range) (HYPH -) (VBN based)) (JJ floating) (NN point) (NN representation)) (PP (IN to) (NP (NN quantize)))))) (CC and) (ADVP (RB further)) (VP (VB compress) (NP (NNS gradients) (NNS frequencies)))) (. .))
(S (NP (DT Both) (NNS components)) (VP (VBP are) (ADJP (JJ dynamic)) (, ,) (PP (IN with) (NP (NP (JJ tunable) (NNS parameters)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP achieve) (NP (JJ different) (NN compression) (NN ratio)) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (NN accuracy) (NN requirement)) (CC and) (NP (NP (NNS systems) (POS ')) (NNS platforms)))))) (, ,) (CC and) (VP (VB achieve) (NP (ADJP (RB very) (JJ high)) (NN throughput)) (PP (IN on) (NP (NNS GPUs)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (PRP$ our) (NNS techniques)) (VP (VB guarantee) (NP (DT the) (NN convergence)) (PP (IN with) (NP (DT a) (VBG diminishing) (NN compression) (NN ratio))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN compression) (NN framework)) (ADVP (RB effectively)) (VP (VBZ improves) (NP (NP (DT the) (NN scalability)) (PP (IN of) (NP (JJS most) (JJ popular) (JJ neural) (NNS networks))) (PP (IN on) (NP (DT a) (NML (CD 32) (NN GPU)) (NN cluster)))) (PP (IN to) (NP (NP (DT the) (NN baseline)) (PP (IN of) (NP (DT no) (NN compression))))) (, ,) (PP (IN without) (S (VP (VBG compromising) (NP (NP (DT the) (NN accuracy)) (CC and) (NP (NN convergence) (NN speed)))))))))) (. .))
