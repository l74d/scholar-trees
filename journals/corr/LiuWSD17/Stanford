(S (NP (JJ Sparse) (NNS tensors)) (VP (VBP appear) (PP (IN in) (NP (JJ many) (NML (JJ large) (HYPH -) (NN scale)) (NNS applications))) (PP (IN with) (NP (ADJP (JJ multidimensional) (CC and) (JJ sparse)) (NNS data)))) (. .))
(S (SBAR (IN While) (S (NP (JJ multidimensional) (JJ sparse) (NNS data)) (ADVP (RB often)) (VP (VBP need) (S (VP (TO to) (VP (VB be) (VP (VBN processed) (PP (IN on) (NP (NN manycore) (NNS processors)))))))))) (, ,) (S (VP (VBZ attempts) (S (VP (TO to) (VP (VB develop) (NP (NP (ADJP (RB highly) (HYPH -) (VBN optimized)) (ADJP (NP (NN GPU)) (HYPH -) (VBN based)) (NNS implementations)) (PP (IN of) (NP (JJ sparse) (NN tensor) (NNS operations))))))))) (VP (VBP are) (ADJP (JJ rare))) (. .))
(S (NP (NP (NP (DT The) (JJ irregular) (NN computation) (NNS patterns)) (CC and) (NP (NN sparsity) (NNS structures))) (CONJP (RB as) (RB well) (IN as)) (NP (NP (DT the) (JJ large) (NN memory) (NNS footprints)) (PP (IN of) (NP (JJ sparse) (NN tensor) (NNS operations))))) (VP (VBP make) (NP (NP (JJ such) (NNS implementations)) (VP (VBG challenging)))) (. .))
(S (NP (PRP We)) (VP (VBP leverage) (NP (DT the) (NN fact)) (SBAR (IN that) (S (NP (JJ sparse) (NN tensor) (NNS operations)) (VP (VBP share) (NP (JJ similar) (NN computation) (NNS patterns)) (S (VP (TO to) (VP (VB propose) (NP (NP (DT a) (JJ unified) (NN tensor) (NN representation)) (VP (VBN called) (NP (NNP F) (HYPH -) (NNP COO))))))))))) (. .))
(S (PP (VBN Combined) (PP (IN with) (NP (NN GPU) (HYPH -) (JJ specific) (NNS optimizations)))) (, ,) (NP (NNP F) (HYPH -) (NNP COO)) (VP (VBZ provides) (NP (NP (ADJP (RB highly) (HYPH -) (VBN optimized)) (NNS implementations)) (PP (IN of) (NP (NP (JJ sparse) (NN tensor) (NNS computations)) (PP (IN on) (NP (NNS GPUs))))))) (. .))
(S (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (DT the) (VBN proposed) (VBN unified) (NN approach)))) (VP (VP (VBZ is) (VP (VBN demonstrated) (PP (IN for) (NP (NP (ADJP (NP (NN tensor)) (HYPH -) (VBN based)) (NNS kernels)) (PP (JJ such) (IN as) (NP (NP (DT the) (JJ Sparse) (NML (NML (NNP Matricized) (NNP Tensor)) (HYPH -) (NML (NNP Times) (HYPH -) (NNP Khatri) (HYPH -) (NNP Rao))) (NN Product) (PRN (-LRB- -LRB-) (NP (NN SpMTTKRP)) (-RRB- -RRB-))) (CC and) (NP (DT the) (JJ Sparse) (NML (NNP Tensor) (HYPH -) (NNP Times) (HYPH -) (NNP Matrix)) (NNP Multiply)))))) (PRN (-LRB- -LRB-) (NP (NNP SpTTM)) (-RRB- -RRB-)))) (CC and) (VP (VBZ is) (VP (VBN used) (PP (IN in) (NP (NN tensor) (NN decomposition) (NNS algorithms)))))) (. .))
(S (PP (VBN Compared) (PP (IN to) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN work)))) (NP (PRP we)) (VP (VBP improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NNP SpTTM) (CC and) (NNP SpMTTKRP)))) (ADVP (RP up) (PP (IN to) (NP (QP (CD 3.7) (CC and) (CD 30.6) (NNS times))) (ADVP (RB respectively)))) (PP (IN on) (NP (NML (NNP NVIDIA) (NNP Titan) (HYPH -) (NNP X)) (NNS GPUs)))) (. .))
(S (NP (PRP We)) (VP (VP (VBP implement) (NP (DT a) (NML (NN CANDECOMP) (HYPH /) (NN PARAFAC) (PRN (-LRB- -LRB-) (NP (NN CP)) (-RRB- -RRB-))) (NN decomposition))) (CC and) (VP (VB achieve) (PRT (RP up)) (PP (IN to) (NP (NP (QP (CD 14.9) (NNS times)) (NN speedup)) (VP (VBG using) (NP (NP (DT the) (JJ unified) (NN method)) (PP (IN over) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS libraries)))) (PP (IN on) (NP (NML (NNP NVIDIA) (NNP Titan) (HYPH -) (NNP X)) (NNS GPUs)))))))) (. .))
