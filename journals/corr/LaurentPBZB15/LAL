(S (NP (NP (JJ Recurrent) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))) (VP (VBP are) (NP (NP (JJ powerful) (NNS models)) (PP (IN for) (NP (JJ sequential) (NNS data))) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (NP (DT the) (JJ potential) (S (VP (TO to) (VP (VB learn) (NP (JJ long-term) (NNS dependencies))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP they)) (VP (VBP are) (ADJP (ADJP (RB computationally) (JJ expensive) (SBAR (S (VP (TO to) (VP (VB train)))))) (CC and) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB parallelize)))))))) (. .))
(S (NP (JJ Recent) (NN work)) (VP (VBZ has) (VP (VBN shown) (SBAR (IN that) (S (S (VP (VBG normalizing) (NP (NP (JJ intermediate) (NNS representations)) (PP (IN of) (NP (JJ neural) (NNS networks)))))) (VP (MD can) (VP (ADVP (RB significantly)) (VB improve) (NP (NP (NN convergence) (NNS rates)) (PP (IN in) (NP (JJ feedforward) (JJ neural) (NNS networks)))))))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (NP (NP (JJ batch) (NN normalization)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NN mini-batch) (NNS statistics)) (S (VP (TO to) (VP (VB standardize) (NP (NNS features)))))))) (, ,)) (VP (VBD was) (VP (VBN shown) (S (VP (TO to) (VP (ADVP (RB significantly)) (VB reduce) (NP (NN training) (NN time))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG applying) (NP (NN batch) (NN normalization)) (PP (TO to) (NP (NP (DT the) (JJ hidden-to-hidden) (NNS transitions)) (PP (IN of) (NP (PRP$ our) (NNP RNNs))))))) (VP (VBZ does) (RB n't) (VP (VB help) (NP (DT the) (NN training) (NN procedure))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (SBAR (WHADVP (WRB when)) (S (VP (VBN applied) (PP (TO to) (NP (DT the) (JJ input-to-hidden) (NNS transitions)))))) (, ,) (NP (NN batch) (NN normalization)) (VP (VP (MD can) (VP (VB lead) (PP (TO to) (NP (NP (DT a) (JJR faster) (NN convergence)) (PP (IN of) (NP (DT the) (NN training) (NN criterion))))))) (CC but) (VP (VBZ does) (RB n't) (VP (VB seem) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN generalization) (NN performance)) (PP (IN on) (NP (DT both) (PRP$ our) (NN language) (NN modelling) (CC and) (NN speech) (NN recognition) (NNS tasks))))))))))))) (. .))
(S (ADVP (NP (DT All)) (PP (IN in) (NP (DT all)))) (, ,) (S (S (VP (VBG applying) (NP (NN batch) (NN normalization)) (PP (TO to) (NP (NNP RNNs))))) (VP (VBZ turns) (PRT (RP out)) (S (VP (TO to) (VP (VB be) (ADJP (ADJP (RBR more) (JJ challenging)) (PP (IN than) (S (VP (VBG applying) (NP (PRP it)) (PP (TO to) (NP (VB feedforward) (NNS networks)))))))))))) (, ,) (CC but) (S (NP (NP (JJ certain) (NNS variants)) (PP (IN of) (NP (PRP it)))) (VP (MD can) (ADVP (RB still)) (VP (VB be) (ADJP (JJ beneficial))))) (. .))
