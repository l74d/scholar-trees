(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (JJ new) (ADJP (NP (NML (JJ first) (HYPH -) (NN order)) (NN gradient)) (HYPH -) (VBN based)) (NN algorithm)) (S (VP (TO to) (VP (VB train) (NP (JJ deep) (JJ neural) (NNS networks)))))) (. .))
(S (NP (PRP We)) (ADVP (RB first)) (VP (VB introduce) (NP (NP (NP (DT the) (NN sign) (NN operation)) (PP (IN of) (NP (JJ stochastic) (NNS gradients))) (PRN (-LRB- -LRB-) (PP (IN as) (IN in) (NP (NP (ADJP (NP (NN sign)) (HYPH -) (VBN based)) (NNS methods)) (, ,) (ADVP (FW e.g.)))) (, ,) (NP (NN SIGN) (HYPH -) (NN SGD)) (-RRB- -RRB-))) (PP (IN into) (NP (NP (NN ADAM)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN called) (PP (IN as) (NP (NN signADAM))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (PP (IN in) (NP (NN order) (S (VP (TO to) (VP (VB make) (NP (NP (DT the) (NN rate)) (PP (IN of) (S (VP (VBG fitting) (ADVP (NP (DT each) (NN feature)) (RBR closer))))))))))) (, ,) (NP (PRP we)) (VP (VBP define) (NP (DT a) (NN confidence) (NN function)) (S (VP (TO to) (VP (VP (VB distinguish) (NP (NP (JJ different) (NNS components)) (PP (IN of) (NP (NNS gradients))))) (CC and) (VP (VB apply) (NP (PRP it)) (PP (IN to) (NP (PRP$ our) (NN algorithm)))))))) (. .))
(S (NP (PRP It)) (VP (MD can) (VP (VB generate) (NP (JJR more) (JJ sparse) (NNS gradients)) (SBAR (IN than) (S (NP (VBG existing) (NNS algorithms)) (VP (VBP do)))))) (. .))
(FRAG (S (NP (PRP We)) (VP (VBP call) (NP (DT this) (JJ new) (NN algorithm)))) (FRAG (NP (NN signADAM) (SYM +)) (NP (SYM +))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (NP (CC both) (NP (PRP$ our) (NNS algorithms))) (VP (VP (VBP are) (ADJP (JJ easy) (S (VP (TO to) (VP (VB implement)))))) (CC and) (VP (MD can) (VP (VB speed) (PRT (RP up)) (NP (NP (NN training)) (PP (IN of) (NP (JJ various) (JJ deep) (JJ neural) (NNS networks))))))) (. .))
(S (NP (NP (DT The) (NN motivation)) (PP (IN of) (NP (NN signADAM) (SYM +)))) (NP (SYM +)) (VP (VBZ is) (ADVP (RB preferably)) (VP (VBG learning) (NP (NP (NNS features)) (PP (IN from) (NP (DT the) (ADJP (RBS most) (JJ different)) (NNS samples)))) (PP (IN by) (S (VP (VBG updating) (NP (ADJP (JJ large) (CC and) (JJ useful)) (NNS gradients)) (ADVP (RB regardless) (PP (IN of) (NP (JJ useless) (NN information)))) (PP (IN in) (NP (JJ stochastic) (NNS gradients)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP establish) (NP (JJ theoretical) (NN convergence) (NNS guarantees)) (PP (IN for) (NP (PRP$ our) (NNS algorithms)))) (. .))
(S (NP (NP (JJ Empirical) (NNS results)) (PP (IN on) (NP (JJ various) (NNS datasets) (CC and) (NNS models)))) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NNS algorithms)) (VP (VBP yield) (NP (ADJP (RB much) (JJR better)) (NN performance)) (PP (IN than) (NP (NP (JJ many) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS algorithms)) (PP (VBG including) (NP (NP (NN SIGN) (HYPH -) (NN SGD)) (, ,) (NP (NNP SIGNUM)) (CC and) (NP (NN ADAM)))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP analyze) (NP (DT the) (NN performance)) (PP (IN from) (NP (NP (JJ multiple) (NNS perspectives)) (PP (VBG including) (NP (DT the) (NN loss) (NN landscape)))))) (CC and) (VP (VB develop) (NP (DT an) (JJ adaptive) (NN method)) (S (VP (TO to) (ADVP (RB further)) (VP (VB improve) (NP (NN generalization))))))) (. .))
(S (NP (DT The) (NN source) (NN code)) (VP (VBZ is) (ADJP (JJ available) (PP (IN at) (NP (NP (DT this)) (SBAR (S (VP (VBZ https) (NP (NN URL))))))))))
