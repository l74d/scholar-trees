(S (NP (NP (NN Progress)) (PP (IN in) (NP (JJ deep) (NN learning)))) (VP (VBZ is) (VP (VBN slowed) (PP (IN by) (NP (NP (DT the) (NNS days) (CC or) (NNS weeks)) (SBAR (S (NP (NP (PRP it))) (VP (VBZ takes) (S (VP (TO to) (VP (VB train) (NP (JJ large) (NNS models)))))))))))) (. .))
(S (NP (NP (DT The) (JJ natural) (NN solution)) (PP (IN of) (S (VP (VBG using) (NP (JJR more) (NN hardware)))))) (VP (VP (VBZ is) (VP (VBN limited) (PP (IN by) (NP (VBG diminishing) (NNS returns))))) (, ,) (CC and) (VP (VBZ leads) (PP (TO to) (NP (NP (VB inefficient) (NN use)) (PP (IN of) (NP (JJ additional) (NNS resources))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ large) (NN batch) (, ,) (JJ stochastic) (NN optimization) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ is) (DT both) (ADJP (ADJP (JJR faster)) (PP (IN than) (NP (NP (ADJP (RB widely) (VBN used)) (NN algorithms)) (PP (IN for) (NP (NP (JJ fixed) (NNS amounts)) (PP (IN of) (NP (NN computation))))))))) (, ,) (CC and) (ADVP (RB also)) (VP (VBZ scales) (PRT (RP up)) (ADVP (RB substantially) (RB better)) (SBAR (IN as) (S (NP (RBR more) (JJ computational) (NNS resources)) (VP (VBP become) (ADJP (JJ available))))))))))) (. .))
(S (S (NP (PRP$ Our) (NN algorithm)) (VP (ADVP (RB implicitly)) (VBZ computes) (NP (NP (DT the) (JJ inverse) (NNP Hessian)) (PP (IN of) (NP (DT each) (NN mini-batch)))) (S (VP (TO to) (VP (VB produce) (NP (JJ descent) (NNS directions))))))) (: ;) (S (NP (PRP we)) (VP (VBP do) (ADVP (RB so)) (PP (IN without) (NP (CC either) (DT an) (JJ explicit) (NN approximation) (PP (TO to) (NP (DT the) (JJ Hessian) (CC or) (JJ Hessian-vector) (NNS products))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (PRP$ our) (NN algorithm)))) (PP (IN by) (S (VP (ADVP (RB successfully)) (VBG training) (NP (NP (JJ large) (NNP ImageNet) (NNS models)) (PRN (-LRB- -LRB-) (NP (NP (NNP Inception-V3)) (, ,) (NP (NNP Resnet-50)) (, ,) (NP (NNP Resnet-101)) (CC and) (NP (NNP Inception-Resnet-V2))) (-RRB- -RRB-))) (PP (IN with) (NP (NP (NN mini-batch) (NNS sizes)) (PP (IN of) (NP (QP (IN up) (TO to) (CD 32000)))))) (PP (IN with) (NP (NP (NP (DT no) (NN loss)) (PP (IN in) (NP (NN validation) (NN error))) (ADVP (VBP relative) (PP (TO to) (NP (JJ current) (NNS baselines))))) (, ,) (CC and) (NP (NP (DT no) (NN increase)) (PP (IN in) (NP (NP (DT the) (JJ total) (NN number)) (PP (IN of) (NP (NNS steps)))))))))))) (. .))
(S (PP (IN At) (NP (JJR smaller) (NN mini-batch) (NNS sizes))) (, ,) (NP (PRP$ our) (NN optimizer)) (VP (VBZ improves) (NP (NP (DT the) (NN validation) (NN error)) (PP (IN in) (NP (DT these) (NNS models)))) (PP (IN by) (NP (JJ 0.8-0.9) (NN %)))) (. .))
(S (ADVP (RB Alternatively)) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB trade) (PRT (RP off)) (NP (DT this) (NN accuracy)) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (VBG training) (NNS steps))) (VP (VBN needed))) (PP (IN by) (NP (QP (RB roughly) (CD 10-30)) (NN %)))))))) (. .))
(S (S (NP (PRP$ Our) (NN work)) (VP (VBZ is) (ADJP (ADJP (JJ practical)) (CC and) (ADJP (RB easily) (JJ usable) (PP (IN by) (NP (NNS others))))))) (: â€”) (S (S (NP (NP (QP (RB only) (CD one)) (NN hyperparameter)) (PRN (-LRB- -LRB-) (NP (VBG learning) (NN rate)) (-RRB- -RRB-))) (VP (VBZ needs) (NP (NN tuning)))) (, ,) (CC and) (S (ADVP (RB furthermore)) (, ,) (NP (DT the) (NN algorithm)) (VP (VBZ is) (ADJP (ADJP (IN as) (RB computationally) (JJ cheap)) (PP (IN as) (NP (DT the) (ADJP (NN commonly) (VBN used)) (NNP Adam) (NN optimizer))))))) (. .))
