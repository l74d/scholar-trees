(S (NP (NP (NN Progress)) (PP (IN in) (NP (JJ deep) (NN learning)))) (VP (VBZ is) (VP (VBN slowed) (PP (IN by) (NP (NP (DT the) (NNS days) (CC or) (NNS weeks)) (SBAR (S (NP (PRP it)) (VP (VBZ takes) (S (VP (TO to) (VP (VB train) (NP (JJ large) (NNS models)))))))))))) (. .))
(S (NP (NP (DT The) (JJ natural) (NN solution)) (PP (IN of) (S (VP (VBG using) (NP (JJR more) (NN hardware)))))) (VP (VP (VBZ is) (VP (VBN limited) (PP (IN by) (S (VP (VBG diminishing) (NP (NNS returns))))))) (, ,) (CC and) (VP (VBZ leads) (PP (IN to) (NP (NP (JJ inefficient) (NN use)) (PP (IN of) (NP (JJ additional) (NNS resources))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP present) (NP (NP (DT a) (JJ large) (NN batch)) (, ,) (NP (NP (JJ stochastic) (NN optimization) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (ADJP (DT both) (JJR faster)) (PP (IN than) (NP (NP (ADJP (RB widely) (VBN used)) (NNS algorithms)) (PP (IN for) (NP (NP (VBN fixed) (NNS amounts)) (PP (IN of) (NP (NN computation)))))))))))))) (, ,) (CC and) (ADVP (RB also)) (VP (VBZ scales) (PRT (RP up)) (S (ADJP (ADJP (RB substantially) (JJR better)) (SBAR (IN as) (S (NP (JJR more) (JJ computational) (NNS resources)) (VP (VBP become) (ADJP (JJ available))))))))) (. .))
(S (S (NP (PRP$ Our) (NN algorithm)) (ADVP (RB implicitly)) (VP (VBZ computes) (NP (NP (DT the) (NN inverse) (NNP Hessian)) (PP (IN of) (NP (DT each) (NN mini-batch) (S (VP (TO to) (VP (VB produce) (NP (NN descent) (NNS directions)))))))))) (: ;) (S (NP (PRP we)) (VP (VBP do) (ADVP (RB so) (PP (IN without) (NP (CC either) (DT an) (JJ explicit) (NN approximation)))) (PP (IN to) (NP (DT the) (NML (ADJP (JJ Hessian) (CC or) (JJ Hessian)) (HYPH -) (NN vector)) (NNS products))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (PRP$ our) (NN algorithm)))) (PP (IN by) (S (ADVP (RB successfully)) (VP (VBG training) (NP (NP (NP (JJ large) (NNP ImageNet) (NNS models)) (-LRB- -LRB-) (NP (NP (NN Inception) (HYPH -) (NN V3)) (, ,) (NP (NNP Resnet) (HYPH -) (CD 50)) (, ,) (NP (NNP Resnet) (HYPH -) (CD 101)) (CC and) (NP (NN Inception) (HYPH -) (NN Resnet) (HYPH -) (NN V2))) (-RRB- -RRB-)) (PP (IN with) (NP (NP (NN mini-batch) (NNS sizes)) (PP (IN of) (NP (NP (ADJP (ADVP (RB up) (NP (QP (IN to) (CD 32000))) (PP (IN with) (NP (NP (DT no) (NN loss)) (PP (IN in) (NP (NN validation) (NN error)))))) (JJ relative) (PP (IN to) (NP (JJ current) (NNS baselines))))) (, ,) (CC and) (NP (NP (DT no) (NN increase)) (PP (IN in) (NP (NP (DT the) (JJ total) (NN number)) (PP (IN of) (NP (NNS steps))))))))))))))) (. .))
(S (PP (IN At) (NP (JJR smaller) (JJ mini-batch) (NNS sizes))) (, ,) (NP (PRP$ our) (NN optimizer)) (VP (VBZ improves) (NP (NP (DT the) (NN validation) (NN error)) (PP (IN in) (NP (DT these) (NNS models)))) (PP (IN by) (NP (QP (CD 0.8) (HYPH -) (CD 0.9)) (NN %)))) (. .))
(S (ADVP (RB Alternatively)) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB trade) (PRT (RP off)) (NP (DT this) (NN accuracy) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NN training) (NNS steps)) (VP (VBN needed) (PP (IN by) (NP (QP (RB roughly) (CD 10) (SYM -) (CD 30)) (NN %))))))))))))) (. .))
(S (S (S (NP (PRP$ Our) (NN work)) (VP (VBZ is) (ADJP (JJ practical)))) (CC and) (S (ADVP (RB easily)) (NP (NP (JJ usable)) (PP (IN by) (NP (NP (NNS others)) (: --) (RB only) (NP (CD one) (NN hyperparameter)) (PRN (-LRB- -LRB-) (NP (NN learning) (NN rate)) (-RRB- -RRB-))))) (VP (VBZ needs) (NP (NN tuning))))) (, ,) (CC and) (S (ADVP (RB furthermore)) (, ,) (NP (DT the) (NN algorithm)) (VP (VBZ is) (ADVP (IN as)) (ADVP (RB computationally)) (ADJP (JJ cheap) (PP (IN as) (NP (DT the) (ADJP (RB commonly) (VBN used)) (NNP Adam) (NN optimizer)))))) (. .))
