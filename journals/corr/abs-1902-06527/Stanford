(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (DT a) (JJ new) (NN learning) (NN technique)) (VP (VBN named) (NP (NN message) (HYPH -) (NN dropout)) (S (VP (TO to) (VP (VB improve) (NP (DT the) (NN performance)) (PP (IN for) (NP (NP (JJ multi-agent) (JJ deep) (NN reinforcement)) (VP (VBG learning) (PP (IN under) (NP (CD two) (NN application) (NNS scenarios))))))))))) (: :) (NP (NP (LST (LS 1) (-RRB- -RRB-)) (NP (JJ classical) (JJ multi-agent) (NN reinforcement)) (VP (VBG learning) (PP (IN with) (NP (JJ direct) (NN message) (NN communication))))) (PP (IN among) (NP (NP (NP (NNS agents)) (CC and) (NP (CD 2))) (-RRB- -RRB-) (NP (NP (JJ centralized) (NN training)) (PP (IN with) (NP (JJ decentralized) (NN execution))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (JJ first) (NN application) (NN scenario)) (PP (IN of) (NP (NP (JJ multi-agent) (NNS systems)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (JJ direct) (NN message) (NN communication)) (PP (IN among) (NP (NNS agents)))) (VP (VBZ is) (VP (VBN allowed))))))))) (, ,) (NP (DT the) (NN message) (HYPH -) (NN dropout) (NN technique)) (VP (VP (VBZ drops) (PRT (RP out)) (NP (NP (DT the) (VBN received) (NNS messages)) (PP (IN from) (NP (NP (JJ other) (NNS agents)) (PP (IN in) (NP (NP (DT a) (JJ block-wise) (NN manner)) (PP (IN with) (NP (NP (DT a) (JJ certain) (NN probability)) (PP (IN in) (NP (DT the) (NN training) (NN phase))))))))))) (CC and) (VP (VBZ compensates) (PP (IN for) (NP (DT this) (NN effect))) (PP (IN by) (S (VP (VBG multiplying) (NP (NP (DT the) (NNS weights)) (PP (IN of) (NP (NP (DT the)) (VP (VBN dropped) (PRT (HYPH -) (RP out)) (NP (NN block) (NNS units)) (PP (IN with) (NP (DT a) (NN correction) (NN probability)))))))))))) (. .))
(S (NP (NP (DT The) (JJ applied) (NN message) (HYPH -) (NN dropout)) (NP (NN technique))) (VP (VP (ADVP (RB effectively)) (VBZ handles) (NP (NP (DT the) (VBN increased) (NN input) (NN dimension)) (PP (IN in) (NP (JJ multi-agent) (NN reinforcement)))) (S (VP (VBG learning) (PP (IN with) (NP (NN communication)))))) (CC and) (VP (VBZ makes) (NP (NN learning)) (S (ADJP (JJ robust) (PP (IN against) (NP (NP (NN communication) (NNS errors)) (PP (IN in) (NP (DT the) (NN execution) (NN phase))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (JJ second) (NN application) (NN scenario)) (PP (IN of) (NP (NP (JJ centralized) (NN training)) (PP (IN with) (NP (JJ decentralized) (NN execution))))))) (, ,) (NP (PRP we)) (ADVP (RB particularly)) (VP (VBP consider) (NP (NP (DT the) (NN application)) (PP (IN of) (NP (DT the) (VBN proposed) (NN message) (HYPH -) (NN dropout)))) (PP (IN to) (NP (NP (NML (NNP Multi-Agent) (NNP Deep)) (JJ Deterministic) (NN Policy) (NN Gradient) (PRN (-LRB- -LRB-) (NP (NNP MADDPG)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (DT a) (JJ centralized) (NN critic)) (S (VP (TO to) (VP (VB train) (NP (DT a) (JJ decentralized) (NN actor)) (PP (IN for) (NP (DT each) (NN agent)))))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP evaluate) (NP (NP (DT the) (VBN proposed) (NN message) (HYPH -) (NN dropout)) (NP (NP (NN technique)) (PP (IN for) (NP (JJ several) (NNS games))))))) (, ,) (CC and) (S (NP (JJ numerical) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (VBN proposed) (NML (NN message) (HYPH -) (NN dropout)) (NN technique)) (PP (IN with) (NP (JJ proper) (NN dropout) (NN rate)))) (VP (VBZ improves) (NP (NP (DT the) (NN reinforcement)) (VP (VBG learning) (NP (NN performance)) (ADVP (RB significantly)) (PP (IN in) (NP (NP (NP (NNS terms)) (PP (IN of) (NP (DT the) (NN training) (NN speed)))) (CC and) (NP (NP (DT the) (NML (JJ steady) (HYPH -) (NN state)) (NN performance)) (PP (IN in) (NP (DT the) (NN execution) (NN phase))))))))))))) (. .))
