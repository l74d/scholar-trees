(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (DT a) (JJ new) (NN learning) (NN technique)) (VP (VBN named) (S (NP (NN message-dropout))))) (SBAR (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN for) (NP (JJ multi-agent) (JJ deep) (NN reinforcement) (VBG learning)))) (PP (IN under) (NP (NP (CD two) (NN application) (NNS scenarios)) (: :) (NP (NP (CD 1) (-RRB- -RRB-) (NP (NP (JJ classical) (JJ multi-agent) (NN reinforcement) (VBG learning)) (PP (IN with) (NP (NP (JJ direct) (NN message) (NN communication)) (PP (IN among) (NP (NNS agents))))))) (CC and) (NP (CD 2) (-RRB- -RRB-) (NP (NP (VBD centralized) (NN training)) (PP (IN with) (NP (JJ decentralized) (NN execution)))))))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (JJ first) (NN application) (NN scenario)) (PP (IN of) (NP (NP (JJ multi-agent) (NNS systems)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (JJ direct) (NN message) (NN communication)) (PP (IN among) (NP (NNS agents)))) (VP (VBZ is) (VP (VBN allowed))))))))) (, ,) (NP (DT the) (NN message-dropout) (NN technique)) (VP (VP (VBZ drops) (PRT (RP out)) (NP (NP (DT the) (JJ received) (NNS messages)) (PP (IN from) (NP (JJ other) (NNS agents)))) (PP (IN in) (NP (DT a) (JJ block-wise) (NN manner))) (PP (IN with) (NP (DT a) (JJ certain) (NN probability))) (PP (IN in) (NP (DT the) (NN training) (NN phase)))) (CC and) (VP (NNS compensates) (PP (IN for) (NP (DT this) (NN effect))) (PP (IN by) (S (VP (VBG multiplying) (NP (NP (DT the) (NNS weights)) (PP (IN of) (NP (DT the) (JJ dropped-out) (NN block) (NNS units)))) (PP (IN with) (NP (DT a) (NN correction) (NN probability)))))))) (. .))
(S (NP (DT The) (JJ applied) (NN message-dropout) (NN technique)) (VP (VP (ADVP (RB effectively)) (VBZ handles) (NP (NP (DT the) (VBN increased) (NN input) (NN dimension)) (PP (IN in) (NP (NP (JJ multi-agent) (NN reinforcement) (VBG learning)) (PP (IN with) (NP (NN communication))))))) (CC and) (VP (VBZ makes) (S (NP (VBG learning)) (ADJP (JJ robust) (PP (IN against) (NP (NP (NN communication) (NNS errors)) (PP (IN in) (NP (DT the) (NN execution) (NN phase))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (JJ second) (NN application) (NN scenario)) (PP (IN of) (NP (NP (JJ centralized) (NN training)) (PP (IN with) (NP (JJ decentralized) (NN execution))))))) (, ,) (NP (PRP we)) (ADVP (RB particularly)) (VP (VBP consider) (NP (NP (DT the) (NN application)) (PP (IN of) (NP (DT the) (VBN proposed) (NN message-dropout))) (PP (TO to) (NP (NP (JJ Multi-Agent) (NNP Deep) (NNP Deterministic) (NNP Policy) (NNP Gradient)) (PRN (-LRB- -LRB-) (NP (NNP MADDPG)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (DT a) (JJ centralized) (NN critic)) (S (VP (TO to) (VP (VB train) (NP (DT a) (JJ decentralized) (NN actor)) (PP (IN for) (NP (DT each) (NN agent))))))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP evaluate) (NP (DT the) (VBN proposed) (NN message-dropout) (NN technique)) (PP (IN for) (NP (JJ several) (NNS games))))) (, ,) (CC and) (S (NP (JJ numerical) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (VBN proposed) (NN message-dropout) (NN technique)) (PP (IN with) (NP (JJ proper) (NN dropout) (NN rate)))) (VP (VBZ improves) (NP (DT the) (NN reinforcement) (VBG learning) (NN performance)) (ADVP (RB significantly)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (DT the) (NN training) (NN speed)) (CC and) (NP (NP (DT the) (JJ steady-state) (NN performance)) (PP (IN in) (NP (DT the) (NN execution) (NN phase))))))))))))) (. .))
