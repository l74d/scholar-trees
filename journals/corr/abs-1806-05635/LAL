(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (NNP Self-Imitation) (NNP Learning)) (PRN (-LRB- -LRB-) (NP (NNP SIL)) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (JJ simple) (JJ off-policy) (JJ actor-critic) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ learns) (S (VP (TO to) (VP (VB reproduce) (NP (NP (DT the) (NN agent) (POS 's)) (JJ past) (JJ good) (NNS decisions))))))))))) (. .))
(S (NP (DT This) (NN algorithm)) (VP (VBZ is) (VP (VBN designed) (S (VP (TO to) (VP (VB verify) (NP (PRP$ our) (NN hypothesis) (SBAR (IN that) (S (S (VP (VBG exploiting) (NP (RB past) (JJ good) (NNS experiences)))) (VP (MD can) (VP (ADVP (RB indirectly)) (VB drive) (NP (JJ deep) (NN exploration)))))))))))) (. .))
(S (NP (PRP$ Our) (JJ empirical) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP SIL)) (VP (VP (ADVP (RB significantly)) (VBZ improves) (NP (NP (JJ advantage) (JJ actor-critic)) (PRN (-LRB- -LRB-) (NP (NNP A2C)) (-RRB- -RRB-))) (PP (IN on) (NP (JJ several) (JJ hard) (NN exploration) (NNP Atari) (NNS games)))) (CC and) (VP (VBZ is) (ADJP (JJ competitive) (PP (TO to) (NP (DT the) (JJ state-of-the-art) (JJ count-based) (NN exploration) (NNS methods))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP SIL)) (VP (VBZ improves) (NP (NP (JJ proximal) (NN policy) (NN optimization)) (PRN (-LRB- -LRB-) (NP (NNP PPO)) (-RRB- -RRB-))) (PP (IN on) (NP (NNP MuJoCo) (NNS tasks))))))) (. .))
