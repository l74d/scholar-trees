(S (NP (JJ Deep) (JJ neural) (NNS networks)) (VP (VBP have) (NP (DT a) (JJ great) (NN potential) (S (VP (TO to) (VP (VB improve) (NP (NN image) (NN denoising)) (PP (IN in) (NP (NML (JJ low) (HYPH -) (NN dose)) (VBN computed) (NN tomography))))))) (PRN (-LRB- -LRB-) (NP (NN LDCT)) (-RRB- -RRB-))) (. .))
(S (NP (NNP Popular) (NNS ways) (S (VP (TO to) (VP (VB increase) (NP (DT the) (NN network) (NN capacity)))))) (VP (VBP include) (S (VP (VP (VBG adding) (NP (JJR more) (NNS layers))) (CC or) (VP (VBG repeating) (NP (NP (DT a) (VBN modularized) (NN clone) (NN model)) (PP (IN in) (NP (DT a) (NN sequence)))))))) (. .))
(S (PP (IN In) (NP (JJ such) (JJ sequential) (NNS architectures))) (, ,) (NP (DT the) (JJ noisy) (NML (NML (NN input) (NN image)) (CC and) (NML (NN end) (NN output))) (NN image)) (VP (VBP are) (ADVP (RB commonly)) (VP (VBN used) (ADVP (RB only) (RB once)) (PP (IN in) (NP (NP (DT the) (NN training) (NN model)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB however)) (VP (VBZ limits) (NP (DT the) (JJ overall) (NN learning) (NN performance))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (ADJP (NP (JJ parallel) (HYPH -) (NN clone)) (JJ neural)) (NN network) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ utilizes) (NP (DT a) (VBN modularized) (NN network) (NN model))) (CC and) (VP (VBZ exploits) (NP (NP (NP (DT the) (NN benefit)) (PP (IN of) (NP (JJ parallel) (NN input)))) (, ,) (NP (NP (JJ parallel) (HYPH -) (NN output)) (NP (NN loss))) (, ,) (CC and) (NP (NML (NN clone) (HYPH -) (NN toclone)) (NN feature) (NN transfer))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN model)) (VP (VP (VBZ keeps) (NP (NP (DT a) (ADJP (ADJP (JJ similar)) (CC or) (ADJP (RBR less))) (NN number)) (PP (IN of) (NP (JJ unknown) (NN network) (NNS weights)))) (PP (IN as) (VBN compared) (PP (IN to) (NP (JJ conventional) (NNS models))))) (CC but) (VP (MD can) (VP (VB accelerate) (NP (DT the) (NN learning) (NN process)) (ADVP (RB significantly))))) (. .))
(S (NP (DT The) (NN method)) (VP (VBD was) (VP (VP (VBN evaluated) (S (VP (VBG using) (NP (DT the) (NNP Mayo) (NNP LDCT) (NN dataset))))) (CC and) (VP (VBN compared) (PP (IN with) (NP (VBG existing) (NML (JJ deep) (NN learning)) (NNS models)))))) (. .))
(S (NP (DT The) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ parallel) (NML (NML (NN input)) (, ,) (NP (JJ parallel) (HYPH -) (NN output))) (NN loss)))) (, ,) (CC and) (NP (NML (NML (NN clone)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN clone) (NN feature)))) (NN transfer)) (NP (DT all))) (VP (MD can) (VP (VP (VB contribute) (PP (IN to) (NP (NP (DT an) (VBN accelerated) (NN convergence)) (PP (IN of) (NP (JJ deep) (NN learning)))))) (CC and) (VP (VB lead) (PP (IN to) (NP (NP (VBN improved) (NN image) (NN quality)) (PP (IN in) (NP (NN testing))))))))))) (. .))
(S (NP (NP (DT The) (JJ parallel) (HYPH -) (NN clone)) (NP (NN network))) (VP (VBZ has) (VP (VBN been) (VP (VBN demonstrated) (S (VP (VBG promising) (PP (IN for) (NP (NNP LDCT) (NN image) (NN denoising)))))))) (. .))
