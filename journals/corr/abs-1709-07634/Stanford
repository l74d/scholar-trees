(S (PP (IN For) (NP (NP (JJS most) (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NNS architectures)) (, ,) (VP (VBN Rectified)))) (NP (NP (NNP Linear) (NNP Unit)) (-LRB- -LRB-) (NP (NNP ReLU)) (-RRB- -RRB-)) (VP (VBZ becomes) (NP (NP (DT a) (JJ standard) (NN component)) (VP (VBN accompanied) (PP (IN with) (NP (DT each) (NN layer)))))) (. .))
(S (SBAR (IN Although) (S (NP (NN ReLU)) (VP (MD can) (VP (VB ease) (NP (DT the) (NN network) (NN training)) (PP (IN to) (NP (DT an) (NN extent))))))) (, ,) (NP (NP (DT the) (NN character)) (PP (IN of) (S (VP (VBG blocking) (NP (JJ negative) (NNS values)))))) (VP (VP (MD may) (VP (VB suppress) (NP (NP (DT the) (NN propagation)) (PP (IN of) (NP (JJ useful) (NN information)))))) (CC and) (VP (VBZ leads) (PP (IN to) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (S (VP (VBG optimizing) (ADVP (RB very) (RB deep)) (NP (JJ Convolutional) (JJ Neural) (NNS Networks))))))) (PRN (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-)))) (. .))
(S (ADVP (RB Moreover)) (, ,) (S (VP (VBG stacking) (NP (NNS layers)) (PP (IN with) (NP (JJ nonlinear) (NNS activations))))) (VP (VBZ is) (ADJP (JJ hard) (S (VP (TO to) (VP (VB approximate) (NP (NP (DT the) (JJ intrinsic) (JJ linear) (NNS transformations)) (PP (IN between) (NP (NN feature) (NNS representations))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP investigate) (NP (NP (DT the) (NN effect)) (PP (IN of) (S (VP (VBG erasing) (NP (NP (NNS ReLUs)) (PP (IN of) (NP (JJ certain) (NNS layers))))))))) (CC and) (VP (VB apply) (NP (PRP it)) (PP (IN to) (NP (NP (JJ various) (JJ representative) (NNS architectures)) (PP (VBG following) (NP (JJ deterministic) (NNS rules))))))) (. .))
(S (NP (PRP It)) (VP (MD can) (VP (VP (VB ease) (NP (DT the) (NN optimization))) (CC and) (VP (VB improve) (NP (DT the) (NN generalization) (NN performance)) (PP (IN for) (NP (ADJP (RB very) (JJ deep)) (NNP CNN) (NNS models)))))) (. .))
(S (S (NP (PRP We)) (VP (VBP find) (NP (CD two) (JJ key) (NNS factors)) (S (VP (VBG being) (ADJP (JJ essential) (PP (IN to) (NP (NP (DT the) (NN performance) (NN improvement)) (: :) (NP (LST (LS 1) (-RRB- -RRB-)) (NP (DT the) (NN location)) (SBAR (WHADVP (WRB where)) (S (NP (NN ReLU)) (VP (MD should) (VP (VB be) (VP (VBN erased) (PP (IN inside) (NP (DT the) (JJ basic) (NN module)))))))) (: ;) (NP (LST (LS 2) (-RRB- -RRB-)) (NP (DT the) (NN proportion)) (PP (IN of) (NP (JJ basic) (NNS modules))) (S (VP (TO to) (VP (VB erase) (NP (NN ReLU)))))))))))))) (: ;) (S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG erasing) (NP (NP (DT the) (JJ last) (NN ReLU) (NN layer)) (PP (IN of) (NP (NP (DT all) (JJ basic) (NNS modules)) (PP (IN in) (NP (DT a) (NN network)))))))) (ADVP (RB usually)) (VP (VBZ yields) (NP (VBN improved) (NN performance))))))) (. .))
(S (PP (IN In) (NP (NNS experiments))) (, ,) (S (NP (PRP$ our) (NN approach)) (ADVP (RB successfully)) (VP (VBZ improves) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ various) (JJ representative) (NNS architectures)))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP report) (NP (NP (NP (DT the) (VBN improved) (NNS results)) (PP (IN on) (NP (NNP SVHN) (, ,) (NNP CIFAR) (HYPH -) (CD 10/100) (, ,)))) (CC and) (NP (NNP ImageNet))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (JJ competitive) (NML (JJ single) (HYPH -) (NN model)) (NN performance)) (PP (IN on) (NP (NML (NML (NN CIFAR) (HYPH -) (CD 100)) (PP (IN with) (NP (CD 16.53) (NN %)))) (NN error) (NN rate)))) (PP (VBN compared) (PP (IN to) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)))))) (. .))
