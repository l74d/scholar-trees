(S (NP (ADJP (RB Very) (JJ deep)) (NNP CNNs)) (VP (VP (VBP achieve) (NP (NP (JJ state-of-the-art) (NNS results)) (PP (IN in) (NP (DT both) (NP (NN computer) (NN vision)) (CC and) (NP (NN speech) (NN recognition)))))) (, ,) (CC but) (VP (VBP are) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB train)))))))) (. .))
(S (NP (NP (DT The) (ADJP (RBS most) (JJ popular)) (NN way)) (SBAR (S (VP (TO to) (VP (VB train) (NP (ADJP (RB very) (JJ deep)) (NNP CNNs))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB use) (NP (NP (NP (JJ shortcut) (NNS connections)) (PRN (-LRB- -LRB-) (NP (NNP SC)) (-RRB- -RRB-))) (ADVP (RB together) (PP (IN with) (NP (NP (NN batch) (NN normalization)) (PRN (-LRB- -LRB-) (NP (NNP BN)) (-RRB- -RRB-)))))))))) (. .))
(S (S (VP (VBN Inspired) (PP (IN by) (NP (NNP Self-) (NNP Normalizing) (NNP Neural) (NNP Networks))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT the) (JJ self-normalizing) (NP (NP (NP (JJ deep) (NNP CNN) (PRN (-LRB- -LRB-) (NNP SNDCNN) (-RRB- -RRB-))))) (VBN based) (JJ acoustic) (NN model) (NN topology)) (, ,) (PP (IN by) (S (VP (VP (VBG removing) (NP (DT the) (NNP SC/BN))) (CC and) (VP (VBG replacing) (NP (DT the) (JJ typical) (NNP RELU) (NNS activations)) (PP (IN with) (NP (NP (NP (JJ scaled) (JJ exponential) (JJ linear) (NN unit)) (PRN (-LRB- -LRB-) (NP (NNP SELU)) (-RRB- -RRB-))) (PP (IN in) (NP (NNP ResNet-50)))))))))) (. .))
(S (NP (JJ SELU) (NNS activations)) (VP (VP (VBP make) (S (NP (DT the) (NN network)) (ADJP (NN self-normalizing)))) (CC and) (VP (VB remove) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (DT both) (NP (JJ shortcut) (NNS connections)) (CC and) (NP (NN batch) (NN normalization))))))) (. .))
(S (PP (VBN Compared) (PP (TO to) (NP (NNP ResNet-) (CD 50)))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB achieve) (NP (NP (DT the) (ADJP (ADJP (JJ same)) (CC or) (JJR lower)) (PRN (-LRB- -LRB-) (ADJP (ADVP (QP (IN up) (TO to) (CD 4.5)) (NN %)) (NN relative)) (-RRB- -RRB-)) (NN word) (NN error) (NN rate)) (PRN (-LRB- -LRB-) (NP (NNP WER)) (-RRB- -RRB-))) (SBAR (IN while) (S (VP (VBG boosting) (NP (DT both) (NN training) (CC and) (NN inference) (NN speed)) (PP (IN by) (NP (QP (CD 60) (NN %) (CD -80) (NN %))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP explore) (NP (JJ other) (NN model) (NN inference) (NN optimization) (NNS schemes)) (S (VP (TO to) (ADVP (JJ further)) (VP (VB reduce) (NP (NN latency)) (PP (IN for) (NP (NN production) (NN use))))))) (. .))
