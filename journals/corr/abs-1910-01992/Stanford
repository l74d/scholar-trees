(S (NP (ADJP (RB Very) (JJ deep)) (NNS CNNs)) (VP (VP (VBP achieve) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NNS results)) (PP (IN in) (NP (NP (DT both) (NN computer) (NN vision)) (CC and) (NP (NN speech) (NN recognition))))) (, ,) (CC but) (VP (VBP are) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB train))))))) (. .))
(S (NP (NP (DT The) (ADJP (RBS most) (JJ popular)) (NN way)) (SBAR (S (VP (TO to) (VP (VB train) (NP (ADJP (RB very) (JJ deep)) (NNS CNNs))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB use) (NP (NN shortcut) (NNS connections) (PRN (-LRB- -LRB-) (NP (NN SC)) (-RRB- -RRB-))) (ADVP (RB together)) (PP (IN with) (NP (NN batch) (NN normalization) (PRN (-LRB- -LRB-) (NP (NN BN)) (-RRB- -RRB-)))))))) (. .))
(S (S (VP (VBN Inspired) (PP (IN by) (S (VP (NN Self) (HYPH -) (VBG Normalizing) (NP (JJ Neural) (NNS Networks))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT the) (ADJP (NN self) (HYPH -) (VBG normalizing)) (NML (JJ deep) (NNP CNN) (-LRB- -LRB-) (NNP SNDCNN) (-RRB- -RRB-)) (ADJP (VBN based) (JJ acoustic)) (NN model) (NN topology)) (, ,) (PP (IN by) (S (VP (VP (VBG removing) (NP (DT the) (NN SC) (HYPH /) (NN BN))) (CC and) (VP (VBG replacing) (NP (DT the) (JJ typical) (NNP RELU) (NNS activations)) (PP (IN with) (NP (NP (NP (VBN scaled) (ADJP (JJ exponential) (JJ linear)) (NN unit)) (-LRB- -LRB-) (NP (NN SELU)) (-RRB- -RRB-)) (PP (IN in) (NP (NNP ResNet) (HYPH -) (CD 50)))))))))) (. .))
(S (NP (NNP SELU) (NNS activations)) (VP (VP (VBP make) (NP (NP (DT the) (NN network)) (VP (NN self) (HYPH -) (VBG normalizing)))) (CC and) (VP (VB remove) (NP (DT the) (NN need)) (PP (IN for) (NP (NP (DT both) (NN shortcut) (NNS connections)) (CC and) (NP (NN batch) (NN normalization)))))) (. .))
(S (PP (VBN Compared) (PP (IN to) (NP (NNP ResNet) (HYPH -) (CD 50)))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB achieve) (NP (DT the) (ADJP (ADJP (JJ same)) (CC or) (ADJP (ADJP (JJR lower)) (-LRB- -LRB-) (ADJP (NP (QP (IN up) (IN to) (CD 4.5)) (NN %)) (JJ relative)) (-RRB- -RRB-))) (NN word) (NN error) (NN rate) (PRN (-LRB- -LRB-) (NP (NN WER)) (-RRB- -RRB-))) (PP (IN while) (S (VP (VBG boosting) (NP (DT both) (NML (NN training) (CC and) (NN inference)) (NN speed)) (PP (IN by) (NP (QP (CD 60) (NN %) (HYPH -) (CD 80) (NN %))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VB explore) (S (NP (JJ other) (NML (NN model) (NN inference)) (NN optimization) (NNS schemes)) (VP (TO to) (ADVP (RB further)) (VP (VB reduce) (NP (NN latency)) (PP (IN for) (NP (NN production) (NN use))))))) (. .))
