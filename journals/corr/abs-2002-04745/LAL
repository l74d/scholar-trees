(S (NP (DT The) (NNP Transformer)) (VP (VBZ is) (VP (ADVP (RB widely)) (VBN used) (PP (IN in) (NP (JJ natural) (NN language) (NN processing) (NNS tasks))))) (. .))
(S (S (VP (TO To) (VP (VB train) (NP (DT a) (NNP Transformer))))) (ADVP (RB however)) (, ,) (NP (CD one)) (ADVP (RB usually)) (VP (VBZ needs) (NP (NP (DT a) (ADJP (RB carefully) (VBN designed)) (VBG learning) (NN rate) (JJ warm-up) (NN stage)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ is) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (JJ crucial) (PP (TO to) (NP (DT the) (JJ final) (NN performance))))))))) (CC but) (VP (MD will) (VP (VP (VB slow) (PRT (RP down)) (NP (DT the) (NN optimization))) (CC and) (VP (VB bring) (NP (JJR more) (JJ hyper-parameter) (NNS tunings)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (ADVP (RB first)) (VBD study) (ADVP (RB theoretically)) (SBAR (WHADVP (WRB why)) (S (NP (DT the) (NN learning) (NN rate) (JJ warm-up) (NN stage)) (VP (VBZ is) (ADJP (JJ essential)))))) (CC and) (VP (NN show) (SBAR (IN that) (S (NP (NP (DT the) (NN location)) (PP (IN of) (NP (NN layer) (NN normalization)))) (VP (NNS matters)))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP prove) (PP (IN with) (NP (JJ mean) (NN field) (NN theory))) (SBAR (WDT that) (S (PP (IN at) (NP (NN initialization))) (, ,) (PP (IN for) (NP (NP (DT the) (JJ original-designed) (NNP Post-LN) (NNP Transformer)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ places) (NP (DT the) (NN layer) (NN normalization)) (PP (IN between) (NP (DT the) (JJ residual) (NNS blocks)))))))) (, ,) (NP (NP (DT the) (JJ expected) (NNS gradients)) (PP (IN of) (NP (DT the) (NNS parameters))) (PP (IN near) (NP (DT the) (NN output) (NN layer)))) (VP (VBP are) (ADJP (JJ large)))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (S (VP (VBG using) (NP (DT a) (JJ large) (VBG learning) (NN rate)) (PP (IN on) (NP (DT those) (NNS gradients))))) (VP (VBZ makes) (S (NP (DT the) (NN training)) (ADJP (JJ unstable)))) (. .))
(S (NP (DT The) (JJ warm-up) (NN stage)) (VP (VBZ is) (ADJP (RB practically) (JJ helpful) (PP (IN for) (S (VP (VBG avoiding) (NP (DT this) (NN problem))))))) (. .))
(S (PP (IN On) (NP (DT the) (JJ other) (NN hand))) (, ,) (NP (PRP$ our) (NN theory)) (ADVP (RB also)) (VP (VBZ shows) (SBAR (IN that) (S (SBAR (IN if) (S (NP (DT the) (NN layer) (NN normalization)) (VP (VBZ is) (VP (VBN put) (PP (IN inside) (NP (NP (DT the) (JJ residual) (NNS blocks)) (PRN (-LRB- -LRB-) (VP (ADVP (RB recently)) (VBN proposed) (PP (IN as) (NP (NNP Pre-LN) (NNP Transformer)))) (-RRB- -RRB-)))))))) (, ,) (NP (DT the) (NNS gradients)) (VP (VBP are) (ADJP (JJ well-behaved)) (PP (IN at) (NP (NN initialization))))))) (. .))
(S (NP (DT This)) (VP (VBZ motivates) (S (NP (PRP us)) (VP (TO to) (VP (VB remove) (NP (NP (DT the) (JJ warm-up) (NN stage)) (PP (IN for) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (NNP Pre-LN) (NNP Transformers)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (PP (IN in) (NP (PRP$ our) (NNS experiments))) (SBAR (IN that) (S (NP (NP (NNP Pre-LN) (NNP Transformers)) (PP (IN without) (NP (DT the) (JJ warm-up) (NN stage)))) (VP (MD can) (VP (VB reach) (NP (JJ comparable) (NNS results)) (PP (IN with) (NP (NNS baselines))) (SBAR (IN while) (S (VP (VBG requiring) (NP (NP (NP (ADJP (RB significantly) (RBR less)) (JJ training) (NN time)) (CC and) (NP (NN hyper-parameter) (NN tuning))) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNS applications)))))))))))))) (. .))
