(S (NP (DT The) (NN Transformer)) (VP (VBZ is) (ADVP (RB widely)) (VP (VBN used) (PP (IN in) (NP (NML (JJ natural) (NN language) (NN processing)) (NNS tasks))))) (. .))
(S (S (VP (TO To) (VP (VB train) (NP (DT a) (NN Transformer)) (ADVP (RB however))))) (, ,) (NP (CD one)) (ADVP (RB usually)) (VP (VP (VBZ needs) (NP (NP (DT a) (ADJP (RB carefully) (VBN designed)) (NML (NML (NN learning) (NN rate)) (ADJP (JJ warm) (HYPH -) (JJ up))) (NN stage)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (JJ crucial) (PP (IN to) (NP (DT the) (JJ final) (NN performance))))))))))))) (CC but) (VP (MD will) (VP (VP (VB slow) (PRT (RP down)) (NP (DT the) (NN optimization))) (CC and) (VP (VB bring) (NP (JJR more) (ADJP (JJ hyper) (HYPH -) (NN parameter)) (NNS tunings)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (ADVP (RB first)) (VP (VB study) (ADVP (RB theoretically)) (SBAR (WHADVP (WRB why)) (S (NP (DT the) (NML (NN learning) (NN rate)) (ADJP (JJ warm) (HYPH -) (JJ up)) (NN stage)) (VP (VP (VBZ is) (ADJP (JJ essential))) (CC and) (VP (VBP show) (PP (IN that) (NP (NP (DT the) (NN location)) (PP (IN of) (NP (NN layer) (NN normalization) (NNS matters)))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP prove) (PP (IN with) (NP (JJ mean) (NN field) (NN theory))) (SBAR (IN that) (S (PP (IN at) (NP (NN initialization))) (, ,) (PP (IN for) (NP (NP (ADJP (NP (DT the) (JJ original)) (HYPH -) (VBN designed)) (NNP Post-LN) (NNP Transformer)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ places) (NP (NP (DT the) (NN layer) (NN normalization)) (PP (IN between) (NP (DT the) (JJ residual) (NNS blocks))))))))) (, ,) (NP (NP (DT the) (VBN expected) (NNS gradients)) (PP (IN of) (NP (NP (DT the) (NNS parameters)) (PP (IN near) (NP (DT the) (NN output) (NN layer)))))) (VP (VBP are) (ADJP (JJ large)))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (S (VP (VBG using) (NP (DT a) (JJ large) (NN learning) (NN rate)) (PP (IN on) (NP (DT those) (NNS gradients))))) (VP (VBZ makes) (S (NP (DT the) (NN training)) (ADJP (JJ unstable)))) (. .))
(S (NP (DT The) (ADJP (JJ warm) (HYPH -) (JJ up)) (NN stage)) (VP (VBZ is) (ADJP (RB practically) (JJ helpful) (PP (IN for) (S (VP (VBG avoiding) (NP (DT this) (NN problem))))))) (. .))
(S (PP (IN On) (NP (DT the) (JJ other) (NN hand))) (, ,) (NP (PRP$ our) (NN theory)) (ADVP (RB also)) (VP (VBZ shows) (SBAR (IN that) (S (SBAR (IN if) (S (NP (DT the) (NN layer) (NN normalization)) (VP (VBZ is) (VP (VBN put) (PP (IN inside) (NP (DT the) (JJ residual) (NNS blocks))) (PRN (-LRB- -LRB-) (S (ADVP (RB recently)) (VP (VBN proposed) (PP (IN as) (NP (NNP Pre-LN) (NNP Transformer))))) (-RRB- -RRB-)))))) (, ,) (NP (DT the) (NNS gradients)) (VP (VBP are) (ADJP (ADJP (RB well) (HYPH -) (VBN behaved)) (PP (IN at) (NP (NN initialization)))))))) (. .))
(S (NP (DT This)) (VP (VBZ motivates) (S (NP (PRP us)) (VP (TO to) (VP (VB remove) (NP (DT the) (ADJP (JJ warm) (HYPH -) (JJ up)) (NN stage)) (PP (IN for) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (NML (NNP Pre-LN) (NNPS Transformers)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (PP (IN in) (NP (PRP$ our) (NNS experiments))) (SBAR (IN that) (S (NP (NP (NML (NNP Pre-LN) (NNPS Transformers))) (PP (IN without) (NP (DT the) (ADJP (JJ warm) (HYPH -) (JJ up)) (NN stage)))) (VP (MD can) (VP (VB reach) (NP (JJ comparable) (NNS results)) (PP (IN with) (NP (NNS baselines))) (PP (IN while) (S (VP (VBG requiring) (NP (NP (ADJP (RB significantly) (JJR less)) (NN training) (NN time)) (CC and) (NP (ADJP (JJ hyper) (HYPH -) (NN parameter)) (NN tuning))) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNS applications))))))))))))) (. .))
