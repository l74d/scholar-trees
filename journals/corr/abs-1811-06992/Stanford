(S (S (NP (JJ Deep) (NN learning)) (VP (VBZ is) (ADJP (RB extremely) (RB computationally) (JJ intensive)))) (, ,) (CC and) (S (NP (NN hardware) (NNS vendors)) (VP (VBP have) (VP (VBN responded) (PP (IN by) (S (VP (VBG building) (ADVP (RBR faster)) (NP (NP (NNS accelerators)) (PP (IN in) (NP (JJ large) (NNS clusters)))))))))) (. .))
(S (S (VP (VBG Training) (NP (JJ deep) (NN learning) (NNS models)) (PP (IN at) (NP (NNP petaFLOPS) (NN scale))))) (VP (VBZ requires) (S (VP (VBG overcoming) (NP (DT both) (UCP (ADJP (JJ algorithmic)) (CC and) (NML (NNS systems))) (NN software) (NNS challenges))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP discuss) (NP (NP (ADJP (NP (CD three) (NNS systems)) (HYPH -) (VBN related)) (NNS optimizations)) (: :) (NP (LST (-LRB- -LRB-) (LS 1) (-RRB- -RRB-)) (NP (NP (VBN distributed) (NN batch)) (NP (NN normalization))) (S (VP (TO to) (VP (VB control) (NP (NP (NML (PP (IN per) (HYPH -) (NP (NN replica) (NN batch)))) (NNS sizes)) (, ,) (NP (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (NP (NML (NN input) (NN pipeline)) (NNS optimizations) (S (VP (TO to) (VP (VB sustain) (NP (NP (NN model) (NN throughput)) (, ,) (CC and) (NP (LST (-LRB- -LRB-) (LS 3) (-RRB- -RRB-)) (ADJP (CD 2) (HYPH -) (NN D)) (NN torus))) (VP (RB all) (HYPH -) (VB reduce)))))) (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (NN gradient) (NN summation))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP combine) (NP (DT these) (NNS optimizations)) (S (VP (TO to) (VP (VB train) (NP (NP (NNP ResNet) (HYPH -) (CD 50)) (PP (IN on) (NP (NNP ImageNet)))) (PP (IN to) (NP (NP (NML (CD 76.3) (NN %)) (NN accuracy)) (PP (IN in) (NP (NP (CD 2.2) (NNS minutes)) (PP (IN on) (NP (DT a) (NML (CD 1024) (HYPH -) (NN chip)) (NN TPU) (NN v3) (NN Pod))))))) (PP (IN with) (NP (NP (DT a) (NN training) (NN throughput)) (PP (IN of) (NP (NP (QP (IN over) (CD 1.05) (CD million)) (NNS images)) (PP (SYM /) (NP (NP (JJ second)) (CC and) (NP (DT no) (NN accuracy) (NN drop)))))))))))) (. .))
