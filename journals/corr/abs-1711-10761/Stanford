(S (NP (JJ Previous) (NN work)) (VP (VBZ has) (VP (VBN shown) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ possible) (S (VP (TO to) (VP (VB train) (NP (JJ deep) (JJ neural) (NNS networks)) (PP (IN with) (NP (NP (JJ low) (NN precision) (NNS weights)) (CC and) (NP (NNS activations))))))))))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ extreme) (NN case))) (NP (PRP it)) (VP (VBZ is) (ADJP (RB even) (JJ possible)) (S (VP (TO to) (VP (VB constrain) (NP (DT the) (NN network)) (PP (IN to) (NP (JJ binary) (NNS values))))))) (. .))
(S (NP (DT The) (JJ costly) (JJ floating) (NN point) (NNS multiplications)) (VP (VBP are) (ADVP (RB then)) (VP (VBN reduced) (PP (IN to) (NP (JJ fast) (JJ logical) (NNS operations))))) (. .))
(S (S (NP (NP (NML (JJ High) (NN end)) (JJ smart) (NNS phones)) (PP (JJ such) (IN as) (NP (NP (NP (NNP Google) (POS 's)) (NN Pixel) (CD 2)) (CC and) (NP (NP (NNP Apple) (POS 's)) (NML (NNP iPhone) (NNP X)))))) (VP (VBP are) (ADVP (RB already)) (VP (VBN equipped) (PP (IN with) (NP (NP (VBN specialised) (NN hardware)) (PP (IN for) (NP (NN image) (NN processing)))))))) (CC and) (S (NP (PRP it)) (VP (VBZ is) (ADJP (RB very) (JJ likely)) (SBAR (IN that) (S (NP (JJ other) (JJ future) (NN consumer) (NN hardware)) (VP (MD will) (ADVP (RB also)) (VP (VB have) (VP (VBN dedicated) (NP (NP (NNS accelerators)) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks))))))))))) (. .))
(S (NP (JJ Binary) (JJ neural) (NNS networks)) (VP (VBP are) (ADJP (JJ attractive) (PP (IN in) (NP (DT this) (NN case)))) (SBAR (IN because) (S (NP (DT the) (JJ logical) (NNS operations)) (VP (VBP are) (ADJP (ADJP (RB very) (RB fast)) (CC and) (ADJP (JJ efficient))) (SBAR (WHADVP (WRB when)) (S (VP (VBN implemented) (PP (IN in) (NP (NN hardware)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (ADJP (NP (NN transfer) (NN learning)) (VBN based)) (NN architecture)) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (ADVP (RB first)) (VP (VP (VB train) (NP (DT a) (JJ binary) (NN network)) (PP (IN on) (NP (NNP Imagenet)))) (CC and) (ADVP (RB then)) (VP (VB retrain) (NP (NP (NN part)) (PP (IN of) (NP (NP (DT the) (NN network)) (PP (IN for) (NP (JJ different) (NNS tasks)))))) (PP (IN while) (S (VP (VBG keeping) (NP (NP (JJS most)) (PP (IN of) (NP (NP (DT the) (NN network)) (VP (VBN fixed)))))))))))))) (. .))
(S (NP (DT The) (VBN fixed) (JJ binary) (NN part)) (VP (MD could) (VP (VB be) (VP (VBN implemented) (PP (IN in) (NP (DT a) (NN hardware) (NN accelerator))) (SBAR (IN while) (S (NP (NP (DT the) (JJ last) (NNS layers)) (PP (IN of) (NP (DT the) (NN network)))) (VP (VBP are) (VP (VBN evaluated) (PP (IN in) (NP (NN software)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT a) (JJ single) (NN binary) (JJ neural) (NN network)) (VP (VBN trained) (PP (IN on) (NP (DT the) (NNP Imagenet) (NN dataset))))) (VP (MD can) (ADVP (RB indeed)) (VP (VB be) (VP (VBN used) (PP (IN as) (NP (NP (DT a) (NN feature) (NN extractor)) (PP (IN for) (NP (JJ other) (NNS datasets))))))))))) (. .))
