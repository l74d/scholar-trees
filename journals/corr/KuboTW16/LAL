(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (JJ dropout) (NN compaction)) (, ,) (NP (NP (DT a) (JJ novel) (NN method)) (PP (IN for) (S (VP (VBG training) (NP (JJ feed-forward) (JJ neural) (NNS networks))))) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ realizes) (NP (NP (DT the) (NN performance) (NNS gains)) (PP (IN of) (S (VP (VBG training) (NP (DT a) (JJ large) (NN model)) (PP (IN with) (NP (NN dropout) (NN regularization)))))))) (, ,) (RB yet) (VP (VBZ extracts) (NP (DT a) (JJ compact) (JJ neural) (NN network)) (PP (IN for) (NP (JJ run-time) (NN efficiency)))))))))) (. .))
(S (PP (IN In) (NP (DT the) (VBN proposed) (NN method))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ sparsity-inducing) (NN prior)) (PP (IN on) (NP (DT the) (ADJP (NN per) (NN unit)) (NN dropout) (NN retention) (NN probability)))) (SBAR (IN so) (IN that) (S (NP (DT the) (NN optimizer)) (VP (MD can) (VP (ADVP (RB effectively)) (VB prune) (NP (JJ hidden) (NNS units)) (PP (IN during) (NP (NN training)))))))) (. .))
(S (PP (IN By) (S (VP (VBG changing) (NP (DT the) (JJ prior) (NNS hyperparameters))))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB control) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT the) (VBG resulting) (NN network)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBD performed) (NP (NP (DT a) (JJ systematic) (NN comparison)) (PP (IN of) (NP (NP (NN dropout) (NN compaction)) (CC and) (NP (VBG competing) (NNS methods))))) (PP (IN on) (NP (JJ several) (JJ real-world) (NN speech) (NN recognition) (NNS tasks)))) (CC and) (VP (VBD found) (SBAR (IN that) (S (NP (NN dropout) (NN compaction)) (VP (VBD achieved) (NP (JJ comparable) (NN accuracy)) (PP (IN with) (NP (NP (QP (JJR fewer) (IN than) (CD 50)) (NN %)) (PP (IN of) (NP (DT the) (JJ hidden) (NNS units))))) (, ,) (S (VP (VBG translating) (PP (TO to) (NP (NP (DT a) (CD 2.5x) (NN speedup)) (PP (IN in) (NP (NN run-time)))))))))))) (. .))
