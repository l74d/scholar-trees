(S (S (NP (PRP We)) (VP (VBP introduce) (NP (NP (NP (NN dropout) (NN compaction)) (, ,) (NP (NP (DT a) (JJ novel) (NN method)) (PP (IN for) (NP (ADJP (NP (NN training) (NN feed)) (HYPH -) (JJ forward)) (JJ neural) (NNS networks))))) (SBAR (WHNP (WDT which)) (S (VP (VBZ realizes) (NP (NP (DT the) (NN performance) (NNS gains)) (PP (IN of) (S (VP (VBG training) (NP (DT a) (JJ large) (NN model)) (PP (IN with) (NP (NN dropout) (NN regularization))))))))))))) (, ,) (CC yet) (FRAG (NP (NNS extracts)) (NP (NP (DT a) (JJ compact) (JJ neural) (NN network)) (PP (IN for) (NP (NML (NN run) (HYPH -) (NN time)) (NN efficiency))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ proposed) (NN method))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (ADJP (NN sparsity) (HYPH -) (VBG inducing))) (PP (JJ prior) (IN on) (NP (DT the) (NML (PP (IN per) (NP (NN unit) (NN dropout)))) (NN retention) (NN probability)))) (SBAR (IN so) (IN that) (S (NP (DT the) (NN optimizer)) (VP (MD can) (ADVP (RB effectively)) (VP (VB prune) (NP (JJ hidden) (NNS units)) (PP (IN during) (NP (NN training)))))))) (. .))
(S (PP (IN By) (S (VP (VBG changing) (NP (DT the) (JJ prior) (NNS hyperparameters))))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB control) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT the) (VBG resulting) (NN network)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBD performed) (NP (NP (NP (DT a) (JJ systematic) (NN comparison)) (PP (IN of) (NP (NN dropout) (NN compaction)))) (CC and) (NP (NP (VBG competing) (NNS methods)) (PP (IN on) (NP (JJ several) (NML (JJ real) (HYPH -) (NN world)) (NN speech) (NN recognition) (NNS tasks)))))) (CC and) (VP (VBD found) (SBAR (IN that) (S (NP (NN dropout) (NN compaction)) (VP (VBD achieved) (NP (JJ comparable) (NN accuracy)) (PP (IN with) (NP (NP (QP (JJR fewer) (IN than) (CD 50)) (NN %)) (PP (IN of) (NP (DT the) (VBN hidden) (NNS units))))) (, ,) (S (VP (VBG translating) (PP (IN to) (NP (NP (DT a) (NML (QP (CD 2.5) (SYM x))) (NN speedup)) (PP (IN in) (NP (NN run) (HYPH -) (NN time)))))))))))) (. .))
