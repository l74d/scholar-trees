(S (NP (EX There)) (VP (VBZ is) (NP (NP (DT a) (VBG growing) (NN desire)) (PP (IN in) (NP (NP (DT the) (NN field)) (PP (IN of) (NP (NP (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (CC and) (NP (NP (NN machine) (NN learning)) (PP (IN in) (ADJP (JJ general)))) (-RRB- -RRB-)))))) (S (VP (TO to) (VP (VB move) (PP (IN from) (NP (JJ black-box) (NNS models))) (PP (IN toward) (NP (ADJP (JJR more) (`` ``) (JJ interpretable)) (NNP AI)))))))) (. .) ('' ''))
(S (NP (PRP We)) (VP (VBP improve) (NP (NP (NN interpretability)) (PP (IN of) (NP (NN reinforcement) (NN learning)))) (PP (IN by) (S (VP (VBG increasing) (NP (NP (DT the) (NN utility)) (PP (IN of) (NP (NP (NN decision) (NN tree) (NNS policies)) (VP (VBD learned) (PP (IN via) (NP (NN reinforcement) (NN learning))))))))))) (. .))
(S (NP (DT These) (NNS policies)) (VP (VBP consist) (PP (IN of) (NP (NP (DT a) (NN decision) (NN tree)) (PP (IN over) (NP (DT the) (NN state) (NN space))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ requires) (NP (NP (NP (JJR fewer) (NNS parameters))) (S (VP (TO to) (VP (VB express)))) (PP (IN than) (NP (JJ traditional) (NN policy) (NNS representations)))))))))) (. .))
(S (S (NP (NP (VBG Existing) (NNS methods)) (PP (IN for) (S (VP (VBG creating) (NP (NN decision) (NN tree) (NNS policies)) (PP (IN via) (NP (NN reinforcement) (VBG learning))))))) (VP (NN focus) (PP (IN on) (S (VP (ADVP (RB accurately)) (VBG representing) (NP (DT an) (JJ action-value) (NN function)) (PP (IN during) (NP (NN training)))))))) (, ,) (CC but) (S (NP (DT this)) (VP (VBZ leads) (PP (TO to) (NP (NP (ADJP (JJ much) (JJR larger)) (NNS trees)) (SBAR (IN than) (S (VP (MD would) (ADVP (RB otherwise)) (VP (VB be) (VP (VBN required)))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this) (NN shortcoming))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN novel) (NN algorithm)) (SBAR (WHNP (WDT which)) (S (ADVP (RB only)) (VP (VBZ increases) (NP (JJ tree) (NN size)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (VBN estimated) (JJ discounted) (JJ future) (NN reward)) (PP (IN of) (NP (DT the) (JJ overall) (NN policy)))) (VP (MD would) (VP (VB increase) (PP (IN by) (NP (DT a) (JJ sufficient) (NN amount)))))))))))) (. .))
(S (PP (IN Through) (NP (NP (NN evaluation)) (PP (IN in) (NP (DT a) (JJ simulated) (NN environment))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (SBAR (IN that) (S (NP (PRP$ its) (NN performance)) (VP (VBZ is) (ADJP (JJ comparable) (CC or) (JJ superior) (PP (TO to) (NP (JJ traditional) (JJ tree-based) (NNS approaches))))))) (CC and) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ yields) (NP (DT a) (ADJP (RBR more) (JJ succinct)) (NN policy))))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (PRP we)) (VP (VBP discuss) (S (VP (VBG tuning) (NP (NNS parameters)) (S (VP (TO to) (VP (VB control) (NP (NP (DT the) (NN tradeoff)) (PP (IN between) (S (VP (VBG optimizing) (PP (PP (IN for) (NP (JJR smaller) (NN tree) (NN size))) (CC or) (PP (IN for) (NP (JJ overall) (NN reward)))))))))))))) (. .))
