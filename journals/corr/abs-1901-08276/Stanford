(S (NP (NP (NNP Random) (NNP Matrix) (NNP Theory)) (-LRB- -LRB-) (NP (NNP RMT)) (-RRB- -RRB-)) (VP (VBZ is) (VP (VBN applied) (S (VP (TO to) (VP (VB analyze) (NP (NP (DT the) (NN weight) (NNS matrices)) (PP (IN of) (NP (NP (NP (NP (JJ Deep) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-)) (, ,) (PP (VBG including) (NP (DT both) (NN production) (NN quality)))) (, ,) (NP (NP (JJ pre-trained) (NNS models)) (PP (JJ such) (IN as) (NP (NNP AlexNet) (CC and) (NNP Inception)))) (, ,) (CC and) (NP (NP (JJR smaller) (NNS models)) (VP (VBN trained) (PP (IN from) (NP (NN scratch))))))) (, ,) (PP (JJ such) (IN as) (NP (NP (NN LeNet5)) (CC and) (NP (NP (DT a) (JJ miniature)) (HYPH -) (NP (NNP AlexNet))))))))))) (. .))
(NP (NP (NP (NP (ADJP (JJ Empirical) (CC and) (JJ theoretical)) (NNS results)) (SBAR (S (ADVP (RB clearly)) (VP (VBP indicate) (SBAR (IN that) (S (NP (NP (NP (DT the) (JJ empirical) (JJ spectral) (NN density)) (-LRB- -LRB-) (NP (NN ESD)) (-RRB- -RRB-)) (PP (IN of) (NP (NN DNN) (NN layer) (NNS matrices)))) (VP (VBZ displays) (NP (NP (NNS signatures)) (PP (IN of) (ADVP (RB traditionally))))))))))) (HYPH -) (VP (VBN regularized) (NP (JJ statistical) (NNS models)) (, ,) (ADVP (RB even)) (PP (IN in) (NP (NP (DT the) (NN absence)) (PP (IN of) (S (ADVP (RB exogenously)) (VP (VBG specifying) (NP (NP (JJ traditional) (NNS forms)) (PP (IN of) (NP (NN regularization))))))))))) (, ,) (PP (JJ such) (IN as) (NP (NP (NN Dropout)) (CC or) (NP (NN Weight) (NN Norm) (NNS constraints)))) (. .))
(S (PP (IN For) (NP (ADJP (ADJP (JJR smaller)) (CONJP (CC and) (HYPH /) (CC or)) (ADJP (JJR older))) (NNS DNNs))) (, ,) (NP (DT this) (JJ Implicit) (NN Self) (HYPH -) (NN Regularization)) (VP (VBZ is) (PP (IN like) (NP (JJ traditional) (NNP Tikhonov) (NN regularization))) (, ,) (PP (IN in) (SBAR (IN that) (S (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (`` `) (NN size) (NN scale) ('' ')) (VP (VBG separating) (NP (NN signal)) (PP (IN from) (NP (NN noise)))))))))) (. .))
(S (NP (DT This) (JJ implicit) (NN Self) (HYPH -) (NN Regularization)) (VP (MD can) (VP (VB depend) (ADVP (RB strongly)) (PP (IN on) (NP (NP (DT the) (JJ many) (NNS knobs)) (PP (IN of) (NP (DT the) (NN training) (NN process))))))) (. .))
(S (PP (IN By) (S (VP (VBG exploiting) (NP (DT the) (NN generalization) (NN gap) (NN phenomena))))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VB cause) (NP (DT a) (JJ small) (NN model)) (S (VP (TO to) (VP (VB exhibit) (NP (NP (QP (DT all) (CD 5)) (CD +1) (NNS phases)) (PP (IN of) (NP (NN training)))) (PP (ADVP (RB simply)) (IN by) (S (VP (VBG changing) (NP (DT the) (NN batch) (NN size))))))))))))) (. .))
