(S (NP (NP (VBN Distributed) (NN machine) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP ML)) (-RRB- -RRB-))) (VP (MD can) (VP (VB bring) (NP (RBR more) (JJ computational) (NNS resources)) (PP (TO to) (NP (VB bear))) (PP (IN than) (NP (JJ single-machine) (NN learning))) (, ,) (S (VP (VBG reducing) (NP (NN training) (NN time)))))) (. .))
(S (ADVP (RB Further)) (, ,) (NP (NN distribution)) (VP (VBZ allows) (S (NP (NNS models)) (VP (TO to) (VP (VB be) (VP (VBN partitioned) (PP (IN over) (NP (JJ many) (NNS machines))))))) (, ,) (S (VP (VBG allowing) (S (NP (ADJP (RB very) (JJ large)) (NNS models)) (VP (TO to) (VP (VB be) (VP (VBN trained) (: â€”) (NP (NP (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (MD may) (VP (VB be) (ADJP (ADJP (RB much) (JJR larger)) (PP (IN than) (NP (NP (DT the) (JJ available) (NN memory)) (PP (IN of) (NP (DT any) (JJ individual) (NN machine)))))))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (NN practice))) (, ,) (NP (VBN distributed) (NNP ML)) (VP (VBZ remains) (ADJP (JJ challenging)) (, ,) (PP (ADVP (RB primarily)) (JJ due) (PP (TO to) (NP (JJ high) (NN communication) (NNS costs))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN approach)) (PP (TO to) (NP (VBN distributed) (JJ neural) (NN network) (NN learning))) (, ,) (VP (VBN called) (S (NP (S (NP (JJ independent) (NN subnet) (NN training))) (PRN (-LRB- -LRB-) (NP (NNP IST)) (-RRB- -RRB-))))))) (. .))
(S (PP (IN In) (NP (NNP IST))) (, ,) (NP (DT a) (JJ neural) (NN network)) (VP (VBZ is) (VP (VBN decomposed) (PP (IN into) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NNS subnetworks)) (PP (IN of) (NP (NP (DT the) (JJ same) (NN depth)) (PP (IN as) (NP (DT the) (JJ original) (NN network))))) (, ,) (SBAR (WHNP (WHNP (DT each)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBZ is) (VP (VBN trained) (ADVP (RB locally)))))))))) (, ,) (SBAR (IN before) (S (S (NP (DT the) (JJ various) (NNS subnets)) (VP (VBP are) (VP (VBN exchanged)))) (CC and) (S (NP (DT the) (NN process)) (VP (VBZ is) (VP (VBN repeated)))))))) (. .))
(S (NP (NNP IST) (NN training)) (VP (VBZ has) (NP (NP (JJ many) (NNS advantages)) (PP (IN over) (NP (JJ standard) (NNS data) (JJ parallel) (NNS approaches))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NNS subsets)) (VP (VBP are) (ADJP (JJ independent))))) (, ,) (NP (JJ communication) (NN frequency)) (VP (VBZ is) (VP (VBN reduced))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (JJ original) (NN network)) (VP (VBZ is) (VP (VBN decomposed) (PP (IN into) (NP (JJ independent) (NNS parts))))))) (, ,) (NP (NN communication) (NN volume)) (VP (VBZ is) (VP (VBN reduced))) (. .))
(S (ADVP (RB Further)) (, ,) (S (NP (DT the) (NN decomposition)) (VP (VBZ makes) (S (NP (NNP IST)) (ADJP (RB naturally) (VBZ model) (JJ parallel))))) (, ,) (CC and) (RB so) (S (NP (NNP IST)) (VP (NNS scales) (PP (TO to) (NP (NP (ADJP (RB very) (JJ large)) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (RB not) (VP (VB fit) (PP (IN on) (NP (DT any) (JJ single) (NN machine))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (ADVP (RB experimentally)) (SBAR (SBAR (IN that) (S (NP (NNP IST)) (VP (NNS results) (PP (IN in) (NP (NP (NN training) (NN time)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (ADJP (RB much) (JJR lower)) (PP (IN than) (NP (NP (NNS data) (JJ parallel) (NNS approaches)) (PP (TO to) (NP (VB distributed) (NN learning)))))))))))))) (, ,) (CC and) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ scales) (PP (TO to) (NP (NP (JJ large) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (RB not) (VP (VB be) (VP (VBN learned) (S (VP (VBG using) (NP (JJ standard) (NNS approaches)))))))))))))))) (. .))
