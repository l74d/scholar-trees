(S (VP (VB Multi-task) (S (NP (NN learning) (-LRB- -LRB-) (NN MTL) (-RRB- -RRB-)) (VP (VBZ allows) (NP (JJ deep) (JJ neural) (NNS networks)) (S (VP (TO to) (VP (VB learn) (PP (IN from) (NP (JJ related) (NNS tasks))) (PP (IN by) (S (VP (VBG sharing) (NP (NNS parameters)) (PP (IN with) (NP (JJ other) (NNS networks)))))))))))) (. .))
(S (PP (IN In) (NP (NN practice))) (, ,) (ADVP (RB however)) (, ,) (NP (NN MTL)) (VP (VBZ involves) (S (VP (VBG searching) (NP (NP (DT an) (JJ enormous) (NN space)) (PP (IN of) (NP (NP (JJ possible) (NN parameter)) (VP (VBG sharing) (NP (NNS architectures)) (S (VP (TO to) (VP (VB find) (NP (NP (LST (-LRB- -LRB-) (DT a) (-RRB- -RRB-)) (NP (DT the) (NNS layers)) (CC or) (NP (NP (NNS subspaces)) (SBAR (WHNP (WDT that)) (S (VP (VBP benefit) (PP (IN from) (NP (NN sharing)))))))) (, ,) (NP (LST (-LRB- -LRB-) (LS b) (-RRB- -RRB-)) (NP (DT the) (JJ appropriate) (NN amount)) (PP (IN of) (NP (NN sharing)))) (, ,) (CC and) (NP (LST (-LRB- -LRB-) (LS c) (-RRB- -RRB-)) (NP (DT the) (JJ appropriate) (JJ relative) (NNS weights)) (PP (IN of) (NP (DT the) (JJ different) (NN task) (NNS losses))))))))))))))) (. .))
(S (NP (JJ Recent) (NN work)) (VP (VBZ has) (VP (VBN addressed) (NP (NP (DT each)) (PP (IN of) (NP (DT the) (JJ above) (NNS problems)))) (PP (IN in) (NP (NN isolation))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (NP (PRP we)) (VP (VBP present) (NP (NP (DT an) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ learns) (S (NP (DT a) (NN latent)) (VP (VB multi-task) (NP (NP (NP (NN architecture)) (SBAR (WHNP (WDT that)) (S (ADVP (RB jointly)) (VP (VBZ addresses))))) (NP (NP (-LRB- -LRB-) (QP (DT a)) (-RRB- -RRB-)) (: --) (LST (-LRB- -LRB-) (LS c) (-RRB- -RRB-))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NNS experiments)) (PP (IN on) (NP (NP (JJ synthetic) (NNS data) (CC and) (NNS data)) (PP (IN from) (NP (NNP OntoNotes) (CD 5.0))) (, ,) (PP (VBG including) (NP (NP (CD four) (JJ different) (NNS tasks)) (CC and) (NP (CD seven) (JJ different) (NNS domains))))))) (. .))
(S (NP (PRP$ Our) (NN extension)) (ADVP (RB consistently)) (VP (VP (VBZ outperforms) (NP (JJ previous) (NNS approaches)) (PP (IN to) (S (VP (VBG learning) (NP (NP (JJ latent) (NNS architectures)) (PP (IN for) (NP (NML (S (VP (VB multi-task)))) (NNS problems)))))))) (CC and) (VP (VBZ achieves) (PRT (RP up)) (PP (IN to) (NP (NP (NML (CD 15) (NN %)) (JJ average) (NN error) (NNS reductions)) (PP (IN over) (NP (NP (JJ common) (NNS approaches)) (PP (IN to) (NP (NN MTL))))))))) (. .))
