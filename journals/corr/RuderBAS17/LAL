(S (NP (NP (NNP Multi-task) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP MTL)) (-RRB- -RRB-))) (VP (VBZ allows) (S (NP (JJ deep) (JJ neural) (NNS networks)) (VP (TO to) (VP (VB learn) (PP (IN from) (NP (JJ related) (NNS tasks))) (PP (IN by) (S (VP (VBG sharing) (NP (NNS parameters)) (PP (IN with) (NP (JJ other) (NNS networks)))))))))) (. .))
(S (PP (IN In) (NP (NN practice))) (, ,) (ADVP (RB however)) (, ,) (NP (NNP MTL)) (VP (VBZ involves) (S (VP (VBG searching) (NP (NP (DT an) (JJ enormous) (NN space)) (PP (IN of) (NP (JJ possible) (NN parameter) (VBG sharing) (NNS architectures)))) (S (VP (TO to) (VP (VB find) (NP (NP (NP (PRN (-LRB- -LRB-) (DT a) (-RRB- -RRB-)) (NP (DT the) (NNS layers) (CC or) (NNS subspaces))) (SBAR (WHNP (WDT that)) (S (VP (VBP benefit) (PP (IN from) (NP (VBG sharing))))))) (, ,) (NP (NP (PRN (-LRB- -LRB-) (NN b) (-RRB- -RRB-)) (NP (DT the) (JJ appropriate) (NN amount))) (PP (IN of) (NP (NN sharing)))) (, ,) (CC and) (NP (PRN (-LRB- -LRB-) (NN c) (-RRB- -RRB-)) (NP (NP (DT the) (JJ appropriate) (JJ relative) (NNS weights)) (PP (IN of) (NP (DT the) (JJ different) (NN task) (NNS losses)))))))))))) (. .))
(S (NP (JJ Recent) (NN work)) (VP (VBZ has) (VP (VBN addressed) (NP (NP (DT each)) (PP (IN of) (NP (DT the) (JJ above) (NNS problems)))) (PP (IN in) (NP (NN isolation))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (NP (PRP we)) (VP (VBP present) (NP (NP (DT an) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ learns) (NP (NP (DT a) (JJ latent) (JJ multi-task) (NN architecture)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB jointly)) (VBZ addresses) (PRN (-LRB- -LRB-) (DT a) (-RRB- -RRB-)) (NX (: â€”) (PRN (-LRB- -LRB-) (NN c) (-RRB- -RRB-)))))))))))) (. .))
(S (NP (PRP We)) (VP (JJ present) (NP (NP (NNS experiments)) (PP (IN on) (NP (NP (JJ synthetic) (NNS data)) (CC and) (NP (NP (NNS data)) (PP (IN from) (NP (NNP OntoNotes) (CD 5.0)))))) (, ,) (PP (VBG including) (NP (NP (CD four) (JJ different) (NNS tasks)) (CC and) (NP (CD seven) (JJ different) (NNS domains)))))) (. .))
(S (NP (PRP$ Our) (NN extension)) (VP (VP (ADVP (RB consistently)) (VBZ outperforms) (NP (NP (JJ previous) (NNS approaches)) (PP (TO to) (S (VP (VBG learning) (NP (JJ latent) (NNS architectures)) (PP (IN for) (NP (NN multi-task) (NNS problems)))))))) (CC and) (VP (VBZ achieves) (NP (NP (ADJP (QP (RB up) (TO to) (CD 15)) (NN %)) (JJ average) (NN error) (NNS reductions)) (PP (IN over) (NP (NP (JJ common) (NNS approaches)) (PP (TO to) (NP (NNP MTL)))))))) (. .))
