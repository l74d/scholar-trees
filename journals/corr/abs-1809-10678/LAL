(S (NP (PRP It)) (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (SBAR (IN that) (S (S (VP (VBG injecting) (NP (RB noise)) (PP (IN into) (NP (DT the) (JJ neural) (NN network) (NNS weights))) (PP (IN during) (NP (DT the) (NN training) (NN process))))) (VP (VBZ leads) (PP (TO to) (NP (NP (DT a) (JJR better) (NN generalization)) (PP (IN of) (NP (DT the) (VBG resulting) (NN model))))))))))) (. .))
(S (S (NP (NP (NNP Noise) (NN injection)) (PP (IN in) (NP (DT the) (JJ distributed) (NN setup)))) (VP (VBZ is) (NP (DT a) (NN straightforward) (NN technique)))) (CC and) (S (NP (PRP it)) (VP (VBZ represents) (NP (NP (DT a) (JJ promising) (NN approach)) (SBAR (S (VP (TO to) (VP (VB improve) (NP (DT the) (ADJP (RB locally) (JJ trained)) (NNS models))))))))) (. .))
(S (NP (PRP We)) (VP (VBP investigate) (NP (NP (DT the) (NNS effects)) (PP (IN of) (NP (NP (NN noise) (NN injection)) (PP (IN into) (NP (DT the) (JJ neural) (NNS networks))))) (PP (IN during) (NP (DT a) (JJ decentralized) (NN training) (NN process))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (ADVP (DT both) (RB theoretically) (CC and) (RB empirically)) (SBAR (IN that) (S (NP (NN noise) (NN injection)) (VP (VBZ has) (NP (NP (DT no) (JJ positive) (NN effect)) (PP (IN in) (NP (NN expectation))) (PP (IN on) (NP (JJ linear) (NNS models))))))) (, ,) (ADVP (RB though))) (. .))
(S (ADVP (RB However)) (PP (IN for) (NP (JJ non-linear) (JJ neural) (NNS networks))) (NP (PRP we)) (ADVP (RB empirically)) (VP (VBP show) (SBAR (IN that) (S (NP (NN noise) (NN injection)) (VP (ADVP (RB substantially)) (VBZ improves) (NP (NN model) (NN quality)) (S (VP (VBG helping) (S (VP (TO to) (VP (VB reach) (NP (NP (DT a) (NN generalization) (NN ability)) (PP (IN of) (NP (NP (DT a) (JJ local) (NN model)) (ADJP (RB close) (PP (TO to) (NP (DT the) (JJ serial) (NN baseline)))))))))))))))) (. .))
