(S (NP (NN Sparsity)) (VP (VBZ has) (VP (VBN become) (S (ADJP (JJ popular))) (PP (IN in) (NP (NN machine) (NN learning))) (, ,) (SBAR (IN because) (S (NP (PRP it)) (VP (MD can) (VP (VP (VB save) (NP (JJ computational) (NNS resources))) (, ,) (VP (VB facilitate) (NP (NNS interpretations))) (, ,) (CC and) (VP (VB prevent) (NP (NN overfitting))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP discuss) (NP (NN sparsity)) (PP (IN in) (NP (NP (DT the) (NN framework)) (PP (IN of) (NP (JJ neural) (NNS networks)))))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (NP (PRP we)) (VP (VBP formulate) (NP (NP (DT a) (JJ new) (NN notion)) (PP (IN of) (NP (NP (NN sparsity)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ concerns) (NP (NP (DT the) (NNS networks) (POS ')) (NNS layers))) (CC and) (, ,) (ADVP (RB therefore)) (, ,) (VP (VBZ aligns) (ADVP (RB particularly)) (ADVP (RB well)) (PP (IN with) (NP (NP (DT the) (JJ current) (NN trend)) (PP (IN toward) (NP (JJ deep) (NNS networks))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP call) (NP (DT this) (NN notion) (NN layer) (NN sparsity))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VBP introduce) (NP (NP (VBG corresponding) (NML (NN regularization) (CC and) (NN refitting)) (NNS schemes)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB complement) (NP (JJ standard) (NML (JJ deep) (HYPH -) (NN learning)) (NNS pipelines)) (S (VP (TO to) (VP (VB generate) (NP (JJR more) (ADJP (JJ compact) (CC and) (JJ accurate)) (NNS networks))))))))))) (. .))
