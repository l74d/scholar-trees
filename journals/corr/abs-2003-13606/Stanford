(S (NP (NML (NN Graph) (NN convolution)) (NNS networks) (PRN (-LRB- -LRB-) (NP (NN GCN)) (-RRB- -RRB-))) (VP (VP (VBP are) (ADJP (RB increasingly) (JJ popular) (PP (IN in) (NP (JJ many) (NNS applications))))) (, ,) (ADVP (RB yet)) (VP (VBP remain) (ADJP (RB notoriously) (JJ hard) (S (VP (TO to) (VP (VB train) (PP (IN over) (NP (JJ large) (NN graph) (NNS datasets))))))))) (. .))
(S (NP (PRP They)) (VP (VBP need) (S (VP (TO to) (VP (VB compute) (NP (NN node) (NNS representations)) (ADVP (RB recursively)) (PP (IN from) (NP (PRP$ their) (NNS neighbors))))))) (. .))
(S (NP (JJ Current) (NN GCN) (NN training) (NNS algorithms)) (VP (VBP suffer) (PP (IN from) (NP (NP (NP (ADJP (RB either) (JJ high)) (JJ computational) (NNS costs)) (SBAR (WHNP (WDT that)) (S (VP (VBP grow) (ADVP (RB exponentially)) (PP (IN with) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS layers))))))))) (, ,) (CC or) (NP (NP (NML (JJ high) (NN memory)) (NN usage)) (PP (IN for) (S (VP (VBG loading) (NP (NP (DT the) (JJ entire) (NN graph)) (CC and) (NP (NN node) (NNS embeddings)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (NN novel) (ADJP (JJ efficient) (JJ layer-wise)) (NN training) (NN framework)) (PP (IN for) (S (NP (NP (NN GCN) (PRN (-LRB- -LRB-) (NP (NN L) (HYPH -) (NN GCN)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBZ disentangles) (NP (NP (NN feature) (NN aggregation)) (CC and) (NP (NN feature) (NN transformation))) (PP (IN during) (NP (NN training)))))) (, ,)) (ADVP (RB hence)) (ADVP (RB greatly)) (VP (VBG reducing) (NP (NML (NN time) (CC and) (NN memory)) (NNS complexities)))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (JJ theoretical) (NN analysis)) (PP (IN for) (NP (NP (NN L) (HYPH -) (NN GCN)) (PP (IN under) (NP (DT the) (NN graph) (NN isomorphism) (NN framework))))) (, ,) (SBAR (IN that) (S (NP (NN L) (HYPH -) (NN GCN)) (VP (VBZ leads) (PP (IN to) (NP (ADJP (RB as) (JJ powerful)) (NNS GCNs))) (SBAR (IN as) (S (NP (DT the) (ADJP (RBR more) (JJ costly)) (JJ conventional) (NN training) (NN algorithm)) (VP (VBZ does)))) (, ,) (PP (IN under) (NP (JJ mild) (NNS conditions))))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VB propose) (S (NP (NNP L$) (SYM ^) (CD 2)) (NP (NP (NP ($ $)) (HYPH -) (NP (NN GCN))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ learns) (NP (NP (DT a) (NN controller)) (PP (IN for) (NP (NP (DT each) (NN layer)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (ADVP (RB automatically)) (VP (VB adjust) (NP (NP (DT the) (NN training) (NNS epochs)) (PP (IN per) (NP (NN layer)))) (PP (IN in) (NP (NN L) (HYPH -) (NN GCN)))))))))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NN L) (HYPH -) (NN GCN)) (VP (VBZ is) (ADVP (ADVP (RBR faster)) (PP (IN than) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NNS arts))))) (PP (IN by) (NP (NP (QP (ADVP (IN at) (RBS least))) (DT an) (NN order)) (PP (IN of) (NP (NN magnitude))) (, ,) (PP (IN with) (NP (DT a) (ADJP (JJ consistent) (PP (IN of) (NP (NN memory)))) (NN usage))))))) (RB not) (ADJP (JJ dependent) (PP (IN on) (NP (NN dataset) (NN size)))) (, ,) (SBAR (IN while) (S (VP (VBG maintaining) (NP (JJ comparable) (NN prediction) (NN performance))))))))) (. .))
(S (PP (IN With) (NP (DT the) (NML (S (VP (VBN learned)))) (NN controller))) (, ,) (NP (NP (NN L$)) (SYM ^) (NP (CD 2) (NML (NML ($ $)) (HYPH -) (NN GCN)))) (VP (MD can) (ADVP (RB further)) (VP (VB cut) (NP (DT the) (NN training) (NN time)) (PP (IN in) (NP (NN half))))) (. .))
(S (NP (PRP$ Our) (NNS codes)) (VP (VBP are) (ADJP (JJ available) (PP (IN at) (NP (NP (DT this)) (SBAR (S (VP (VBZ https) (NP (NN URL))))))))))
