(S (NP (NP (DT The) (NNS effects)) (PP (IN of) (NP (NP (NN policy) (VBG sharing)) (PP (IN between) (NP (NP (NNS agents)) (PP (IN in) (NP (DT a) (JJ multi-agent) (JJ dynamical) (NN system)))))))) (VP (VBZ has) (RB not) (VP (VBN been) (VP (VBN studied) (ADVP (RB extensively))))) (. .))
(S (NP (PRP I)) (VP (VBP simulate) (NP (NP (DT a) (NN system)) (PP (IN of) (NP (NP (NNS agents)) (VP (VBG optimizing) (NP (DT the) (JJ same) (NN task)) (S (VP (VBG using) (NP (JJ reinforcement) (NN learning)))))))) (, ,) (S (VP (TO to) (VP (VB study) (NP (NP (DT the) (NNS effects)) (PP (IN of) (NP (NP (JJ different) (NN population) (NNS densities)) (CC and) (NP (NN policy) (NN sharing))))))))) (. .))
(S (NP (PRP I)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (VBG sharing) (NP (NNS policies))) (VP (VP (VBZ decreases) (NP (NP (DT the) (NN time)) (SBAR (S (VP (TO to) (VP (VB reach) (NP (JJ asymptotic) (NN behavior)))))))) (, ,) (CC and) (VP (NNS results) (PP (IN in) (NP (JJ improved) (JJ asymptotic) (NN behavior)))))))) (. .))
