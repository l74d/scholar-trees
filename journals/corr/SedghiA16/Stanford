(S (NP (PRP We)) (VP (VBP consider) (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (NP (NN training) (ADJP (NP (NN input) (HYPH -) (NN output)) (JJ recurrent)) (JJ neural) (NNS networks) (PRN (-LRB- -LRB-) (NP (NN RNN)) (-RRB- -RRB-))) (PP (IN for) (NP (NML (NN sequence) (NN labeling)) (NNS tasks))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (JJ novel) (JJ spectral) (NN approach)) (PP (IN for) (S (VP (VBG learning) (NP (DT the) (NN network) (NNS parameters)))))) (. .))
(S (NP (PRP It)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (NP (NN decomposition)) (PP (IN of) (NP (NP (NP (DT the) (JJ cross-moment) (NN tensor)) (PP (IN between) (NP (DT the) (NN output)))) (CC and) (NP (NP (DT a) (JJ non-linear) (NN transformation)) (PP (IN of) (NP (DT the) (NN input)))))))) (, ,) (PP (VBN based) (PP (IN on) (NP (NN score) (NNS functions)))))) (. .))
(S (NP (PRP We)) (VP (VBP guarantee) (NP (JJ consistent) (NN learning)) (PP (IN with) (NP (NP (JJ polynomial) (NN sample)) (CC and) (NP (JJ computational) (NN complexity)))) (PP (IN under) (NP (NP (JJ transparent) (NNS conditions)) (PP (JJ such) (IN as) (NP (NP (NP (NN non-degeneracy)) (PP (IN of) (NP (NN model) (NNS parameters)))) (, ,) (NP (NP (JJ polynomial) (NNS activations)) (PP (IN for) (NP (DT the) (NNS neurons)))) (, ,) (CC and) (NP (NP (DT a) (JJ Markovian) (NN evolution)) (PP (IN of) (NP (DT the) (NN input) (NN sequence))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP extend) (NP (PRP$ our) (NNS results)) (PP (IN to) (NP (NP (JJ Bidirectional) (NN RNN)) (SBAR (WHNP (WDT which)) (S (VP (VBZ uses) (NP (NP (DT both) (JJ previous)) (CC and) (NP (JJ future) (NN information))) (PP (IN to) (NP (NN output)))))))) (S (NP (NP (DT the) (NN label)) (PP (IN at) (NP (DT each) (NN time) (NN point)))))) (, ,) (CC and) (VP (VBZ is) (VP (VBN employed) (PP (IN in) (NP (NP (JJ many) (NN NLP) (NNS tasks)) (PP (JJ such) (IN as) (NP (NN POS) (NN tagging)))))))) (. .))
