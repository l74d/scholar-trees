(S (NP (PRP We)) (VP (VBP consider) (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (VBG training) (NP (NP (JJ input-output) (JJ recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNN)) (-RRB- -RRB-))) (PP (IN for) (NP (NN sequence) (NN labeling) (NNS tasks)))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (JJ spectral) (NN approach)) (PP (IN for) (S (VP (VBG learning) (NP (DT the) (NN network) (NNS parameters))))))) (. .))
(S (NP (PRP It)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (NP (NP (NN decomposition)) (PP (IN of) (NP (NP (DT the) (JJ cross-moment) (NN tensor)) (PP (IN between) (NP (DT the) (NN output)))))) (CC and) (NP (NP (DT a) (JJ non-linear) (NN transformation)) (PP (IN of) (NP (DT the) (NN input)))) (, ,) (VP (VBN based) (PP (IN on) (NP (NN score) (NNS functions)))))))) (. .))
(S (NP (PRP We)) (VP (VBP guarantee) (NP (NP (JJ consistent) (VBG learning)) (PP (IN with) (NP (NP (JJ polynomial) (NN sample)) (CC and) (NP (JJ computational) (NN complexity))))) (PP (IN under) (NP (NP (JJ transparent) (NNS conditions)) (PP (JJ such) (IN as) (NP (NP (NP (NN non-degeneracy)) (PP (IN of) (NP (NN model) (NNS parameters)))) (, ,) (NP (NP (JJ polynomial) (NNS activations)) (PP (IN for) (NP (DT the) (NNS neurons)))) (, ,) (CC and) (NP (NP (DT a) (JJ Markovian) (NN evolution)) (PP (IN of) (NP (DT the) (NN input) (NN sequence))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP extend) (NP (PRP$ our) (NNS results)) (PP (TO to) (NP (NP (NNP Bidirectional) (NNP RNN)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ uses) (NP (QP (DT both) (JJ previous) (CC and) (JJ future)) (NN information)) (S (VP (TO to) (VP (NN output) (NP (DT the) (NN label)) (PP (IN at) (NP (DT each) (NN time) (NN point))))))) (, ,) (CC and) (VP (VBZ is) (VP (VBN employed) (PP (IN in) (NP (NP (JJ many) (NNP NLP) (NNS tasks)) (PP (JJ such) (IN as) (NP (NNP POS) (NN tagging))))))))))))) (. .))
