(S (NP (DT This) (NN paper)) (VP (VBZ presents) (NP (NP (DT the) (JJ first) (JJ actor-critic) (NN algorithm)) (PP (IN for) (NP (JJ off-policy) (NN reinforcement) (NN learning))))) (. .))
(S (S (NP (PRP$ Our) (NN algorithm)) (VP (VBZ is) (ADJP (JJ online) (CC and) (JJ incremental)))) (, ,) (CC and) (S (NP (PRP$ its) (JJ per-time-step) (NN complexity)) (VP (NNS scales) (ADVP (RB linearly)) (PP (IN with) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ learned) (NNS weights))))))) (. .))
(S (NP (NP (JJ Previous) (NN work)) (PP (IN on) (NP (JJ actor-critic) (NN algorithms)))) (VP (VP (VBZ is) (ADJP (VBN limited) (PP (TO to) (NP (DT the) (NN on-policy) (NN setting))))) (CC and) (VP (VBZ does) (RB not) (VP (VB take) (NP (NN advantage)) (PP (IN of) (NP (NP (DT the) (JJ recent) (NNS advances)) (PP (IN in) (NP (JJ off-policy) (JJ gradient) (NN temporal-difference) (NN learning)))))))) (. .))
(S (NP (NP (NN Off-policy) (NNS techniques)) (, ,) (PP (JJ such) (IN as) (NP (NNP Greedy-GQ))) (, ,)) (VP (VB enable) (S (NP (DT a) (NN target) (NN policy)) (VP (TO to) (VP (VB be) (VP (VBN learned) (SBAR (IN while) (S (VP (VP (VBG following)) (CC and) (VP (VBG obtaining) (NP (NNS data)) (PP (IN from))) (NP (DT another) (PRN (-LRB- -LRB-) (NN behavior) (-RRB- -RRB-)) (NN policy)))))))))) (. .))
(S (S (PP (IN For) (NP (JJ many) (NNS problems))) (, ,) (ADVP (RB however)) (, ,) (NP (JJ actor-critic) (NNS methods)) (VP (VBP are) (ADJP (ADJP (RBR more) (JJ practical)) (PP (IN than) (NP (NP (NN action) (NN value) (NNS methods)) (PRN (-LRB- -LRB-) (PP (IN like) (NP (NNP Greedy-GQ))) (-RRB- -RRB-))))) (SBAR (IN because) (S (NP (PRP they)) (VP (ADVP (RB explicitly)) (VBP represent) (NP (DT the) (NN policy))))))) (: ;) (S (ADVP (RB consequently)) (, ,) (NP (DT the) (NN policy)) (VP (MD can) (VP (VP (VB be) (ADJP (JJ stochastic))) (CC and) (VP (VB utilize) (NP (DT a) (JJ large) (NN action) (NN space)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP illustrate) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (ADVP (RB practically)) (VP (VB combine) (NP (NP (DT the) (NX (NX (NN generality)) (CC and) (NX (VBG learning) (JJ potential)))) (PP (IN of) (NP (NN off-policy) (NN learning)))) (PP (IN with) (NP (NP (DT the) (NN flexibility)) (PP (IN in) (NP (NN action) (NN selection))) (VP (VBN given) (PP (IN by) (NP (JJ actor-critic) (NNS methods))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP derive) (NP (NP (DT an) (NN incremental) (, ,) (JJ linear) (NN time) (CC and) (NN space) (NN complexity) (VBP algorithm)) (SBAR (WHNP (WDT that)) (S (VP (S (VP (VBZ includes) (NP (NN eligibility) (NNS traces)))) (, ,) (VP (VB prove) (NP (NN convergence)) (PP (IN under) (NP (NP (NNS assumptions)) (ADJP (JJ similar) (PP (TO to) (NP (JJ previous) (NN off-policy) (NN algorithms))))))) (, ,) (CC and) (VP (ADVP (RB empirically)) (VB show) (NP (NP (ADJP (RBR better) (CC or) (JJ comparable)) (NN performance)) (PP (TO to) (NP (VBG existing) (NNS algorithms))) (PP (IN on) (NP (JJ standard) (JJ reinforcement-learning) (NN benchmark) (NNS problems)))))))))) (. .))
