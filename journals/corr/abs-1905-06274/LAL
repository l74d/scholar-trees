(S (NP (NP (JJ Model-free) (ADJP (NN reinforcement) (VBG learning) (VBN based)) (NNS methods)) (PP (JJ such) (IN as) (NP (NP (JJ Proximal) (NNP Policy) (NNP Optimization)) (, ,) (CC or) (NP (NNP Q-learning))))) (ADVP (RB typically)) (VP (VBP require) (NP (NP (NNS thousands)) (PP (IN of) (NP (NP (NNS interactions)) (PP (IN with) (NP (DT the) (NN environment)))))) (S (VP (TO to) (VP (VB approximate) (NP (NP (DT the) (NN optimum) (NN controller)) (SBAR (WHNP (WDT which)) (S (VP (MD may) (RB not) (ADVP (RB always)) (VP (VB be) (ADJP (JJ feasible)) (PP (IN in) (NP (NNS robotics))) (PP (JJ due) (PP (TO to) (NP (NP (NN safety)) (CC and) (NP (NN time) (NN consumption)))))))))))))) (. .))
(S (NP (NP (JJ Model-based) (NNS methods)) (PP (JJ such) (IN as) (NP (NNP PILCO) (CC or) (NNP BlackDrops)))) (, ,) (SBAR (IN while) (FRAG (ADJP (JJ data-efficient)))) (, ,) (VP (JJ provide) (NP (NP (NNS solutions)) (PP (IN with) (NP (JJ limited) (NN robustness) (CC and) (NN complexity))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this) (NN tradeoff))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (ADJP (JJ active) (NN uncertainty) (JJ reduction-based)) (JJ virtual) (NNS environments)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN formed) (PP (IN through) (NP (NP (JJ limited) (NNS trials)) (VP (VBN conducted) (PP (IN in) (NP (DT the) (JJ original) (NN environment)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (NP (DT an) (JJ efficient) (NN method)) (PP (IN for) (NP (NN uncertainty) (NN management))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN used) (PP (IN as) (NP (NP (DT a) (JJ metric)) (PP (IN for) (NP (JJ self-improvement))))) (PP (IN by) (NP (NP (NN identification)) (PP (IN of) (NP (NP (DT the) (NNS points)) (PP (IN with) (NP (JJ maximum) (VBN expected) (NN improvement))))) (PP (IN through) (NP (JJ adaptive) (NN sampling))))))))))) (. .))
(S (S (VP (VBG Capturing) (NP (DT the) (NN uncertainty)))) (ADVP (RB also)) (VP (VBZ allows) (PP (IN for) (NP (NP (JJR better) (NN mimicking)) (PP (IN of) (NP (NP (DT the) (NN reward) (NNS responses)) (PP (IN of) (NP (DT the) (JJ original) (NN system)))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ enables) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ complex) (NX (NX (NN policy) (NNS structures)) (CC and) (NX (NN reward) (NNS functions)))))) (PP (IN through) (NP (NP (DT a) (JJ unique) (NN combination)) (PP (IN of) (NP (ADJP (JJ model-based) (CC and) (JJ model-free)) (NNS methods))))) (, ,) (SBAR (IN while) (S (ADVP (RB still)) (VP (VBG retaining) (NP (DT the) (NN data) (NN efficiency)))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN validity)) (PP (IN of) (NP (PRP$ our) (NN method)))) (PP (IN on) (NP (JJ several) (JJ classic) (NN reinforcement) (VBG learning) (NNS problems))) (PP (IN in) (NP (NNP OpenAI) (NN gym)))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (VBZ offers) (NP (NP (DT a) (JJR better) (NN modeling) (NN capacity)) (PP (IN for) (NP (JJ complex) (NN system) (NNS dynamics))) (SBAR (IN as) (S (VP (VBN compared) (PP (TO to) (NP (VBN established) (NNS methods))))))))))) (. .))
