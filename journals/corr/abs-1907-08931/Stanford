(S (NP (NP (NN Regularization)) (PP (IN in) (NP (NP (DT the) (NN optimization)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))))) (VP (VBZ is) (ADVP (RB often)) (ADJP (JJ critical) (S (VP (TO to) (VP (VB avoid) (NP (JJ undesirable) (NN over-fitting) (VBG leading)) (PP (IN to) (NP (NP (JJR better) (NN generalization)) (PP (IN of) (NP (NN model)))))))))) (. .))
(S (S (NP (NP (CD One)) (PP (IN of) (NP (DT the) (ADJP (RBS most) (JJ popular)) (NN regularization) (NNS algorithms)))) (VP (VBZ is) (S (VP (TO to) (VP (VB impose) (NP (NML (NN L) (HYPH -) (CD 2)) (NN penalty)) (PP (IN on) (NP (NP (DT the) (NN model) (NNS parameters)) (VP (VBG resulting) (PP (IN in) (NP (NP (NP (DT the) (NN decay)) (PP (IN of) (NP (NNS parameters)))) (, ,) (VP (VBN called) (NP (NN weight) (HYPH -) (NN decay))))))))))))) (, ,) (CC and) (S (NP (DT the) (NN decay) (NN rate)) (VP (VBZ is) (ADJP (RB generally) (JJ constant) (PP (IN to) (NP (NP (PDT all) (DT the) (NN model) (NNS parameters)) (PP (IN in) (NP (NP (DT the) (NN course)) (PP (IN of) (NP (NN optimization)))))))))) (. .))
(S (PP (IN In) (NP (NP (NN contrast)) (PP (IN to) (NP (NP (DT the) (JJ previous) (NN approach)) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (JJ constant) (NN rate)) (PP (IN of) (NP (NN weight) (HYPH -) (NN decay)))))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB consider) (NP (NP (DT the) (JJ residual)) (SBAR (WHNP (WDT that)) (S (VP (VBZ measures) (NP (NP (NN dissimilarity)) (PP (IN between) (NP (NP (DT the) (JJ current) (NN state)) (PP (IN of) (NP (NN model) (CC and) (NNS observations)))))) (PP (IN in) (NP (NP (NP (DT the) (NN determination)) (PP (IN of) (NP (NP (DT the) (NN weight) (HYPH -) (NN decay)) (PP (IN for) (NP (NP (DT each) (NN parameter)) (PP (IN in) (NP (DT an) (JJ adaptive) (NN way)))))))) (, ,) (VP (VBN called) (NP (JJ adaptive) (NN weight) (HYPH -) (NN decay))))) (PRN (-LRB- -LRB-) (NP (NNP AdaDecay)) (-RRB- -RRB-))))))))) (SBAR (WHADVP (WRB where)) (S (S (NP (DT the) (NN gradient) (NNS norms)) (VP (VBP are) (VP (VBN normalized) (PP (IN within) (NP (DT each) (NN layer)))))) (CC and) (S (NP (NP (DT the) (NN degree)) (PP (IN of) (NP (NP (NN regularization)) (PP (IN for) (NP (DT each) (NN parameter)))))) (VP (VBZ is) (VP (VBN determined) (PP (IN in) (ADJP (JJ proportional))) (PP (IN to) (NP (NP (DT the) (NN magnitude)) (PP (IN of) (NP (PRP$ its) (NN gradient))))) (S (VP (VBG using) (NP (DT the) (NN sigmoid) (NN function)))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB empirically)) (VP (VBP demonstrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NP (NNP AdaDecay)) (PP (IN in) (NP (NN comparison)))))) (PP (IN to) (NP (NP (DT the) (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NN optimization) (NNS algorithms)) (VP (VBG using) (NP (NP (JJ popular) (NN benchmark) (NNS datasets)) (: :) (NP (NNP MNIST)) (, ,) (NP (NNP Fashion) (HYPH -) (NNP MNIST)) (, ,) (CC and) (NP (NP (NN CIFAR) (HYPH -) (CD 10)) (PP (IN with) (NP (NP (JJ conventional) (JJ neural) (NN network) (NNS models)) (VP (VBG ranging) (PP (IN from) (ADJP (JJ shallow))) (PP (IN to) (ADJP (JJ deep)))))))))))) (. .))
(S (NP (NP (DT The) (JJ quantitative) (NN evaluation)) (PP (IN of) (NP (PRP$ our) (VBN proposed) (NN algorithm)))) (VP (VBZ indicates) (SBAR (IN that) (S (NP (NNP AdaDecay)) (VP (VBZ improves) (NP (NP (NN generalization)) (VP (VBG leading) (PP (IN to) (NP (NP (JJR better) (NN accuracy)) (PP (IN across) (NP (PDT all) (DT the) (NNS datasets) (CC and) (NNS models))))))))))) (. .))
