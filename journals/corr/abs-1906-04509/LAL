(S (NP (NP (PRP It))) (VP (VBZ is) (ADVP (RB well)) (VBN known) (SBAR (IN that) (S (NP (NP (NNP Convolutional) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP CNNs)) (-RRB- -RRB-))) (VP (VBP have) (NP (NP (JJ significant) (NN redundancy)) (PP (IN in) (NP (PRP$ their) (NN filter) (NNS weights)))))))) (. .))
(S (NP (NP (JJ Various) (NNS methods))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN in) (NP (DT the) (NN literature))) (S (VP (TO to) (VP (VB compress) (NP (JJ trained) (NNP CNNs)))))))) (. .))
(S (NP (DT These)) (VP (VBP include) (NP (NP (NNS techniques)) (PP (IN like) (S (VP (VP (VBG pruning) (NP (NNS weights))) (, ,) (NP (NN filter) (NN quantization)) (CC and) (VP (VBG representing) (NP (NNS filters)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (DT a) (NN basis) (NNS functions))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VP (VBZ falls) (PP (IN in) (NP (NP (DT this) (JJ latter) (NN class)) (PP (IN of) (NP (NNS strategies)))))) (, ,) (CC but) (VP (VBZ is) (ADJP (JJ distinct)) (SBAR (IN in) (SBAR (DT that) (IN that) (S (NP (PRP we)) (VP (VBP show) (SBAR (S (NP (DT both) (NP (VBN compressed) (NN learning)) (CC and) (NP (NN representation))) (VP (MD can) (VP (VB be) (VP (VBN achieved) (PP (IN without) (NP (NP (JJ significant) (NNS modifications)) (PP (IN of) (NP (JJ popular) (NNP CNN) (NNS architectures)))))))))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (NP (DT any) (NN convolution) (NN layer)) (PP (IN of) (NP (DT the) (NNP CNN)))) (VP (VBZ is) (VP (ADVP (RB easily)) (VBN replaced) (PP (IN by) (NP (NP (CD two) (JJ successive) (NN convolution) (NNS layers)) (: :) (S (NP (DT the) (JJ first)) (VP (VBZ is) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (JJ fixed) (NNS filters)) (PRN (-LRB- -LRB-) (SBAR (WHNP (WDT that)) (S (VP (VP (VBP represent) (NP (NP (DT the) (NN knowledge) (NN space)) (PP (IN of) (NP (DT the) (JJ entire) (NN layer))))) (CC and) (VP (VBP do) (RB not) (VP (VB change)))))) (-RRB- -RRB-)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN followed) (PP (IN by) (NP (NP (DT a) (NN layer)) (PP (IN of) (NP (NP (JJ one-dimensional) (NNS filters)) (PRN (-LRB- -LRB-) (SBAR (WHNP (WDT that)) (S (VP (VBP represent) (NP (DT the) (JJ learned) (NN knowledge)) (PP (IN in) (NP (DT this) (NN space)))))) (-RRB- -RRB-))))))))))))))))) (. .))
(S (PP (IN For) (NP (DT the) (JJ pre-trained) (NNS networks))) (, ,) (NP (DT the) (JJ fixed) (NN layer)) (VP (VBZ is) (ADVP (RB just)) (NP (NP (DT the) (JJ truncated) (NNS eigen-decompositions)) (PP (IN of) (NP (DT the) (JJ original) (NNS filters))))) (. .))
(S (NP (DT The) (CD 1D) (NNS filters)) (VP (VP (VBP are) (VP (VBN initialized) (PP (IN as) (NP (NP (DT the) (NNS weights)) (PP (IN of) (NP (JJ linear) (NN combination))))))) (, ,) (CC but) (VP (VBP are) (VP (JJ fine-tuned) (S (VP (TO to) (VP (VB recover) (NP (NP (DT any) (NN performance) (NN loss)) (ADJP (JJ due) (PP (TO to) (NP (DT the) (NN truncation))))))))))) (. .))
(S (PP (IN For) (S (VP (VBG training) (NP (NNS networks)) (PP (IN from) (NP (NN scratch)))))) (, ,) (NP (PRP we)) (VP (VP (VBP use) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (JJ random) (JJ orthogonal) (VBN fixed) (NNS filters)) (PRN (-LRB- -LRB-) (SBAR (WHNP (IN that)) (S (ADVP (RB never)) (VP (NN change)))) (-RRB- -RRB-)))))) (, ,) (CC and) (VP (VB learn) (NP (DT the) (CD 1D) (NN weight) (NN vector)) (ADVP (RB directly)) (PP (IN from) (NP (DT the) (VBN labeled) (NNS data))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (ADVP (RB substantially)) (VBZ reduces) (NP (NP (NN i) (-RRB- -RRB-) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ learnable) (NNS parameters))) (PP (IN during) (NP (NN training))))) (, ,) (CC and) (NP (NN ii) (-RRB- -RRB-) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NN multiplication) (NNS operations)) (CC and) (NP (NN filter) (NN storage) (NNS requirements)))) (PP (IN during) (NP (NN implementation))))))) (. .))
(S (NP (PRP It)) (VP (VP (VBZ does) (ADVP (RB so)) (PP (IN without) (S (VP (VBG requiring) (NP (NP (DT any) (JJ special) (NNS operators)) (PP (IN in) (NP (DT the) (NN convolution) (NN layer)))))))) (, ,) (CC and) (VP (VBZ extends) (PP (TO to) (NP (DT all) (VBN known) (JJ popular) (NNP CNN) (NNS architectures))))) (. .))
(S (NP (PRP We)) (VP (VBP apply) (NP (PRP$ our) (NN method)) (PP (TO to) (NP (NP (CD four) (ADJP (RB well) (VBN known)) (NN network) (NNS architectures)) (VP (VBD trained) (PP (IN with) (NP (CD three) (JJ different) (NNS data) (NNS sets))))))) (. .))
(S (NP (NNP Results)) (VP (VBP show) (NP (NP (DT a) (JJ consistent) (NN reduction)) (PP (IN in) (UCP (NP (NN i) (-RRB- -RRB-) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS operations)))) (PP (IN by) (NP (NP (QP (IN up) (TO to)) (NP (DT a) (NN factor))) (PP (IN of) (NP (CD 5)))))) (, ,) (CC and) (NP (LST (NN ii) (-RRB- -RRB-)) (NP (NN number))) (PP (IN of) (NP (JJ learnable) (NNS parameters))) (PP (IN by) (PP (IN up) (PP (TO to) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (CD 18)))))))))) (, ,) (PP (IN with) (NP (NP (ADJP (QP (JJR less) (IN than) (CD 3)) (NN %)) (NN drop)) (PP (IN in) (NP (NN performance))) (PP (IN on) (NP (DT the) (NNP CIFAR100) (NN dataset)))))) (. .))
