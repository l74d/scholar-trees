(S (NP (NP (JJ Convolutional) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-)) (VP (VBP have) (VP (VBN achieved) (NP (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN performance)) (PP (IN in) (NP (JJ many) (NML (NN computer) (NN vision)) (NNS tasks)))) (PP (IN over) (NP (DT the) (NNS years))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT this)) (VP (VBZ comes) (PP (IN at) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (JJ heavy) (NML (NN computation) (CC and) (NN memory)) (JJ intensive) (NN network) (NNS designs))))) (, ,) (S (VP (VBG suggesting) (NP (JJ potential) (NNS improvements)) (PP (IN in) (NP (NN efficiency)))))) (. .))
(S (NP (NP (JJ Convolutional) (NNS layers)) (PP (IN of) (NP (NNS CNNs)))) (ADVP (RB partly)) (VP (VBP account) (PP (IN for) (NP (PDT such) (DT an) (NN inefficiency))) (, ,) (SBAR (IN as) (S (NP (PRP they)) (VP (VBP are) (VP (VBN known) (S (VP (TO to) (VP (VB learn) (NP (JJ redundant) (NNS features)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VP (VBP exploit) (NP (DT this) (NN redundancy)) (, ,) (S (VP (VBG observing) (NP (PRP it)) (PP (IN as) (NP (NP (DT the) (NN correlation)) (PP (IN between) (NP (NP (JJ convolutional) (NNS filters)) (PP (IN of) (NP (DT a) (NN layer)))))))))) (, ,) (CC and) (VP (VB propose) (NP (DT an) (JJ alternative) (NN approach)) (PP (IN to) (S (VP (VB reproduce) (NP (PRP it)) (ADVP (RB efficiently))))))) (. .))
(S (NP (DT The) (VBN proposed) (NML (`` ') (NNP LinearConv) ('' ')) (NN layer)) (VP (VBZ learns) (NP (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ orthogonal) (NNS filters)))) (, ,) (CC and) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NNS coefficients)) (SBAR (WHNP (WDT that)) (S (ADVP (RB linearly)) (VP (VBZ combines) (S (NP (PRP them)) (VP (TO to) (VP (VB introduce) (NP (DT a) (VBN controlled) (NN redundancy))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (ADJP (NP (DT a) (NN correlation)) (HYPH -) (VBN based)) (NN regularization) (NN loss)) (S (VP (TO to) (VP (VP (VB achieve) (NP (JJ such) (NN flexibility)) (PP (IN over) (NP (NN redundancy)))) (, ,) (CC and) (VP (VB control) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS parameters)) (PP (IN in) (NP (NN turn))))))))))) (. .))
(S (S (NP (DT This)) (VP (VBZ is) (VP (VBN designed) (PP (IN as) (NP (NP (DT a) (NN plug) (HYPH -)) (CC and)))))) (HYPH -) (S (VP (VB play) (NP (NN layer)) (PP (IN to) (ADVP (RB conveniently)) (VP (VB replace) (NP (DT a) (JJ conventional) (JJ convolutional) (NN layer)) (, ,) (PP (IN without) (NP (NP (DT any) (JJ additional) (NNS changes)) (VP (VBN required) (PP (IN in) (NP (DT the) (NN network))))))))) (NP (NP (NN architecture)) (CC or) (NP (DT the) (NN hyperparameter) (NNS settings)))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP verify) (SBAR (IN that) (S (NP (NNP LinearConv) (NNS models)) (VP (VBP achieve) (NP (NP (DT a) (NN performance)) (PP (IN on) (HYPH -) (NP (NN par)))) (PP (IN with) (NP (PRP$ their) (NNS counterparts))) (, ,) (PP (IN with) (NP (NP (NP (RB almost) (DT a) (NML (CD 50) (NN %)) (NN reduction)) (PP (IN in) (NP (NP (NNS parameters)) (PP (IN on) (NP (JJ average)))))) (, ,) (CC and) (NP (NP (DT the) (JJ same) (JJ computational) (NN requirement) (CC and) (NN speed)) (PP (IN at) (NP (NN inference)))))))))) (. .))
