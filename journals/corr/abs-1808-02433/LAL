(S (ADVP (RB Arguably)) (NP (NP (DT the) (JJS biggest) (NN challenge)) (PP (IN in) (S (VP (VBG applying) (NP (JJ neural) (NNS networks)))))) (VP (VBZ is) (S (VP (VBG tuning) (NP (NP (DT the) (NNS hyperparameters)) (, ,) (PP (IN in) (ADJP (JJ particular))) (NP (DT the) (NN learning) (NN rate)))))) (. .))
(S (NP (NP (DT The) (NN sensitivity)) (PP (TO to) (NP (DT the) (NN learning) (NN rate)))) (VP (VBZ is) (ADJP (JJ due) (PP (TO to) (NP (NP (DT the) (NN reliance)) (PP (IN on) (NP (NN backpropagation))) (SBAR (S (VP (TO to) (VP (VB train) (NP (DT the) (NN network)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBD present) (NP (NP (DT the) (JJ first) (NN application)) (PP (IN of) (NP (NP (NP (NNP Implicit) (NNP Stochastic) (NNP Gradient) (NNP Descent)) (PRN (-LRB- -LRB-) (NP (NNP ISGD)) (-RRB- -RRB-))) (SBAR (S (VP (TO to) (VP (VB train) (NP (JJ neural) (NNS networks)))))) (, ,) (NP (NP (DT a) (NN method)) (VP (VBN known) (PP (IN in) (NP (NN convex) (NN optimization))) (S (VP (TO to) (VP (VB be) (ADJP (ADJP (RB unconditionally) (JJ stable)) (CC and) (ADJP (JJ robust) (PP (TO to) (NP (DT the) (NN learning) (NN rate)))))))))))))) (. .))
(S (NP (PRP$ Our) (JJ key) (NN contribution)) (VP (VBZ is) (NP (NP (DT a) (JJ novel) (JJ layer-wise) (NN approximation)) (PP (IN of) (NP (NNP ISGD))) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (NP (PRP$ its) (NNS updates)) (ADJP (JJ tractable) (PP (IN for) (NP (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (VP (VBZ is) (ADJP (RBR more) (JJ robust) (PP (TO to) (NP (JJ high) (NN learning) (NNS rates))))) (CC and) (VP (ADVP (RB generally)) (VBZ outperforms) (NP (JJ standard) (NN backpropagation)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS tasks)))))))))) (. .))
