(S (NP (NP (DT The) (JJ general) (NN trend)) (PP (IN in) (NP (NN NLP)))) (VP (VBZ is) (PP (IN towards) (S (VP (VBG increasing) (NP (NP (NN model) (NN capacity) (CC and) (NN performance)) (PP (IN via) (NP (JJR deeper) (JJ neural) (NNS networks)))))))) (. .))
(FRAG (ADVP (RB However)) (, ,) (ADVP (RB simply)) (S (VP (VBG stacking) (NP (NP (JJR more) (NNS layers)) (PP (IN of) (NP (NP (DT the) (JJ popular) (NN Transformer) (NN architecture)) (PP (IN for) (NP (NML (NN machine) (NN translation)) (NNS results)))))) (PP (IN in) (NP (NP (JJ poor) (NN convergence)) (CC and) (NP (JJ high) (JJ computational) (NN overhead)))))) (. .))
(S (NP (PRP$ Our) (JJ empirical) (NN analysis)) (VP (VBZ suggests) (SBAR (IN that) (S (NP (NN convergence)) (VP (VBZ is) (ADJP (JJ poor) (PP (IN due) (PP (IN to) (NP (NP (NN gradient) (VBG vanishing)) (VP (VBN caused) (PP (IN by) (NP (NP (DT the) (NN interaction)) (PP (IN between) (NP (NP (JJ residual) (NNS connections)) (CC and) (NP (NN layer) (NN normalization))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (ADJP (NN depth) (HYPH -) (VBN scaled)) (NN initialization) (PRN (-LRB- -LRB-) (NP (NNP DS) (HYPH -) (NNP Init)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ decreases) (NP (NN parameter) (NN variance)) (PP (IN at) (NP (DT the) (NN initialization) (NN stage)))) (, ,) (CC and) (VP (VBZ reduces) (NP (NP (NN output) (NN variance)) (PP (IN of) (NP (JJ residual) (NNS connections))))))))) (SBAR (IN so) (IN as) (S (VP (TO to) (VP (VB ease) (NP (NN gradient) (NML (RB back) (HYPH -) (NN propagation))) (PP (IN through) (NP (NN normalization) (NNS layers)))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (JJ computational) (NN cost))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (DT a) (JJ merged) (NN attention) (NN sublayer)) (-LRB- -LRB-) (NP (NNP MAtt)) (-RRB- -RRB-)) (SBAR (WHNP (WDT which)) (S (VP (VBZ combines) (NP (NP (DT a) (VBN simplified) (ADJP (JJ averagebased) (NP (NN self) (HYPH -) (NN attention))) (NN sublayer)) (CC and) (NP (NP (DT the) (NN encoderdecoder) (NN attention) (NN sublayer)) (PP (IN on) (NP (DT the) (NN decoder) (NN side)))))))))) (. .))
(S (NP (NP (NNS Results)) (PP (IN on) (NP (NML (NN WMT) (CC and) (NN IWSLT)) (NN translation) (NNS tasks))) (PP (IN with) (NP (NML (CD five) (NN translation)) (NNS directions)))) (VP (VBP show) (SBAR (IN that) (S (NP (JJ deep) (NML (NML (NML (NNPS Transformers)) (PP (IN with) (NP (NNP DS) (HYPH -) (NNP Init)))) (CC and) (NML (NNP MAtt)))) (VP (MD can) (ADVP (RB substantially)) (VP (VB outperform) (NP (PRP$ their) (NN base) (NN counterpart)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NN BLEU) (PRN (-LRB- -LRB-) (NP (NP (CD +1.1) (NN BLEU)) (PP (IN on) (NP (NP (JJ average)) (PP (IN for) (NP (NML (CD 12) (HYPH -) (NN layer)) (NNS models)))))) (-RRB- -RRB-)))))) (, ,) (PP (IN while) (S (VP (VBG matching) (NP (NP (DT the) (NN decoding) (NN speed)) (PP (IN of) (NP (DT the) (NN baseline) (NN model)))) (PP (NP (NNS thanks)) (IN to) (NP (NP (DT the) (NN efficiency) (NNS improvements)) (PP (IN of) (NP (NNP MAtt))))))))))))) (. .))
