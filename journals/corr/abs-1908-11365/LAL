(S (NP (NP (DT The) (JJ general) (NN trend)) (PP (IN in) (NP (NNP NLP)))) (VP (VBZ is) (PP (NNS towards) (S (VP (VBG increasing) (NP (NP (NX (NN model) (NN capacity)) (CC and) (NX (NN performance))) (PP (IN via) (NP (JJR deeper) (JJ neural) (NNS networks)))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (ADVP (RB simply)) (VP (VBG stacking) (NP (NP (JJR more) (NNS layers)) (PP (IN of) (NP (DT the) (JJ popular) (NNP Transformer) (NN architecture)))) (PP (IN for) (NP (NN machine) (NN translation))))) (VP (NNS results) (PP (IN in) (NP (NP (JJ poor) (NN convergence)) (CC and) (NP (JJ high) (JJ computational) (NN overhead))))) (. .))
(S (NP (PRP$ Our) (JJ empirical) (NN analysis)) (VP (VBZ suggests) (SBAR (IN that) (S (NP (NN convergence)) (VP (VBZ is) (ADJP (JJ poor)) (PP (JJ due) (PP (TO to) (NP (NP (VB gradient) (VBG vanishing)) (VP (VBN caused) (PP (IN by) (NP (NP (DT the) (NN interaction)) (PP (IN between) (NP (NP (JJ residual) (NNS connections)) (CC and) (NP (JJ layer) (NN normalization)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (JJ depth-scaled) (NN initialization)) (PRN (-LRB- -LRB-) (NP (NNP DS-Init)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ decreases) (NP (NN parameter) (NN variance)) (PP (IN at) (NP (DT the) (NN initialization) (NN stage)))) (, ,) (CC and) (VP (NNS reduces) (NP (NP (NN output) (NN variance)) (PP (IN of) (NP (JJ residual) (NNS connections)))) (SBAR (RB so) (IN as) (S (VP (TO to) (VP (VB ease) (NP (NP (JJ gradient) (NN back-propagation)) (PP (IN through) (NP (NN normalization) (NNS layers)))))))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (JJ computational) (NN cost))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ merged) (NN attention) (NN sublayer)) (PRN (-LRB- -LRB-) (NP (NNP MAtt)) (-RRB- -RRB-)) (SBAR (WHNP (WDT which)) (S (VP (VBZ combines) (NP (NP (NP (DT a) (JJ simplified) (JJ averagebased) (NN self-attention) (NN sublayer)) (CC and) (NP (DT the) (NN encoderdecoder) (NN attention) (NN sublayer))) (PP (IN on) (NP (DT the) (NN decoder) (NN side))))))))) (. .))
(S (NP (NP (NNS Results)) (PP (IN on) (NP (NP (NNP WMT) (CC and) (NNP IWSLT) (NN translation) (NNS tasks)) (PP (IN with) (NP (CD five) (NN translation) (NNS directions)))))) (VP (VBP show) (SBAR (IN that) (S (NP (NP (JJ deep) (NNS Transformers)) (PP (IN with) (NP (NNP DS-Init) (CC and) (NNP MAtt)))) (VP (MD can) (VP (ADVP (RB substantially)) (VB outperform) (NP (PRP$ their) (NN base) (NN counterpart)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (NNP BLEU)) (PRN (-LRB- -LRB-) (NP (NP (NNP +1.1) (NNP BLEU)) (PP (IN on) (NP (NN average))) (PP (IN for) (NP (JJ 12-layer) (NNS models)))) (-RRB- -RRB-)))))) (, ,) (SBAR (IN while) (S (VP (VBG matching) (NP (NP (DT the) (VBG decoding) (NN speed)) (PP (IN of) (NP (DT the) (NN baseline) (NN model)))) (NP (NP (NNS thanks)) (PP (TO to) (NP (NP (DT the) (NN efficiency) (NNS improvements)) (PP (IN of) (NP (NNP MAtt)))))))))))))) (. .))
