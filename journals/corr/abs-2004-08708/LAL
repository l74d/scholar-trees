(S (NP (NP (JJ Recent) (NNS developments)) (PP (IN in) (NP (NNP Transformers))) (PP (IN for) (NP (NN language) (NN modeling)))) (VP (VBP have) (VP (VBN opened) (NP (NP (JJ new) (NNS areas)) (PP (IN of) (NP (NN research))) (PP (IN in) (NP (NN computer) (NN vision)))))) (. .))
(S (NP (NP (NNS Results)) (PP (IN from) (NP (JJ late) (CD 2019)))) (VP (VBD showed) (NP (NP (JJ vast) (NN performance) (NNS increases)) (PP (IN in) (NP (DT both) (NP (JJ object) (NN detection)) (CC and) (NP (NN recognition)))) (SBAR (WHADVP (WRB when)) (S (NP (NNS convolutions)) (VP (VBP are) (VP (VBN replaced) (PP (IN by) (NP (JJ local) (NN self-attention) (NNS kernels))))))))) (. .))
(S (NP (NP (NNS Models)) (VP (VBG using) (NP (JJ local) (NN self-attention) (NNS kernels)))) (VP (VBD were) (ADVP (RB also)) (VP (VBN shown) (S (VP (TO to) (VP (VB have) (NP (JJR less) (NNS parameters) (CC and) (NNP FLOPS)) (PP (VBN compared) (PP (TO to) (NP (NP (VB equivalent) (NNS architectures)) (SBAR (WHNP (IN that)) (S (ADVP (RB only)) (VP (JJ use) (NP (NNS convolutions))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN method)) (PP (IN for) (S (VP (VBG learning) (NP (DT the) (JJ local) (NN self-attention) (NN kernel) (NN size))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VB compare) (NP (PRP$ its) (NN performance)) (PP (TO to) (NP (VB fixed-size) (JJ local) (NN attention) (CC and) (NN convolution) (NNS kernels)))) (. .))
(S (NP (NP (DT The) (NN code)) (PP (IN for) (NP (DT all) (PRP$ our) (NNS experiments) (CC and) (NNS models)))) (VP (VBZ is) (ADJP (JJ available)) (PP (IN at) (NP (DT this) (NN https) (NNP URL)))))
