(S (NP (PRP We)) (VP (VBP propose) (NP (NNP Matrix) (NNP ALPS)) (PP (IN for) (S (VP (VBG recovering) (NP (NP (DT a) (JJ sparse) (CC plus) (JJ low-rank) (NN decomposition)) (PP (IN of) (NP (DT a) (NN matrix)))) (PP (VBN given) (NP (PRP$ its) (ADJP (JJ corrupted) (CC and) (JJ incomplete)) (JJ linear) (NNS measurements))))))) (. .))
(S (S (NP (PRP$ Our) (NN approach)) (VP (VBZ is) (NP (NP (DT a) (JJ first-order) (JJ projected) (NN gradient) (NN method)) (PP (IN over) (NP (JJ non-convex) (NNS sets)))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBZ exploits) (NP (DT a) (JJ well-known) (JJ memory-based) (NN acceleration) (NN technique)))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB theoretically)) (VBP characterize) (NP (NP (DT the) (NN convergence) (NNS properties)) (PP (IN of) (NP (NNP Matrix) (NNP ALPS)))) (S (VP (VBG using) (NP (NP (DT the) (JJ stable) (VBG embedding) (NNS properties)) (PP (IN of) (NP (DT the) (JJ linear) (NN measurement) (NN operator))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (ADVP (RB numerically)) (VBP illustrate) (SBAR (IN that) (S (NP (PRP$ our) (NN algorithm)) (VP (VBZ outperforms) (NP (DT the) (VBG existing) (UCP (NN convex) (CONJP (RB as) (RB well) (IN as)) (JJ non-convex)) (JJ state-of-the-art) (NN algorithms)) (PP (IN in) (NP (JJ computational) (NN efficiency))) (PP (IN without) (S (VP (VBG sacrificing) (NP (NN stability))))))))) (. .))
