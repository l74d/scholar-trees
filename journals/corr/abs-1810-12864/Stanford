(S (PP (IN In) (NP (DT the) (JJ past) (NN decade))) (, ,) (NP (ADJP (NN sparsity) (HYPH -) (VBN driven)) (NN regularization)) (VP (VBZ has) (VP (VBN led) (PP (IN to) (NP (NP (JJ significant) (NNS improvements)) (PP (IN in) (NP (NN image) (NN reconstruction))))))) (. .))
(S (NP (NP (JJ Traditional) (NNS regularizers)) (, ,) (PP (JJ such) (IN as) (NP (JJ total) (NN variation) (PRN (-LRB- -LRB-) (NP (NN TV)) (-RRB- -RRB-)))) (, ,)) (VP (VBP rely) (PP (IN on) (NP (NP (JJ analytical) (NNS models)) (PP (IN of) (NP (NN sparsity)))))) (. .))
(S (ADVP (RB However)) (, ,) (ADVP (RB increasingly)) (NP (DT the) (NN field)) (VP (VBZ is) (VP (VBG moving) (PP (IN towards) (NP (NP (ADJP (JJ trainable)) (NNS models)) (, ,) (VP (VBN inspired) (PP (IN from) (NP (JJ deep) (NN learning)))))))) (. .))
(S (NP (NP (JJ Deep) (NN image) (JJ prior)) (-LRB- -LRB-) (NP (NN DIP)) (-RRB- -RRB-)) (VP (VBZ is) (NP (NP (DT a) (JJ recent) (NN regularization) (NN framework)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (DT a) (JJ convolutional) (NML (NML (JJ neural) (NN network)) (-LRB- -LRB-) (NML (NP (NNP CNN))) (-RRB- -RRB-)) (NN architecture)) (PP (IN without) (NP (ADJP (NN data) (HYPH -) (VBN driven)) (NN training)))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ extends) (NP (DT the) (NN DIP) (NN framework)) (PP (IN by) (S (VP (VBG combining) (NP (PRP it)) (PP (IN with) (NP (DT the) (JJ traditional) (NN TV) (NN regularization))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN inclusion)) (PP (IN of) (NP (NN TV)))) (VP (VBZ leads) (PP (IN to) (NP (JJ considerable) (NN performance) (NNS gains))) (SBAR (WHADVP (WRB when)) (S (VP (VBN tested) (PP (IN on) (NP (NP (JJ several) (JJ traditional) (NN restoration) (NNS tasks)) (PP (JJ such) (IN as) (NP (NN image) (NN denoising) (CC and) (NN deblurring)))))))))))) (. .))
