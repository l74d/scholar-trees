(S (NP (DT The) (NML (S (VP (VB skip) (HYPH -) (NP (NNS connections)) (S (VP (VBN used) (PP (IN in) (NP (JJ residual) (NNS networks))))))))) (VP (VBP have) (VP (VBN become) (NP (DT a) (JJ standard) (NN architecture) (NN choice)) (PP (IN in) (NP (JJ deep) (NN learning))) (PP (IN due) (IN to) (NP (NP (DT the) (VBN increased) (NN training) (NN stability)) (CC and) (NP (NP (NN generalization) (NN performance)) (PP (IN with) (NP (DT this) (NN architecture)))))) (, ,) (SBAR (IN although) (S (NP (EX there)) (VP (VBZ has) (VP (VBN been) (VP (VBN limited) (NP (JJ theoretical) (NN understanding)) (PP (IN for) (NP (DT this) (NN improvement)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VP (VBP analyze) (VP (VBN overparameterized) (NP (NP (JJ deep) (JJ residual) (NNS networks)) (VP (VBN trained) (PP (IN by) (NP (NP (NN gradient) (NN descent)) (PP (VBG following) (NP (JJ random) (NN initialization))))))))) (, ,) (CC and) (VP (VBP demonstrate) (SBAR (IN that) (S (S (LST (-LRB- -LRB-) (LS i) (-RRB- -RRB-)) (NP (NP (DT the) (NN class)) (PP (IN of) (NP (NP (NNS networks)) (VP (VBN learned) (PP (IN by) (NP (NN gradient) (NN descent))))))) (VP (VBZ constitutes) (NP (NP (DT a) (JJ small) (NN subset)) (PP (IN of) (NP (DT the) (JJ entire) (NML (JJ neural) (NN network)) (NN function) (NN class)))))) (, ,) (CC and) (S (LST (-LRB- -LRB-) (LS ii) (-RRB- -RRB-)) (NP (NP (DT this) (NN subclass)) (PP (IN of) (NP (NNS networks)))) (VP (VBZ is) (ADJP (RB sufficiently) (JJ large)) (S (VP (TO to) (VP (VB guarantee) (NP (JJ small) (NN training) (NN error))))))))))) (. .))
(S (PP (IN By) (S (VP (VBG showing) (S (UCP (SBAR (LST (-LRB- -LRB-) (LS i) (-RRB- -RRB-)) (S (NP (PRP we)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB demonstrate) (SBAR (IN that) (S (NP (NP (JJ deep) (JJ residual) (NNS networks)) (VP (VBN trained) (PP (IN with) (NP (NN gradient) (NN descent))))) (VP (VBP have) (NP (NP (DT a) (JJ small) (NN generalization) (NN gap)) (PP (IN between) (NP (NML (NN training) (CC and) (NN test)) (NN error)))))))))))))) (, ,) (CC and) (PP (ADVP (RB together)) (IN with) (PRN (-LRB- -LRB-) (NP (CD ii)) (-RRB- -RRB-)))))))) (NP (DT this)) (VP (VBZ guarantees) (SBAR (IN that) (S (NP (DT the) (NN test) (NN error)) (VP (MD will) (VP (VB be) (ADJP (JJ small))))))) (. .))
(S (NP (PRP$ Our) (NML (NN optimization) (CC and) (NN generalization)) (NNS guarantees)) (VP (VBP require) (NP (NP (NN overparameterization)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (NP (NP (RB only) (JJ logarithmic)) (PP (IN in) (NP (NP (DT the) (NN depth)) (PP (IN of) (NP (DT the) (NN network)))))) (, ,) (SBAR (IN while) (S (NP (NP (DT all) (VBN known) (NN generalization) (NNS bounds)) (PP (IN for) (NP (JJ deep) (JJ non-residual) (NNS networks)))) (VP (VBP have) (NP (NP (NN overparameterization) (NNS requirements)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (ADVP (IN at) (RBS least)) (JJ polynomial) (PP (IN in) (NP (DT the) (NN depth)))))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ provides) (NP (NP (DT an) (NN explanation)) (PP (IN for) (SBAR (WHADVP (WRB why)) (S (NP (JJ residual) (NNS networks)) (VP (VBP are) (ADJP (JJ preferable) (PP (IN to) (NP (JJ non-residual) (NNS ones)))))))))) (. .))
