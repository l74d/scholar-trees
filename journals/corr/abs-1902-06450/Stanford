(S (NP (NP (NN Self) (HYPH -) (NN attention) (NN network)) (, ,) (NP (DT an) (ADJP (NN attention) (HYPH -) (VBN based)) (JJ feedforward) (JJ neural) (NN network)) (, ,)) (VP (VBZ has) (ADVP (RB recently)) (VP (VBN shown) (NP (DT the) (NN potential)) (S (VP (TO to) (VP (VB replace) (NP (NP (ADJP (JJ recurrent)) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (PP (IN in) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NN NLP) (NNS tasks)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP it)) (VP (VBZ is) (RB not) (ADJP (JJ clear)) (SBAR (IN if) (S (NP (DT the) (ADJP (NN self) (HYPH -) (NN attention)) (NN network)) (VP (MD could) (VP (VB be) (NP (NP (DT a) (JJ good) (NN alternative)) (PP (IN of) (NP (NP (NP (NNS RNNs)) (PP (IN in) (NP (JJ automatic) (NN speech) (NN recognition) (PRN (-LRB- -LRB-) (NP (NN ASR)) (-RRB- -RRB-))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ processes) (ADVP (DT the) (RBR longer)) (NP (NN speech) (NNS sequences))) (CC and) (VP (MD may) (VP (VB have) (NP (JJ online) (NN recognition) (NNS requirements))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NP (DT a) (NML (NN RNN) (HYPH -) (NML (JJ free) (NN end)) (HYPH -) (IN to) (HYPH -) (NN end)) (NN model)) (: :) (NP (NN self) (HYPH -) (NN attention) (NN aligner) (PRN (-LRB- -LRB-) (NP (NNP SAA)) (-RRB- -RRB-)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ applies) (NP (DT the) (ADJP (NN self) (HYPH -) (NN attention)) (NNS networks)) (PP (IN to) (NP (DT a) (VBN simplified) (NML (NML (ADJP (JJ recurrent) (JJ neural)) (NN aligner)) (-LRB- -LRB-) (NML (NN RNA)) (-RRB- -RRB-)) (NN framework)))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP propose) (NP (DT a) (NN chunk) (HYPH -)) (S (VP (VBG hopping) (NP (NP (NN mechanism)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ enables) (NP (DT the) (NNP SAA) (NN model)) (S (VP (TO to) (VP (VB encode) (PP (IN on) (NP (NP (JJ segmented) (NN frame) (NNS chunks)) (NP-TMP (CD one)))) (SBAR (IN after) (S (NP (DT another)) (VP (TO to) (VP (VB support) (NP (JJ online) (NN recognition)))))))))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (CD two) (NNP Mandarin) (NNP ASR) (NNS datasets)))) (VP (VBP show) (SBAR (S (NP (NP (DT the) (NN replacement)) (PP (IN of) (NP (NP (NNS RNNs)) (PP (IN by) (NP (DT the) (ADJP (NN self) (HYPH -) (NN attention)) (NNS networks)))))) (VP (VBZ yields) (NP (DT a) (NML (CD 8.4) (NN %)) (HYPH -) (ADJP (NP (CD 10.2) (NN %)) (JJ relative)) (NML (NN character) (NN error)) (NN rate) (-LRB- -LRB-) (NN CER) (-RRB- -RRB-) (NN reduction)))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (NP (DT the) (NN chunk) (HYPH -)) (VP (VBG hopping) (NP (NN mechanism)))) (VP (VBZ allows) (NP (DT the) (NNP SAA)) (S (VP (TO to) (VP (VB have) (NP (NP (RB only) (DT a) (ADJP (NP (CD 2.5) (NN %)) (JJ relative)) (NN CER) (NN degradation)) (PP (IN with) (NP (DT a) (NNS 320ms) (NN latency)))))))) (. .))
(S (PP (IN After) (S (ADVP (RB jointly)) (VP (VBG training) (PP (IN with) (NP (DT a) (ADJP (NN self) (HYPH -) (NN attention)) (NML (NN network) (NN language)) (NN model)))))) (, ,) (NP (PRP$ our) (NNP SAA) (NN model)) (VP (VBZ obtains) (NP (NP (JJ further) (NN error) (NN rate) (NN reduction)) (PP (IN on) (NP (JJ multiple) (NNS datasets))))) (. .))
(S (ADVP (RB Especially)) (, ,) (NP (PRP it)) (VP (VBZ achieves) (NP (NML (CD 24.12) (NN %)) (NN CER)) (PP (IN on) (NP (DT the) (NNP Mandarin) (NNP ASR) (NN benchmark) (-LRB- -LRB-) (NN HKUST) (-RRB- -RRB-))) (, ,) (S (VP (VBG exceeding) (NP (DT the) (JJS best) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NN model)) (PP (IN by) (PP (IN over) (NP (NML (CD 2) (NN %)) (JJ absolute) (NN CER))))))) (. .))
