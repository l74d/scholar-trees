(S (NP (JJ Bayesian) (NN optimization)) (VP (VBZ is) (ADJP (JJ popular) (PP (IN for) (S (VP (VBG optimizing) (NP (ADJP (NN time) (HYPH -) (VBG consuming)) (NML (JJ black) (HYPH -) (NN box)) (NNS objectives))))))) (. .))
(S (ADVP (RB Nonetheless)) (, ,) (PP (IN for) (NP (NP (NN hyperparameter) (NN tuning)) (PP (IN in) (NP (JJ deep) (JJ neural) (NNS networks))))) (, ,) (NP (NP (DT the) (NN time)) (VP (VBN required) (S (VP (TO to) (VP (VB evaluate) (NP (DT the) (NN validation) (NN error)) (PP (IN for) (NP (RB even) (DT a) (JJ few) (NN hyperparameter) (NNS settings)))))))) (VP (VBZ remains) (NP (DT a) (NN bottleneck))) (. .))
(S (NP (NN Multi-fidelity) (NN optimization)) (VP (VBZ promises) (NP (NP (NP (NN relief)) (VP (VBG using) (NP (JJR cheaper) (NNS proxies)) (PP (IN to) (NP (JJ such) (NNS objectives))))) (, ---) (PP (IN for) (NP (NN example))) (, ,) (NP (NP (NN validation) (NN error)) (PP (IN for) (NP (NP (DT a) (NN network)) (VP (VBN trained) (S (VP (VBG using) (NP (NP (DT a) (NN subset)) (PP (IN of) (NP (DT the) (NN training) (NNS points)))))))))) (CC or) (NP (NP (JJR fewer) (NNS iterations)) (VP (ADVP (IN than)) (VBN required) (PP (IN for) (NP (NN convergence))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (SBAR (S (NP (NP (DT a) (ADJP (RB highly) (JJ flexible) (CC and) (JJ practical)) (NN approach)) (PP (IN to) (NP (NN multi-fidelity) (NML (JJ Bayesian) (NN optimization))))) (, ,) (VP (VBD focused) (PP (IN on) (S (ADVP (RB efficiently)) (VP (VBG optimizing) (NP (NP (NNS hyperparameters)) (PP (IN for) (NP (ADJP (RB iteratively) (VBN trained)) (JJ supervised) (NN learning) (NNS models))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (ADJP (NP (NP (JJ new) (NN acquisition) (NN function)) (, ,) (NP (DT the) (NN trace))) (HYPH -) (JJ aware)) (NN knowledge) (HYPH -) (NN gradient)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB efficiently)) (VP (VBZ leverages) (S (NP (NP (DT both) (JJ multiple) (NML (JJ continuous) (NN fidelity)) (NNS controls)) (CC and) (NP (NP (NN trace) (NNS observations)) (, ---) (NP (NP (NNS values)) (PP (IN of) (NP (NP (DT the) (NN objective)) (PP (IN at) (NP (NP (DT a) (NN sequence)) (PP (IN of) (NP (NNS fidelities)))))))) (, ,))) (ADJP (JJ available))) (SBAR (WHADVP (WRB when)) (S (NP (VBG varying) (NN fidelity)) (VP (VBG using) (NP (NN training) (NNS iterations)))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP provide) (NP (DT a) (ADJP (RB provably) (JJ convergent)) (NN method)) (PP (IN for) (S (VP (VBG optimizing) (NP (PRP$ our) (NN acquisition) (NN function)))))) (CC and) (VP (VB show) (SBAR (S (NP (PRP it)) (VP (VBZ outperforms) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NNS alternatives)) (PP (IN for) (NP (NP (NN hyperparameter) (NN tuning)) (PP (IN of) (NP (NML (NML (JJ deep) (JJ neural) (NNS networks)) (CC and) (NML (JJ large) (HYPH -) (NN scale))) (NN kernel) (NN learning)))))))))) (. .))
