(S (NP (NNP Off-policy) (JJ stochastic) (JJ actor-critic) (NNS methods)) (VP (RB rely) (PP (IN on) (S (VP (VBG approximating) (NP (DT the) (JJ stochastic) (NN policy) (NN gradient))))) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB derive) (NP (DT an) (JJ optimal) (NN policy))))))) (. .))
(S (NP (CD One)) (VP (MD may) (ADVP (RB also)) (VP (VB derive) (NP (DT the) (JJ optimal) (NN policy)) (PP (IN by) (S (VP (VBG approximating) (NP (DT the) (JJ action-value) (NN gradient))))))) (. .))
(S (NP (NP (DT The) (NN use)) (PP (IN of) (NP (JJ action-value) (NNS gradients)))) (VP (VBZ is) (ADJP (JJ desirable)) (SBAR (IN as) (S (NP (NN policy) (NN improvement)) (VP (VBZ occurs) (PP (IN along) (NP (NP (DT the) (NN direction)) (PP (IN of) (NP (JJ steepest) (NN ascent))))))))) (. .))
(S (NP (DT This)) (VP (VBZ has) (VP (VBN been) (VP (VBN studied) (ADVP (RB extensively)) (PP (PP (IN within) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (JJ natural) (JJ gradient) (JJ actor-critic) (NN algorithms))))) (CC and) (ADVP (RBR more) (RB recently)) (PP (IN within) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (JJ deterministic) (NN policy) (NNS gradients))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (ADVP (VBP briefly)) (VB discuss) (NP (NP (NP (DT the) (JJ off-policy) (JJ stochastic) (NN counterpart)) (PP (TO to) (NP (JJ deterministic) (JJ action-value) (NNS gradients)))) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NP (DT an) (JJ incremental) (NN approach)) (PP (IN for) (S (VP (VBG following) (NP (DT the) (NN policy) (NN gradient)) (PP (IN in) (NP (NP (NN lieu)) (PP (IN of) (NP (DT the) (JJ natural) (NN gradient))))))))))) (. .))
