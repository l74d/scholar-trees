(S (PP (IN By) (S (VP (VBG lifting) (NP (DT the) (NN ReLU) (NN function)) (PP (IN into) (NP (DT a) (ADJP (JJR higher) (JJ dimensional)) (NN space)))))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (DT a) (JJ smooth) (NN multi-convex) (NN formulation)) (PP (IN for) (NP (NP (ADJP (NP (NN training) (NN feed)) (HYPH -) (JJ forward)) (JJ deep) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-))))) (. .))
(S (NP (DT This)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB develop) (NP (DT a) (NN block) (NN coordinate) (NN descent) (-LRB- -LRB-) (NN BCD) (-RRB- -RRB-) (NN training) (NN algorithm)) (S (VP (VBG consisting) (PP (IN of) (NP (NP (DT a) (NN sequence)) (PP (IN of) (NP (ADJP (RB numerically) (RB well) (HYPH -) (VBN behaved)) (NN convex) (NNS optimizations))))))))))) (. .))
(S (S (VP (VBG Using) (NP (NNS ideas)) (PP (IN from) (NP (NP (JJ proximal) (NN point) (NNS methods)) (PP (IN in) (NP (NN convex) (NN analysis))))))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (DT this) (NN BCD) (NN algorithm)) (VP (MD will) (VP (VB converge) (ADVP (RB globally)) (PP (IN to) (NP (NP (DT a) (JJ stationary) (NN point)) (PP (IN with) (NP (NP (NML (NN R) (HYPH -) (JJ linear)) (NN convergence) (NN rate)) (PP (IN of) (NP (NN order) (CD one)))))))))))) (. .))
(S (PP (IN In) (NP (NP (NNS experiments)) (PP (IN with) (NP (DT the) (NNP MNIST) (NN database))))) (, ,) (NP (NP (NNS DNNs)) (VP (VBN trained) (PP (IN with) (NP (DT this) (NN BCD) (NN algorithm))))) (ADVP (RB consistently)) (VP (VBD yielded) (NP (NP (JJR better)) (VP (NN test) (HYPH -) (VBN set))) (FRAG (NP (NN error) (NNS rates)) (PP (IN than) (NP (NP (JJ identical) (NN DNN) (NNS architectures)) (VP (VBN trained) (PP (IN via) (NP (PDT all) (DT the) (JJ stochastic) (NN gradient) (NN descent))) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)))))) (S (NP (NP (NNS variants)) (PP (IN in) (NP (DT the) (NNP Caffe) (NN toolbox)))))) (. .))
