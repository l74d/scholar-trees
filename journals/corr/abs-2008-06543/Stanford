(S (NP (NP (JJ Convolutional) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-)) (VP (VBD achieved) (NP (JJ great) (JJ cognitive) (NN performance)) (PP (IN at) (NP (NP (DT the) (NN expense)) (PP (IN of) (NP (JJ considerable) (NN computation) (NN load)))))) (. .))
(S (S (VP (TO To) (VP (VB relieve) (NP (DT the) (NN computation) (NN load))))) (, ,) (NP (JJ many) (NN optimization) (NNS works)) (VP (VBP are) (VP (VBN developed) (S (VP (TO to) (VP (VB reduce) (NP (DT the) (NN model) (NN redundancy)) (PP (IN by) (S (VP (VBG identifying) (CC and) (VBG removing) (NP (ADJP (JJ insignificant) (NP-TMP (NP (NN model) (NNS components)) (, ,) (PP (JJ such) (IN as) (NP (NN weight) (NN sparsity) (CC and) (NN filter))))) (NN pruning)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT these) (NNS works)) (ADVP (RB only)) (VP (VBP evaluate) (NP (NP (NN model) (NNS components) (POS ')) (NN static) (NN significance)) (PP (IN with) (NP (JJ internal) (NN parameter) (NN information))) (, ,) (S (VP (VBG ignoring) (NP (PRP$ their) (JJ dynamic) (NN interaction)) (PP (IN with) (NP (JJ external) (NNS inputs)))))) (. .))
(S (PP (IN With) (NP (NML (IN per) (HYPH -) (NN input)) (NN feature) (NN activation))) (, ,) (S (NP (DT the) (NN model) (NN component) (NN significance)) (VP (MD can) (ADVP (RB dynamically)) (VP (VB change)))) (, ,) (CC and) (S (ADVP (RB thus)) (NP (DT the) (NN static) (NNS methods)) (VP (MD can) (ADVP (RB only)) (VP (VB achieve) (NP (JJ sub-optimal) (NNS results))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ dynamic) (NNP CNN) (NN optimization) (NN framework)) (PP (IN in) (NP (DT this) (NN work))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (DT the) (NML (JJ neural) (NN network)) (NN attention) (NN mechanism)))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ comprehensive) (NML (JJ dynamic) (NN optimization)) (NN framework)) (PP (VBG including) (NP (NP (NP (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (NP (NML (NN testing) (HYPH -) (NN phase)) (NML (NN channel) (CC and) (NN column)) (NN feature) (NN map) (NN pruning))) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NP (-LRB- -LRB-) (CD 2) (-RRB- -RRB-)) (NP (NML (NN training) (HYPH -) (NN phase)) (NN optimization)))))) (PP (IN by) (NP (VBN targeted) (NN dropout)))) (. .))
(S (NP (PDT Such) (DT a) (JJ dynamic) (NN optimization) (NN framework)) (VP (VBZ has) (NP (NP (JJ several) (NNS benefits)) (: :) (S (LST (-LRB- -LRB-) (LS 1) (-RRB- -RRB-)) (S (ADVP (RB First)) (, ,) (NP (PRP it)) (VP (MD can) (ADVP (RB accurately)) (VP (VP (VB identify)) (CC and) (ADVP (RB aggressively)) (VP (VB remove) (NP (NML (IN per) (HYPH -) (NN input)) (NN feature) (NN redundancy)) (PP (IN with) (S (VP (VBG considering) (NP (NP (NP (DT the) (NML (NN model) (HYPH -) (NN input)) (NN interaction)) (: ;) (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-))) (ADVP (RB Meanwhile)))))))))) (, ,) (S (NP (PRP it)) (VP (MD can) (ADVP (RB maximally)) (VP (VB remove) (NP (NP (DT the) (NN feature) (NN map) (NN redundancy)) (PP (IN in) (NP (JJ various) (NNS dimensions)))) (ADVP (NNS thanks) (PP (IN to) (NP (DT the) (NN multi-dimension) (NN flexibility))))))) (: ;) (S (LST (-LRB- -LRB-) (LS 3) (-RRB- -RRB-)) (NP (DT The) (NML (NN training) (HYPH -) (NN testing)) (NN co-optimization)) (VP (VP (VBZ favors) (NP (DT the) (JJ dynamic) (NN pruning))) (CC and) (VP (VBZ helps) (S (VP (VB maintain) (NP (DT the) (NN model) (NN accuracy)) (ADVP (RB even)) (PP (IN with) (NP (ADJP (RB very) (JJ high)) (NN feature) (NN pruning) (NN ratio))))))))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (MD could) (VP (VB bring) (NP (QP (CD 37.4) (NN %) (IN to) (CD 54.5) (NN %)) (NNS FLOPs) (NN reduction)) (PP (IN with) (NP (JJ negligible) (NN accuracy) (NN drop))) (PP (IN on) (NP (NP (JJ various)) (PP (IN of) (NP (NN test) (NNS networks)))))))))) (. .))
