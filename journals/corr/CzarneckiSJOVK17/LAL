(S (SBAR (WHADVP (WRB When)) (S (VP (VBG training) (NP (JJ neural) (NNS networks))))) (, ,) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (JJ Synthetic) (NNP Gradients)) (PRN (-LRB- -LRB-) (NP (NNP SG)) (-RRB- -RRB-))))) (VP (VBZ allows) (S (NP (NNS layers) (CC or) (NNS modules)) (VP (TO to) (VP (VB be) (VP (VBN trained) (PP (IN without) (NP (JJ update) (VBG locking))) (: -) (PP (IN without) (S (VP (VBG waiting) (SBAR (IN for) (S (NP (DT a) (JJ true) (NN error) (NN gradient)) (VP (TO to) (VP (VB be) (VP (VBN backpropagated))))))))) (: -) (S (VP (VBG resulting) (PP (IN in) (NP (NP (NNP Decoupled) (NNP Neural) (NNP Interfaces)) (PRN (-LRB- -LRB-) (NP (NNP DNIs)) (-RRB- -RRB-))))))))))) (. .))
(S (NP (NP (DT This) (JJ unlocked) (NN ability)) (PP (IN of) (S (VP (VBG being) (ADJP (JJ able) (S (VP (TO to) (VP (VB update) (NP (NP (NNS parts)) (PP (IN of) (NP (DT a) (JJ neural) (NN network)))) (UCP (ADVP (RB asynchronously)) (CC and) (PP (IN with) (NP (RB only) (JJ local) (NN information)))))))))))) (VP (VBD was) (VP (VBN demonstrated) (S (VP (TO to) (VP (VB work) (ADVP (RB empirically))))) (PP (IN in) (NP (NP (NNP Jaderberg) (CC et) (NN al)) (PRN (-LRB- -LRB-) (NP (CD 2016)) (-RRB- -RRB-)))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (EX there)) (VP (VBZ has) (VP (VBN been) (NP (NP (ADJP (RB very) (JJ little)) (NN demonstration)) (PP (IN of) (SBAR (WHNP (WP what) (NNS changes)) (S (NP (NNP DNIs) (CC and) (NNP SGs)) (VP (VBP impose) (PP (IN from) (NP (NP (DT a) (UCP (JJ functional) (, ,) (JJ representational) (, ,) (CC and) (VBG learning) (NNS dynamics)) (NN point)) (PP (IN of) (NP (NN view)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NNP DNIs)) (PP (IN through) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ synthetic) (NNS gradients))) (PP (IN on) (NP (JJ feed-forward) (NNS networks))))) (S (VP (TO to) (VP (VP (ADVP (RBR better)) (VB understand) (NP (PRP$ their) (NN behaviour))) (CC and) (VP (VB elucidate) (NP (NP (PRP$ their) (NN effect)) (PP (IN on) (NP (NN optimisation))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN incorporation)) (PP (IN of) (NP (NNP SGs)))) (VP (VBZ does) (RB not) (VP (VB affect) (NP (NP (DT the) (JJ representational) (NN strength)) (PP (IN of) (NP (NP (DT the) (NN learning) (NN system)) (PP (IN for) (NP (DT a) (JJ neural) (NN network))))))))))) (, ,) (CC and) (VP (VB prove) (NP (NP (DT the) (NN convergence)) (PP (IN of) (NP (DT the) (NN learning) (NN system))) (PP (IN for) (NP (ADJP (JJ linear) (CC and) (JJ deep)) (NN linear) (NNS models)))))) (. .))
(S (PP (IN On) (NP (JJ practical) (NNS problems))) (NP (PRP we)) (VP (VBP investigate) (NP (NP (NP (DT the) (NN mechanism)) (SBAR (WHPP (IN by) (WHNP (WDT which))) (S (NP (JJ synthetic) (NN gradient) (NNS estimators)) (VP (VBP approximate) (NP (DT the) (JJ true) (NN loss)))))) (, ,) (CC and) (PRN (, ,) (ADVP (RB surprisingly)) (, ,)) (SBAR (WHADVP (WRB how)) (S (NP (DT that)) (VP (VBZ leads) (PP (TO to) (NP (ADJP (RB drastically) (JJ different)) (JJ layer-wise) (NNS representations)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VP (VBP expose) (NP (NP (DT the) (NN relationship)) (PP (IN of) (S (VP (VBG using) (NP (JJ synthetic) (NNS gradients))))) (PP (TO to) (NP (JJ other) (JJ error) (NN approximation) (NNS techniques))))) (CC and) (VP (VB find) (NP (NP (DT a) (JJ unifying) (NN language)) (PP (IN for) (NP (NN discussion) (CC and) (NN comparison)))))) (. .))
