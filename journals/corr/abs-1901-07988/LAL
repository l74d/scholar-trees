(S (S (VP (VBG Training) (NP (JJ convolutional) (JJ neural) (NN network) (NNS models)))) (VP (VBZ is) (ADJP (JJ memory) (JJ intensive)) (SBAR (IN since) (S (NP (NN back-propagation)) (VP (VBZ requires) (S (VP (VBG storing) (NP (NP (NNS activations)) (PP (IN of) (NP (DT all) (JJ intermediate) (NNS layers)))))))))) (. .))
(S (NP (DT This)) (VP (VBZ presents) (NP (DT a) (JJ practical) (NN concern)) (SBAR (WHADVP (WRB when)) (S (VP (VBG seeking) (S (VP (TO to) (VP (VB deploy) (NP (ADJP (RB very) (JJ deep)) (NNS architectures)) (PP (IN in) (NP (NN production))))))))) (, ,) (SBAR (ADVP (RB especially)) (WRB when) (S (NP (NNS models)) (VP (VBP need) (S (VP (TO to) (VP (VB be) (ADVP (RB frequently)) (VP (VBN re-trained) (PP (IN on) (NP (JJ updated) (NNS datasets))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN implementation)) (PP (IN for) (NP (NN back-propagation))) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB significantly)) (VBZ reduces) (NP (NN memory) (NN usage)) (, ,) (PP (IN by) (S (VP (VBG enabling) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (NNS approximations)) (PP (IN with) (NP (NP (JJ negligible) (JJ computational) (NN cost)) (CC and) (NP (NP (JJ minimal) (NN effect)) (PP (IN on) (NP (NN training) (NN performance))))))))))))))))) (. .))
(S (NP (DT The) (NN algorithm)) (VP (VBZ reuses) (NP (JJ common) (NNS buffers)) (S (VP (TO to) (VP (VP (ADVP (RB temporarily)) (VB store) (NP (JJ full) (NNS activations))) (CC and) (VP (VB compute) (NP (DT the) (NN forward) (NN pass)) (ADVP (RB exactly))))))) (. .))
(S (NP (PRP It)) (ADVP (RB also)) (VP (NNS stores) (NP (NP (VBP approximate) (JJ per-layer) (NNS copies)) (PP (IN of) (NP (NNS activations)))) (, ,) (PP (IN at) (NP (JJ significant) (NN memory) (NNS savings))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (VBN used) (PP (IN in) (NP (DT the) (NN backward) (NN pass)))))))) (. .))
(S (PP (VBN Compared) (PP (TO to) (S (VP (ADVP (RB simply)) (VBG approximating) (NP (NNS activations)) (PP (IN within) (NP (JJ standard) (NN back-propagation))))))) (, ,) (NP (PRP$ our) (NN method)) (VP (VBZ limits) (NP (NP (NN accumulation)) (PP (IN of) (NP (NNS errors))) (PP (IN across) (NP (NNS layers))))) (. .))
(S (NP (DT This)) (VP (VBZ allows) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (ADJP (JJ much) (NN lower-precision)) (NNS approximations))) (PP (IN without) (S (VP (VBG affecting) (NP (VBG training) (NN accuracy))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NP (NNP CIFAR-10)) (, ,) (NP (NNP CIFAR-100)) (, ,) (CC and) (NP (NNP ImageNet))))) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (NNS yields) (NP (NP (NN performance)) (ADJP (RB close) (PP (TO to) (NP (VB exact) (NN training))))) (, ,) (SBAR (IN while) (S (VP (VBG storing) (NP (NNS activations)) (ADVP (RB compactly)) (PP (IN with) (NP (ADJP (ADJP (RB as) (JJ low)) (PP (IN as) (ADJP (JJ 4-bit)))) (NN precision)))))))))) (. .))
