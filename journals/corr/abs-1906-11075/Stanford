(S (NP (NP (NN Reinforcement) (NN Learning)) (, ,) (NP (NP (DT a) (NN machine)) (VP (VBG learning) (NP (NN framework)) (PP (IN for) (S (VP (VBG training) (NP (DT an) (JJ autonomous) (NN agent)) (PP (VBN based) (PP (IN on) (NP (NNS rewards))))))))) (, ,)) (VP (VBZ has) (VP (VBN shown) (NP (JJ outstanding) (NNS results)) (PP (IN in) (NP (JJ various) (NNS domains))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBN known) (SBAR (IN that) (S (S (VP (VBG learning) (NP (DT a) (JJ good) (NN policy)))) (VP (VBZ is) (ADJP (JJ difficult) (PP (IN in) (NP (DT a) (NN domain)))) (SBAR (WHADVP (WRB where)) (S (NP (NNS rewards)) (VP (VBP are) (ADJP (JJ rare)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (NP (NP (DT a) (NN method)) (, ,) (NP (NML (ADJP (JJ optimistic) (JJ proximal)) (NN policy)) (NN optimization) (PRN (-LRB- -LRB-) (NP (NN OPPO)) (-RRB- -RRB-)))) (VP (TO to) (VP (VB alleviate) (NP (DT this) (NN difficulty)))))) (. .))
(S (NP (NNP OPPO)) (VP (VP (VBZ considers) (NP (NP (DT the) (NN uncertainty)) (PP (IN of) (NP (DT the) (VBN estimated) (JJ total) (NN return))))) (CC and) (VP (ADVP (RB optimistically)) (VBZ evaluates) (NP (DT the) (NN policy)) (PP (VBN based) (PP (IN on) (NP (DT that) (NN amount)))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP OPPO)) (VP (VBZ outperforms) (NP (NP (DT the) (VBG existing) (NNS methods)) (PP (IN in) (NP (DT a) (JJ tabular) (NN task)))))))) (. .))
