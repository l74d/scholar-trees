(S (NP (PRP We)) (VP (VBP improve) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (ADJP (NP (NP (NN propagation)) (HYPH -) (CC and) (NP (JJ linear) (HYPH -) (NN optimization))) (HYPH -) (VBN based)) (NML (JJ neural) (NN network) (NN verification)) (NNS algorithms)))) (PP (IN with) (NP (NP (DT a) (JJ new) (VBN tightened) (NN convex) (NN relaxation)) (PP (IN for) (NP (NN ReLU) (NNS neurons)))))) (. .))
(S (PP (IN Unlike) (NP (NP (JJ previous) (NML (JJ single) (HYPH -) (NN neuron)) (NNS relaxations)) (SBAR (WHNP (WDT which)) (S (VP (VBP focus) (ADVP (RB only)) (PP (IN on) (NP (NP (DT the) (JJ univariate) (NN input) (NN space)) (PP (IN of) (NP (DT the) (NN ReLU)))))))))) (, ,) (NP (PRP$ our) (NN method)) (VP (VBZ considers) (NP (NP (DT the) (JJ multivariate) (NN input) (NN space)) (PP (IN of) (NP (NP (DT the) (JJ affine) (NN pre-activation) (NN function)) (VP (VBG preceding) (NP (DT the) (NN ReLU))))))) (. .))
(S (S (VP (VBG Using) (NP (NNS results)) (PP (IN from) (NP (NML (NN submodularity) (CC and) (NN convex)) (NN geometry))))) (, ,) (NP (PRP we)) (VP (VBP derive) (NP (NP (DT an) (JJ explicit) (NN description)) (PP (IN of) (NP (NP (DT the) (JJS tightest) (JJ possible) (NN convex) (NN relaxation)) (SBAR (WHADVP (WRB when)) (S (NP (DT this) (JJ multivariate) (NN input)) (VP (VBZ is) (PP (IN over) (NP (DT a) (NN box) (NN domain)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN convex) (NN relaxation)) (VP (VBZ is) (ADJP (ADJP (RB significantly) (JJR stronger)) (PP (IN than) (NP (NP (DT the) (NML (ADJP (ADJP (RB commonly) (VBN used)) (JJ univariate)) (HYPH -) (NN input)) (NN relaxation)) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN proposed) (PP (IN as) (NP (NP (DT a) (NML (JJ natural) (NN convex)) (NN relaxation) (NN barrier)) (PP (IN for) (NP (NN verification))))))))))))))))) (. .))
(S (SBAR (IN While) (S (NP (NP (PRP$ our) (NN description)) (PP (IN of) (NP (DT the) (NN relaxation)))) (VP (MD may) (VP (VB require) (NP (NP (DT an) (ADJP (JJ exponential)) (NN number)) (PP (IN of) (NP (NNS inequalities)))))))) (, ,) (NP (PRP we)) (VP (VP (VBP show) (SBAR (IN that) (S (NP (PRP they)) (VP (MD can) (VP (VB be) (VP (VBN separated) (PP (IN in) (NP (JJ linear) (NN time))))))))) (CC and) (ADVP (RB hence)) (VP (MD can) (VP (VB be) (ADVP (RB efficiently)) (VP (VBN incorporated) (PP (IN into) (NP (NN optimization) (NNS algorithms))) (PP (IN on) (NP (DT an) (NML (SBAR (IN as) (HYPH -) (FRAG (VP (VBN needed))))) (NN basis))))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (DT this) (JJ novel) (NN relaxation)))) (, ,) (NP (PRP we)) (VP (VBP design) (NP (NP (NP (CD two) (ADJP (JJ polynomial) (HYPH -) (NN time)) (NNS algorithms)) (PP (IN for) (NP (JJ neural) (NN network) (NN verification)))) (: :) (NP (NP (DT a) (ADJP (NP (JJ linear) (HYPH -) (NN programming)) (HYPH -) (VBN based)) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ leverages) (NP (NP (DT the) (JJ full) (NN power)) (PP (IN of) (NP (PRP$ our) (NN relaxation)))))))) (, ,) (CC and) (NP (NP (DT a) (JJ fast) (NN propagation) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ generalizes) (NP (VBG existing) (NNS approaches)))))))) (. .))
(S (PP (IN In) (NP (DT both) (NNS cases))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (PP (IN for) (NP (NP (DT a) (JJ modest) (NN increase)) (PP (IN in) (NP (JJ computational) (NN effort))))) (, ,) (NP (PRP$ our) (VBN strengthened) (NN relaxation)) (VP (VBZ enables) (S (NP (PRP us)) (VP (TO to) (VP (VB verify) (NP (NP (DT a) (ADJP (RB significantly) (JJR larger)) (NN number)) (PP (IN of) (NP (NNS instances)))) (PP (VBN compared) (PP (IN to) (NP (JJ similar) (NNS algorithms))))))))))) (. .))
