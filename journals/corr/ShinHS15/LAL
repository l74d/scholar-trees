(S (S (NP (JJ Recurrent) (JJ neural) (NNS networks)) (VP (VBP have) (VP (VBN shown) (NP (JJ excellent) (NN performance)) (PP (IN in) (NP (JJ many) (NNS applications)))))) (, ,) (S (ADVP (RB however)) (NP (PRP they)) (VP (VBP require) (NP (JJ increased) (NN complexity)) (PP (IN in) (NP (ADJP (UCP (NN hardware) (CC or) (NN software)) (VBN based)) (NNS implementations))))) (. .))
(S (NP (DT The) (NN hardware) (NN complexity)) (VP (MD can) (VP (VB be) (VP (ADVP (RB much)) (VBN lowered) (PP (IN by) (S (VP (VBG minimizing) (NP (NP (DT the) (NN word-length)) (PP (IN of) (NP (NNS weights) (CC and) (NNS signals)))))))))) (. .))
(S (NP (DT This) (NN work)) (VP (VBZ analyzes) (NP (NP (DT the) (JJ fixed-point) (NN performance)) (PP (IN of) (NP (JJ recurrent) (JJ neural) (NNS networks)))) (S (VP (VBG using) (NP (DT a) (ADJP (NN retrain) (VBN based)) (NN quantization) (NN method))))) (. .))
(S (S (NP (NP (DT The) (NN quantization) (NN sensitivity)) (PP (IN of) (NP (NP (DT each) (NN layer)) (PP (IN in) (NP (NNP RNNs)))))) (VP (VBZ is) (VP (VBN studied)))) (, ,) (CC and) (S (NP (NP (DT the) (JJ overall) (JJ fixed-point) (NN optimization) (NNS results)) (VP (VBG minimizing) (NP (NP (DT the) (NN capacity)) (PP (IN of) (NP (NNS weights)))) (SBAR (IN while) (S (RB not) (VP (VBG sacrificing) (NP (DT the) (NN performance))))))) (VP (VBP are) (VP (VBN presented)))) (. .))
(S (NP (NP (DT A) (NN language) (NN model)) (CC and) (NP (DT a) (JJ phoneme) (NN recognition) (NNS examples))) (VP (VBP are) (VP (VBN used))) (. .))
