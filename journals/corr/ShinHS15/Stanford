(S (S (NP (JJ Recurrent) (JJ neural) (NNS networks)) (VP (VBP have) (VP (VBN shown) (NP (JJ excellent) (NN performance)) (PP (IN in) (NP (JJ many) (NNS applications)))))) (, ,) (S (ADVP (RB however)) (NP (PRP they)) (VP (VBP require) (NP (NP (JJ increased) (NN complexity)) (PP (IN in) (NP (ADJP (NP (NN hardware) (CC or) (NN software)) (VBN based)) (NNS implementations)))))) (. .))
(S (NP (DT The) (NN hardware) (NN complexity)) (VP (MD can) (VP (VB be) (ADVP (JJ much)) (VP (VBN lowered) (PP (IN by) (S (VP (VBG minimizing) (NP (NP (DT the) (NN word) (HYPH -) (NN length)) (PP (IN of) (NP (NNS weights) (CC and) (NNS signals)))))))))) (. .))
(S (NP (DT This) (NN work)) (VP (VBZ analyzes) (NP (NP (DT the) (NML (VBN fixed) (HYPH -) (NN point)) (NN performance)) (PP (IN of) (NP (NP (ADJP (JJ recurrent)) (JJ neural) (NNS networks)) (VP (VBG using) (NP (DT a) (NN retrain)) (PP (VBN based) (NP (NN quantization) (NN method)))))))) (. .))
(S (S (NP (NP (DT The) (NN quantization) (NN sensitivity)) (PP (IN of) (NP (NP (DT each) (NN layer)) (PP (IN in) (NP (NNS RNNs)))))) (VP (VBZ is) (VP (VBN studied)))) (, ,) (CC and) (S (NP (DT the) (JJ overall) (NML (VBN fixed) (HYPH -) (NN point)) (NN optimization)) (VP (VBZ results) (S (VP (VBG minimizing) (NP (NP (DT the) (NN capacity)) (PP (IN of) (NP (NNS weights)))) (SBAR (IN while) (S (S (RB not) (VP (VBG sacrificing) (NP (DT the) (NN performance)))) (VP (VBP are) (VP (VBN presented))))))))) (. .))
(S (NP (NP (DT A) (NN language) (NN model)) (CC and) (NP (DT a) (NML (NN phoneme) (NN recognition)) (NNS examples))) (VP (VBP are) (VP (VBN used))) (. .))
