(S (NP (NP (JJ Real) (NN time) (NN application)) (PP (IN of) (NP (JJ deep) (NN learning) (NN algorithms)))) (VP (VBZ is) (ADVP (RB often)) (VP (VBN hindered) (PP (IN by) (NP (NP (JJ high) (JJ computational) (NN complexity)) (CC and) (NP (JJ frequent) (NN memory) (NNS accesses)))))) (. .))
(S (NP (NNP Network) (NN pruning)) (VP (VBZ is) (NP (NP (DT a) (NN promising) (NN technique)) (SBAR (S (VP (TO to) (VP (VB solve) (NP (DT this) (NN problem)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (VBG pruning)) (ADVP (RB usually)) (VP (NNS results) (PP (IN in) (NP (NP (JJ irregular) (NN network) (NNS connections)) (SBAR (WHNP (IN that)) (S (VP (CONJP (RB not) (RB only)) (VP (NN demand) (NP (JJ extra) (NN representation) (NNS efforts))) (CC but) (RB also) (VP (VBP do) (RB not) (VP (VB fit) (ADVP (RB well)) (PP (IN on) (NP (JJ parallel) (NN computation))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (JJ structured) (NN sparsity)) (PP (IN at) (NP (JJ various) (NNS scales))) (PP (IN for) (NP (NP (JJ convolutional) (JJ neural) (NNS networks)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADJP (ADJP (NNS channel) (NN wise)) (, ,) (ADJP (VB kernel) (NN wise)) (CC and) (ADJP (ADJP (JJ intra) (NNS kernel) (VBD strided)) (NN sparsity))))))))) (. .))
(S (NP (DT This) (JJ structured) (NN sparsity)) (VP (VBZ is) (ADJP (RB very) (JJ advantageous) (PP (IN for) (NP (NP (JJ direct) (JJ computational) (NN resource) (NNS savings)) (PP (IN on) (NP (NP (JJ embedded) (NNS computers)) (, ,) (NP (JJ parallel) (VBG computing) (NNS environments)) (CC and) (NP (ADJP (NN hardware) (VBN based)) (NNS systems)))))))) (. .))
(S (S (VP (TO To) (VP (VB decide) (NP (NP (DT the) (NN importance)) (PP (IN of) (NP (NN network) (NNS connections) (CC and) (NNS paths))))))) (, ,) (NP (DT the) (VBN proposed) (NN method)) (VP (VBZ uses) (NP (DT a) (NN particle) (VBG filtering) (NN approach))) (. .))
(S (NP (NP (DT The) (NN importance) (NN weight)) (PP (IN of) (NP (DT each) (NN particle)))) (VP (VBZ is) (VP (VBN assigned) (PP (IN by) (S (VP (VBG computing) (NP (NP (DT the) (NN misclassification) (NN rate)) (PP (IN with) (NP (VBG corresponding) (NN connectivity) (NN pattern))))))))) (. .))
(S (NP (DT The) (JJ pruned) (NN network)) (VP (VBZ is) (VP (JJ re-trained) (S (VP (TO to) (VP (VB compensate) (PP (IN for) (NP (NP (DT the) (NNS losses)) (ADJP (JJ due) (PP (TO to) (NP (VBG pruning))))))))))) (. .))
(S (SBAR (IN While) (S (VP (VBG implementing) (NP (NNS convolutions)) (PP (IN as) (NP (NN matrix) (NNS products)))))) (, ,) (NP (PRP we)) (VP (ADVP (RB particularly)) (VBP show) (SBAR (IN that) (S (NP (NP (ADJP (JJ intra) (NNS kernel)) (VBD strided) (NN sparsity)) (PP (IN with) (NP (DT a) (JJ simple) (NN constraint)))) (VP (MD can) (VP (ADVP (RB significantly)) (VB reduce) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (NNS kernel) (CC and) (NN feature) (NN map) (NNS matrices))))))))) (. .))
(S (NP (DT The) (JJ pruned) (NN network)) (VP (VBZ is) (ADVP (RB finally)) (VP (NP (VBN fixed) (NN point)) (VBN optimized) (PP (IN with) (NP (JJ reduced) (NN word) (NN length) (NN precision))))) (. .))
(S (NP (DT This)) (VP (NNS results) (PP (IN in) (NP (NP (JJ significant) (NN reduction)) (PP (IN in) (NP (DT the) (JJ total) (NN storage) (NN size))))) (S (VP (NN providing) (NP (NP (NNS advantages)) (PP (IN for) (NP (NP (ADJP (JJ on-chip) (NN memory) (VBN based)) (NNS implementations)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks))))))))) (. .))
