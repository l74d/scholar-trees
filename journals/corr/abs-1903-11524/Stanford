(S (NP (NML (NN Reinforcement) (NN learning)) (NNS algorithms)) (VP (VBP rely) (PP (IN on) (NP (NN exploration))) (S (VP (TO to) (VP (VB discover) (NP (NP (JJ new) (NNS behaviors)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADVP (RB typically)) (VP (VBN achieved) (PP (IN by) (S (VP (VBG following) (NP (DT a) (JJ stochastic) (NN policy)))))))))))))) (. .))
(S (PP (IN In) (NP (JJ continuous) (NN control) (NNS tasks))) (, ,) (NP (NP (NNS policies)) (PP (IN with) (NP (DT a) (JJ Gaussian) (NN distribution)))) (VP (VBP have) (VP (VBN been) (ADVP (RB widely)) (VP (VBN adopted)))) (. .))
(S (NP (JJ Gaussian) (NN exploration)) (ADVP (RB however)) (VP (VBZ does) (RB not) (VP (VB result) (PP (IN in) (NP (NP (JJ smooth) (NNS trajectories)) (SBAR (WHNP (WDT that)) (S (ADVP (RB generally)) (VP (VBP correspond) (PP (IN to) (NP (NP (ADJP (JJ safe) (CC and) (JJ rewarding)) (NNS behaviors)) (PP (IN in) (NP (JJ practical) (NNS tasks)))))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (JJ Gaussian) (NNS policies)) (VP (VBP do) (RB not) (VP (VP (VB result) (PP (IN in) (NP (NP (DT an) (JJ effective) (NN exploration)) (PP (IN of) (NP (DT an) (NN environment)))))) (CC and) (VP (VB become) (NP (ADJP (RB increasingly) (JJ inefficient) (PP (IN as) (NP (DT the) (NN action) (NN rate)))) (NNS increases))))) (. .))
(S (NP (DT This)) (VP (VBZ contributes) (PP (IN to) (NP (NP (DT a) (JJ low) (NN sample) (NN efficiency)) (VP (ADVP (RB often)) (VBN observed) (PP (IN in) (S (VP (VBG learning) (NP (JJ continuous) (NN control) (NNS tasks))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (NN family)) (PP (IN of) (NP (JJ stationary) (NML (NN autoregressive) (-LRB- -LRB-) (NN AR) (-RRB- -RRB-)) (JJ stochastic) (NNS processes)))) (S (VP (TO to) (VP (VB facilitate) (NP (NN exploration)) (PP (IN in) (NP (JJ continuous) (NN control) (NNS domains))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (VBN proposed) (NNS processes)) (VP (VBP possess) (NP (CD two) (JJ desirable) (NNS features))))))) (: :) (S (S (NP (JJ subsequent) (NN process) (NNS observations)) (VP (VBP are) (ADJP (RB temporally) (JJ coherent) (PP (IN with) (NP (NP (ADJP (RB continuously) (JJ adjustable)) (NN degree)) (PP (IN of) (NP (NN coherence)))))))) (, ,) (CC and) (S (NP (DT the) (NN process) (JJ stationary) (NN distribution)) (VP (VBZ is) (ADJP (JJ standard) (JJ normal))))) (. .))
(S (NP (PRP We)) (VP (VBP derive) (NP (NP (NP (DT an) (JJ autoregressive) (NN policy)) (-LRB- -LRB-) (NP (NN ARP)) (-RRB- -RRB-)) (SBAR (WHNP (WDT that)) (S (VP (VBZ implements) (NP (JJ such) (NNS processes)) (S (VP (VBG maintaining) (NP (DT the) (JJ standard) (NML (NN agent) (HYPH -) (NN environment)) (NN interface))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (NP (NNS ARPs)) (VP (MD can) (VP (VB be) (ADVP (RB easily)) (VP (VBN used) (PP (IN with) (NP (NP (DT the) (VBG existing) (NML (RB off) (HYPH -) (DT the) (HYPH -) (NN shelf)) (NN learning)) (NP (NNS algorithms)))))))))) (. .))
(S (ADVP (RB Empirically)) (NP (PRP we)) (VP (VP (VBP demonstrate) (SBAR (IN that) (S (VP (VBG using) (NP (NNS ARPs) (NNS results)) (PP (IN in) (NP (NP (VBN improved) (NML (NN exploration) (CC and) (NN sample)) (NN efficiency)) (PP (IN in) (NP (NP (DT both) (JJ simulated)) (CC and) (NP (JJ real) (NN world) (NNS domains)))))))))) (, ,) (CC and) (, ,) (ADVP (RB furthermore)) (, ,) (VP (VBZ provides) (NP (NP (NML (JJ smooth) (NN exploration)) (NNS trajectories)) (SBAR (WHNP (WDT that)) (S (VP (VBP enable) (NP (NP (JJ safe) (NN operation)) (PP (IN of) (NP (JJ robotic) (NN hardware)))))))))) (. .))
