(S (PP (IN Despite) (NP (NP (DT the) (VBG growing) (NN popularity)) (PP (IN of) (NP (JJ metric) (NN learning) (NNS approaches))))) (, ,) (NP (ADJP (RB very) (JJ little)) (NN work)) (VP (VBZ has) (VP (VBN attempted) (S (VP (TO to) (VP (VB perform) (NP (NP (DT a) (JJ fair) (NN comparison)) (PP (IN of) (NP (NP (DT these) (NNS techniques)) (PP (IN for) (NP (NN speaker) (NN verification))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP try) (S (VP (TO to) (VP (VP (VB fill) (NP (DT this) (NN gap))) (CC and) (VP (VB compare) (SBAR (S (NP (JJ several) (JJ metric) (NN learning) (NN loss)) (VP (VBZ functions) (PP (IN in) (NP (NP (DT a) (JJ systematic) (NN manner)) (PP (IN on) (NP (DT the) (NNP VoxCeleb) (NN dataset))))))))))))) (. .))
(S (NP (NP (DT The) (JJ first) (NN family)) (PP (IN of) (NP (NN loss) (NNS functions)))) (VP (VP (VBZ is) (VP (VBN derived) (PP (IN from) (NP (DT the) (NN cross) (NN entropy) (NN loss))) (PRN (-LRB- -LRB-) (S (ADVP (RB usually)) (VP (VBN used) (PP (IN for) (NP (JJ supervised) (NN classification))))) (-RRB- -RRB-)))) (CC and) (VP (VBZ includes) (NP (NP (DT the) (JJ congenerous) (NN cosine) (NN loss)) (, ,) (NP (DT the) (JJ additive) (JJ angular) (NN margin) (NN loss)) (, ,) (CC and) (NP (DT the) (NN center) (NN loss))))) (. .))
(S (NP (NP (DT The) (JJ second) (NN family)) (PP (IN of) (NP (NN loss) (NNS functions)))) (VP (VP (VBZ focuses) (PP (IN on) (NP (NP (DT the) (NN similarity)) (PP (IN between) (NP (NN training) (NNS samples)))))) (CC and) (VP (VBZ includes) (NP (NP (DT the) (JJ contrastive) (NN loss)) (CC and) (NP (DT the) (JJ triplet) (NN loss))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (JJ additive) (JJ angular) (NN margin) (NN loss) (NN function)) (VP (VBZ outperforms) (NP (NP (DT all) (JJ other) (NN loss) (NNS functions)) (PP (IN in) (NP (DT the) (NN study)))) (, ,) (SBAR (IN while) (S (VP (VBG learning) (NP (JJR more) (JJ robust) (NNS representations))))))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (NP (DT a) (NN combination)) (PP (IN of) (NP (NP (NNP SincNet) (JJ trainable) (NNS features)) (CC and) (NP (DT the) (NN x-vector) (NN architecture))))))) (, ,) (NP (NP (DT the) (NN network)) (VP (VBN used) (PP (IN in) (NP (DT this) (NN paper))))) (VP (VBZ brings) (NP (PRP us)) (PP (ADVP (NP (DT a) (NN step)) (RBR closer)) (IN to) (NP (NML (S (NP (DT a) (RB really)) (HYPH -) (VP (VB end) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))))) (NML (NN speaker) (NN verification)) (NN system))) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBN combined) (PP (IN with) (NP (DT the) (JJ additive) (JJ angular) (NN margin) (NN loss)))))) (, ,) (SBAR (IN while) (S (ADVP (RB still)) (VP (VBG being) (ADJP (JJ competitive) (PP (IN with) (NP (DT the) (NN x-vector) (NN baseline)))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (NN spirit)) (PP (IN of) (NP (JJ reproducible) (NN research))))) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VBP release) (NP (NP (NP (JJ open) (NN source) (NN Python) (NN code)) (PP (IN for) (S (VP (VBG reproducing) (NP (PRP$ our) (NNS results)))))) (, ,) (CC and) (NP (NP (NN share)) (VP (VBN pretrained) (NP (NNP PyTorch) (NNS models)) (PP (IN on) (NP (NP (NN torch.hub)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN used) (ADVP (CC either) (RB directly) (CC or) (RB after)) (NP (JJ fine) (HYPH -) (NN tuning))))))))))))) (. .))
