(S (PP (IN With) (NP (NP (DT the) (NN implementation)) (PP (IN of) (NP (NML (NML (NN reinforcement) (NN learning)) (-LRB- -LRB-) (NML (NN RL)) (-RRB- -RRB-)) (NNS algorithms))))) (, ,) (NP (NML (NML (JJ current) (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (NN art)))) (NML (JJ autonomous) (NN vehicle)) (NN technology)) (VP (VBP have) (NP (DT the) (NN potential) (S (VP (TO to) (VP (VB get) (ADJP (ADJP (JJR closer)) (PP (IN to) (NP (JJ full) (NN automation))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (JJS most)) (PP (IN of) (NP (DT the) (NNS applications)))) (VP (VBP have) (VP (VBN been) (VP (VBN limited) (PP (IN to) (NP (NP (NN game) (NNS domains)) (CC or) (NP (NP (JJ discrete) (NN action) (NN space)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADVP (RB far) (PP (IN from) (NP (DT the) (JJ real) (NN world)))) (VP (VBG driving))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (RB very) (JJ tough)) (S (VP (TO to) (VP (VB tune) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (NN reward) (NN mechanism))))))) (SBAR (IN since) (S (NP (DT the) (NN driving) (NNS styles)) (VP (VBP vary) (NP (NP (DT a) (NN lot)) (PP (IN among) (NP (DT the) (JJ different) (NNS users)))))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (NP (DT an) (JJ aggressive) (NN driver)) (VP (MD may) (VP (VB prefer) (S (VP (VBG driving) (PP (IN with) (NP (JJ high) (NN acceleration))))) (SBAR (IN whereas) (S (NP (DT some) (JJ conservative) (NNS drivers)) (VP (VBP prefer) (NP (DT a) (JJR safer) (NN driving) (NN style))))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (NN apprenticeship) (NN learning)) (PP (IN in) (NP (NN combination)))) (PP (IN with) (NP (NP (JJ deep) (NN reinforcement)) (VP (VP (VBG learning) (NP (NP (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ allows) (NP (DT the) (NN agent) (S (VP (TO to) (VP (VB learn) (NP (DT the) (NN driving))))))))))) (CC and) (VP (VBG stopping) (NP (NNS behaviors)) (PP (IN with) (NP (JJ continuous) (NNS actions)))))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (NN gradient) (NN inverse) (NN reinforcement) (NN learning) (-LRB- -LRB-) (NN GIRL) (-RRB- -RRB-) (NN algorithm)) (S (VP (TO to) (VP (VP (VB recover) (NP (DT the) (JJ unknown) (NN reward) (NN function))) (CC and) (VP (VB employ) (S (VP (VB REINFORCE) (NP (CONJP (RB as) (RB well) (IN as)) (NP (JJ Deep) (JJ Deterministic) (NN Policy)) (NP (NN Gradient)) (NP (NN algorithm) (-LRB- -LRB-) (NN DDPG) (-RRB- -RRB-))) (S (VP (TO to) (VP (VB learn) (NP (DT the) (JJ optimal) (NN policy)))))))))))) (. .))
(S (S (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (PRP$ our) (NN method)))) (VP (VBZ is) (VP (VBN evaluated) (PP (IN in) (NP (ADJP (NN simulation) (HYPH -) (VBN based)) (NN scenario)))))) (CC and) (S (NP (DT the) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (NN agent)) (VP (VBZ performs) (ADJP (JJ human) (PP (IN like) (S (VP (VP (VBG driving)) (CC and) (VP (ADVP (RB even) (RBR better)) (PP (IN in) (NP (DT some) (NNS aspects))) (PP (IN after) (NP (NN training))))))))))))) (. .))
