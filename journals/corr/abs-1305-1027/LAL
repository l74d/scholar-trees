(S (PP (IN In) (NP (DT some) (NN reinforcement) (VBG learning) (NNS problems))) (NP (DT an) (NN agent)) (VP (MD may) (VP (VB be) (VP (VBN provided) (PP (IN with) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NN input) (NNS policies)) (, ,) (VP (VP (ADVP (RB perhaps)) (VBN learned) (PP (IN from) (NP (JJ prior) (NN experience)))) (CC or) (VP (VBN provided) (PP (IN by) (NP (NNS advisors)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT a) (NAC (NN reinforcement) (VBG learning) (PP (IN with) (NP (NN policy) (NN advice)))) (PRN (-LRB- -LRB-) (NNP RLPA) (-RRB- -RRB-)) (NN algorithm)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ leverages) (NP (DT this) (NN input) (VBN set))) (CC and) (VP (NNS learns) (S (VP (TO to) (VP (VB use) (NP (NP (DT the) (JJS best) (NN policy)) (PP (IN in) (NP (DT the) (NN set)))) (PP (IN for) (NP (NP (DT the) (NN reinforcement) (VBG learning) (NN task)) (PP (IN at) (NP (NN hand)))))))))))))) (. .))
(S (NP (PRP$ Our) (JJ empirical) (NNS simulations)) (VP (VB support) (NP (PRP$ our) (JJ theoretical) (NN analysis))) (. .))
(S (NP (DT This)) (VP (VBZ suggests) (SBAR (S (NP (NNP RLPA)) (VP (MD may) (VP (VB offer) (NP (JJ significant) (NNS advantages)) (PP (IN in) (NP (NP (JJ large) (NNS domains)) (SBAR (WHADVP (WRB where)) (S (NP (DT some) (RB prior) (JJ good) (NNS policies)) (VP (VBP are) (VP (VBN provided)))))))))))) (. .))
