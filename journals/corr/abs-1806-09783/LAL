(S (S (PP (IN As) (NP (NP (CD one)) (PP (IN of) (NP (NP (JJ standard) (NNS approaches)) (SBAR (S (VP (TO to) (VP (VB train) (NP (JJ deep) (JJ neural) (NNS networks)))))))))) (, ,) (NP (NN dropout)) (VP (VBZ has) (VP (VBN been) (VP (VBN applied) (S (VP (TO to) (VP (VB regularize) (NP (JJ large) (NNS models)) (S (VP (TO to) (VP (VB avoid) (NP (NN overfitting)))))))))))) (, ,) (CC and) (S (NP (NP (DT the) (NN improvement)) (PP (IN in) (NP (NN performance))) (PP (IN by) (NP (NN dropout)))) (VP (VBZ has) (VP (VBN been) (VP (VBN explained) (PP (IN as) (S (VP (VBG avoiding) (NP (NP (NN co-adaptation)) (PP (IN between) (NP (NNS nodes))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNS correlations)) (PP (IN between) (NP (NNS nodes)))) (VP (VBP are) (VP (VBN compared) (PP (IN after) (S (VP (VBG training) (NP (DT the) (NNS networks)) (PP (IN with) (CC or) (IN without) (NP (NN dropout)))))))))) (, ,) (NP (CD one) (NN question)) (VP (VBZ arises) (SBAR (IN if) (S (NP (NN co-adaptation) (NN avoidance)) (VP (VBZ explains) (NP (DT the) (NN dropout) (NN effect)) (ADVP (RB completely)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP propose) (NP (NP (DT an) (JJ additional) (NN explanation)) (PP (IN of) (SBAR (WHADVP (WRB why)) (S (NP (NN dropout)) (VP (NN works))))))) (CC and) (VP (VB propose) (NP (NP (DT a) (JJ new) (NN technique)) (SBAR (S (VP (TO to) (VP (VB design) (NP (JJR better) (NN activation) (NNS functions))))))))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NN dropout)) (VP (MD can) (VP (VB be) (VP (VBN explained) (PP (IN as) (NP (NP (DT an) (NN optimization) (NN technique)) (SBAR (S (VP (TO to) (VP (VB push) (NP (DT the) (NN input)) (PP (IN towards) (NP (NP (DT the) (NN saturation) (NN area)) (PP (IN of) (NP (JJ nonlinear) (NN activation) (NN function))))) (PP (IN by) (S (VP (VBG accelerating) (NP (NP (JJ gradient) (NN information)) (VP (VBG flowing) (PP (ADVP (RB even)) (IN in) (NP (DT the) (NN saturation) (NN area))) (PP (IN in) (NP (NN backpropagation)))))))))))))))))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (NP (NN input)) (PP (TO to) (NP (DT the) (NN activation) (NN function)))) (VP (MD can) (VP (VB climb) (PP (IN onto) (NP (NP (DT the) (NN saturation) (NN area)) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (NP (DT the) (NN network)) (ADJP (RBR more) (JJ robust))) (SBAR (IN because) (S (NP (DT the) (NN model)) (VP (VBZ converges) (PP (IN on) (NP (DT a) (JJ flat) (NN region))))))))))))) (. .))
(S (NP (JJ Experiment) (NNS results)) (VP (VP (VB support) (NP (NP (PRP$ our) (NN explanation)) (PP (IN of) (NP (NN dropout))))) (CC and) (VP (NN confirm) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NNP GAAF) (NN technique)) (VP (VBZ improves) (NP (NN image) (NN classification) (NN performance)) (PP (IN with) (NP (VBN expected) (NNS properties)))))))) (. .))
