(S (NP (PRP We)) (VP (VBP provide) (NP (DT a) (JJ theoretical) (NN explanation)) (PP (IN for) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NP (NN gradient)) (VP (VBG clipping) (PP (IN in) (NP (NN training) (JJ deep) (JJ neural) (NNS networks))))))))) (. .))
(S (NP (DT The) (JJ key) (NN ingredient)) (VP (VBZ is) (NP (NP (DT a) (JJ new) (NN smoothness) (NN condition)) (VP (VBN derived) (PP (IN from) (NP (JJ practical) (NML (JJ neural) (NN network) (NN training)) (NNS examples)))))) (. .))
(S (NP (PRP We)) (VP (VBP observe) (SBAR (IN that) (S (NP (NP (NN gradient) (NN smoothness)) (, ,) (NP (NP (NP (DT a) (NN concept)) (ADJP (JJ central) (PP (IN to) (NP (NP (DT the) (NN analysis)) (PP (IN of) (NP (NML (JJ first) (HYPH -) (NN order)) (NN optimization) (NNS algorithms))))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADVP (RB often)) (VP (VBN assumed) (S (VP (TO to) (VP (VB be) (NP (DT a) (JJ constant)))))))))) (, ,)) (VP (VBZ demonstrates) (NP (NP (JJ significant) (NN variability)) (PP (IN along) (NP (NP (DT the) (NN training) (NN trajectory)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))))))))) (. .))
(S (ADVP (RB Further)) (, ,) (S (NP (DT this) (NN smoothness)) (ADVP (RB positively)) (VP (VBZ correlates) (PP (IN with) (NP (DT the) (NN gradient) (NN norm))))) (, ,) (CC and) (S (ADVP (JJ contrary) (PP (IN to) (NP (NP (JJ standard) (NNS assumptions)) (PP (IN in) (NP (DT the) (NN literature)))))) (, ,) (NP (PRP it)) (VP (MD can) (VP (VB grow) (PP (IN with) (NP (NP (DT the) (NN norm)) (PP (IN of) (NP (DT the) (NN gradient)))))))) (. .))
(S (NP (DT These) (JJ empirical) (NNS observations)) (VP (VBP limit) (NP (NP (DT the) (NN applicability)) (PP (IN of) (NP (NP (VBG existing) (JJ theoretical) (NNS analyses)) (PP (IN of) (NP (NP (NNS algorithms)) (SBAR (WHNP (WDT that)) (S (VP (VBP rely) (PP (IN on) (NP (NP (DT a) (VBN fixed)) (VP (VBN bound) (PP (IN on) (NP (NN smoothness))))))))))))))) (. .))
(S (NP (DT These) (NNS observations)) (VP (VBP motivate) (S (NP (PRP us)) (VP (TO to) (VP (VB introduce) (NP (NP (DT a) (JJ novel) (NN relaxation)) (PP (IN of) (NP (NP (NN gradient) (NN smoothness)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (ADJP (JJR weaker)) (PP (IN than) (NP (DT the) (ADJP (RB commonly) (VBN used)) (NNP Lipschitz) (NN smoothness) (NN assumption)))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VBP explain) (SBAR (WHADVP (WRB why)) (S (NP (JJ such) (ADJP (ADVP (RB adaptively)) (VBN scaled)) (NN gradient) (NNS methods)) (VP (MD can) (VP (VP (VB accelerate) (NP (JJ empirical) (NN convergence))) (CC and) (VP (VB verify) (NP (PRP$ our) (NNS results)) (ADVP (RB empirically)) (PP (IN in) (NP (JJ popular) (NML (JJ neural) (NN network) (NN training)) (NNS settings))))))))) (. .))
