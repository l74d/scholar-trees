(S (PP (IN In) (NP (NP (NN representation) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)))) (, ,) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB make) (S (NP (DT the) (JJ learned) (NNS representations)) (ADJP (ADJP (VBP easy) (SBAR (S (VP (TO to) (VP (VB interpret)))))) (CC and) (ADJP (RBR less) (VBN overfitted) (PP (TO to) (NP (VBG training) (NNS data)))))))))) (VP (VBP are) (NP (CD two) (ADJP (JJ important) (CC but) (JJ challenging)) (NNS issues))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS problems))))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT a) (JJ new) (NN type)) (PP (IN of) (NP (JJ regulariza-) (NN tion) (NN approach))) (SBAR (WHNP (WDT that)) (S (VP (VBZ encourages) (S (NP (NP (DT the) (NNS supports)) (PP (IN of) (NP (NN weight) (NNS vectors))) (PP (IN in) (NP (NNP RL) (NNS models)))) (VP (TO to) (VP (VB have) (NP (JJ small) (NNS overlap))))) (, ,) (PP (IN by) (S (VP (ADVP (RB simultaneously)) (VBG promoting) (NP (NP (NP (NN near-orthogonality)) (PP (IN among) (NP (NNS vectors)))) (CC and) (NP (NP (NN sparsity)) (PP (IN of) (NP (DT each) (NN vector))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP apply) (NP (DT the) (VBN proposed) (NN regularizer)) (PP (TO to) (NP (NP (CD two) (NNS models)) (: :) (NP (NP (NP (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP NNs)) (-RRB- -RRB-))) (CC and) (NP (NP (JJ sparse) (NN coding)) (PRN (-LRB- -LRB-) (NP (NNP SC)) (-RRB- -RRB-))))))) (, ,) (CC and) (VP (VB develop) (NP (NP (DT an) (JJ efficient) (JJ ADMM-based) (NN algorithm)) (PP (IN for) (NP (JJ regu-) (JJ larized) (NNP SC)))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (JJ various) (NNS datasets)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (NN weight) (NNS vectors)) (VP (VBD learned) (PP (IN under) (NP (PRP$ our) (NN regularizer))))) (VP (VP (VBP are) (ADJP (RBR more) (JJ interpretable))) (CC and) (VP (VBP have) (NP (JJR better) (NN generalization) (NN performance))))))) (. .))
