(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP consider) (NP (JJ self-supervised) (NN representation) (NN learning)) (S (VP (TO to) (VP (VB improve) (NP (NP (NN sample) (NN efficiency)) (PP (IN in) (NP (NP (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (NN forward) (NN prediction) (NN objective)) (PP (IN for) (S (VP (ADVP (RB simultaneously)) (VBG learning) (NP (NP (NNS embeddings)) (PP (IN of) (NP (NP (NNS states)) (CC and) (NP (NN action) (NNS sequences)))))))))) (. .))
(S (NP (DT These) (NNS embeddings)) (VP (VBP capture) (NP (NP (DT the) (NN structure)) (PP (IN of) (NP (NP (DT the) (NN environment) (POS 's)) (NNS dynamics)))) (, ,) (S (VP (VBG enabling) (NP (JJ efficient) (NN policy) (NN learning))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (PRP$ our) (NN action) (VBZ embeddings)) (ADVP (RB alone))) (VP (VB improve) (NP (NP (DT the) (NX (NX (NN sample) (NN efficiency)) (CC and) (NX (JJ peak) (NN performance)))) (PP (IN of) (NP (JJ model-free) (NNP RL))) (PP (IN on) (NP (NP (NN control)) (PP (IN from) (NP (JJ low-dimensional) (NNS states)))))))))) (. .))
(S (PP (IN By) (S (VP (VBG combining) (NP (NN state) (CC and) (NN action) (NNS embeddings))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (JJ efficient) (NN learning)) (PP (IN of) (NP (NP (NN high-quality) (NNS policies)) (PP (IN on) (NP (JJ goal-conditioned) (JJ continuous) (NN control))))) (PP (IN from) (NP (JJ pixel) (NNS observations)))) (PP (IN in) (NP (QP (RB only) (JJ 1-2) (CD million)) (NN environment) (NNS steps)))) (. .))
