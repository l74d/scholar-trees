(S (NP (NP (JJ Conventional) (NN wisdom)) (PP (IN in) (NP (NP (JJ deep) (NN learning) (NNS states)) (SBAR (WHNP (WDT that)) (S (VP (VBG increasing) (NP (NN depth)))))))) (VP (VP (VBZ improves) (NP (NN expressiveness))) (CC but) (VP (VBZ complicates) (NP (NN optimization)))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ suggests) (SBAR (IN that) (S (, ,) (ADVP (RB sometimes)) (, ,) (NP (VBG increasing) (NN depth)) (VP (MD can) (VP (VB speed) (PRT (RP up)) (NP (NN optimization))))))) (. .))
(S (NP (NP (DT The) (NN effect)) (PP (IN of) (NP (NP (NN depth)) (PP (IN on) (NP (NN optimization)))))) (VP (VBZ is) (VP (VBN decoupled) (PP (IN from) (NP (NN expressiveness))) (PP (IN by) (S (VP (VBG focusing) (PP (IN on) (NP (NP (NNS settings)) (SBAR (WHADVP (WRB where))))) (NP (NP (NP (JJ additional) (NNS layers) (NN amount)) (PP (IN to) (NP (NML (NN overparameterization) (HYPH -) (JJ linear)) (JJ neural) (NNS networks)))) (, ,) (NP (DT a) (ADJP (RB well) (HYPH -) (VBN studied)) (NN model)))))))) (. .))
(S (NP (NP (JJ Theoretical) (NN analysis)) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NNS experiments)) (, ,)) (VP (VBP show) (SBAR (IN that) (S (ADVP (RB here)) (NP (NN depth)) (VP (VBZ acts) (PP (IN as) (NP (NP (DT a) (NN preconditioner)) (SBAR (WHNP (WDT which)) (S (VP (MD may) (VP (VB accelerate) (NP (NN convergence)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP prove) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADVP (RB mathematically)) (ADJP (JJ impossible) (S (VP (TO to) (VP (VB obtain) (NP (NP (DT the) (NN acceleration) (NN effect)) (PP (IN of) (NP (NP (NN overparametrization)) (PP (IN via) (NP (NP (NNS gradients)) (PP (IN of) (NP (DT any) (NN regularizer)))))))))))))))) (. .))
