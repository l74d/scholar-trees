(S (NP (NP (JJ Conventional) (NN wisdom)) (PP (IN in) (NP (JJ deep) (NN learning)))) (VP (NNS states) (SBAR (IN that) (S (S (VP (VBG increasing) (NP (NN depth)))) (VP (VP (VBZ improves) (NP (RB expressiveness))) (CC but) (VP (VBZ complicates) (NP (NN optimization))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ suggests) (SBAR (IN that) (, ,) (S (ADVP (RB sometimes)) (, ,) (S (VP (VBG increasing) (NP (NN depth)))) (VP (MD can) (VP (VB speed) (PRT (RP up)) (NP (NN optimization))))))) (. .))
(S (NP (NP (DT The) (NN effect)) (PP (IN of) (NP (NN depth))) (PP (IN on) (NP (NN optimization)))) (VP (VBZ is) (VP (VBN decoupled) (PP (IN from) (NP (NN expressiveness))) (PP (IN by) (S (VP (VBG focusing) (PP (IN on) (NP (NP (NNS settings)) (SBAR (WHADVP (WRB where)) (S (NP (JJ additional) (NNS layers)) (VP (VBP amount) (PP (TO to) (NP (NP (VB overparameterization)) (: -) (NP (NP (JJ linear) (JJ neural) (NNS networks)) (, ,) (NP (DT a) (JJ well-studied) (NN model))))))))))))))) (. .))
(S (NP (NP (JJ Theoretical) (NN analysis)) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NNS experiments)) (, ,)) (VP (VBP show) (SBAR (IN that) (S (ADVP (RB here)) (NP (JJ depth)) (VP (NNS acts) (PP (IN as) (NP (NP (DT a) (NN preconditioner)) (SBAR (WHNP (WDT which)) (S (VP (MD may) (VP (VB accelerate) (NP (NN convergence)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP prove) (SBAR (IN that) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (RB mathematically) (JJ impossible)) (S (VP (TO to) (VP (VB obtain) (NP (NP (DT the) (NN acceleration) (NN effect)) (PP (IN of) (NP (NN overparametrization)))) (PP (IN via) (NP (NP (NNS gradients)) (PP (IN of) (NP (DT any) (NN regularizer)))))))))))) (. .))
