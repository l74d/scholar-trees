(S (NP (UCP (NP (JJ Deep) (NN feedforward)) (CC and) (ADJP (JJ recurrent))) (NNS networks)) (VP (VBP have) (VP (VBN achieved) (NP (JJ impressive) (NNS results)) (PP (IN in) (NP (NP (JJ many) (NN perception)) (CC and) (NP (NML (NN language) (NN processing)) (NNS applications)))))) (. .))
(S (NP (DT This) (NN success)) (VP (VBZ is) (ADVP (RB partially)) (VP (VBN attributed) (PP (IN to) (NP (NP (JJ architectural) (NNS innovations)) (PP (JJ such) (IN as) (NP (ADJP (JJ convolutional) (CC and) (JJ long)) (NML (NML (JJ short) (HYPH -) (NN term)) (NN memory)) (NNS networks))))))) (. .))
(S (NP (NP (DT The) (JJ main) (NN motivation)) (PP (IN for) (NP (DT these) (JJ architectural) (NNS innovations)))) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP they)) (VP (VP (VBP capture) (NP (JJR better) (NN domain) (NN knowledge))) (, ,) (CC and) (ADVP (RB importantly)) (VP (VBP are) (ADJP (ADJP (JJR easier)) (S (VP (TO to) (VP (VB optimize) (PP (IN than) (NP (JJR more) (JJ basic) (NNS architectures)))))))))))) (. .))
(S (ADVP (RB Recently)) (, ,) (NP (NP (ADJP (RBR more) (JJ complex)) (NNS architectures)) (PP (JJ such) (IN as) (NP (NP (JJ Neural) (NN Turing) (NNS Machines)) (CC and) (NP (NN Memory) (NNS Networks))))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN for) (NP (NP (NNS tasks)) (PP (VBG including) (NP (NP (NN question) (NN answering)) (CC and) (NP (JJ general) (NN computation)))))) (, ,) (S (VP (VBG creating) (NP (NP (DT a) (JJ new) (NN set)) (PP (IN of) (NP (NN optimization) (NNS challenges))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP discuss) (NP (NP (DT a) (UCP (NML (JJ low) (HYPH -) (NN overhead)) (CC and) (ADJP (JJ easy) (S (VP (HYPH -) (TO to) (HYPH -) (VP (VB implement) (NP (NP (NN technique)) (PP (IN of) (S (VP (VBG adding) (NP (NN gradient))))))))))) (NN noise)) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP find) (S (VP (TO to) (VP (VB be) (ADJP (RB surprisingly) (JJ effective)) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (DT these) (ADJP (RB very) (JJ deep)) (NNS architectures))))))))))))) (. .))
(S (NP (DT The) (NN technique)) (VP (CONJP (RB not) (RB only)) (VP (VBZ helps) (S (VP (TO to) (VP (VB avoid) (NP (NN overfitting)))))) (, ,) (CONJP (CC but) (RB also)) (VP (MD can) (VP (VB result) (PP (IN in) (NP (JJR lower) (NN training) (NN loss)))))) (. .))
(S (NP (DT This) (NN method)) (ADVP (JJ alone)) (VP (VBZ allows) (NP (DT a) (ADJP (RB fully) (HYPH -) (VBN connected)) (NML (CD 20) (HYPH -) (NN layer)) (JJ deep) (NN network)) (S (VP (TO to) (VP (VB be) (VP (VBN trained) (PP (IN with) (NP (JJ standard) (NN gradient) (NN descent))) (, ,) (S (ADVP (RB even)) (VP (VBG starting) (PP (IN from) (NP (DT a) (JJ poor) (NN initialization)))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP see) (NP (NP (JJ consistent) (NNS improvements)) (PP (IN for) (NP (JJ many) (JJ complex) (NNS models)))) (, ,) (PP (VBG including) (NP (NP (DT a) (NML (CD 72) (NN %)) (JJ relative) (NN reduction)) (PP (IN in) (NP (NP (NN error) (NN rate)) (PP (IN over) (NP (NP (DT a) (ADJP (RB carefully) (HYPH -) (VBN tuned)) (NN baseline)) (PP (IN on) (NP (DT a) (ADJP (NP (JJ challenging) (NN question)) (HYPH -) (VBG answering)) (NN task))))))))))) (, ,) (CC and) (S (NP (NP (DT a) (NN doubling)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ accurate) (JJ binary) (NN multiplication) (NNS models)))))) (VP (VBD learned) (PP (IN across) (NP (CD 7,000) (JJ random) (NNS restarts))))) (. .))
(S (NP (PRP We)) (VP (VBP encourage) (NP (NP (JJ further) (NN application)) (PP (IN of) (NP (DT this) (NN technique)))) (PP (IN to) (NP (JJ additional) (JJ complex) (JJ modern) (NNS architectures)))) (. .))
