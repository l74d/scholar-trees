(S (NP (NP (NNP Deep) (NN feedforward)) (CC and) (NP (NN recurrent) (NNS networks))) (VP (VBP have) (VP (VBN achieved) (NP (JJ impressive) (NNS results)) (PP (IN in) (NP (JJ many) (NN perception) (CC and) (NN language) (NN processing) (NNS applications))))) (. .))
(S (NP (DT This) (NN success)) (VP (VBZ is) (VP (ADVP (RB partially)) (VBN attributed) (PP (TO to) (NP (NP (JJ architectural) (NNS innovations)) (PP (JJ such) (IN as) (NP (ADJP (ADJP (JJ convolutional)) (CC and) (ADJP (JJ long) (JJ short-term))) (NN memory) (NNS networks))))))) (. .))
(S (NP (NP (DT The) (JJ main) (NN motivation)) (PP (IN for) (NP (DT these) (JJ architectural) (NNS innovations)))) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP they)) (VP (VP (VBP capture) (NP (JJR better) (NN domain) (NN knowledge))) (, ,) (CC and) (VP (ADVP (RB importantly)) (VBP are) (ADJP (ADJP (JJR easier) (SBAR (S (VP (TO to) (VP (VB optimize)))))) (PP (IN than) (NP (ADJP (JJR more) (JJ basic)) (NNS architectures))))))))) (. .))
(S (ADVP (RB Recently)) (, ,) (NP (NP (ADJP (RBR more) (JJ complex)) (NNS architectures)) (PP (JJ such) (IN as) (NP (NP (JJ Neural) (NNP Turing) (NNPS Machines)) (CC and) (NP (NNP Memory) (NNP Networks))))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN for) (NP (NP (NNS tasks)) (PP (VBG including) (NP (NP (NN question) (NN answering)) (CC and) (NP (JJ general) (NN computation)))))) (, ,) (S (VP (VBG creating) (NP (NP (DT a) (JJ new) (NN set)) (PP (IN of) (NP (NN optimization) (NNS challenges))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP discuss) (NP (NP (DT a) (ADJP (JJ low-overhead) (CC and) (JJ easy-to-implement)) (NN technique)) (PP (IN of) (S (VP (VBG adding) (NP (NN gradient) (NN noise))))) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP find) (S (VP (TO to) (VP (VB be) (ADJP (RB surprisingly) (JJ effective)) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (DT these) (ADJP (RB very) (JJ deep)) (NNS architectures))))))))))))) (. .))
(S (NP (DT The) (NN technique)) (VP (CONJP (RB not) (RB only)) (VP (VBZ helps) (S (VP (TO to) (VP (VB avoid) (NP (NN overfitting)))))) (, ,) (CONJP (CC but) (RB also)) (VP (MD can) (VP (VB result) (PP (IN in) (NP (JJR lower) (NN training) (NN loss)))))) (. .))
(S (NP (NP (DT This) (NN method)) (ADVP (RB alone))) (VP (VBZ allows) (S (NP (DT a) (JJ fully-connected) (JJ 20-layer) (JJ deep) (NN network)) (VP (TO to) (VP (VB be) (VP (VBN trained) (PP (IN with) (NP (JJ standard) (NN gradient) (NN descent))) (, ,) (S (VP (ADVP (RB even)) (VBG starting) (PP (IN from) (NP (DT a) (JJ poor) (NN initialization)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP see) (NP (NP (JJ consistent) (NNS improvements)) (PP (IN for) (NP (JJ many) (JJ complex) (NNS models))) (, ,) (PP (VBG including) (NP (NP (NP (DT a) (ADJP (CD 72) (NN %)) (JJ relative) (NN reduction)) (PP (IN in) (NP (NN error) (NN rate))) (PP (IN over) (NP (NP (DT a) (JJ carefully-tuned) (NN baseline)) (PP (IN on) (NP (DT a) (JJ challenging) (JJ question-answering) (NN task)))))) (, ,) (CC and) (NP (NP (DT a) (NN doubling)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ accurate) (JJ binary) (NN multiplication) (NNS models))) (VP (VBN learned) (PP (IN across) (NP (CD 7,000) (NN random) (NNS restarts))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP encourage) (NP (NP (JJ further) (NN application)) (PP (IN of) (NP (DT this) (NN technique))) (PP (TO to) (NP (JJ additional) (JJ complex) (JJ modern) (NNS architectures))))) (. .))
