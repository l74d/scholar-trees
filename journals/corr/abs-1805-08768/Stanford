(S (ADVP (RB Currently)) (, ,) (NP (ADJP (RB progressively) (JJR larger)) (JJ deep) (JJ neural) (NNS networks)) (VP (VBP are) (VP (VBN trained) (PP (IN on) (S (ADVP (RB ever)) (VP (VBG growing) (NP (NNS data) (NNS corpora))))))) (. .))
(S (SBAR (IN As) (S (NP (DT this) (NN trend)) (VP (VBZ is) (ADVP (RB only)) (VP (VBG going) (S (VP (TO to) (VP (VB increase) (PP (IN in) (NP (DT the) (NN future)))))))))) (, ,) (NP (VBN distributed) (NN training) (NNS schemes)) (VP (VBP are) (VP (VBG becoming) (ADJP (RB increasingly) (JJ relevant)))) (. .))
(S (NP (NP (DT A) (JJ major) (NN issue)) (PP (IN in) (NP (VBN distributed) (NN training)))) (VP (VBZ is) (NP (NP (DT the) (JJ limited) (NN communication) (NN bandwidth)) (PP (IN between) (NP (NP (VBG contributing) (NNS nodes)) (CC or) (NP (NP (ADJP (JJ prohibitive)) (NN communication) (NN cost)) (PP (IN in) (NP (JJ general)))))))) (. .))
(S (NP (DT These) (NNS challenges)) (VP (VBP become) (ADJP (ADVP (RB even) (RBR more)) (JJ pressing)) (, ,) (SBAR (IN as) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NN computation) (NNS nodes)))) (VP (VBZ increases))))) (. .))
(S (S (VP (TO To) (VP (VB counteract) (NP (DT this) (NN development))))) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ sparse) (JJ binary) (NN compression) (PRN (-LRB- -LRB-) (NP (NN SBC)) (-RRB- -RRB-))) (, ,) (NP (NP (DT a) (NN compression) (NN framework)) (SBAR (WHNP (WDT that)) (S (VP (VBZ allows) (PP (IN for) (NP (NP (DT a) (JJ drastic) (NN reduction)) (PP (IN of) (NP (NP (NN communication) (NN cost)) (PP (IN for) (NP (VBN distributed) (NN training))))))))))))) (. .))
(S (NP (NNP SBC)) (VP (VBZ combines) (NP (NP (NP (VBG existing) (NNS techniques)) (PP (IN of) (NP (NP (NN communication) (NN delay)) (CC and) (NP (NN gradient) (NN sparsification)))) (PP (IN with) (NP (DT a) (JJ novel) (NN binarization) (NN method)))) (CC and) (NP (NP (JJ optimal) (NN weight) (NN update)) (VP (VBG encoding) (S (VP (TO to) (VP (VB push) (NP (NN compression) (NNS gains)) (PP (IN to) (NP (JJ new) (NNS limits)))))))))) (. .))
(S (PP (IN By) (S (VP (VBG doing) (ADVP (RB so))))) (, ,) (NP (PRP$ our) (NN method)) (ADVP (RB also)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (ADVP (RB smoothly)) (VP (VB trade) (PRT (HYPH -) (RP off)) (NP (NP (NN gradient) (NN sparsity)) (CC and) (NP (JJ temporal) (NN sparsity))) (S (VP (TO to) (VP (VB adapt) (PP (IN to) (NP (NP (DT the) (NNS requirements)) (PP (IN of) (NP (DT the) (NN learning) (NN task)))))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (, ,) (SBAR (IN that) (S (NP (NNP SBC)) (VP (MD can) (VP (VB reduce) (NP (DT the) (JJ upstream) (NN communication)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (ADJP (JJ convolutional) (CC and) (JJ recurrent)) (NML (JJ neural) (NN network)) (NNS architectures))))) (PP (IN by) (NP (NP (QP (JJR more) (IN than) (CD four)) (NNS orders)) (PP (IN of) (NP (NN magnitude))))))))) (PP (IN without) (S (ADVP (RB significantly)) (VP (VBG harming) (NP (DT the) (NN convergence) (NN speed)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (ADJP (RB forward) (HYPH -) (JJ backward)) (NNS passes))))))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ latter) (NN case))) (, ,) (NP (NP (DT the) (JJ total) (JJ upstream) (NN communication)) (VP (VBN required))) (VP (VBZ is) (VP (VBN cut) (PP (IN from) (NP (CD 125) (NNS terabytes))) (PP (IN to) (NP (NP (CD 3.35) (NNS gigabytes)) (PP (IN for) (NP (DT every) (VBG participating) (NN client))))))) (. .))
