(S (NP (NP (JJ High) (NN network) (NN communication) (NN cost)) (PP (IN for) (S (VP (VBG synchronizing) (NP (NNS gradients) (CC and) (NNS parameters)))))) (VP (VBZ is) (NP (NP (DT the) (JJ well-known) (NN bottleneck)) (PP (IN of) (NP (JJ distributed) (NN training))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NNP TernGrad)) (SBAR (WHNP (WDT that)) (S (VP (VBZ uses) (NP (JJ ternary) (NNS gradients)) (S (VP (TO to) (VP (VB accelerate) (NP (JJ distributed) (JJ deep) (NN learning)) (PP (IN in) (NP (NNS data) (NN parallelism))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ requires) (NP (NP (QP (RB only) (CD three)) (JJ numerical) (NNS levels)) (PRN (-LRB- -LCB-) (NP (NN -1,0,1)) (-RRB- -RCB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (ADVP (RB aggressively)) (VB reduce) (NP (DT the) (NN communication) (NN time)))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB mathematically)) (VBP prove) (NP (NP (DT the) (NN convergence)) (PP (IN of) (NP (NNP TernGrad)))) (PP (IN under) (NP (NP (DT the) (NN assumption)) (PP (IN of) (NP (NP (DT a) (NN bound)) (PP (IN on) (NP (NNS gradients)))))))) (. .))
(S (S (VP (VBN Guided) (PP (IN by) (NP (DT the) (NN bound))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ layer-wise) (NN ternarizing)) (CC and) (NP (NN gradient) (NN clipping))) (S (VP (TO to) (VP (VB improve) (NP (PRP$ its) (NN convergence)))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG applying) (NP (NNP TernGrad)) (PP (IN on) (NP (NNP AlexNet))))) (VP (VP (VBZ does) (RB not) (VP (VB incur) (NP (DT any) (JJ accuracy) (NN loss)))) (CC and) (VP (MD can) (ADVP (RB even)) (VP (VB improve) (NP (NN accuracy)))))))) (. .))
(S (NP (NP (DT The) (NN accuracy) (NN loss)) (PP (IN of) (NP (NNP GoogLeNet))) (VP (VBN induced) (PP (IN by) (NP (NNP TernGrad))))) (VP (VBZ is) (NP (QP (JJR less) (IN than) (CD 2)) (NN %)) (PP (IN on) (NP (NN average)))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (DT a) (NN performance) (NN model)) (VP (VBZ is) (VP (VBN proposed) (S (VP (TO to) (VP (VB study) (NP (NP (DT the) (NN scalability)) (PP (IN of) (NP (NNP TernGrad))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (NP (NP (JJ significant) (NN speed) (NNS gains)) (PP (IN for) (NP (JJ various) (JJ deep) (JJ neural) (NNS networks))))) (. .))
(S (NP (PRP$ Our) (NN source) (NN code)) (VP (VBZ is) (ADJP (JJ available))) (. .))
