(S (NP (NP (NN Reduction)) (PP (IN of) (NP (NN training) (NN time)))) (VP (VBZ is) (NP (DT an) (JJ important) (NN issue)) (PP (IN in) (NP (NP (JJ many) (NNS tasks)) (PP (IN like) (NP (NN patent) (NN translation))) (VP (VBG involving) (NP (JJ neural) (NNS networks)))))) (. .))
(S (NP (NP (NNP Data) (NN parallelism)) (CC and) (NP (NN model) (NN parallelism))) (VP (VBP are) (NP (NP (CD two) (JJ common) (NNS approaches)) (PP (IN for) (S (VP (VBG reducing) (NP (NN training) (NN time)) (S (VP (VBG using) (NP (NP (JJ multiple) (NNS graphics) (VBG processing) (NNS units)) (PRN (-LRB- -LRB-) (NP (NNP GPUs)) (-RRB- -RRB-))) (PP (IN on) (NP (CD one) (NN machine)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ hybrid) (NN data-model) (JJ parallel) (NN approach)) (PP (IN for) (NP (NN sequence-to-sequence) (PRN (-LRB- -LRB-) (NNP Seq2Seq) (-RRB- -RRB-)) (NN recurrent) (JJ neural) (NN network) (PRN (-LRB- -LRB-) (NNP RNN) (-RRB- -RRB-)) (NN machine) (NN translation))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP apply) (NP (DT a) (NN model) (JJ parallel) (NN approach)) (PP (TO to) (NP (NP (DT the) (NNP RNN) (JJ encoder-decoder) (NN part)) (PP (IN of) (NP (DT the) (NNP Seq2Seq) (NN model)))))) (CC and) (VP (NP (DT a) (NN data) (RB parallel) (NN approach)) (PP (TO to) (NP (NP (DT the) (JJ attention-softmax) (NN part)) (PP (IN of) (NP (DT the) (NN model))))))) (. .))
(S (NP (PRP We)) (VP (VBD achieved) (NP (NP (NP (DT a) (NN speed-up)) (PP (IN of) (NP (QP (CD 4.13) (TO to) (CD 4.20)) (NNS times))))) (SBAR (WHADVP (WRB when)) (S (VP (VBG using) (NP (CD 4) (NNP GPUs))))) (PP (VBN compared) (PP (IN with) (NP (NP (DT the) (NN training) (NN speed)) (SBAR (WHADVP (WRB when)) (S (VP (VBG using) (NP (CD 1) (NNP GPU)))))))) (PP (IN without) (S (VP (VBG affecting) (NP (NN machine) (NN translation) (NN accuracy)) (SBAR (IN as) (S (VP (VBN measured) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NNP BLEU) (NNS scores)))))))))))) (. .))
