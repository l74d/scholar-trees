(S (SBAR (WHADVP (WRB When)) (S (VP (VBG optimizing) (NP (NP (JJ over-parameterized) (NNS models)) (, ,) (PP (JJ such) (IN as) (NP (JJ deep) (JJ neural) (NNS networks))) (, ,))))) (NP (NP (DT a) (JJ large) (NN set)) (PP (IN of) (NP (NNS parameters)))) (VP (MD can) (VP (VB achieve) (NP (CD zero) (VBG training) (NN error)))) (. .))
(S (PP (IN In) (NP (JJ such) (NNS cases))) (, ,) (NP (NP (DT the) (NN choice)) (PP (IN of) (NP (NP (DT the) (NN optimization) (NN algorithm)) (CC and) (NP (PRP$ its) (JJ respective) (NNS hyper-parameters))))) (VP (NNS introduces) (NP (NP (NNS biases)) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB lead) (PP (TO to) (NP (NP (VB convergence)) (PP (TO to) (NP (NP (JJ specific) (NNS minimizers)) (PP (IN of) (NP (DT the) (NN objective))))))))))))) (. .))
(S (ADVP (RB Consequently)) (, ,) (NP (DT this) (NN choice)) (VP (MD can) (VP (VB be) (VP (VBN considered) (PP (IN as) (NP (NP (DT an) (JJ implicit) (NN regularization)) (PP (IN for) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ over-parametrized) (NNS models)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP push) (NP (DT this) (NN idea)) (ADVP (RB further)) (PP (IN by) (S (VP (VBG studying) (NP (NP (DT the) (JJ discrete) (NN gradient) (NNS dynamics)) (PP (IN of) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (DT a) (JJ two-layer) (JJ linear) (NN network))) (PP (IN with) (NP (DT the) (JJ least-squares) (NN loss)))))))))) (. .))
(S (S (VP (VBG Using) (NP (DT a) (NN time) (NN rescaling)))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (, ,) (S (PP (IN with) (NP (NP (DT a) (VBG vanishing) (NN initialization)) (CC and) (NP (DT a) (JJ small) (JJ enough) (NN step) (NN size)))) (, ,) (NP (DT this) (NNS dynamics)) (VP (ADVP (RB sequentially)) (VBZ learns) (NP (NP (DT the) (NNS solutions)) (PP (IN of) (NP (NP (DT a) (JJ reduced-rank) (NN regression)) (PP (IN with) (NP (DT a) (ADJP (RB gradually) (VBG increasing)) (NN rank)))))))))) (. .))
