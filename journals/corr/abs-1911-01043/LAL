(S (SBAR (WHADVP (WRB When)) (S (NP (DT an) (NN online) (NN learning) (NN algorithm)) (VP (VBZ is) (VP (VBN used) (S (VP (TO to) (VP (VB estimate) (NP (NP (DT the) (JJ unknown) (NNS parameters)) (PP (IN of) (NP (DT a) (NN model))))))))))) (, ,) (NP (NP (DT the) (NNS signals)) (VP (VBG interacting) (PP (IN with) (NP (DT the) (NN parameter) (NNS estimates))))) (VP (MD should) (RB not) (VP (VB decay) (ADVP (ADVP (RB too) (RB quickly)) (SBAR (IN for) (S (NP (DT the) (JJ optimal) (NNS values)) (VP (TO to) (VP (VB be) (VP (VBN discovered) (ADVP (RB correctly)))))))))) (. .))
(S (S (NP (DT This) (NN requirement)) (VP (VBZ is) (VP (VBN referred) (PP (TO to)) (PP (IN as) (NP (NP (NN persistency)) (PP (IN of) (NP (NN excitation)))))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBZ arises) (PP (IN in) (NP (NP (JJ various) (NNS contexts)) (, ,) (PP (JJ such) (IN as) (NP (NP (NP (NN optimization)) (PP (IN with) (NP (JJ stochastic) (NN gradient) (NNS methods)))) (, ,) (NP (NP (NN exploration)) (PP (IN for) (NP (JJ multi-armed) (NNS bandits)))) (, ,) (CC and) (NP (NP (JJ adaptive) (NN control)) (PP (IN of) (NP (JJ dynamical) (NNS systems)))))))))) (. .))
(S (S (SBAR (IN While) (S (VP (VBG training) (NP (DT a) (JJ neural) (NN network))))) (, ,) (NP (NP (DT the) (JJ iterative) (NN optimization) (NN algorithm)) (VP (VBN involved))) (ADVP (RB also)) (VP (VBZ creates) (NP (DT an) (NN online) (NN learning) (NN problem)))) (, ,) (CC and) (S (ADVP (RB consequently)) (, ,) (S (NP (NP (JJ correct) (NN estimation)) (PP (IN of) (NP (DT the) (JJ optimal) (NNS parameters)))) (VP (VBZ requires) (NP (NP (JJ persistent) (NN excitation)) (PP (IN of) (NP (DT the) (NN network) (NNS weights))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (S (NP (PRP we)) (VP (VBP analyze) (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (DT the) (JJ gradient) (NN descent) (NN algorithm)))) (SBAR (IN while) (S (VP (VBG training) (NP (NP (DT a) (JJ two-layer) (JJ neural) (NN network)) (PP (IN with) (NP (NP (CD two) (JJ different) (NN loss) (NNS functions)) (, ,) (NP (NP (DT the) (JJ squared-error) (NN loss)) (CC and) (NP (DT the) (JJ cross-entropy) (NN loss))))))))))) (: ;) (CC and) (S (NP (PRP we)) (VP (VB obtain) (NP (NP (NNS conditions)) (SBAR (S (VP (TO to) (VP (VB guarantee) (NP (NP (JJ persistent) (NN excitation)) (PP (IN of) (NP (DT the) (NN network) (NNS weights))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VBP show) (SBAR (SBAR (IN that) (S (NP (DT these) (NNS conditions)) (VP (VBP are) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB satisfy)))))) (SBAR (WHADVP (WRB when)) (S (NP (DT a) (NN multi-layer) (NN network)) (VP (VBZ is) (VP (VBN trained) (PP (IN for) (NP (DT a) (NN classification) (NN task)))))))))) (, ,) (SBAR (IN for) (S (NP (NP (DT the) (NNS signals)) (PP (IN in) (NP (NP (DT the) (JJ intermediate) (NNS layers)) (PP (IN of) (NP (DT the) (NN network)))))) (VP (VP (JJ become) (ADJP (JJ low-dimensional)) (PP (IN during) (NP (NN training)))) (CC and) (VP (NN fail) (S (VP (TO to) (VP (VB remain) (ADJP (RB persistently) (VBG exciting))))))))))) (. .))
(S (S (VP (TO To) (VP (VB provide) (NP (DT a) (NN remedy))))) (, ,) (NP (PRP we)) (VP (VP (VBP delve) (PP (IN into) (NP (NP (DT the) (JJ classical) (NN regularization) (NNS terms)) (VP (VBN used) (PP (IN for) (NP (JJ linear) (NNS models))))))) (, ,) (VP (VB reinterpret) (NP (PRP them)) (PP (IN as) (NP (NP (DT a) (NN means)) (SBAR (S (VP (TO to) (VP (VB ensure) (NP (NP (JJ persistent) (NN excitation)) (PP (IN of) (NP (DT the) (NN model) (NNS parameters))))))))))) (, ,) (CC and) (VP (VB propose) (NP (NP (DT an) (NN algorithm)) (PP (IN for) (NP (JJ neural) (NNS networks)))) (PP (IN by) (S (VP (VBG building) (NP (DT an) (NN analogy))))))) (. .))
(S (NP (NP (DT The) (NNS results)) (PP (IN in) (NP (DT this) (NN work)))) (VP (VBD shed) (NP (DT some) (NN light)) (PP (IN on) (SBAR (SBAR (WHADVP (WRB why)) (S (NP (JJ adversarial) (NNS examples)) (VP (VBP have) (VP (VBN become) (NP (DT a) (JJ challenging) (NN problem)) (PP (IN for) (NP (JJ neural) (NNS networks))))))) (, ,) (SBAR (WHADVP (WRB why)) (S (S (ADVP (RB merely)) (VBG augmenting) (NP (VBG training) (NNS data) (NNS sets))) (VP (MD will) (RB not) (VP (VB be) (NP (NP (DT an) (JJ effective) (NN approach)) (SBAR (S (VP (TO to) (VP (VB address) (NP (PRP them))))))))))) (, ,) (CC and) (SBAR (WHADVP (WRB why)) (S (NP (EX there)) (VP (MD may) (RB not) (VP (VB exist) (NP (NP (DT a) (JJ data-independent) (NN regularization) (NN term)) (PP (IN for) (NP (NP (JJ neural) (NNS networks)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP involve) (NP (RB only) (NP (DT the) (NN model) (NNS parameters)) (CC but) (RB not) (NP (DT the) (NN training) (NNS data)))))))))))))))) (. .))
