(S (S (VP (VBG Using) (NP (DT a) (ADJP (NN sparsity) (VBG inducing)) (NN penalty)) (PP (IN in) (NP (NP (JJ artificial) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP ANNs)) (-RRB- -RRB-)))))) (VP (VBZ avoids) (NP (JJ over-fitting)) (, ,) (PP (ADVP (RB especially)) (IN in) (NP (NP (NNS situations)) (SBAR (WHADVP (WRB where)) (S (S (NP (NN noise)) (VP (VBZ is) (ADJP (JJ high)))) (CC and) (S (NP (DT the) (NN training) (NN set)) (VP (VBZ is) (ADJP (JJ small)) (PP (IN in) (NP (NP (NN comparison)) (PP (TO to) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS features)))))))))))))) (. .))
(S (PP (IN For) (NP (JJ linear) (NNS models))) (, ,) (NP (PDT such) (DT an) (NN approach)) (ADVP (RB provably)) (ADVP (RB also)) (VP (VBZ recovers) (NP (DT the) (JJ important) (NNS features)) (PP (IN with) (NP (JJ high) (NN probability))) (PP (IN in) (NP (NP (NNS regimes)) (PP (IN for) (NP (DT a) (JJ well-chosen) (NN penalty) (NN parameter)))))) (. .))
(S (NP (NP (DT The) (JJ typical) (NN way)) (PP (IN of) (S (VP (VBG setting) (NP (DT the) (NN penalty) (NN parameter)))))) (VP (VBZ is) (PP (IN by) (S (VP (VP (VBG splitting) (NP (DT the) (NN data) (NN set))) (CC and) (VP (VBG performing) (NP (NP (DT the) (NN cross-validation)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (ADJP (PRN (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (ADJP (RB computationally) (JJ expensive))) (CC and) (ADJP (PRN (-LRB- -LRB-) (CD 2) (-RRB- -RRB-)) (ADJP (RB not) (JJ desirable)))) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN data) (NN set)) (VP (VBZ is) (ADJP (RB already) (JJ small) (S (VP (TO to) (VP (VP (VB be) (ADVP (JJ further)) (NN split)) (PRN (-LRB- -LRB-) (PP (IN for) (NP (NN example))) (, ,) (NP (JJ whole-genome) (NN sequence) (NNS data)) (-RRB- -RRB-)))))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN study))) (, ,) (NP (PRP we)) (VP (VB establish) (NP (NP (DT the) (JJ theoretical) (NN foundation)) (SBAR (S (VP (TO to) (VP (VB select) (NP (DT the) (NN penalty) (NN parameter)) (PP (IN without) (NP (NN cross-validation))))))) (PP (VBN based) (PP (IN on) (S (VP (VBG bounding) (PP (IN with) (NP (DT a) (JJ high) (NN probability))) (NP (NP (DT the) (JJ infinite) (NN norm)) (PP (IN of) (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (DT the) (NN loss) (NN function))) (PP (IN at) (NP (CD zero))))) (PP (IN under) (NP (DT the) (JJ zero-feature) (NN assumption)))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ is) (NP (NP (DT a) (NN generalization)) (PP (IN of) (NP (NP (DT the) (JJ universal) (NN threshold)) (PP (IN of) (NP (NP (NNP Donoho) (CC and) (NNP Johnstone)) (PRN (-LRB- -LRB-) (NP (CD 1994)) (-RRB- -RRB-)))))) (PP (TO to) (NP (VB nonlinear) (NNP ANN) (NN learning))))) (. .))
(S (S (NP (PRP We)) (VP (VBP perform) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ comprehensive) (NNP Monte) (NNP Carlo) (NNS simulations)))) (PP (IN on) (NP (DT a) (JJ simple) (NN model))))) (, ,) (CC and) (S (NP (DT the) (JJ numerical) (NNS results)) (VP (VBP show) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (DT the) (VBN proposed) (NN approach)))))) (. .))
