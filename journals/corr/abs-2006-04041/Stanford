(SINV (VP (VBG Using) (NP (DT a) (NN sparsity)) (S (VP (VBG inducing) (NP (NN penalty)) (PP (IN in) (NP (NP (JJ artificial) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS ANNs)) (-RRB- -RRB-)))))) (VP (VBZ avoids)) (NP (NP (NN over-fitting)) (, ,) (RRC (ADVP (RB especially)) (PP (IN in) (NP (NP (NNS situations)) (SBAR (WHADVP (WRB where)) (S (S (NP (NN noise)) (VP (VBZ is) (ADJP (JJ high)))) (CC and) (S (NP (DT the) (NN training) (NN set)) (VP (VBZ is) (ADJP (JJ small) (PP (IN in) (NP (NN comparison)))) (PP (IN to) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS features))))))))))))) (. .))
(S (PP (IN For) (NP (JJ linear) (NNS models))) (, ,) (NP (PDT such) (DT an) (NN approach)) (ADVP (RB provably)) (ADVP (RB also)) (VP (VBZ recovers) (NP (DT the) (JJ important) (NNS features)) (PP (IN with) (NP (NP (JJ high) (NN probability)) (PP (IN in) (NP (NP (NNS regimes)) (PP (IN for) (NP (DT a) (ADJP (RB well) (HYPH -) (VBN chosen)) (NN penalty) (NN parameter)))))))) (. .))
(S (NP (NP (DT The) (JJ typical) (NN way)) (PP (IN of) (S (VP (VBG setting) (NP (DT the) (NN penalty) (NN parameter)))))) (VP (VBZ is) (PP (IN by) (S (VP (VP (VBG splitting) (NP (DT the) (NNS data) (NN set))) (CC and) (VP (VBG performing) (NP (NP (DT the) (NN cross-validation)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (NP (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (RRC (ADVP (RB computationally)) (ADJP (JJ expensive)))) (CC and) (NP (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (NP (NP (RB not) (JJ desirable)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NNS data) (NN set)) (VP (VBZ is) (ADJP (RB already) (JJ small)))))) (S (VP (TO to) (VP (VB be) (NP (NP (JJ further) (NN split)) (-LRB- -LRB-) (PP (IN for) (NP (NP (NN example)) (, ,) (NP (NML (JJ whole) (HYPH -) (NN genome)) (NN sequence) (NNS data)))) (-RRB- -RRB-)))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN study))) (, ,) (NP (PRP we)) (VP (VBP establish) (NP (DT the) (JJ theoretical) (NN foundation)) (S (VP (TO to) (VP (VB select) (NP (DT the) (NN penalty) (NN parameter)) (PP (IN without) (NP (NN cross-validation))) (PP (VBN based) (PP (IN on) (S (VP (VBG bounding) (PP (IN with) (NP (DT a) (JJ high) (NN probability))) (NP-TMP (NP (DT the) (JJ infinite) (NN norm)) (PP (IN of) (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (NP (DT the) (NN loss) (NN function)) (PP (IN at) (NP (CD zero)))))))) (PP (IN under) (NP (DT the) (NML (CD zero) (HYPH -) (NN feature)) (NN assumption))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ is) (NP (NP (DT a) (NN generalization)) (PP (IN of) (NP (NP (DT the) (JJ universal) (NN threshold)) (PP (IN of) (NP (NNP Donoho) (CC and) (NNP Johnstone) (PRN (-LRB- -LRB-) (NP (CD 1994)) (-RRB- -RRB-)))))) (PP (IN to) (NP (JJ nonlinear) (NN ANN) (NN learning))))) (. .))
(S (S (NP (PRP We)) (VP (VBP perform) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ comprehensive) (NML (NNP Monte) (NNP Carlo)) (NNS simulations)))) (PP (IN on) (NP (DT a) (JJ simple) (NN model))))) (, ,) (CC and) (S (NP (DT the) (JJ numerical) (NNS results)) (VP (VBP show) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (DT the) (VBN proposed) (NN approach)))))) (. .))
