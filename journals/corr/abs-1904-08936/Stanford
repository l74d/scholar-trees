(S (NP (NP (NP (JJ Recurrent) (JJ Neural) (NNS Networks) (PRN (-LRB- -LRB-) (NP (NN RNN)) (-RRB- -RRB-))) (, ,) (NP (NP (NML (NNP Long) (NNP Short) (HYPH -) (NNP Term)) (NNP Memory) (NNP Networks)) (-LRB- -LRB-) (NP (NNP LSTM)) (-RRB- -RRB-)) (, ,) (CC and) (NP (NN Memory) (NNS Networks))) (SBAR (WHNP (WDT which)) (S (VP (VBP contain) (NP (NN memory)))))) (VP (VBP are) (ADVP (RB popularly)) (VP (VBN used) (S (VP (TO to) (VP (VB learn) (NP (NNS patterns)) (PP (IN in) (NP (JJ sequential) (NNS data)))))))) (. .))
(S (NP (JJ Sequential) (NNS data)) (VP (VBZ has) (NP (NP (JJ long) (NNS sequences)) (SBAR (WHNP (WDT that)) (S (VP (VBP hold) (NP (NNS relationships))))))) (. .))
(S (NP (NN RNN)) (VP (VP (MD can) (VP (VB handle) (NP (JJ long) (NNS sequences)))) (CC but) (VP (VBZ suffers) (PP (IN from) (NP (NP (DT the) (VBG vanishing)) (CC and) (NP (VBG exploding) (NN gradient) (NNS problems)))))) (. .))
(S (SBAR (IN While) (S (NP (NP (NNP LSTM)) (CC and) (NP (JJ other) (NN memory) (NNS networks))) (VP (VBP address) (NP (DT this) (NN problem))))) (, ,) (NP (PRP they)) (VP (VBP are) (RB not) (ADJP (JJ capable)) (PP (IN of) (S (VP (VBG handling) (NP (JJ long) (NNS sequences))))) (PRN (-LRB- -LRB-) (NP (NP (QP (CD 50) (CC or) (JJR more)) (NNS data) (NNS points)) (NP (JJ long) (NN sequence) (NNS patterns))) (-RRB- -RRB-))) (. .))
(S (NP (NP (NNP Language)) (VP (VBG modelling) (S (VP (VBG requiring) (NP (NN learning)) (PP (IN from) (NP (JJR longer) (NNS sequences))))))) (VP (VBP are) (VP (VBN affected) (PP (IN by) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NP (JJR more) (NN information)) (PP (IN in) (NP (NN memory))))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VP (VBZ introduces) (NP (NP (NML (NNP Long) (NNP Term)) (NNP Memory) (NN network) (PRN (-LRB- -LRB-) (NP (NN LTM)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB tackle) (NP (NP (DT the) (VBG exploding)) (CC and) (NP (VBG vanishing) (NN gradient) (NNS problems))))))))) (CC and) (VP (VBZ handles) (NP (JJ long) (NNS sequences)) (PP (IN without) (S (VP (VBG forgetting)))))) (. .))
(S (NP (NN LTM)) (VP (VP (VBZ is) (VP (VBN designed) (S (VP (TO to) (VP (VB scale) (NP (NNS data)) (PP (IN in) (NP (DT the) (NN memory)))))))) (CC and) (VP (VBZ gives) (NP (DT a) (JJR higher) (NN weight)) (PP (IN to) (NP (NP (DT the) (NN input)) (PP (IN in) (NP (DT the) (NN sequence))))))) (. .))
(FRAG (NP (NN LTM) (NN avoid)) (VP (VBG overfitting) (PP (IN by) (S (VP (VBG scaling) (NP (DT the) (NN cell) (NN state)) (PP (IN after) (S (VP (VBG achieving) (NP (DT the) (JJ optimal) (NNS results))))))))) (. .))
(S (S (NP (DT The) (NN LTM)) (VP (VBZ is) (VP (VBN tested) (PP (IN on) (NP (NNP Penn) (NN treebank) (NN dataset)))))) (, ,) (CC and) (S (NP (NN Text8) (NN dataset) (CC and) (NN LTM)) (VP (VBZ achieves) (NP (NP (NN test) (NNS perplexities)) (PP (IN of) (NP (CD 83) (CC and) (CD 82)))) (ADVP (RB respectively)))) (. .))
(S (S (NP (CD 650) (NN LTM) (NNS cells)) (VP (VBD achieved) (NP (NP (DT a) (NN test) (NN perplexity)) (PP (IN of) (NP (CD 67)))) (PP (IN for) (NP (NNP Penn) (NN treebank))))) (, ,) (CC and) (S (NP (CD 600) (NNS cells)) (VP (VBD achieved) (NP (NP (DT a) (NN test) (NN perplexity)) (PP (IN of) (NP (CD 77)))) (PP (IN for) (NP (NN Text8))))) (. .))
(S (NP (NNP LTM)) (VP (VBZ achieves) (NP (NP (NN state)) (PP (IN of) (NP (DT the) (NN art) (NNS results)))) (PP (IN by) (S (ADVP (RB only)) (VP (VBG using) (NP (CD ten) (JJ hidden) (NN LTM) (NNS cells)) (PP (IN for) (NP (DT both) (NNS datasets))))))) (. .))
