(S (NP (NP (NP (JJ Recurrent) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP RNN)) (-RRB- -RRB-))) (, ,) (NP (NP (JJ Long) (JJ Short-Term) (NN Memory) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP LSTM)) (-RRB- -RRB-))) (, ,) (CC and) (NP (NP (NNP Memory) (NNP Networks)) (SBAR (WHNP (WDT which)) (S (VP (VBP contain) (NP (NN memory))))))) (VP (VBP are) (ADVP (RB popularly)) (VP (VBN used) (S (VP (TO to) (VP (VB learn) (NP (NNS patterns)) (PP (IN in) (NP (JJ sequential) (NNS data)))))))) (. .))
(S (NP (NNP Sequential) (NN data)) (VP (VBZ has) (NP (NP (RB long) (NNS sequences)) (SBAR (WHNP (IN that)) (S (VP (VBP hold) (NP (NNS relationships))))))) (. .))
(S (NP (NNP RNN)) (VP (VP (MD can) (VP (VB handle) (NP (JJ long) (NNS sequences)))) (CC but) (VP (NNS suffers) (PP (IN from) (NP (DT the) (NN vanishing) (CC and) (VBG exploding) (NN gradient) (NNS problems))))) (. .))
(S (SBAR (IN While) (S (NP (NP (NNP LSTM)) (CC and) (NP (JJ other) (NN memory) (NNS networks))) (VP (VBP address) (NP (DT this) (NN problem))))) (, ,) (NP (PRP they)) (VP (VBP are) (RB not) (ADJP (JJ capable) (PP (IN of) (S (VP (VBG handling) (NP (NP (JJ long) (NNS sequences)) (PRN (-LRB- -LRB-) (NP (NP (QP (CD 50) (CC or) (JJR more)) (NNS data) (NNS points)) (JJ long) (NN sequence) (NNS patterns)) (-RRB- -RRB-)))))))) (. .))
(S (NP (NP (NN Language) (VBG modelling)) (VP (VBG requiring) (NP (NP (VBG learning)) (PP (IN from) (NP (JJR longer) (NNS sequences)))))) (VP (VBP are) (VP (VBN affected) (PP (IN by) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NP (JJR more) (NN information)) (PP (IN in) (NP (NN memory))))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ introduces) (NP (NP (JJ Long) (NNP Term) (NNP Memory) (NN network)) (PRN (-LRB- -LRB-) (NP (NNP LTM)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (MD can) (VP (VB tackle) (NP (DT the) (ADJP (NN exploding) (CC and) (VBG vanishing)) (NN gradient) (NNS problems)))) (CC and) (VP (NNS handles) (NP (RB long) (NNS sequences)) (PP (IN without) (S (VP (VBG forgetting)))))))))) (. .))
(S (NP (NNP LTM)) (VP (VP (VBZ is) (VP (VBN designed) (S (VP (TO to) (VP (VB scale) (NP (NP (NNS data)) (PP (IN in) (NP (DT the) (NN memory))))))))) (CC and) (VP (VBZ gives) (NP (DT a) (JJR higher) (NN weight)) (PP (TO to) (NP (NP (DT the) (NN input)) (PP (IN in) (NP (DT the) (NN sequence))))))) (. .))
(S (NP (NNP LTM)) (VP (NN avoid) (NP (NN overfitting)) (PP (IN by) (S (VP (VBG scaling) (NP (DT the) (NN cell) (NN state)) (PP (IN after) (S (VP (VBG achieving) (NP (DT the) (JJ optimal) (NNS results))))))))) (. .))
(S (S (NP (DT The) (NNP LTM)) (VP (VBZ is) (VP (VBN tested) (PP (IN on) (NP (NNP Penn) (NN treebank) (NN dataset)))))) (, ,) (CC and) (S (NP (NP (NNP Text8) (NN dataset)) (CC and) (NX (NNP LTM))) (VP (VBZ achieves) (NP (NP (JJ test) (NNS perplexities)) (PP (IN of) (NP (NP (CD 83) (CC and) (CD 82)) (ADVP (RB respectively))))))) (. .))
(S (S (NP (CD 650) (NNP LTM) (NNS cells)) (VP (VBD achieved) (NP (NP (DT a) (NN test) (NN perplexity)) (PP (IN of) (NP (CD 67)))) (PP (IN for) (NP (NNP Penn) (NN treebank))))) (, ,) (CC and) (S (NP (CD 600) (NNS cells)) (VP (VBD achieved) (NP (NP (DT a) (NN test) (NN perplexity)) (PP (IN of) (NP (CD 77)))) (PP (IN for) (NP (NNP Text8))))) (. .))
(S (NP (NNP LTM)) (VP (VBZ achieves) (NP (NAC (NN state) (PP (IN of) (NP (DT the) (NN art)))) (NNS results)) (PP (IN by) (S (VP (ADVP (RB only)) (VBG using) (NP (VBN ten) (JJ hidden) (NNP LTM) (NNS cells)) (PP (IN for) (NP (DT both) (NNS datasets))))))) (. .))
