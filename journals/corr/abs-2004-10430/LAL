(S (PP (IN With) (NP (NN reinforcement) (NN learning))) (, ,) (NP (DT an) (NN agent)) (VP (MD could) (VP (VB learn) (NP (JJ complex) (NNS behaviors)) (PP (IN from) (NP (NP (JJ high-level) (NNS abstractions)) (PP (IN of) (NP (DT the) (NN task))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NN exploration) (CC and) (NN reward) (NN shaping)) (VP (VBD remained) (ADJP (VBG challenging)) (PP (IN for) (NP (VBG existing) (NNS methods))) (, ,) (PP (ADVP (RB especially)) (IN in) (NP (NP (NNS scenarios)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (JJ extrinsic) (NN feedback)) (VP (VBD was) (ADJP (NN sparse)))))))) (. .))
(S (S (NP (JJ Expert) (NNS demonstrations)) (VP (VBP have) (VP (VBN been) (VP (VBN investigated) (S (VP (TO to) (VP (VB solve) (NP (DT these) (NNS difficulties))))))))) (, ,) (CC but) (S (NP (NP (DT a) (JJ tremendous) (NN number)) (PP (IN of) (NP (JJ high-quality) (NNS demonstrations)))) (VP (VBD were) (ADVP (RB usually)) (VP (VBN required)))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (DT an) (JJ integrated) (NN policy) (NN gradient) (NN algorithm)) (VP (VBD was) (VP (VBN proposed) (S (VP (TO to) (VP (VP (VB boost) (NP (NN exploration))) (CC and) (VP (NN facilitate) (NP (JJ intrinsic) (NN reward) (VBG learning)) (PP (IN from) (NP (NP (ADJP (RB only) (JJ limited)) (NN number)) (PP (IN of) (NP (NNS demonstrations))))))))))) (. .))
(S (NP (PRP We)) (VP (VBD achieved) (NP (DT this)) (PP (IN by) (S (VP (VBG reformulating) (NP (DT the) (JJ original) (NN reward) (NN function)) (PP (IN with) (NP (NP (CD two) (JJ additional) (NNS terms)) (, ,) (SBAR (WHADVP (WRB where)) (S (S (NP (DT the) (JJ first) (NN term)) (VP (VBD measured) (NP (NP (DT the) (NNP Jensen-Shannon) (NN divergence)) (PP (IN between) (NP (NP (JJ current) (NN policy)) (CC and) (NP (DT the) (NN expert))))))) (, ,) (CC and) (S (NP (DT the) (JJ second) (NN term)) (VP (VBD estimated) (NP (NP (NP (DT the) (NN agent) (POS 's)) (NN uncertainty)) (PP (IN about) (NP (DT the) (NN environment)))))))))))))) (. .))
(S (NP (DT The) (JJ presented) (NN algorithm)) (VP (VBD was) (VP (VP (VBN evaluated) (PP (IN on) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (NP (JJ simulated) (NNS tasks)) (PP (IN with) (NP (JJ sparse) (JJ extrinsic) (NN reward) (NNS signals))) (SBAR (WHADVP (WRB where)) (S (NP (QP (RB only) (CD one)) (JJ single) (VBD demonstrated) (NN trajectory)) (VP (VBD was) (VP (VBN provided) (PP (TO to) (NP (DT each) (NN task)))))))))))) (, ,) (S (NP (NP (JJ superior) (NN exploration) (NN efficiency)) (CC and) (NP (JJ high) (JJ average) (NN return))) (VP (VBD were) (VP (VBN demonstrated) (PP (IN in) (NP (DT all) (NNS tasks)))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP it)) (VP (VBD was) (VP (VBN found) (SBAR (IN that) (S (NP (DT the) (NN agent)) (VP (MD could) (VP (VP (VB imitate) (NP (NP (DT the) (NN expert) (POS 's)) (NN behavior))) (CC and) (VP (ADVP (RB meanwhile)) (VB sustain) (NP (JJ high) (NN return))))))))) (. .))
