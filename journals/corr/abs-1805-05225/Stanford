(S (NP (PRP We)) (VP (VBP compare) (NP (NP (DT the) (NML (NML (JJ fast) (NN training)) (CC and) (NML (NN decoding))) (NN speed)) (PP (IN of) (NP (NP (NNP RETURNN)) (PP (IN of) (NP (NP (NN attention) (NNS models)) (PP (IN for) (NP (NN translation)))))))) (, ,) (PP (IN due) (IN to) (NP (NP (NML (JJ fast) (NNP CUDA) (NNP LSTM)) (NNS kernels)) (, ,) (CC and) (NP (DT a) (ADJP (JJ fast) (JJ pure)) (NNP TensorFlow) (NML (NN beam) (NN search)) (NN decoder))))) (. .))
(S (S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT a) (JJ layer-wise) (NN pretraining) (NN scheme)) (PP (IN for) (NP (ADJP (JJ recurrent)) (NN attention) (NNS models)))) (VP (VBZ gives) (PP (IN over) (NP (NP (CD 1) (NN %)) (ADJP (NP (NN BLEU) (NN improvement)) (JJ absolute))))))))) (CC and) (S (NP (PRP it)) (VP (VBZ allows) (S (VP (TO to) (VP (VB train) (NP (ADJP (JJR deeper) (JJ recurrent)) (NN encoder) (NNS networks))))))) (. .))
(S (VP (VBG Promising) (NP (JJ preliminary) (NNS results)) (PP (IN on) (NP (NN max)))) (. .))
(S (NP (VBN expected) (NN BLEU) (NN training)) (VP (VBP are) (VP (VBN presented))) (. .))
(S (NP (PRP We)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB train) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NNS models)) (PP (IN for) (NP (NP (NML (NML (NN translation) (CC and) (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NNS models)) (PP (IN for) (NP (NN speech) (NML (NN recognition) (CC and) (NN show)) (NNS results))))) (PP (IN on) (NP (NP (NNP WMT) (CD 2017)) (CC and) (NP (NN Switchboard))))))))) (. .))
(S (S (NP (NP (DT The) (NN flexibility)) (PP (IN of) (NP (NNP RETURNN)))) (VP (VBZ allows) (NP (DT a) (NML (JJ fast) (NN research)) (NN feedback) (NN loop)) (PP (IN to) (NP (NP (NN experiment)) (PP (IN with) (NP (JJ alternative) (NNS architectures))))))) (, ,) (CC and) (S (NP (PRP$ its) (NN generality)) (VP (VBZ allows) (S (VP (TO to) (VP (VB use) (NP (PRP it)) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN range)) (PP (IN of) (NP (NNS applications)))))))))) (. .))
