(S (S (VP (VBG Controlling) (S (NP (DT a) (JJ biped) (NN robot)) (VP (TO to) (VP (VB walk) (ADVP (RB stably))))))) (VP (VBZ is) (NP (DT a) (VBG challenging) (NN task)) (PP (VBG considering) (NP (PRP$ its) (NX (NX (NN nonlinearity)) (CC and) (NX (JJ hybrid) (NNS dynamics)))))) (. .))
(S (NP (JJ Reinforcement) (NN learning)) (VP (MD can) (VP (VB address) (NP (DT these) (NNS issues)) (PP (IN by) (S (VP (ADVP (RB directly)) (VBG mapping) (NP (DT the) (JJ observed) (NNS states)) (PP (TO to) (NP (NP (JJ optimal) (NNS actions)) (SBAR (WHNP (WDT that)) (S (VP (VBP maximize) (NP (DT the) (JJ cumulative) (NN reward)))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (NP (DT the) (JJ local) (NN minima)) (VP (VBN caused) (PP (IN by) (NP (JJ unsuitable) (NNS rewards))))) (CC and) (NP (NP (DT the) (NN overestimation)) (PP (IN of) (NP (DT the) (JJ cumulative) (NN reward))))) (VP (VBP impede) (NP (NP (DT the) (NN maximization)) (PP (IN of) (NP (DT the) (JJ cumulative) (NN reward))))) (. .))
(S (S (VP (TO To) (VP (VB increase) (NP (DT the) (JJ cumulative) (NN reward))))) (, ,) (NP (DT this) (NN paper)) (VP (VBZ designs) (NP (NP (DT a) (NN gait) (NN reward)) (VP (VBN based) (PP (IN on) (NP (VBG walking) (NNS principles)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ compensates) (NP (DT the) (JJ local) (NN minima)) (PP (IN for) (NP (JJ unnatural) (NNS motions)))))))) (. .))
(S (ADVP (IN Besides)) (, ,) (NP (NP (DT an) (NNP Adversarial) (NNP Twin) (NNP Delayed) (NNP Deep) (NNP Deterministic) (PRN (-LRB- -LRB-) (NNP ATD3) (-RRB- -RRB-)) (NN policy) (NN gradient) (NN algorithm)) (PP (IN with) (NP (NP (DT a) (JJ recurrent) (JJ neural) (NN network)) (PRN (-LRB- -LRB-) (NP (NNP RNN)) (-RRB- -RRB-))))) (VP (VBZ is) (VP (VBN proposed) (S (VP (TO to) (ADVP (RBR further)) (VP (VB boost) (NP (DT the) (JJ cumulative) (NN reward)) (PP (IN by) (S (VP (VBG mitigating) (NP (NP (DT the) (NN overestimation)) (PP (IN of) (NP (DT the) (JJ cumulative) (NN reward)))))))))))) (. .))
(S (NP (NP (JJ Experimental) (NNS results)) (PP (IN in) (NP (DT the) (NNP Roboschool) (NNP Walker2d) (CC and) (NNP Webots) (NNP Atlas) (NNS simulators)))) (VP (VBP indicate) (SBAR (IN that) (S (NP (DT the) (NN test) (NNS rewards)) (VP (NN increase) (PP (IN by) (NP (NP (CD 23.50) (NN %)) (CC and) (NP (CD 9.63) (NN %)))) (PP (IN after) (S (VP (VBG adding) (NP (DT the) (NN gait) (NN reward))))))))) (. .))
(S (S (NP (DT The) (NN test) (VBZ rewards)) (VP (ADVP (JJ further)) (NN increase) (PP (IN by) (NP (NP (CD 15.96) (NN %)) (CC and) (NP (CD 12.68) (NN %)))) (PP (IN after) (S (VP (VBG using) (NP (DT the) (NNP ATD3_RNN))))))) (, ,) (CC and) (S (NP (DT the) (NN reason)) (VP (MD may) (VP (VB be) (SBAR (IN that) (S (NP (DT the) (NNP ATD3_RNN)) (VP (VBZ decreases) (NP (NP (DT the) (NN error)) (PP (IN of) (S (VP (VBG estimating) (NP (JJ cumulative) (NN reward)))))) (PP (IN from) (NP (CD 19.86) (NN %))) (PP (TO to) (NP (CD 3.35) (NN %))))))))) (. .))
(S (ADVP (IN Besides)) (, ,) (NP (NP (DT the) (NN cosine) (JJ kinetic) (NN similarity)) (PP (IN between) (NP (NP (DT the) (JJ human)) (CC and) (NP (NP (DT the) (JJ biped) (NN robot)) (VP (VBN trained) (PP (IN by) (NP (NP (DT the) (NN gait) (NN reward)) (CC and) (NP (NNP ATD3_RNN))))))))) (VP (NNS increases) (PP (IN by) (NP (QP (IN over) (CD 69.23)) (NN %)))) (. .))
(S (ADVP (RB Consequently)) (, ,) (NP (NP (DT the) (VBN designed) (NN gait) (NN reward)) (CC and) (NP (NNP ATD3_RNN))) (VP (VP (VBD boost) (NP (DT the) (JJ cumulative) (NN reward))) (CC and) (VP (NN teach) (NP (VBD biped) (NNS robots)) (S (VP (TO to) (VP (VB walk) (ADVP (JJR better))))))) (. .))
