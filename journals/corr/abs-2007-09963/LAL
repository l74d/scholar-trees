(S (SBAR (IN While) (S (NP (NP (DT the) (NN accuracy)) (PP (IN of) (NP (JJ convolutional) (JJ neural) (NNS networks)))) (VP (VBZ has) (VP (VBN achieved) (NP (JJ vast) (NNS improvements)) (PP (IN by) (S (VP (VBG introducing) (NP (ADJP (JJR larger) (CC and) (JJR deeper)) (NN network) (NNS architectures))))))))) (, ,) (ADVP (RB also)) (NP (NP (DT the) (NN memory) (NN footprint)) (PP (IN for) (S (VP (VBG storing) (NP (PRP$ their) (NNS parameters) (CC and) (NNS activations)))))) (VP (VBZ has) (VP (VBN increased))) (. .))
(S (NP (DT This) (NN trend)) (VP (ADVP (RB especially)) (VBZ challenges) (NP (NP (ADJP (JJ power-) (CC and) (JJ resource-limited)) (NN accelerator) (NNS designs)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADVP (RB often)) (VP (VBN restricted) (S (VP (TO to) (VP (VB store) (NP (DT all) (NN network) (NNS data)) (PP (IN in) (NP (JJ on-chip) (NN memory))) (S (VP (TO to) (VP (VB avoid) (S (VP (VBG interfacing) (NP (JJ energy-hungry) (JJ external) (NNS memories)))))))))))))))) (. .))
(S (S (VP (VBG Maximizing) (NP (NP (DT the) (NN network) (NN size)) (SBAR (WHNP (WDT that)) (S (VP (VBZ fits) (PP (IN on) (NP (DT a) (VBN given) (NN accelerator))))))))) (ADVP (RB thus)) (VP (VBZ requires) (S (VP (TO to) (VP (VB maximize) (NP (PRP$ its) (NN memory) (NN utilization)))))) (. .))
(S (SBAR (IN While) (S (NP (DT the) (ADJP (RB traditionally) (VBN used)) (JJ ping-pong) (NN buffering) (NN technique)) (VP (VBZ is) (VP (VBG mapping) (NP (JJ subsequent) (NN activation) (NNS layers)) (PP (TO to) (NP (VB disjunctive) (NN memory) (NNS regions))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN mapping) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ allows) (S (NP (DT these) (NNS regions)) (VP (VP (TO to) (VP (VB overlap))) (CC and) (ADVP (RB thus)) (VP (VB utilize) (NP (DT the) (NN memory)) (ADVP (RBR more) (RB efficiently)))))))))) (. .))
(S (NP (DT This) (NN work)) (VP (VBZ presents) (NP (NP (DT the) (JJ mathematical) (NN model)) (SBAR (S (VP (TO to) (VP (VB compute) (NP (NP (DT the) (JJ maximum) (NNS activations) (NN memory) (NN overlap)) (CC and) (ADVP (RB thus)) (NP (NP (DT the) (JJR lower) (NN bound)) (PP (IN of) (NP (NP (JJ on-chip) (NN memory)) (VP (VBN needed) (S (VP (TO to) (VP (VB perform) (NP (NP (JJ layer-by-layer) (NN processing)) (PP (IN of) (NP (JJ convolutional) (JJ neural) (NNS networks)))) (PP (IN on) (NP (JJ memory-limited) (NNS accelerators))))))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (PP (IN with) (NP (JJ various) (JJ real-world) (NN object) (NN detector) (NNS networks)))) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN mapping) (NN technique)) (VP (MD can) (VP (VB decrease) (NP (DT the) (NNS activations) (NN memory)) (PP (IN by) (NP (QP (IN up) (TO to) (CD 32.9)) (NN %))) (, ,) (S (VP (VBG reducing) (NP (NP (DT the) (JJ overall) (NN memory)) (PP (IN for) (NP (DT the) (JJ entire) (NN network)))) (PP (IN by) (NP (QP (IN up) (TO to) (CD 23.9)) (NN %))) (PP (VBN compared) (PP (TO to) (NP (JJ traditional) (JJ ping-pong) (NN buffering))))))))))) (. .))
(S (PP (IN For) (NP (JJR higher) (NN resolution) (JJ de-noising) (NNS networks))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (JJ activation) (NN memory) (NNS savings)) (PP (IN of) (NP (CD 48.8) (NN %))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (PRP we)) (VP (VBP implement) (NP (DT a) (NN face) (NN detector) (NN network)) (PP (IN on) (NP (DT an) (JJ FPGA-based) (NN camera))) (S (VP (TO to) (VP (VB validate) (NP (DT these) (NN memory) (NNS savings)) (PP (IN on) (NP (DT a) (JJ complete) (JJ end-to-end) (NN system))))))) (. .))
