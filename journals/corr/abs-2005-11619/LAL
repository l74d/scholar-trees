(S (NP (NP (JJ Bayesian) (JJ neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP BNNs)) (-RRB- -RRB-))) (VP (VBP are) (NP (NP (NP (DT a) (JJ promising) (NN method)) (PP (IN of) (S (VP (VBG obtaining) (NP (NP (JJ statistical) (NNS uncertainties)) (PP (IN for) (NP (JJ neural) (NN network) (NNS predictions)))))))) (CC but) (PP (IN with) (NP (NP (DT a) (JJR higher) (JJ computational) (NN overhead)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB limit) (NP (PRP$ their) (JJ practical) (NN usage)))))))))) (. .))
(S (NP (DT This) (NN work)) (VP (VBZ explores) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ high) (NN performance) (VBG computing))) (PP (IN with) (NP (JJ distributed) (NN training))) (S (VP (TO to) (VP (VB address) (NP (NP (DT the) (NNS challenges)) (PP (IN of) (S (VP (NN training) (NP (NNP BNNs)) (PP (IN at) (NP (NN scale)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT a) (NN performance) (CC and) (NN scalability) (NN comparison)) (PP (IN of) (S (VP (VBG training) (NP (DT the) (NNP VGG-16) (CC and) (NNP Resnet-18) (NNS models)) (PP (IN on) (NP (DT a) (JJ Cray-XC40) (NN cluster)))))))) (. .))
(S (PP (IN With) (NP (NP (DT the) (NN development)) (PP (IN of) (NP (NP (JJ new) (NN hardware) (NNS accelerators)) (PP (IN for) (NP (NNP Deep) (NNP Learning))))))) (, ,) (NP (NNP BNNs)) (VP (VBP are) (PP (IN of) (NP (JJ considerable) (NN interest))) (PP (IN for) (NP (VBG benchmarking) (NN performance)))) (. .))
(S (NP (NP (DT This) (NN analysis)) (PP (IN of) (S (VP (VBG training) (NP (DT a) (NNP BNN)) (PP (IN at) (NP (NN scale))))))) (VP (VBP outlines) (NP (NP (DT the) (NNS limitations) (CC and) (NNS benefits)) (VP (VBN compared) (PP (TO to) (NP (DT a) (JJ conventional) (JJ neural) (NN network)))))) (. .))
