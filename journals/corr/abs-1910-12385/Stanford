(S (NP (JJ Mixed) (NN precision) (NN training) (PRN (-LRB- -LRB-) (NP (NN MPT)) (-RRB- -RRB-))) (VP (VBZ is) (VP (VBG becoming) (NP (DT a) (JJ practical) (NN technique)) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NML (NN speed) (CC and) (NN energy)) (NN efficiency)) (PP (IN of) (NP (NN training) (JJ deep) (JJ neural) (NNS networks)))) (PP (IN by) (S (VP (VBG leveraging) (NP (DT the) (NML (JJ fast) (NN hardware)) (NN support)) (PP (IN for) (NP (NP (NP (NNP IEEE) (NN half) (HYPH -) (NN precision)) (NP (NN floating) (NN point))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ available) (PP (IN in) (NP (VBG existing) (NNS GPUs))))))))))))))))) (. .))
(S (NP (NNP MPT)) (VP (VBZ is) (ADVP (RB typically)) (VP (VBN used) (PP (IN in) (NP (NN combination))) (PP (IN with) (NP (NP (DT a) (NN technique)) (VP (VBN called) (NP (NP (NN loss) (NN scaling)) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBZ works) (PP (IN by) (S (VP (VBG scaling) (PRT (RP up)) (NP (DT the) (NN loss) (NN value)) (ADVP (RP up)) (PP (IN before) (NP (NP (DT the) (NN start)) (PP (IN of) (NP (NN backpropagation))))) (PP (IN in) (NP (NN order))) (S (VP (TO to) (VP (VB minimize) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (JJ numerical) (NN underflow)))) (PP (IN on) (NP (NN training)))))))))))))))))) (. .))
(S (ADVP (RB Unfortunately)) (, ,) (S (VP (VBG existing) (S (NP (NNS methods)) (VP (VB make) (NP (NP (NP (DT this) (NML (NN loss) (NN scale)) (NN value)) (NP (DT a) (NN hyperparameter))) (SBAR (WHNP (WDT that)) (S (VP (VBZ needs) (S (VP (TO to) (VP (VB be) (ADJP (VBN tuned) (PP (IN per) (HYPH -) (NP (NN model))))))))))))))) (, ,) (CC and) (S (NP (DT a) (JJ single) (NN scale)) (VP (MD can) (RB not) (VP (VB be) (VP (VBN adapted) (PP (IN to) (NP (JJ different) (NNS layers))) (PP (IN at) (NP (JJ different) (NN training) (NNS stages))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (ADJP (NP (NN loss) (NN scaling)) (HYPH -) (VBN based)) (NN training) (NN method)) (VP (VBN called) (NP (NP (JJ adaptive) (NN loss) (NN scaling)) (SBAR (WHNP (WDT that)) (S (VP (VBZ makes) (S (NP (NNP MPT)) (ADJP (ADJP (RBR easier)) (CC and) (ADJP (RBR more) (JJ practical) (S (VP (TO to) (VP (VB use))))))))))))) (, ,) (PP (IN by) (S (VP (VBG removing) (NP (DT the) (NN need)) (S (VP (TO to) (VP (VB tune) (NP (DT a) (ADJP (NP (NN model)) (HYPH -) (JJ specific)) (NML (NN loss) (NN scale)) (NN hyperparameter))))))))) (. .))
(S (NP (PRP We)) (VP (VBP achieve) (NP (DT this)) (PP (IN by) (S (VP (VBG introducing) (NP (NP (JJ layer-wise) (NML (NN loss) (NN scale)) (NNS values)) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADVP (RB automatically)) (VP (VBN computed) (PP (IN during) (NP (NN training))) (S (VP (TO to) (VP (VB deal) (PP (IN with) (NP (NN underflow))) (ADVP (ADVP (RBR more) (RB effectively)) (PP (IN than) (NP (VBG existing) (NNS methods)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (JJ experimental) (NNS results)) (PP (IN on) (NP (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS networks) (CC and) (NNS tasks)))) (SBAR (WHNP (WDT that)) (S (VP (VBP show) (SBAR (S (NP (PRP$ our) (NN approach)) (VP (MD can) (VP (VP (VB shorten) (NP (DT the) (NN time)) (PP (IN to) (NP (NN convergence)))) (CC and) (VP (VB improve) (NP (NN accuracy)) (PP (VBN compared) (PP (IN to) (NP (DT the) (VBG existing) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NML (NML (NNP MPT)) (CC and) (NML (JJ single) (HYPH -) (NN precision))) (VBG floating) (NN point))))))))))))))))
