(S (NP (NP (NN Sequence) (NN model)) (VP (VBG learning) (NP (NNS algorithms)) (ADVP (RB typically)))) (VP (VBP maximize) (NP (NN log) (HYPH -) (NN likelihood)) (PP (IN minus) (NP (NP (DT the) (NN norm)) (PP (IN of) (NP (DT the) (NN model))))) (PRN (-LRB- -LRB-) (S (CC or) (VP (VB minimize) (NP (NN Hamming) (NN loss) (SYM +) (NN norm)))) (-RRB- -RRB-))) (. .))
(S (PP (IN In) (NP (JJ cross-lingual) (NML (NML (NN part)) (HYPH -) (PP (IN of) (HYPH -) (NP (NN speech) (-LRB- -LRB-) (NN POS) (-RRB- -RRB-)))) (NN tagging))) (, ,) (NP (PRP$ our) (NN target) (NN language) (NN training) (NNS data)) (VP (VBZ consists) (PP (IN of) (NP (NP (NNS sequences)) (PP (IN of) (NP (NNS sentences))))) (PP (IN with) (NP (NP (NP (NML (NML (NN word)) (HYPH -) (PP (IN by) (HYPH -) (NP (NN word)))) (NNS labels)) (VP (VBN projected) (PP (IN from) (NP (NP (NP (NNS translations)) (PP (IN in) (NP (NML (NML (QP ($ $) (CD k))) (NML ($ $))) (NNS languages)))) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBP have) (VP (VBN labeled) (NP (NNS data)))))))))) (, ,) (PP (IN via) (NP (NN word) (NNS alignments)))))) (. .))
(S (S (NP (PRP$ Our) (NN training) (NNS data)) (VP (VBZ is) (ADVP (RB therefore)) (ADJP (RB very) (JJ noisy)))) (, ,) (CC and) (S (SBAR (IN if) (S (NP (NNP Rademacher) (NN complexity)) (VP (VBZ is) (ADJP (JJ high))))) (, ,) (NP (VBG learning) (NNS algorithms)) (VP (VBP are) (ADJP (JJ prone) (PP (IN to) (NP (NN overfit)))))) (. .))
(S (NP (ADJP (NN Norm) (HYPH -) (VBN based)) (NN regularization)) (VP (VBZ assumes) (NP (NP (DT a) (JJ constant) (NN width)) (CC and) (NP (CD zero) (NN mean))) (PP (JJ prior))) (. .))
(S (NP (PRP We)) (ADVP (RB instead)) (VP (VBP propose) (S (VP (TO to) (VP (VB use) (NP (QP (DT the) ($ $) (CD k)) (NML (NML ($ $)) (NN source)) (NN language) (NNS models)) (S (VP (TO to) (VP (VB estimate) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (NP (DT a) (NNP Gaussian)) (PP (JJ prior) (IN for) (S (VP (VBG learning) (NP (JJ new) (NN POS) (NNS taggers))))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ leads) (PP (IN to) (NP (NP (ADJP (RB significantly) (JJR better)) (NN performance)) (PP (IN in) (NP (JJ multi-source) (NN transfer) (NN set) (HYPH -) (NNS ups)))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP present) (NP (NP (NP (DT a) (NN drop)) (HYPH -) (NP (NN out) (NN version))) (SBAR (WHNP (WDT that)) (S (VP (VBZ injects) (NP (NP (-LRB- -LRB-) (JJ empirical) (-RRB- -RRB-) (JJ Gaussian) (NN noise)) (PP (IN during) (NP (JJ online) (NN learning))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP note) (SBAR (IN that) (S (S (VP (VBG using) (NP (JJ empirical) (JJ Gaussian) (NNS priors)))) (VP (VP (VBZ leads) (PP (IN to) (NP (NP (RB much) (JJR lower) (NNP Rademacher)) (NP (NN complexity))))) (, ,) (CC and) (VP (VBZ is) (NP (ADJP (JJ superior) (PP (IN to) (NP (ADVP (RB optimally)) (JJ weighted) (NN model)))) (NN interpolation))))))) (. .))
