(S (NP (NP (PRP It))) (VP (VBZ remains) (NP (DT an) (JJ interesting) (NN question)) (SBAR (WHADVP (WRB how)) (S (NP (JJ non-convex) (NN loss) (NNS functions)) (VP (VBP help) (S (VP (VB improve) (NP (NP (DT the) (NN generalization)) (PP (IN of) (NP (VBG learning)))) (PP (IN with) (NP (JJ broad) (NN applicability))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT a) (NN family)) (PP (IN of) (NP (JJ objective) (NNS functions))) (VP (VBN formed) (PP (IN by) (S (VP (VBG truncating) (NP (JJ traditional) (NN loss) (NNS functions)))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ applicable) (PP (TO to) (NP (DT both) (NP (JJ shallow) (NN learning)) (CC and) (NP (JJ deep) (NN learning)))))))))) (. .))
(S (S (VP (VBG Truncating) (NP (NN loss) (NNS functions)))) (VP (VBZ has) (NP (JJ potential) (S (VP (TO to) (VP (VB be) (ADJP (ADJP (ADJP (RBR less) (JJ vulnerable)) (CC and) (ADJP (RBR more) (JJ robust))) (PP (TO to) (NP (NP (JJ large) (NN noise)) (PP (IN in) (NP (NP (NNS observations)) (SBAR (WHNP (WDT that)) (S (VP (MD could) (VP (VB be) (ADJP (JJ adversarial)))))))))))))))) (. .))
(S (ADVP (RBR More) (RB importantly)) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (DT a) (JJ generic) (NN technique)) (PP (IN without) (S (VP (VBG assuming) (NP (NP (DT the) (NN knowledge)) (PP (IN of) (NP (NN noise) (NN distribution)))))))) (. .))
(S (S (VP (TO To) (VP (VB justify) (NP (NP (JJ non-convex) (VBG learning)) (PP (IN with) (NP (JJ truncated) (NNS losses))))))) (, ,) (NP (PRP we)) (VP (VB establish) (NP (NP (JJ excess) (NN risk) (NNS bounds)) (PP (IN of) (NP (JJ empirical) (NN risk) (NN minimization))) (VP (VBN based) (PP (IN on) (NP (NP (NP (JJ truncated) (NNS losses)) (PP (IN for) (NP (JJ heavy-tailed) (NN output)))) (, ,) (CC and) (NP (NP (JJ statistical) (NN error)) (PP (IN of) (NP (NP (DT an) (JJ approximate) (JJ stationary) (NN point)) (VP (VBN found) (PP (IN by) (NP (JJ stochastic) (NN gradient) (NN descent) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)) (NN method)))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (PP (IN for) (NP (NP (NN shallow) (CC and) (JJ deep) (NN learning)) (PP (IN for) (NP (NP (NN regression)) (PP (IN with) (NP (NP (NNS outliers)) (, ,) (NP (VBN corrupted) (NNS data)) (CC and) (NP (JJ heavy-tailed) (NN noise))))))))) (VP (ADVP (RBR further)) (VB justify) (NP (DT the) (VBN proposed) (NN method))) (. .))
