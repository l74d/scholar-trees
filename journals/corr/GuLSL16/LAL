(S (NP (JJ Model-free) (NN reinforcement) (NN learning)) (VP (VP (VBZ has) (VP (VBN been) (VP (ADVP (RB successfully)) (VBN applied) (PP (TO to) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (VBG challenging) (NNS problems)))))))) (, ,) (CC and) (VP (VBZ has) (ADVP (RB recently)) (VP (VBN been) (VP (VBN extended) (S (VP (TO to) (VP (VB handle) (NP (JJ large) (NX (NX (JJ neural) (NN network) (NNS policies)) (CC and) (NX (NN value) (NNS functions))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (NP (DT the) (JJ sample) (NN complexity)) (PP (IN of) (NP (JJ model-free) (NNS algorithms)))) (, ,) (SBAR (WHADVP (ADVP (RB particularly)) (WRB when)) (S (VP (VBG using) (NP (JJ high-dimensional) (NN function) (NNS approximators))))) (, ,)) (VP (VBZ tends) (S (VP (TO to) (VP (VB limit) (NP (NP (PRP$ their) (NN applicability)) (PP (TO to) (NP (JJ physical) (NNS systems)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP explore) (NP (NP (JJ algorithms) (CC and) (NNS representations)) (SBAR (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN sample) (NN complexity)) (PP (IN of) (NP (JJ deep) (NN reinforcement) (VBG learning))) (PP (IN for) (NP (JJ continuous) (NN control) (NNS tasks)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (CD two) (JJ complementary) (NNS techniques)) (PP (IN for) (S (VP (VBG improving) (NP (NP (DT the) (NN efficiency)) (PP (IN of) (NP (JJ such) (NNS algorithms))))))))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP derive) (NP (NP (DT a) (JJ continuous) (NN variant)) (PP (IN of) (NP (DT the) (NNP Q-learning) (NN algorithm))) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP call) (S (NP (NP (JJ normalized) (NN adantage) (NNS functions)) (PRN (-LRB- -LRB-) (NP (NNP NAF)) (-RRB- -RRB-)))) (, ,) (PP (IN as) (NP (NP (DT an) (NN alternative)) (PP (TO to) (NP (DT the) (ADJP (ADVP (JJR more) (JJ commonly)) (JJ used)) (NN policy) (NN gradient) (CC and) (JJ actor-critic) (NNS methods)))))))))) (. .))
(S (NP (NNP NAF) (NN representation)) (VP (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB apply) (NP (NP (JJ Q-learning)) (PP (IN with) (NP (NN experience) (NN replay)))) (PP (TO to) (NP (JJ continuous) (NNS tasks))))))) (, ,) (CC and) (VP (ADVP (RB substantially)) (VBZ improves) (NP (NP (NN performance)) (PP (IN on) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ simulated) (JJ robotic) (NN control) (NNS tasks)))))))) (. .))
(S (S (VP (TO To) (ADVP (RBR further)) (VP (VB improve) (NP (NP (DT the) (NN efficiency)) (PP (IN of) (NP (PRP$ our) (NN approach))))))) (, ,) (NP (PRP we)) (VP (VBP explore) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ learned) (NNS models))) (PP (IN for) (S (VP (VBG accelerating) (NP (JJ model-free) (NN reinforcement) (NN learning))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP show) (SBAR (IN that) (S (NP (ADJP (RB iteratively) (VBN refitted)) (JJ local) (JJ linear) (NNS models)) (VP (VBP are) (ADJP (RB especially) (JJ effective) (PP (IN for) (NP (DT this)))))))) (, ,) (CC and) (VP (VB demonstrate) (NP (NP (ADJP (RB substantially) (RBR faster)) (VBG learning)) (PP (IN on) (NP (NP (NNS domains)) (SBAR (WHADVP (WRB where)) (S (NP (JJ such) (NNS models)) (VP (VBP are) (ADJP (JJ applicable)))))))))) (. .))
