(S (NP (VBG Spiking) (JJ Neural) (NNS Networks) (PRN (-LRB- -LRB-) (NP (NNS SNNs)) (-RRB- -RRB-))) (VP (VBP are) (VP (VBG being) (VP (VBN explored) (PP (IN for) (NP (NP (PRP$ their) (JJ potential) (NN energy) (NN efficiency)) (VP (VBG resulting) (PP (IN from) (NP (JJ sparse) (, ,) (ADJP (NN event) (HYPH -) (VBN driven)) (NNS computations))))))))) (. .))
(S (NP (JJ Many) (JJ recent) (NNS works)) (VP (VBP have) (VP (VBN demonstrated) (NP (NP (JJ effective) (NN backpropagation)) (PP (IN for) (NP (NP (NML (JJ deep) (NN Spiking)) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS SNNs)) (-RRB- -RRB-)))) (PP (IN by) (S (VP (VP (VBG approximating) (NP (NP (NNS gradients)) (PP (IN over) (NP (JJ discontinuous) (NN neuron) (NNS spikes))))) (CC or) (VP (VBG firing) (NP (NNS events)))))))) (. .))
(S (NP (NP (DT A) (JJ beneficial) (NN side) (HYPH -) (NN effect)) (PP (IN of) (NP (NP (DT these) (JJ surrogate) (NN gradient)) (VP (VBG spiking) (NP (NN backpropagation) (NNS algorithms)))))) (VP (VBZ is) (SBAR (IN that) (S (NP (NP (DT the) (NNS spikes)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP trigger) (NP (JJ additional) (NNS computations))))) (, ,)) (VP (MD may) (ADVP (RB now)) (ADVP (PRP themselves)) (VP (VB be) (ADVP (RB directly)) (VP (VBN considered) (PP (IN in) (NP (DT the) (NN gradient) (NNS calculations))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT an) (JJ explicit) (NN inclusion)) (PP (IN of) (NP (NP (NN spike) (NNS counts)) (PP (IN in) (NP (DT the) (NN loss) (NN function))) (, ,) (ADVP (IN along) (PP (IN with) (NP (NP (DT a) (JJ traditional) (NN error) (NN loss)) (, ,) (VP (VBG causing) (NP (DT the) (NN backpropagation)) (S (VP (VBG learning) (NP (NNS algorithms)) (S (VP (TO to) (VP (VB optimize) (NP (NN weight) (NNS parameters)) (PP (IN for) (NP (DT both) (NML (NN accuracy) (CC and) (NN spiking)) (NN sparsity)))))))))))))))) (. .))
(S (SBAR (IN As) (S (VP (VBN supported) (PP (IN by) (NP (NP (VBG existing) (NN theory)) (PP (IN of) (NP (VBN over-parameterized) (JJ neural) (NNS networks)))))))) (, ,) (NP (EX there)) (VP (VBP are) (NP (NP (JJ many) (NN solution) (NNS states)) (PP (IN with) (NP (ADJP (RB effectively) (JJ equivalent)) (NN accuracy))))) (. .))
(S (PP (IN As) (ADJP (JJ such))) (, ,) (NP (NP (JJ appropriate) (NN weighting)) (PP (IN of) (NP (NP (DT the) (CD two) (NN loss) (NNS goals)) (PP (IN during) (NP (NP (NN training)) (PP (IN in) (NP (DT this) (JJ multi-objective) (NN optimization) (NN process)))))))) (VP (MD can) (VP (VB yield) (NP (NP (DT an) (NN improvement)) (PP (IN in) (NP (NN spiking) (NN sparsity)))) (PP (IN without) (NP (NP (DT a) (JJ significant) (NN loss)) (PP (IN of) (NP (NN accuracy))))))) (. .))
(S (NP (PRP We)) (ADVP (RB additionally)) (VP (VB explore) (NP (DT a) (ADJP (NP (JJ simulated) (JJ annealing)) (HYPH -) (JJ inspired)) (NN loss) (NN weighting) (NN technique)) (S (VP (TO to) (VP (VB increase) (NP (NP (DT the) (NN weighting)) (PP (IN for) (NP (NN sparsity)))) (PP (IN as) (NP (NN training) (NN time) (NNS increases))))))) (. .))
(S (NP (NP (PRP$ Our) (JJ preliminary) (NNS results)) (PP (IN on) (NP (DT the) (NML (NNP Cifar) (HYPH -) (CD 10)) (NN dataset) (NN show) (NML (QP (IN up) (IN to) (CD 70.1)) (NN %)) (NN reduction))) (PP (IN in) (NP (NP (NN spiking) (NN activity)) (PP (IN with) (NP (NP (NN iso) (HYPH -) (NN accuracy)) (PP (VBN compared) (PP (IN to) (NP (DT an) (JJ equivalent) (NNP SNN))))))))) (VP (VBD trained) (ADVP (RB only)) (PP (IN for) (NP (NP (NN accuracy)) (CC and) (NP (NP (NML (QP (IN up) (IN to) (CD 73.3)) (NN %)) (NN reduction)) (PP (IN in) (NP (NN spiking) (NN activity)))))) (SBAR (IN if) (S (VP (VBN allowed) (NP (DT a) (NML (NML (NN trade) (HYPH -) (NN off)) (PP (IN of) (NP (CD 1) (NN %)))) (NN reduction)) (PP (IN in) (NP (NN classification) (NN accuracy))))))) (. .))
