(S (NP (NNP Tucker) (NN decomposition)) (VP (VBZ is) (NP (NP (DT the) (NN cornerstone)) (PP (IN of) (NP (NP (JJ modern) (NN machine) (VBG learning)) (PP (IN on) (NP (NP (JJ tensorial) (NNS data) (NN analysis)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP have) (VP (VBN attracted) (NP (JJ considerable) (NN attention)) (PP (IN for) (NP (NP (JJ multiway) (NN feature) (NN extraction)) (, ,) (NP (JJ compressive) (NN sensing)) (, ,) (CC and) (NP (NN tensor) (NN completion)))))))))))))) (. .))
(S (NP (DT The) (ADJP (RBS most) (JJ challenging)) (NN problem)) (VP (VBZ is) (VP (VBN related) (PP (TO to) (NP (NP (NN determination)) (PP (IN of) (NP (NP (NN model) (NN complexity)) (PRN (-LRB- -LRB-) (INTJ (FW i.e.)) (, ,) (NP (FW multilinear) (NN rank)) (-RRB- -RRB-)))))) (, ,) (SBAR (WHADVP (ADVP (RB especially)) (WRB when)) (S (NP (NP (NN noise)) (CC and) (NP (VBG missing) (NNS data))) (VP (VBP are) (ADJP (JJ present))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (VBG existing) (NNS methods)) (VP (MD can) (RB not) (VP (VB take) (PP (IN into) (NP (NN account))) (NP (NP (NN uncertainty) (NN information)) (PP (IN of) (NP (NN latent) (NNS factors)))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (JJ low) (NN generalization) (NN performance))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS issues))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (NN class)) (PP (IN of) (NP (NP (JJ probabilistic) (JJ generative) (NNP Tucker) (NNS models)) (PP (IN for) (NP (NP (NP (NN tensor) (NN decomposition)) (CC and) (NP (NN completion))) (PP (IN with) (NP (NP (JJ structural) (NN sparsity)) (PP (IN over) (NP (JJ multilinear) (JJ latent) (NN space))))))))))) (. .))
(S (S (VP (TO To) (VP (VB exploit) (NP (JJ structural) (NN sparse) (NN modeling))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (CD two) (NN group) (NN sparsity) (VBG inducing) (NNS priors)) (PP (IN by) (NP (NP (JJ hierarchial) (NN representation)) (PP (IN of) (NP (NNP Laplace) (CC and) (NNP Student-t) (NNS distributions))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ facilitates) (NP (ADJP (RB fully) (JJ posterior)) (NN inference)))))))) (. .))
(S (PP (IN For) (NP (NN model) (NN learning))) (, ,) (NP (PRP we)) (VP (VP (VBD derived) (NP (NP (JJ variational) (JJ Bayesian) (NNS inferences)) (PP (IN over) (NP (DT all) (NN model) (PRN (-LRB- -LRB-) (JJ hyper) (-RRB- -RRB-)) (NNS parameters))))) (, ,) (CC and) (VP (VBD developed) (NP (NP (ADJP (NN efficient) (CC and) (JJ scalable)) (NNS algorithms)) (VP (VBN based) (PP (IN on) (NP (JJ multilinear) (NNS operations))))))) (. .))
(S (NP (PRP$ Our) (NNS methods)) (VP (MD can) (VP (VP (ADVP (RB automatically)) (VB adapt) (NP (NN model) (NN complexity))) (CC and) (VP (VB infer) (NP (DT an) (JJ optimal) (NN multilinear) (NN rank)) (PP (IN by) (NP (NP (DT the) (NN principle)) (PP (IN of) (NP (NP (JJ maximum) (JJR lower) (NN bound)) (PP (IN of) (NP (NN model) (NN evidence)))))))))) (. .))
(S (NP (NP (JJ Experimental) (NNS results)) (CC and) (NP (NP (NNS comparisons)) (PP (IN on) (NP (ADJP (JJ synthetic) (, ,) (NNS chemometrics) (CC and) (VBG neuroimaging)) (NNS data))))) (VP (NN demonstrate) (NP (NP (JJ remarkable) (NN performance)) (PP (IN of) (NP (PRP$ our) (NNS models))) (PP (IN for) (S (VP (VBG recovering) (NP (NP (NN ground-truth)) (PP (IN of) (NP (NP (JJ multilinear) (NN rank)) (CC and) (NP (VBG missing) (NNS entries)))))))))) (. .))
