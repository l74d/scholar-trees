(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT a) (JJ new) (NN algorithm)) (PP (IN for) (NP (NN training) (JJ neural) (NNS networks)))) (PP (IN with) (NP (NP (UCP (NP (JJ binary) (NNS activations)) (CC and) (ADJP (JJ multi-level))) (NNS weights)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ enables) (NP (JJ efficient) (NML (NN processing) (HYPH -) (IN in) (HYPH -) (NN memory)) (NNS circuits)) (PP (IN with) (NP (NN eNVM))))))))) (. .))
(S (NP (JJ Binary) (NNS activations)) (VP (VBP obviate) (NP (JJ costly) (NNS DACs) (CC and) (NNS ADCs))) (. .))
(FRAG (NP (JJ Multi-level) (NNS weights)) (NP (NN leverage)) (ADJP (JJ multi-level)) (NP (NN eNVM) (NNS cells)) (. .))
(S (PP (VBN Compared) (PP (IN with) (NP (JJ previous) (NN quantization) (NNS algorithms)))) (, ,) (NP (PRP$ our) (NN method)) (VP (CONJP (RB not) (RB only)) (VP (VBZ works) (PP (IN for) (NP (NP (NML (NN feed) (HYPH -) (JJ forward)) (NNS networks)) (VP (VBG including) (S (ADJP (ADJP (RB fully) (HYPH -) (VBN connected)) (CC and) (ADJP (JJ convolutional)))))))) (, ,) (CONJP (CC but) (RB also)) (VP (VBZ achieves) (NP (JJR higher) (NN accuracy) (CC and) (NN noise) (NN resilience)) (PP (IN for) (NP (ADJP (JJ recurrent)) (NNS networks))))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (NN RNN) (NML (NN trigger) (HYPH -) (NN word)) (NML (NN detection) (NN PIM)) (NN accelerator)) (, ,) (SBAR (WHNP (WP$ whose) (NML (NN modeling)) (NNS results)) (S (VP (VBP demonstrate) (NP (JJ high) (NN performance)) (S (VP (VBG using) (NP (PRP$ our) (JJ new) (NN training) (NN algorithm))))))))) (. .))
