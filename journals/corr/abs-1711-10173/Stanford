(S (S (VP (VBG Learning) (NP (DT an) (JJ optimal) (NN policy)) (PP (IN from) (NP (DT a) (JJ multi-modal) (NN reward) (NN function))))) (VP (VBZ is) (NP (NP (DT a) (JJ challenging) (NN problem)) (PP (IN in) (NP (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-)))))) (. .))
(S (S (NP (NP (JJ Hierarchical) (NN RL)) (-LRB- -LRB-) (NP (NN HRL)) (-RRB- -RRB-)) (VP (VBZ tackles) (NP (DT this) (NN problem)) (PP (IN by) (S (VP (VBG learning) (NP (DT a) (JJ hierarchical) (NN policy))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (JJ multiple) (NN option) (NNS policies)) (VP (VBP are) (PP (IN in) (NP (NP (NN charge)) (PP (IN of) (NP (NP (JJ different) (NNS strategies)) (VP (VBG corresponding) (PP (IN to) (NP (NP (NNS modes)) (PP (IN of) (NP (DT a) (NN reward) (NN function))))))))))))))) (CC and) (S (NP (DT a) (NN gating) (NN policy)) (VP (VBZ selects) (NP (NP (DT the) (JJS best) (NN option)) (PP (IN for) (NP (DT a) (VBN given) (NN context)))))) (. .))
(S (SBAR (IN Although) (S (NP (NN HRL)) (VP (VBZ has) (VP (VBN been) (VP (VBN demonstrated) (S (VP (TO to) (VP (VB be) (ADJP (JJ promising)))))))))) (, ,) (NP (NML (NML (JJ current) (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS methods)) (VP (MD can) (RB not) (ADVP (RB still)) (VP (VB perform) (ADVP (RB well) (PP (IN in) (NP (JJ complex) (NML (JJ real) (HYPH -) (NN world)) (NNS problems)))) (PP (IN due) (IN to) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (S (VP (VBG identifying) (NP (NP (NNS modes)) (PP (IN of) (NP (DT the) (NN reward) (NN function))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN method)) (VP (VBN called) (NP (NP (JJ hierarchical) (NN policy) (NN search)) (PP (IN via) (NP (NP (ADJP (NP (NN return)) (HYPH -) (VBN weighted)) (NN density) (NN estimation) (PRN (-LRB- -LRB-) (NP (NN HPSDE)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (ADVP (RB efficiently)) (VP (VB identify) (NP (DT the) (NNS modes)) (PP (IN through) (NP (ADJP (NP (NP (NN density) (NN estimation)) (PP (IN with) (NP (NN return)))) (HYPH -) (VBN weighted)) (NN importance) (NN sampling))))))))))))) (. .))
(S (NP (PRP$ Our) (JJ proposed) (NN method)) (VP (VP (VBZ finds) (NP (NP (NN option) (NNS policies)) (VP (VBG corresponding) (PP (IN to) (NP (NP (DT the) (NNS modes)) (PP (IN of) (NP (DT the) (NN return) (NN function)))))))) (CC and) (VP (ADVP (RB automatically)) (VBZ determines) (NP (NP (NP (DT the) (NN number)) (CC and) (NP (NP (DT the) (NN location)) (PP (IN of) (NP (NN option) (NNS policies))))) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB significantly)) (VP (VBZ reduces) (NP (NP (DT the) (NN burden)) (PP (IN of) (NP (ADJP (JJ hyper) (HYPH -)) (NNS parameters) (NN tuning)))))))))) (. .))
(S (PP (IN Through) (NP (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN HPSDE)) (ADVP (RB successfully)) (VP (VBZ learns) (NP (NP (NN option) (NNS policies)) (VP (VBG corresponding) (PP (IN to) (NP (NP (NNS modes)) (PP (IN of) (NP (DT the) (NN return) (NN function)))))))))) (CC and) (SBAR (IN that) (S (NP (PRP it)) (VP (MD can) (VP (VB be) (ADVP (RB successfully)) (VP (VBN applied) (PP (IN to) (NP (NP (DT a) (JJ challenging) (NML (NN motion) (NN planning)) (NN problem)) (PP (IN of) (NP (DT a) (JJ redundant) (JJ robotic) (NN manipulator)))))))))))) (. .))
