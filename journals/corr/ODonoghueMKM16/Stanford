(S (NP (NN Policy) (NN gradient)) (VP (VBZ is) (NP (NP (DT an) (JJ efficient) (NN technique)) (PP (IN for) (S (VP (VBG improving) (NP (NP (DT a) (NN policy)) (PP (IN in) (NP (DT a) (NN reinforcement) (VBG learning) (NN setting))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NN vanilla) (JJ online) (NNS variants)) (VP (VBP are) (UCP (PP (IN on) (NP (HYPH -) (NN policy)) (ADVP (RB only))) (CC and) (RB not) (ADJP (JJ able) (S (VP (TO to) (VP (VB take) (NP (NP (NN advantage)) (PP (IN of) (NP (NML (RB off) (HYPH -) (NN policy)) (NNS data)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP describe) (NP (NP (DT a) (JJ new) (NN technique)) (SBAR (WHNP (WDT that)) (S (VP (VBZ combines) (NP (NN policy) (NN gradient)) (PP (IN with) (NP (NML (RB off) (HYPH -) (NN policy)) (NML (NN Q) (HYPH -) (NN learning)))) (, ,) (S (VP (VBG drawing) (NP (NN experience)) (PP (IN from) (NP (DT a) (NN replay) (NN buffer)))))))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (VP (VBN motivated) (PP (IN by) (S (VP (VBG making) (NP (NP (DT a) (NN connection)) (PP (IN between) (NP (NP (DT the) (VBN fixed) (NNS points)) (PP (IN of) (NP (NP (DT the) (VBN regularized) (NML (NN policy) (NN gradient)) (NN algorithm)) (CC and) (NP (DT the) (NML (NN Q) (HYPH -) (NNS values))))))))))))) (. .))
(S (NP (DT This) (NN connection)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB estimate) (NP (DT the) (NN Q) (HYPH -) (NNS values)) (PP (IN from) (NP (NP (DT the) (NN action) (NNS preferences)) (PP (IN of) (NP (NP (DT the) (NN policy)) (, ,) (SBAR (WHPP (TO to) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBP apply) (NP (NML (NN Q) (HYPH -) (NN learning)) (NNS updates))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP refer) (PP (IN to) (NP (DT the) (JJ new) (NN technique))) (PP (IN as) (NP (`` ') (NN PGQL) ('' '))) (, ,) (PP (IN for) (NP (NN policy) (NML (NML (NN gradient)) (CC and) (NML (NN Q) (HYPH -) (NN learning)))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP establish) (NP (NP (DT an) (NN equivalency)) (PP (IN between) (NP (NP (ADJP (NP (NN action) (HYPH -) (NN value)) (JJ fitting)) (NNS techniques)) (CC and) (NP (NML (NN actor) (HYPH -) (NN critic)) (NNS algorithms))))) (, ,) (S (VP (VBG showing) (SBAR (IN that) (S (NP (VBN regularized) (NML (NN policy) (NN gradient)) (NNS techniques)) (VP (MD can) (VP (VB be) (VP (VBN interpreted) (PP (IN as) (NP (NN advantage) (NN function))) (S (VP (VBG learning) (NP (NNS algorithms)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP conclude) (PP (IN with) (NP (NP (DT some) (JJ numerical) (NNS examples)) (SBAR (WHNP (WDT that)) (S (VP (VBP demonstrate) (NP (NP (VBN improved) (NNS data)) (NP (NP (NN efficiency) (CC and) (NN stability)) (PP (IN of) (NP (NN PGQL))))))))))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (NP (PRP we)) (VP (VP (VBD tested) (NP (NNP PGQL)) (PP (IN on) (NP (NP (DT the) (JJ full) (NN suite)) (PP (IN of) (NP (NNP Atari) (NNS games)))))) (CC and) (VP (VBN achieved) (NP (NP (NN performance)) (VP (VBG exceeding) (IN that) (PP (IN of) (NP (ADJP (DT both) (JJ asynchronous)) (NN advantage) (NML (NML (NN actor) (HYPH -) (NN critic) (PRN (-LRB- -LRB-) (NP (NN A3C)) (-RRB- -RRB-))) (CC and) (NML (NN Q) (HYPH -) (NN learning))))))))) (. .))
