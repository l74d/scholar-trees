(S (NP (NML (NML (JJ Current) (NN reinforcement) (NN learning)) (-LRB- -LRB-) (NML (NN RL)) (-RRB- -RRB-)) (NNS algorithms)) (VP (MD can) (VP (VB be) (ADJP (JJ brittle) (CC and) (JJ difficult) (S (VP (TO to) (VP (VB use))))) (, ,) (SBAR (RB especially) (WHADVP (WRB when)) (S (VP (VBG learning) (NP (ADJP (NN goal) (HYPH -) (VBG reaching)) (NNS behaviors)) (PP (IN from) (NP (JJ sparse) (NNS rewards)))))))) (. .))
(S (SBAR (IN Although) (S (NP (JJ supervised) (NN imitation) (NN learning)) (VP (VBZ provides) (NP (DT a) (ADJP (JJ simple) (CC and) (JJ stable)) (NN alternative))))) (, ,) (NP (PRP it)) (VP (VBZ requires) (NP (NN access)) (PP (IN to) (NP (NP (NNS demonstrations)) (PP (IN from) (NP (DT a) (JJ human) (NN supervisor)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NNP RL) (NNS algorithms)) (PP (IN for) (S (VP (VBG learning) (NP (NP (ADJP (NN goal) (VBG reaching)) (NNS policies)) (SBAR (WHNP (WDT that)) (S (VP (VBP leverage) (NP (NP (DT the) (NN stability)) (PP (IN of) (NP (NN imitation) (NN learning)))) (PP (IN without) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (JJ explicit) (NN expert) (NNS demonstrations))))))))))))) (. .))
(S (PP (IN In) (NP (NP (NN lieu)) (PP (IN of) (NP (JJ expert) (NNS demonstrations))))) (, ,) (NP (NN supervision)) (VP (MD can) (VP (VB be) (VP (VBN derived) (PP (IN by) (S (VP (VBG leveraging) (NP (DT the) (NN property)) (SBAR (IN that) (S (NP (DT any) (NN trajectory)) (VP (VBZ is) (NP (NP (DT a) (JJ successful) (NN demonstration)) (PP (IN for) (S (VP (VBG reaching) (NP (DT the) (JJ final) (NN state)) (PP (IN in) (NP (DT that) (JJ same) (NN trajectory)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP propose) (NP (NP (DT a) (JJ simple) (NN algorithm)) (PP (IN in) (NP (NML (FRAG (NP (WDT which) (DT an) (NN agent)) (ADVP (RB continually)))) (NNS relabels))))) (CC and) (VP (VBZ imitates) (NP (PRP$ its) (JJ own) (NN experience)) (S (VP (TO to) (ADVP (RB progressively)) (VP (VB learn) (NP (ADJP (NN goal) (HYPH -) (VBG reaching)) (NNS behaviors))))))) (. .))
(S (NP (NP (DT Each) (NN iteration)) (, ,) (NP (DT the) (NN agent))) (VP (VP (VBZ collects) (NP (JJ new) (NNS trajectories)) (S (VP (VBG using) (NP (DT the) (JJS latest) (NN policy))))) (, ,) (CC and) (VP (VBZ maximizes) (NP (NP (DT the) (NN likelihood)) (PP (IN of) (NP (NP (DT the) (NNS actions)) (PP (IN along) (NP (DT these) (NNS trajectories)))))) (PP (IN under) (NP (NP (NP (DT the) (NN goal)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (ADVP (RB actually)) (VP (VBN reached)))))) (, ,) (CONJP (RB so) (IN as)) (S (VP (TO to) (VP (VB improve) (NP (DT the) (NN policy))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB formally)) (VP (VP (VBP link) (NP (PRP$ our) (JJ supervised) (NN learning) (NN objective)) (PP (IN to) (NP (DT the) (JJ true) (NN RL) (NN objective)))) (, ,) (VP (VBP derive) (NP (NN performance) (NNS bounds))) (, ,) (CC and) (VP (VBP demonstrate) (NP (NP (VBN improved) (NN performance)) (PP (IN over) (NP (NP (JJ current) (NN RL) (NNS algorithms)) (PP (IN on) (NP (ADJP (ADJP (NN goal) (HYPH -) (VBG reaching)) (PP (IN in) (NP (JJ several) (NN benchmark)))) (NNS tasks)))))))) (. .))
