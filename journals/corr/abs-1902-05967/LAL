(S (NP (JJ Modern) (JJ deep) (JJ neural) (NNS networks)) (VP (VBP are) (ADVP (RB typically)) (ADJP (RB highly) (VBN overparameterized))) (. .))
(S (NP (VBG Pruning) (NNS techniques)) (VP (VBP are) (ADJP (JJ able) (S (VP (TO to) (VP (VB remove) (NP (NP (DT a) (JJ significant) (NN fraction)) (PP (IN of) (NP (NN network) (NNS parameters)))) (PP (IN with) (NP (NP (JJ little) (NN loss)) (PP (IN in) (NP (NN accuracy)))))))))) (. .))
(S (ADVP (RB Recently)) (, ,) (NP (NP (NNS techniques)) (VP (VBN based) (PP (IN on) (NP (NP (JJ dynamic) (NN reallocation)) (PP (IN of) (NP (JJ non-zero) (NNS parameters))))))) (VP (VBP have) (VP (VBN emerged) (, ,) (S (VP (VBG allowing) (NP (NP (JJ direct) (NN training)) (PP (IN of) (NP (NN sparse) (NNS networks))) (PP (IN without) (S (VP (VBG having) (S (VP (TO to) (VP (VB pre-train) (NP (DT a) (JJ large) (NN dense) (NN model))))))))))))) (. .))
(S (ADVP (RB Here)) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ novel) (JJ dynamic) (JJ sparse) (NN reparameterization) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ addresses) (NP (NP (DT the) (NNS limitations)) (PP (IN of) (NP (JJ previous) (NNS techniques))) (PP (JJ such) (IN as) (NP (NP (JJ high) (JJ computational) (NN cost)) (CC and) (NP (NP (DT the) (NN need)) (PP (IN for) (NP (NP (JJ manual) (NN configuration)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ free) (NNS parameters))) (VP (VBD allocated) (PP (TO to) (NP (DT each) (NN layer))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (JJ dynamic) (NN reallocation) (NNS methods))) (PP (IN in) (S (VP (VBG training) (NP (JJ deep) (JJ convolutional) (NNS networks))))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (VBZ outperforms) (NP (JJ previous) (ADJP (JJ static) (CC and) (JJ dynamic)) (NN reparameterization) (NNS methods)) (, ,) (S (VP (VBG yielding) (NP (NP (NP (DT the) (JJS best) (NN accuracy)) (PP (IN for) (NP (DT a) (JJ fixed) (NN parameter) (NN budget)))) (, ,) (PP (IN on) (NP (NP (NN par)) (PP (IN with) (NP (NP (NNS accuracies)) (VP (VBN obtained) (PP (IN by) (S (VP (ADVP (RB iteratively)) (VBG pruning) (NP (DT a) (JJ pre-trained) (NN dense) (NN model)))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB further)) (VBD investigated) (NP (NP (DT the) (NNS mechanisms)) (VP (VBG underlying) (NP (NP (DT the) (JJ superior) (NN generalization) (NN performance)) (PP (IN of) (NP (DT the) (JJ resultant) (NN sparse) (NNS networks))))))) (. .))
(S (NP (PRP We)) (VP (VBD found) (SBAR (IN that) (S (NP (CC neither) (NP (DT the) (NN structure)) (, ,) (CC nor) (NP (NP (DT the) (NN initialization)) (PP (IN of) (NP (DT the) (JJ non-zero) (NNS parameters))))) (VP (VBD were) (ADJP (JJ sufficient) (S (VP (TO to) (VP (VB explain) (NP (DT the) (JJ superior) (NN performance)))))))))) (. .))
(S (ADVP (RB Rather)) (, ,) (NP (JJ effective) (VBG learning)) (VP (ADVP (RB crucially)) (VBN depended) (PP (IN on) (NP (NP (DT the) (JJ continuous) (NN exploration)) (PP (IN of) (NP (DT the) (JJ sparse) (NN network) (NN structure) (NN space))) (PP (IN during) (NP (NN training)))))) (. .))
(S (NP (PRP$ Our) (NN work)) (VP (VBZ suggests) (SBAR (IN that) (S (S (VP (VBG exploring) (NP (NP (JJ structural) (NNS degrees)) (PP (IN of) (NP (NN freedom)))) (PP (IN during) (NP (NN training))))) (VP (VBZ is) (ADJP (ADJP (RBR more) (JJ effective)) (PP (IN than) (S (VP (VBG adding) (NP (JJ extra) (NNS parameters)) (PP (TO to) (NP (DT the) (NN network))))))))))) (. .))
