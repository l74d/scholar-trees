(S (S (VP (VBG Selecting) (NP (DT an) (NN optimizer)))) (VP (VBZ is) (NP (NP (DT a) (JJ central) (NN step)) (PP (IN in) (NP (DT the) (JJ contemporary) (NML (JJ deep) (NN learning)) (NN pipeline))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (NP (DT the) (NN sensitivity)) (PP (IN of) (NP (NN optimizer) (NNS comparisons)))) (PP (IN to) (NP (DT the) (NN hyperparameter) (NN tuning) (NN protocol)))) (. .))
(S (NP (PRP$ Our) (NNS findings)) (VP (VBP suggest) (SBAR (IN that) (S (NP (DT the) (NML (NN hyperparameter) (NN search)) (NN space)) (VP (MD may) (VP (VB be) (NP (NP (DT the) (JJ single) (ADJP (RBS most) (JJ important)) (NN factor)) (VP (VBG explaining) (NP (NP (DT the) (NNS rankings)) (VP (VBN obtained) (PP (IN by) (NP (NP (JJ recent) (JJ empirical) (NNS comparisons)) (PP (IN in) (NP (DT the) (NN literature)))))))))))))) (. .))
(S (PP (IN In) (NP (NN fact))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT these) (NNS results)) (VP (MD can) (VP (VB be) (VP (VBN contradicted) (SBAR (WHADVP (WRB when)) (S (NP (NML (NN hyperparameter) (NN search)) (NNS spaces)) (VP (VBP are) (VP (VBN changed))))))))))) (. .))
(S (SBAR (IN As) (S (NP (NN tuning) (NN effort)) (VP (VBZ grows) (PP (IN without) (ADJP (VBN bound)))))) (, ,) (NP (ADJP (RBR more) (JJ general)) (NNS optimizers)) (VP (MD should) (ADVP (RB never)) (VP (VB underperform) (NP (NP (DT the) (NNS ones)) (SBAR (S (NP (PRP they)) (VP (MD can) (VP (VP (VB approximate) (S (S (-LRB- -LRB-) (ADVP (FW i.e.)) (, ,) (NP (NNP Adam)) (VP (MD should) (ADVP (RB never)) (VP (VB perform) (ADJP (ADJP (JJR worse)) (PP (IN than) (NP (NN momentum)))))) (-RRB- -RRB-)) (, ,) (CC but) (S (NP (JJ recent) (NNS attempts) (S (VP (TO to) (VP (VP (VB compare) (NP (NNS optimizers))) (CC either) (VP (VB assume) (NP (DT these) (NN inclusion) (NNS relationships))))))) (VP (VBP are) (RB not) (ADJP (RB practically) (JJ relevant)))))) (CC or) (VP (VB restrict) (NP (DT the) (NNS hyperparameters)) (PP (IN in) (NP (NP (NNS ways)) (SBAR (WHNP (WDT that)) (S (VP (VBP break) (NP (DT the) (NNS inclusions))))))))))))))) (. .))
(S (PP (IN In) (NP (PRP$ our) (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (NP (NN inclusion) (NNS relationships)) (PP (IN between) (NP (NP (NNS optimizers)) (ADVP (ADVP (RB matter) (PP (IN in) (NP (NN practice)))) (CC and) (ADVP (RB always)))))) (VP (VBP predict) (NP (NN optimizer) (NNS comparisons)))))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (DT the) (JJ popular) (JJ adaptive) (NN gradient) (NNS methods)) (ADVP (RB never)) (VP (VBP underperform) (NP (NN momentum) (CC or) (NN gradient) (NN descent)))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP report) (NP (JJ practical) (NNS tips)) (PP (IN around) (NP (NP (NN tuning)) (VP (ADVP (RB often)) (VBN ignored) (NP (NP (NNS hyperparameters)) (PP (IN of) (NP (JJ adaptive) (NN gradient) (NNS methods)))))))) (CC and) (VP (VB raise) (NP (NNS concerns)) (NP (NP (RB about) (ADJP (RB fairly) (JJ benchmarking)) (NNS optimizers)) (PP (IN for) (NP (JJ neural) (NN network) (NN training)))))) (. .))
