(S (S (VP (VBN Distributed) (S (ADJP (JJ asynchronous))))) (S (ADVP (RB offline)) (NP (NN training)) (VP (VBZ has) (VP (VBN received) (NP (NP (JJ widespread) (NN attention)) (PP (IN in) (NP (JJ recent) (NNS years)))) (PP (IN because) (PP (IN of) (NP (PRP$ its) (JJ high) (NN performance)))) (PP (IN on) (NP (NP (NML (JJ large) (HYPH -) (NN scale)) (NNS data)) (CC and) (NP (JJ complex) (NNS models))))))) (. .))
(S (SBAR (IN As) (S (NP (NNS data)) (VP (VBP are) (VP (VBN distributed) (PP (IN from) (NP (NP (NN cloud) (HYPH -) (JJ centric)) (SBAR (S (VP (TO to) (VP (VB edge) (NP (NNS nodes)))))))))))) (, ,) (NP (NP (DT a) (JJ big) (NN challenge)) (PP (IN for) (NP (VBN distributed) (NML (NN machine) (NN learning)) (NNS systems)))) (VP (VBZ is) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB handle) (NP (ADJP (JJ native) (CC and) (JJ natural)) (ADJP (ADJP (JJ non-independent)) (CC and) (ADJP (RB identically) (VBN distributed))) (ADJP (-LRB- -LRB-) (JJ non-IID) (-RRB- -RRB-)) (NNS data)) (PP (IN for) (NP (NN training)))))))) (. .))
(S (NP (JJ Previous) (ADJP (JJ asynchronous)) (NN training) (NNS methods)) (VP (VBP do) (RB not) (VP (VB have) (NP (NP (DT a) (ADJP (JJ satisfying)) (NN performance)) (PP (IN on) (NP (JJ non-IID) (NNS data)))) (SBAR (IN because) (S (NP (PRP it)) (VP (MD would) (VP (VB result) (PP (IN in) (SBAR (IN that) (S (NP (DT the) (NN training) (NN process)) (VP (VBZ fluctuates) (ADVP (RB greatly)) (SBAR (WHNP (WDT which)) (S (VP (VBZ leads) (PP (IN to) (NP (DT an) (JJ abnormal) (NN convergence)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (NML (NN gradient) (NN scheduling)) (NN algorithm)) (PP (IN with) (NP (NP (ADJP (RB partly) (VBN averaged)) (NNS gradients)) (CC and) (NP (NP (JJ global) (NN momentum) (-LRB- -LRB-) (NN GSGM) (-RRB- -RRB-)) (PP (IN for) (NP (NP (JJ non-IID) (NNS data)) (VP (VBN distributed) (NP (ADJP (JJ asynchronous)) (NN training))))))))) (. .))
(S (NP (PRP$ Our) (JJ key) (NN idea)) (VP (VBZ is) (S (VP (TO to) (VP (VB apply) (NP (NP (JJ global) (NN momentum)) (CC and) (NP (JJ local) (NN average))) (PP (IN to) (NP (NP (DT the) (JJ biased) (NN gradient)) (PP (IN after) (NP (NN scheduling))))) (, ,) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB make) (S (NP (DT the) (NN training) (NN process)) (ADJP (JJ steady))))))))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (PP (IN for) (NP (NP (JJ non-IID) (NNS data) (NN training)) (PP (IN under) (NP (DT the) (JJ same) (JJ experimental) (NNS conditions))))) (, ,) (NP (NP (NNP GSGM)) (PP (IN on) (NP (JJ popular) (NN optimization) (NNS algorithms)))) (VP (MD can) (VP (VB achieve) (NP (NP (DT a) (NML (CD 20) (NN %)) (NN increase)) (PP (IN in) (NP (NN training) (NN stability)))) (PP (IN with) (NP (NP (DT a) (JJ slight) (NN improvement)) (PP (IN in) (NP (NN accuracy))))) (PP (IN on) (NP (NML (NML (NN Fashion) (HYPH -) (NN Mnist)) (CC and) (NML (NN CIFAR) (HYPH -) (CD 10))) (NNS datasets)))))))) (. .))
(S (ADVP (RB Meanwhile)) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBG expanding) (NP (VBN distributed) (NN scale)) (PP (IN on) (NP (NP (NML (NN CIFAR) (HYPH -) (CD 100)) (NN dataset)) (SBAR (WHNP (WDT that)) (S (VP (VBZ results) (PP (IN in) (NP (JJ sparse) (NNS data) (NN distribution))))))))))) (, ,) (NP (NNP GSGM)) (VP (MD can) (VP (VB perform) (NP (DT a) (NML (CD 37) (NN %)) (NN improvement)) (PP (IN on) (NP (NN training) (NN stability))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (RB only) (NNP GSGM)) (VP (MD can) (VP (VB converge) (SBAR (WHADVP (RB well) (WRB when)) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (VBG computing) (NNS nodes)))) (VP (VBZ grows) (PP (IN to) (NP (CD 30))) (, ,) (PP (VBN compared) (PP (IN to) (NP (DT the) (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (ADJP (VBN distributed) (JJ asynchronous)) (NNS algorithms))))))))) (. .))
(S (PP (IN At) (NP (DT the) (JJ same) (NN time))) (, ,) (NP (NNP GSGM)) (VP (VBZ is) (ADJP (JJ robust) (PP (IN to) (NP (NP (JJ different) (NNS degrees)) (PP (IN of) (NP (JJ non-IID) (NNS data))))))) (. .))
