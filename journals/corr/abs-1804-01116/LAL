(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT an) (JJ online) (NN reinforcement) (VBG learning) (NN algorithm)) (, ,) (VP (VBN called) (S (NP (S (NP (NNP Renewal) (NNP Monte) (NNP Carlo))) (PRN (-LRB- -LRB-) (NP (NNP RMC)) (-RRB- -RRB-))))) (, ,) (PP (IN for) (NP (NP (JJ infinite) (NN horizon) (NNP Markov) (NN decision) (VBZ processes)) (PP (IN with) (NP (DT a) (JJ designated) (NN start) (NN state))))))) (. .))
(S (NP (NNP RMC)) (VP (VP (VBZ is) (NP (DT a) (NNP Monte) (NNP Carlo) (NN algorithm))) (CC and) (VP (VBZ retains) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (NP (NNP Monte) (NNP Carlo) (NNS methods))) (PP (VBG including) (NP (NP (JJ low) (NN bias)) (, ,) (NP (NN simplicity)) (, ,) (CC and) (NP (NP (NN ease)) (PP (IN of) (NP (NN implementation))))))) (SBAR (IN while) (, ,) (PP (IN at) (NP (DT the) (JJ same) (NN time))) (, ,) (VP (NNS circumvents) (NP (NP (PRP$ their) (JJ key) (NNS drawbacks)) (PP (IN of) (NP (NP (JJ high) (NN variance)) (CC and) (NP (NN delayed) (PRN (-LRB- -LRB-) (NAC (NN end) (PP (IN of) (NP (NN episode)))) (-RRB- -RRB-)) (VBZ updates))))))))) (. .))
(S (NP (NP (DT The) (NN key) (NNS ideas)) (PP (IN behind) (NP (NNP RMC)))) (VP (VBP are) (SBAR (IN as) (S (VP (VBZ follows))))) (. .))
(S (ADVP (RB First)) (, ,) (PP (IN under) (NP (DT any) (JJ reasonable) (NN policy))) (, ,) (NP (DT the) (NN reward) (NN process)) (VP (VBZ is) (ADJP (JJ ergodic))) (. .))
(S (ADVP (RB So)) (, ,) (PP (IN by) (NP (NN renewal) (NN theory))) (, ,) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT a) (NN policy)))) (VP (VBZ is) (ADJP (JJ equal) (PP (TO to) (NP (NP (DT the) (NN ratio)) (PP (IN of) (NP (VBN expected) (VBN discounted) (NN reward))) (PP (TO to) (NP (NP (DT the) (VBN expected) (JJ discounted) (NN time)) (PP (IN over) (NP (DT a) (JJ regenerative) (NN cycle))))))))) (. .))
(S (ADVP (JJ Second)) (, ,) (PP (IN by) (S (VP (ADVP (RB carefully)) (VBG examining) (NP (NP (DT the) (NN expression)) (PP (IN for) (NP (NN performance) (NN gradient))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ stochastic) (NN approximation) (NN algorithm)) (SBAR (WHNP (IN that)) (S (ADVP (RB only)) (VP (VBZ requires) (NP (NP (NNS estimates)) (PP (IN of) (NP (NP (NP (DT the) (NX (VBN expected) (NX (NX (VBN discounted) (NN reward)) (CC and) (NX (VBD discounted) (NN time))))) (PP (IN over) (NP (DT a) (JJ regenerative) (NN cycle)))) (CC and) (NP (PRP$ their) (NNS gradients)))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP propose) (NP (NP (NP (CD two) (JJ unbiased) (NNS estimators)) (PP (IN for) (S (VP (VBG evaluating) (NP (NN performance) (NNS gradients)))))) (: —) (NP (NP (VB -a) (ADJP (NN likelihood) (NN ratio) (VBN based)) (NN estimator)) (CC and) (NP (DT a) (JJ simultaneous) (NN perturbation) (VBN based) (NN estimator))) (: —))) (VB -and) (VP (NN show) (SBAR (IN that) (S (PP (IN for) (NP (DT both) (NNS estimators))) (, ,) (NP (NNP RMC)) (VP (VBZ converges) (PP (TO to) (NP (DT a) (ADJP (RB locally) (JJ optimal)) (NN policy)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP generalize) (NP (DT the) (NNP RMC) (NN algorithm)) (PP (TO to) (NP (NN post-decision) (NN state) (NNS models)))) (CC and) (ADVP (RB also)) (VP (VB present) (NP (NP (DT a) (NN variant)) (SBAR (WHNP (WDT that)) (S (VP (VBZ converges) (ADVP (JJR faster)) (PP (TO to) (NP (DT an) (ADJP (RB approximately) (JJ optimal)) (NN policy))))))))) (. .))
(S (NP (PRP We)) (VP (VBP conclude) (PP (IN by) (S (VP (VBG presenting) (NP (NP (JJ numerical) (NNS experiments)) (PP (IN on) (NP (NP (DT a) (ADJP (RB randomly) (VBN generated)) (NNP MDP)) (, ,) (NP (JJ event-triggered) (NN communication)) (, ,) (CC and) (NP (NN inventory) (NN management))))))))) (. .))
