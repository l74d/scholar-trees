(S (NP (NP (VBN Regularized) (NN training)) (PP (IN of) (NP (DT an) (NN autoencoder)))) (ADVP (RB typically)) (VP (VBZ results) (PP (IN in) (NP (NP (JJ hidden) (NN unit) (NNS biases)) (SBAR (WHNP (WDT that)) (S (VP (VBP take) (PRT (RB on)) (NP (JJ large) (JJ negative) (NNS values)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ negative) (NNS biases)) (VP (VBP are) (NP (NP (DT a) (JJ natural) (NN result)) (PP (IN of) (S (VP (VBG using) (NP (NP (DT a) (JJ hidden) (NN layer)) (SBAR (WHNP (WP$ whose) (NN responsibility)) (S (VP (VBZ is) (S (VP (TO to) (VP (DT both) (VP (VB represent) (NP (DT the) (NN input) (NNS data))) (CC and) (VP (VB act) (PP (IN as) (NP (NP (DT a) (NN selection) (NN mechanism)) (SBAR (WHNP (WDT that)) (S (VP (VBZ ensures) (NP (NP (NN sparsity)) (PP (IN of) (NP (DT the) (NN representation))))))))))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ negative) (NNS biases)) (VP (VBP impede) (NP (NP (DT the) (NN learning)) (PP (IN of) (NP (NP (NNS data) (NNS distributions)) (SBAR (WHNP (WP$ whose)) (S (NP (JJ intrinsic) (NN dimensionality)) (VP (VBZ is) (ADJP (JJ high)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP propose) (NP (DT a) (JJ new) (NN activation) (NN function)) (SBAR (SBAR (WHNP (WDT that)) (S (VP (VBZ decouples) (NP (NP (DT the) (CD two) (NNS roles)) (PP (IN of) (NP (DT the) (JJ hidden) (NN layer))))))) (CC and) (SBAR (IN that) (S (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB learn) (NP (NNS representations)) (PP (IN on) (NP (NP (NNS data)) (PP (IN with) (NP (NP (ADJP (RB very) (JJ high)) (JJ intrinsic) (NN dimensionality)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (JJ standard) (NNS autoencoders)) (ADVP (RB typically)) (VP (VBP fail)))))))))))))))) (. .))
(S (SBAR (IN Since) (S (NP (DT the) (VBN decoupled) (NN activation) (NN function)) (VP (VBZ acts) (PP (IN like) (NP (DT an) (JJ implicit) (NN regularizer)))))) (, ,) (NP (DT the) (NN model)) (VP (MD can) (VP (VB be) (VP (VBN trained) (PP (IN by) (S (VP (VBG minimizing) (NP (NP (DT the) (NN reconstruction) (NN error)) (PP (IN of) (NP (NN training) (NNS data))))))) (, ,) (PP (IN without) (S (VP (VBG requiring) (NP (DT any) (JJ additional) (NN regularization)))))))) (. .))
