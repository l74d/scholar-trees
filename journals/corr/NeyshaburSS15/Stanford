(S (NP (PRP We)) (VP (VBP revisit) (NP (NP (DT the) (NN choice)) (PP (IN of) (NP (NNP SGD)))) (PP (IN for) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks)) (PP (IN by) (S (VP (VBG reconsidering) (NP (NP (DT the) (JJ appropriate) (NN geometry)) (PP (IN in) (SBAR (WHNP (WDT which)) (S (VP (TO to) (VP (VB optimize) (NP (DT the) (NNS weights))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP argue) (PP (IN for) (NP (DT a) (NN geometry) (ADJP (JJ invariant) (PP (IN to) (NP (NP (NN rescaling)) (PP (IN of) (NP (NP (NNS weights)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ does) (RB not) (VP (VB affect) (NP (NP (DT the) (NN output)) (PP (IN of) (NP (DT the) (NN network)))))) (, ,) (CC and) (VP (VBP suggest) (NP (NP (NN Path) (HYPH -) (NN SGD)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (DT an) (JJ approximate) (JJS steepest) (NN descent) (NN method)) (PP (IN with) (NP (NP (NN respect)) (PP (IN to) (NP (NP (DT a) (JJ path-wise) (NN regularizer)) (VP (VBN related) (PP (IN to) (NP (NN max) (HYPH -) (NN norm)))))))))))))))))))))) (NN regularization)))) (. .))
(S (NP (NN Path) (HYPH -) (NN SGD)) (VP (VP (VBZ is) (ADJP (JJ easy) (CC and) (JJ efficient) (S (VP (TO to) (VP (VB implement)))))) (CC and) (VP (VBZ leads) (PP (IN to) (NP (NP (JJ empirical) (NNS gains)) (PP (IN over) (NP (NNP SGD) (CC and) (NNP AdaGrad))))))) (. .))
