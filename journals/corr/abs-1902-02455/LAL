(S (PP (IN In) (NP (JJ recent) (NNS years))) (, ,) (NP (NN speaker) (NN verification)) (VP (VBZ has) (ADVP (RB primarily)) (VP (VBN performed) (S (VP (VBG using) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (VBN trained) (S (VP (TO to) (VP (NN output) (NP (NNS embeddings)) (PP (IN from) (NP (NP (NN input) (NNS features)) (PP (JJ such) (IN as) (NP (NP (NNS spectrograms)) (CC or) (NP (JJ Mel-filterbank) (NNS energies)))))))))))))))))) (. .))
(S (NP (NP (NNS Studies)) (SBAR (WHNP (WDT that)) (S (VP (VBP design) (NP (NP (JJ various) (NN loss) (NNS functions)) (, ,) (PP (VBG including) (NP (JJ metric) (NN learning)))))))) (VP (VBP have) (VP (VBN been) (VP (ADVP (RB widely)) (VBN explored)))) (. .))
(S (PP (IN In) (NP (DT this) (NN study))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (CD two) (JJ end-to-end) (NN loss) (NNS functions)) (PP (IN for) (NP (NN speaker) (NN verification)))) (S (VP (VBG using) (NP (NP (DT the) (NN concept)) (PP (IN of) (NP (NP (NN speaker) (NNS bases)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (NP (JJ trainable) (NNS parameters))))))))))) (. .))
(S (S (NP (CD One) (NN loss) (NN function)) (VP (VBZ is) (VP (VBN designed) (S (VP (TO to) (ADVP (RBR further)) (VP (VB increase) (NP (DT the) (JJ inter-speaker) (NN variation)))))))) (, ,) (CC and) (S (NP (DT the) (JJ other)) (VP (VBZ is) (VP (VBN designed) (S (VP (TO to) (VP (VB conduct) (NP (DT the) (JJ identical) (NN concept)) (PP (IN with) (NP (JJ hard) (JJ negative) (NN mining))))))))) (. .))
(S (NP (DT Each) (NN speaker) (NN basis)) (VP (VBZ is) (VP (VBN designed) (S (VP (TO to) (VP (VB represent) (NP (NP (DT the) (JJ corresponding) (NN speaker)) (PP (IN in) (NP (NP (DT the) (NN process)) (PP (IN of) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks))))))))))))) (. .))
(S (PP (IN In) (NP (NP (NN contrast)) (PP (TO to) (NP (NP (DT the) (JJ conventional) (NN loss) (NNS functions)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB consider) (NP (NP (RB only) (DT a) (JJ limited) (NN number)) (PP (IN of) (NP (NNS speakers))) (VP (VBN included) (PP (IN in) (NP (DT a) (NN mini-batch))))))))))))) (, ,) (NP (DT the) (VBN proposed) (NN loss) (NNS functions)) (VP (MD can) (VP (VB consider) (NP (NP (DT all) (DT the) (NNS speakers)) (PP (IN in) (NP (DT the) (NN training) (VBN set)))) (ADVP (RB regardless) (PP (IN of) (NP (DT the) (JJ mini-batch) (NN composition)))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (NP (DT the) (VBN proposed) (NN loss) (NNS functions)) (VP (JJ enable) (NP (NP (NP (JJ hard) (JJ negative) (NN mining)) (CC and) (NP (NP (NNS calculations)) (PP (IN of) (NP (NN between-speaker) (NNS variations))))) (PP (IN with) (NP (NP (NN consideration)) (PP (IN of) (NP (DT all) (NNS speakers))))))) (. .))
(S (PP (IN Through) (NP (NP (NNS experiments)) (PP (IN on) (NP (NNP VoxCeleb1) (CC and) (NNP VoxCeleb2) (NNS datasets))))) (, ,) (NP (PRP we)) (VP (VBD confirmed) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN loss) (NNS functions)) (VP (MD could) (VP (VB supplement) (NP (JJ conventional) (NN softmax) (CC and) (NN center) (NN loss) (NNS functions))))))) (. .))
