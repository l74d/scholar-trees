(S (NP (NP (DT The) (JJ high) (NN energy) (NN cost)) (PP (IN of) (S (VP (VBG processing) (NP (JJ deep) (JJ convolutional) (JJ neural) (NNS networks)))))) (VP (VBP impedes) (NP (NP (PRP$ their) (JJ ubiquitous) (NN deployment)) (PP (IN in) (NP (NP (JJ energy-constrained) (NNS platforms)) (PP (JJ such) (IN as) (NP (NP (JJ embedded) (NNS systems)) (CC and) (NP (NNP IoT) (NNS devices)))))))) (. .))
(S (NP (DT This) (NN work)) (VP (VBZ introduces) (NP (NP (JJ convolutional) (NNS layers)) (PP (IN with) (NP (NP (JJ pre-defined) (NN sparse) (CD 2D) (NNS kernels)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (NP (NP (VBN support) (NNS sets)) (SBAR (WHNP (WDT that)) (S (VP (VBP repeat) (ADVP (RB periodically)) (PP (IN within) (CC and) (IN across) (NP (NNS filters)))))))))))))) (. .))
(S (PP (JJ Due) (TO to) (NP (NP (DT the) (JJ efficient) (NN storage)) (PP (IN of) (NP (PRP$ our) (JJ periodic) (NN sparse) (NNS kernels))))) (, ,) (NP (DT the) (NN parameter) (NNS savings)) (VP (MD can) (VP (VB translate) (PP (IN into) (NP (NP (JJ considerable) (NNS improvements)) (PP (IN in) (NP (NN energy) (NN efficiency))) (PP (JJ due) (PP (TO to) (NP (VB reduced) (NNP DRAM) (NNS accesses)))))) (, ,) (S (ADVP (RB thus)) (VP (VBG promising) (NP (NP (JJ significant) (NNS improvements)) (PP (IN in) (NP (NP (DT the) (NN trade-off)) (PP (IN between) (NP (NP (NN energy) (NN consumption)) (CC and) (NP (NN accuracy)))))) (PP (IN for) (NP (DT both) (NN training) (CC and) (NN inference)))))))) (. .))
(S (S (VP (TO To) (VP (VB evaluate) (NP (DT this) (NN approach))))) (, ,) (NP (PRP we)) (VP (VBD performed) (NP (NNS experiments)) (PP (IN with) (NP (NP (CD two) (ADJP (RB widely) (VBN accepted)) (NNS datasets)) (, ,) (NP (NP (NNP CIFAR-10)) (CC and) (NP (NNP Tiny) (NNP ImageNet))))) (PP (IN in) (NP (NP (JJ sparse) (NNS variants)) (PP (IN of) (NP (DT the) (VP (NP (NNP ResNet18) (CC and))) (NNP VGG16) (NNS architectures)))))) (. .))
(S (PP (VBN Compared) (PP (TO to) (NP (VB baseline) (NNS models)))) (, ,) (NP (PRP$ our) (VBN proposed) (NN sparse) (NNS variants)) (VP (VBP require) (NP (ADJP (NP (QP (IN up) (TO to) (CD 82)) (NN %)) (JJR fewer)) (NN model) (NNS parameters)) (PP (IN with) (NP (CD 5.6times) (JJR fewer) (NNP FLOPs))) (PP (IN with) (NP (NP (JJ negligible) (NN loss)) (PP (IN in) (NP (NN accuracy))))) (PP (IN for) (NP (NP (NNP ResNet18)) (PP (IN on) (NP (NNP CIFAR-10)))))) (. .))
(S (PP (IN For) (NP (NP (NNP VGG16)) (VP (VBD trained) (PP (IN on) (NP (NNP Tiny) (NNP ImageNet)))))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ requires) (NP (NP (ADJP (QP (CD 5.8times)) (JJR fewer)) (NN FLOPs)) (CC and) (NP (ADJP (NP (QP (RB up) (TO to) (CD 83.3)) (NN %)) (JJR fewer)) (NN model) (NNS parameters))) (PP (IN with) (NP (NP (DT a) (NN drop)) (PP (IN in) (NP (JJ top-5) (PRN (-LRB- -LRB-) (JJ top-1) (-RRB- -RRB-)) (NN accuracy))) (PP (IN of) (NP (NP (QP (RB only) (CD 1.2)) (NN %)) (PRN (-LRB- -LRB-) (NP (CD 2.1) (NN %)) (-RRB- -RRB-))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBN compared) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (PRP$ our) (VBN proposed) (NNS architectures)))) (PP (IN with) (NP (NP (DT that)) (PP (IN of) (NP (NNP ShuffleNet) (NN andMobileNetV2)))))) (. .))
(S (S (VP (VBG Using) (NP (JJ similar) (NNS hyperparameters) (CC and) (NNP FLOPs)))) (, ,) (NP (PRP$ our) (NNP ResNet18) (NNS variants)) (VP (VBP yield) (NP (NP (DT an) (JJ average) (NN accuracy) (NN improvement)) (PP (IN of) (NP (CD 2.8) (NN %))))) (. .))
