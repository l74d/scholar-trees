(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT an) (NN algorithm)) (PP (IN for) (NP (ADJP (NP (JJ inexpensive) (NN gradient)) (HYPH -) (VBN based)) (NN hyperparameter) (NN optimization) (SBAR (WHNP (WDT that)) (S (VP (VBZ combines) (NP (DT the) (JJ implicit) (NN function) (NN theorem))))) (PRN (-LRB- -LRB-) (NP (NN IFT)) (-RRB- -RRB-))))) (PP (IN with) (NP (JJ efficient) (NN inverse) (JJ Hessian) (NNS approximations)))) (. .))
(S (S (NP (PRP We)) (VP (VBP present) (NP (NNS results)) (PP (IN about) (NP (NP (DT the) (NN relationship)) (PP (IN between) (NP (DT the) (NNP IFT))))))) (CC and) (S (S (VP (VBG differentiating) (PP (IN through) (NP (NN optimization))))) (, ,) (S (VP (VBG motivating) (NP (PRP$ our) (NN algorithm))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (DT the) (VBN proposed) (NN approach)) (PP (IN to) (NP (NP (NN train) (JJ modern) (NN network) (NNS architectures)) (PP (IN with) (NP (NP (NNS millions)) (PP (IN of) (NP (NP (NNS weights) (CC and) (NNS millions)) (PP (IN of) (NP (ADJP (JJ hyper) (HYPH -)) (NNS parameters)))))))))) (. .))
(S (PP (IN For) (NP (NN example))) (, ,) (NP (PRP we)) (VP (VBP learn) (NP (DT a) (NML (NN data) (HYPH -) (NN augmentation)) (NN network)) (: -) (SBAR (WHADVP (WRB where)) (S (NP (DT every) (NN weight)) (VP (VBZ is) (NP (NP (DT a) (NN hyperparameter)) (VP (VBN tuned) (PP (IN for) (NP (NN validation))) (NP (NP (NN performance) (HYPH -) (VBG outputting)) (VP (VBN augmented) (NP (NN training) (NNS examples)))))))))) (. .))
(S (ADVP (RB Jointly)) (VP (VBP tuning) (SBAR (S (NP (NP (NNS weights) (CC and) (NNS hyperparameters)) (PP (IN with) (NP (PRP$ our) (NN approach)))) (VP (VP (VBZ is) (ADJP (NP (QP (RB only) (DT a) (JJ few)) (NNS times)) (ADJP (RBR more) (JJ costly) (PP (IN in) (NP (NN memory)))))) (CC and) (VP (VB compute) (PP (IN than) (NP (JJ standard) (NN training)))))))) (. .))
