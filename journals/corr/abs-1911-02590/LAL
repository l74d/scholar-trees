(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT an) (NN algorithm)) (PP (IN for) (NP (JJ inexpensive) (JJ gradient-based) (NN hyperparameter) (NN optimization))) (SBAR (WHNP (WDT that)) (S (VP (VBZ combines) (NP (NP (DT the) (JJ implicit) (NN function) (NN theorem)) (PRN (-LRB- -LRB-) (NP (NNP IFT)) (-RRB- -RRB-))) (PP (IN with) (NP (JJ efficient) (JJ inverse) (JJ Hessian) (NNS approximations)))))))) (. .))
(S (NP (PRP We)) (VP (JJ present) (NP (NP (NP (NNS results)) (PP (IN about) (NP (NP (DT the) (NN relationship)) (PP (IN between) (NP (NP (DT the) (NNP IFT)) (CC and) (S (VP (VBG differentiating) (PP (IN through) (NP (NN optimization)))))))))) (, ,) (VP (VBG motivating) (NP (PRP$ our) (NN algorithm))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (DT the) (VBN proposed) (NN approach)) (S (VP (TO to) (VP (VB train) (NP (JJ modern) (NN network) (NNS architectures)) (PP (IN with) (NP (NP (NP (NNS millions)) (PP (IN of) (NP (NNS weights)))) (CC and) (NP (NP (NNS millions)) (PP (IN of) (NP (NNS hyper-parameters)))))))))) (. .))
(S (PP (IN For) (NP (NN example))) (, ,) (NP (PRP we)) (VP (VBP learn) (NP (NP (NP (DT a) (NN data-augmentation) (NN network)) (PRN (: -) (SBAR (WHADVP (WRB where)) (S (NP (DT every) (NN weight)) (VP (VBZ is) (NP (NP (DT a) (NN hyperparameter)) (VP (VBN tuned) (PP (IN for) (NP (NN validation) (NN performance)))))))) (: -))) (VP (NN outputting) (NP (VBD augmented) (NN training) (NNS examples))))) (. .))
(S (S (VP (ADVP (RB Jointly)) (VBG tuning) (NP (NNS weights) (CC and) (NNS hyperparameters)) (PP (IN with) (NP (PRP$ our) (NN approach))))) (VP (VBZ is) (ADJP (ADJP (QP (RB only) (DT a) (JJ few) (NNS times)) (RBR more) (JJ costly)) (PP (IN in) (NP (NN memory) (CC and) (NN compute))) (PP (IN than) (NP (JJ standard) (NN training))))) (. .))
