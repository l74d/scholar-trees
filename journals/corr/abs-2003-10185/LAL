(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (JJ model-free) (NN reinforcement) (VBG learning) (NNS algorithm)) (SBAR (S (VP (TO to) (VP (VB compute) (NP (NP (DT the) (JJ optimal) (NNS policies)) (PP (IN for) (NP (NP (DT a) (JJ multi-agent) (NN system)) (PP (IN with) (NP (ADJP ($ $) (NNP N) ($ $)) (JJ cooperative) (NNS agents))) (SBAR (WHADVP (WRB where)) (S (NP (DT each) (NN agent)) (VP (VP (ADVP (RB privately)) (VBZ observes) (NP (NP (PRP it) (VBZ 's)) (JJ own) (JJ private) (NN type))) (CC and) (VP (ADVP (RB publicly)) (VBZ observes) (NP (NP (DT each) (NNS others) (POS â€º)) (NNS actions))))))))))))))) (. .))
(S (NP (DT The) (NN goal)) (VP (VBZ is) (S (VP (TO to) (VP (VB maximize) (NP (PRP$ their) (JJ collective) (NN reward)))))) (. .))
(S (NP (DT The) (NN problem)) (VP (VBZ belongs) (PP (TO to) (NP (NP (DT the) (JJ broad) (NN class)) (PP (IN of) (NP (NP (VBN decentralized) (NN control) (NNS problems)) (PP (IN with) (NP (JJ partial) (NN information)))))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (NP (DT the) (JJ common) (NN agent) (NN approach)) (SBAR (WHNP (VBD wherein)) (S (NP (DT some) (JJ fictitious) (JJ common) (NN agent)) (VP (VBZ picks) (NP (DT the) (JJS best) (NN policy)) (PP (VBN based) (PP (IN on) (NP (NP (DT a) (NN belief)) (PP (IN on) (NP (NP (DT the) (JJ current) (NNS states)) (PP (IN of) (NP (DT the) (NNS agents))))))))))))) (. .))
(S (NP (DT These) (NNS beliefs)) (VP (VBP are) (VP (VBN updated) (ADVP (RB individually)) (PP (IN for) (NP (DT each) (NN agent))) (PP (IN from) (NP (PRP$ their) (JJ current) (NN belief) (CC and) (NN action) (NNS histories))))) (. .))
(S (NP (NP (NNP Belief) (NN state) (NNS updates)) (PP (IN without) (NP (NP (DT the) (NN knowledge)) (PP (IN of) (NP (NN system) (NNS dynamics)))))) (VP (VBZ is) (NP (DT a) (NN challenge))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP employ) (NP (NP (NN particle) (NNS filters)) (VP (VBD called) (S (NP (DT the) (NN bootstrap) (NN filter))))) (ADVP (RB distributively)) (PP (IN across) (NP (NNS agents))) (S (VP (TO to) (VP (VB update) (NP (DT the) (NN belief)))))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (NP (NP (DT a) (JJ model-free) (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NNP RL) (-RRB- -RRB-)) (NN method)) (PP (IN for) (NP (DT this) (JJ multi-agent) (ADJP (RB partially) (JJ observable)) (NNP Markov) (NN decision) (VBZ processes)))) (VP (VBG using) (NP (NP (DT the) (NN particle) (NN filter)) (CC and) (NP (JJ sampled) (NNS trajectories))) (S (VP (TO to) (VP (VB estimate) (NP (NP (DT the) (JJ optimal) (NNS policies)) (PP (IN for) (NP (DT the) (NNS agents)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP showcase) (NP (PRP$ our) (NNS results)) (PP (IN with) (NP (NP (DT the) (NN help)) (PP (IN of) (NP (NP (DT a) (JJ smartgrid) (NN application)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NNS users)) (VP (VBP strive) (S (VP (TO to) (VP (VB reduce) (NP (NP (JJ collective) (NN cost)) (PP (IN of) (NP (NN power))) (PP (IN for) (NP (NP (PDT all) (DT the) (NNS agents)) (PP (IN in) (NP (DT the) (NN grid))))))))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP compare) (NP (NP (DT the) (NNS performances)) (PP (IN for) (NP (NP (ADJP (NN model) (CC and) (JJ model-free)) (NN implementation)) (PP (IN of) (NP (DT the) (NNP RL) (NN algorithm)))))) (S (VP (VBG establishing) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NN particle) (NN filter) (PRN (-LRB- -LRB-) (NN pf) (-RRB- -RRB-)) (NN method))))))) (. .))
