(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP propose) (NP (DT a) (ADJP (NP (JJ novel) (NN model)) (HYPH -) (JJ free)) (NN reinforcement)) (S (VP (VBG learning) (NP (NN algorithm)) (PP (IN to) (VP (VB compute) (NP (NP (DT the) (JJ optimal) (NNS policies)) (PP (IN for) (NP (DT a) (JJ multi-agent) (NN system)))) (PP (IN with) (NP (NP (QP ($ $) (CD N$)) (JJ cooperative) (NNS agents)) (SBAR (WHADVP (WRB where)) (S (NP (DT each) (NN agent)) (ADVP (RB privately)) (VP (VBZ observes) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (NP (JJ own) (NML (JJ private) (NN type)))))))))))))))) (CC and) (VP (ADVP (RB publicly)) (VBZ observes) (NP (NP (DT each) (NNS others) (POS ')) (NNS actions)))) (. .))
(S (NP (DT The) (NN goal)) (VP (VBZ is) (S (VP (TO to) (VP (VB maximize) (NP (PRP$ their) (JJ collective) (NN reward)))))) (. .))
(S (NP (DT The) (NN problem)) (VP (VBZ belongs) (PP (IN to) (NP (NP (DT the) (JJ broad) (NN class)) (PP (IN of) (NP (JJ decentralized) (NN control) (NNS problems))))) (PP (IN with) (NP (JJ partial) (NN information)))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (DT the) (JJ common) (NN agent) (NN approach)) (SBAR (WHADVP (IN wherein)) (S (NP (DT some) (JJ fictitious) (JJ common) (NN agent)) (VP (VBZ picks) (NP (NP (DT the) (JJS best) (NN policy)) (PP (VBN based) (PP (IN on) (NP (NP (DT a) (NN belief)) (PP (IN on) (NP (NP (DT the) (JJ current) (NNS states)) (PP (IN of) (NP (DT the) (NNS agents))))))))))))) (. .))
(S (NP (DT These) (NNS beliefs)) (VP (VBP are) (VP (VBN updated) (ADVP (RB individually)) (PP (IN for) (NP (NP (DT each) (NN agent)) (PP (IN from) (NP (NP (PRP$ their) (JJ current) (NN belief)) (CC and) (NP (NN action) (NNS histories)))))))) (. .))
(S (NP (NP (NN Belief) (NN state) (NNS updates)) (PP (IN without) (NP (NP (DT the) (NN knowledge)) (PP (IN of) (NP (NN system) (NNS dynamics)))))) (VP (VBZ is) (NP (DT a) (NN challenge))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP employ) (SBAR (S (NP (NN particle) (NNS filters)) (VP (VBD called) (NP (DT the) (NN bootstrap) (NN filter)) (ADVP (RB distributively)) (PP (IN across) (NP (NNS agents))) (S (VP (TO to) (VP (VB update) (NP (DT the) (NN belief))))))))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (NP (DT a) (NML (NML (NN model)) (HYPH -) (NML (JJ free) (NN reinforcement) (NN learning)) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-))) (NN method)) (PP (IN for) (NP (NP (DT this) (JJ multi-agent) (ADJP (RB partially) (JJ observable)) (NNP Markov) (NN decision) (NNS processes)) (VP (VP (VBG using) (NP (DT the) (NN particle) (NN filter))) (CC and) (VP (VBN sampled) (NP (NNS trajectories)) (S (VP (TO to) (VP (VB estimate) (NP (NP (DT the) (JJ optimal) (NNS policies)) (PP (IN for) (NP (DT the) (NNS agents))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP showcase) (NP (PRP$ our) (NNS results)) (PP (IN with) (NP (NP (DT the) (NN help)) (PP (IN of) (NP (DT a) (JJ smartgrid) (NN application))))) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NNS users)) (VP (VB strive) (S (VP (TO to) (VP (VB reduce) (NP (NP (JJ collective) (NN cost)) (PP (IN of) (NP (NN power)))) (PP (IN for) (NP (NP (PDT all) (DT the) (NNS agents)) (PP (IN in) (NP (DT the) (NN grid)))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP compare) (NP (DT the) (NNS performances)) (PP (IN for) (NP (NP (ADJP (NP (NN model) (CC and) (NN model)) (HYPH -) (JJ free)) (NN implementation)) (PP (IN of) (NP (NP (DT the) (NN RL) (NN algorithm)) (VP (VBG establishing) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NML (NML (NN particle) (NN filter)) (-LRB- -LRB-) (NML (NN pf)) (-RRB- -RRB-)) (NN method)))))))))) (. .))
