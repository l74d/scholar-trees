(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (S (NP (NP (NNP ReBNet)) (, ,) (NP (NP (DT an) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NN framework)) (PP (IN for) (NP (NN training))))) (NP (NP (NP (JJ reconfigurable) (JJ binary) (JJ neural) (NNS networks)) (PP (IN on) (NP (NN software)))) (CC and) (NP (NP (VBG developing) (JJ efficient) (NNS accelerators)) (PP (IN for) (NP (NN execution))) (PP (IN on) (NP (NNP FPGA))))))) (. .))
(S (NP (JJ Binary) (JJ neural) (NNS networks)) (VP (VBP offer) (NP (DT an) (JJ intriguing) (NN opportunity)) (PP (IN for) (S (VP (VBG deploying) (NP (NML (JJ large) (HYPH -) (NN scale)) (NML (JJ deep) (NN learning)) (NNS models)) (PP (IN on) (NP (ADJP (NP (NN resource)) (HYPH -) (VBN constrained)) (NNS devices))))))) (. .))
(S (NP (NN Binarization)) (VP (VP (VBZ reduces) (NP (DT the) (NN memory) (NN footprint))) (CC and) (VP (VBZ replaces) (NP (DT the) (ADJP (NN power) (HYPH -) (JJ hungry)) (NML (NN matrix) (HYPH -) (NN multiplication))) (PP (IN with) (NP (NML (NN light) (HYPH -) (NN weight)) (NNP XnorPopcount) (NNS operations))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (JJ binary) (NNS networks)) (VP (VBP suffer) (PP (IN from) (NP (DT a) (JJ degraded) (NN accuracy))) (PP (VBN compared) (PP (IN to) (NP (PRP$ their) (NML (VBN fixed) (HYPH -) (NN point)) (NNS counterparts))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NNS methods)) (PP (IN for) (S (VP (VBG optimizing) (NP (JJ binary) (NNS networks) (NN accuracy)))))) (, ,) (ADVP (RB significantly)) (VP (VB increase) (NP (NP (DT the) (NN implementation) (NN cost)) (CC and) (NP (NN complexity))))))) (. .))
(S (S (VP (TO To) (VP (VB compensate) (PP (IN for) (NP (DT the) (JJ degraded) (NN accuracy))) (PP (IN while) (S (VP (VBG adhering) (PP (IN to) (NP (NP (DT the) (NN simplicity)) (PP (IN of) (NP (JJ binary) (NNS networks))))))))))) (, ,) (NP (PRP we)) (VP (VBP devise) (NP (NP (DT the) (JJ first) (JJ reconfigurable) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB adjust) (NP (DT the) (NN classification) (NN accuracy)) (PP (VBN based) (PP (IN on) (NP (DT the) (NN application)))))))))) (. .))
(S (NP (PRP$ Our) (NN proposition)) (VP (VBZ improves) (NP (DT the) (NN classification) (NN accuracy)) (PP (IN by) (S (VP (VBG representing) (NP (NNS features)) (PP (IN with) (NP (NP (JJ multiple) (NNS levels)) (PP (IN of) (NP (JJ residual) (NN binarization))))))))) (. .))
(S (PP (IN Unlike) (NP (JJ previous) (NNS methods))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ does) (RB not) (VP (VB exacerbate) (NP (NP (DT the) (NN area) (NN cost)) (PP (IN of) (NP (DT the) (NN hardware) (NN accelerator)))))) (. .))
(S (ADVP (RB Instead)) (, ,) (NP (PRP it)) (VP (VBZ provides) (NP (NP (DT a) (NN tradeoff)) (PP (IN between) (NP (NN throughput) (CC and) (NN accuracy)))) (SBAR (IN while) (S (NP (NP (DT the) (NN area) (NN overhead)) (PP (IN of) (NP (JJ multi-level) (NN binarization)))) (VP (VBZ is) (ADJP (JJ negligible)))))) (. .))
