(S (NP (NML (PP (IN Off) (HYPH -) (NP (NN policy)))) (NN learning)) (VP (VBZ is) (ADJP (RBR more) (JJ unstable)) (PP (VBN compared) (PP (IN to) (NP (NP (NML (PP (IN on) (HYPH -) (NP (NN policy)))) (NN learning)) (PP (IN in) (NP (NN reinforcement) (NN learning)))))) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-))) (. .))
(S (S (VP (TO To) (VP (VB cope) (PP (IN with) (NP (NN instability)))))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT the) (JJ first) (NML (NML (JJ relative) (NN importance)) (NN sampling) (HYPH -) (NN off) (HYPH -) (NN policy)) (NML (NN actor) (HYPH -) (NN critic) (PRN (-LRB- -LRB-) (NP (NN RIS) (HYPH -) (NN Off) (HYPH -) (NN PAC)) (-RRB- -RRB-))) (NML (NN model) (HYPH -) (JJ free)) (NNS algorithms)) (PP (IN in) (NP (NN RL))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (NP (NN action) (NN value)) (VP (VBN generated) (PP (PP (IN from) (NP (NP (DT the) (NN behavior) (NN policy)) (PP (IN in) (NP (NN reward) (NN function))) (S (VP (TO to) (VP (VB train) (NP (PRP$ our) (NN algorithm))))))) (CONJP (RB rather) (IN than)) (PP (IN from) (NP (DT the) (NN target) (NN policy))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP use) (NP (JJ deep) (JJ neural) (NNS networks)) (S (VP (TO to) (VP (VB train) (NP (DT both) (NN actor) (CC and) (NN critic)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBD evaluated) (NP (PRP$ our) (NN algorithm)) (PP (IN on) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (NML (NNP Open) (NN AI)) (NNP Gym) (NN benchmark) (NNS problems)))))) (CC and) (VP (VB demonstrate) (NP (ADJP (ADJP (JJR better)) (CC or) (ADJP (JJ comparable))) (NN performance)) (PP (IN to) (NP (JJ several) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN RL) (NNS baselines))))) (. .))
