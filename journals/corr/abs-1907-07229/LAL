(S (NP (DT The) (JJ state-of-the-art) (NNS approaches)) (VP (VBP employ) (NP (JJ approximate) (NN computing)) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN energy) (NN consumption)) (PP (IN of) (NP (NNP DNN) (NN hardware)))))))) (. .))
(S (NP (NNP Approximate) (NNP DNNs)) (ADVP (RB then)) (VP (VBP require) (NP (JJ extensive) (NN retraining)) (ADVP (NNS afterwards)) (S (VP (TO to) (VP (VB recover) (PP (IN from) (NP (NP (DT the) (NN accuracy) (NN loss)) (VP (VBN caused) (PP (IN by) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (JJ approximate) (NNS operations)))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (VBG retraining)) (PP (IN of) (NP (JJ complex) (NNP DNNs)))) (VP (VBZ does) (RB not) (VP (VB scale) (ADVP (RB well)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (DT that) (S (NP (JJ efficient) (NNS approximations)) (VP (MD can) (VP (VB be) (VP (VBN introduced) (PP (IN into) (NP (NP (DT the) (JJ computational) (NN path)) (PP (IN of) (NP (NNP DNN) (NNS accelerators))))) (SBAR (IN while) (S (NP (VBG retraining)) (VP (MD can) (ADVP (RB completely)) (VP (VB be) (VP (VBN avoided)))))))))))) (. .))
(S (NP (NNP ALWANN)) (VP (VBZ provides) (NP (NP (NP (ADJP (RB highly) (JJ optimized)) (NNS implementations)) (PP (IN of) (NP (NNP DNNs)))) (PP (IN for) (NP (NP (JJ custom) (JJ low-power) (NNS accelerators)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (VBG computing) (NNS units)))) (VP (VBZ is) (ADJP (ADJP (JJR lower)) (PP (IN than) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNP DNN) (NNS layers))))))))))))) (. .))
(S (ADVP (RB First)) (, ,) (NP (DT a) (ADJP (RB fully) (JJ trained)) (NNP DNN)) (VP (VBZ is) (VP (VBN converted) (S (VP (TO to) (VP (VB operate) (PP (IN with) (NP (NP (JJ 8-bit) (NNS weights)) (CC and) (NP (JJ 8-bit) (NNS multipliers)))) (PP (IN in) (NP (JJ convolutional) (NNS layers)))))))) (. .))
(S (NP (DT A) (JJ suitable) (NN approximate) (NN multiplier)) (VP (VBZ is) (ADVP (RB then)) (VP (VBN selected) (PP (IN for) (NP (DT each) (VBG computing) (NN element))) (PP (IN from) (NP (NP (DT a) (NN library)) (PP (IN of) (NP (JJ approximate) (NNS multipliers))))) (PP (IN in) (NP (NP (JJ such) (DT a) (NN way)) (SBAR (IN that) (S (S (PRN (-LRB- -LRB-) (NN i) (-RRB- -RRB-)) (NP (CD one) (NN approximate) (NN multiplier)) (VP (VBZ serves) (NP (JJ several) (NNS layers)))) (, ,) (CC and) (S (PRN (-LRB- -LRB-) (NN ii) (-RRB- -RRB-)) (NP (DT the) (NX (NX (JJ overall) (NX (NN classification) (NN error))) (CC and) (NX (NN energy) (NN consumption)))) (VP (VBP are) (VP (VBN minimized)))))))))) (. .))
(S (NP (NP (DT The) (NNS optimizations)) (PP (VBG including) (NP (DT the) (JJR multiplier) (NN selection) (NN problem)))) (VP (VBP are) (VP (VBN solved) (PP (IN by) (NP (NP (NNS means)) (PP (IN of) (NP (DT a) (JJ multiobjective) (NN optimization) (NNP NSGA-II) (NN algorithm))))))) (. .))
(S (SBAR (IN In) (NN order) (S (VP (TO to) (VP (ADVP (RB completely)) (VB avoid) (NP (NP (DT the) (ADJP (RB computationally) (JJ expensive)) (NN retraining)) (PP (IN of) (NP (NNP DNN))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADVP (RB usually)) (VP (VBN employed) (S (VP (TO to) (VP (VB improve) (NP (DT the) (NN classification) (NN accuracy)))))))))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ simple) (NN weight) (VBG updating) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (VBZ compensates) (NP (NP (DT the) (NN inaccuracy)) (VP (VBN introduced) (PP (IN by) (S (VP (VBG employing) (NP (JJ approximate) (NNS multipliers)))))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN approach)) (VP (VBZ is) (VP (VBN evaluated) (PP (IN for) (NP (NP (CD two) (NNS architectures)) (PP (IN of) (NP (NNP DNN) (NNS accelerators))) (PP (IN with) (NP (NP (JJ approximate) (NNS multipliers)) (PP (IN from) (NP (DT the) (JJ open-source) (`` ``) (NNP EvoApprox) ('' '') (NN library))))))))) (. .))
(S (NP (PRP We)) (VP (VBP report) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN approach)) (VP (VBZ saves) (NP (NP (CD 30) (NN %)) (PP (IN of) (NP (NP (NN energy)) (VP (VBN needed) (PP (IN for) (NP (NP (NN multiplication)) (PP (IN in) (NP (NP (JJ convolutional) (NNS layers)) (PP (IN of) (NP (NNP ResNet-50))))))))))) (SBAR (IN while) (S (NP (DT the) (NN accuracy)) (VP (VBZ is) (VP (VBN degraded) (PP (IN by) (NP (QP (RB only) (CD 0.6)) (NN %))))))))))) (. .))
(S (NP (NP (DT The) (NX (VBN proposed) (NN technique))) (CC and) (NX (JJ approximate) (NNS layers))) (VP (VBP are) (ADJP (ADJP (JJ available)) (PP (IN as) (NP (NP (DT an) (JJ open-source) (NN extension)) (PP (IN of) (NP (NNP TensorFlow)))))) (PP (IN at) (NP (DT this) (NN https) (NNP URL)))))
