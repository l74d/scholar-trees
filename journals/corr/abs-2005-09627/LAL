(S (SBAR (WHADVP (WRB When)) (S (VP (VBG training) (NP (NP (DT an) (NN estimator)) (PP (JJ such) (IN as) (NP (DT a) (JJ neural) (NN network)))) (PP (IN for) (NP (NP (NNS tasks)) (PP (IN like) (NP (NN image) (NN denoising)))))))) (, ,) (NP (NP (PRP it))) (VP (VBZ is) (ADVP (RB often)) (VP (VBN preferred) (S (VP (TO to) (VP (VP (VB train) (NP (CD one) (NN estimator))) (CC and) (VP (VB apply) (NP (PRP it)) (PP (TO to) (NP (DT all) (NN noise) (NNS levels))))))))) (. .))
(S (NP (NP (DT The) (FW de) (FW facto) (VBG training) (NN protocol)) (SBAR (S (VP (TO to) (VP (VB achieve) (NP (DT this) (NN goal))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB train) (NP (DT the) (NN estimator)) (PP (IN with) (NP (NP (JJ noisy) (NNS samples)) (SBAR (WHNP (WP$ whose) (NN noise) (NNS levels)) (S (VP (VBP are) (VP (ADVP (RB uniformly)) (VBN distributed) (PP (IN across) (NP (NP (DT the) (NN range)) (PP (IN of) (NP (NN interest))))))))))))))) (. .))
(SBARQ (ADVP (RB However)) (, ,) (WHADVP (WRB why)) (SQ (MD should) (NP (PRP we)) (VP (VB allocate) (NP (DT the) (NNS samples)) (ADVP (RB uniformly)))) (. ?))
(SQ (MD Can) (NP (PRP we)) (VP (VB have) (NP (NP (NP (RBR more) (NN training) (NNS samples)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RBR less) (JJ noisy)))))) (, ,) (CC and) (NP (NP (JJR fewer) (NNS samples)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJR more) (NNS noisy)))))))) (. ?))
(SBARQ (WHNP (WP What)) (SQ (VP (VBZ is) (NP (DT the) (JJ optimal) (NN distribution)))) (. ?))
(SBARQ (WHADVP (WRB How)) (SQ (VBP do) (NP (PRP we)) (VP (VB obtain) (NP (JJ such) (DT a) (NN distribution)))) (. ?))
(S (NP (NP (DT The) (NN goal)) (PP (IN of) (NP (DT this) (NN paper)))) (VP (VBZ is) (S (VP (TO to) (VP (VB address) (NP (DT this) (NN training) (JJ sample) (NN distribution) (NN problem)) (PP (IN from) (NP (DT a) (NN minimax) (NN risk) (NN optimization) (NN perspective))))))) (. .))
(S (NP (PRP We)) (VP (VBP derive) (NP (NP (DT a) (JJ dual) (NN ascent) (NN algorithm)) (SBAR (S (VP (TO to) (VP (VB determine) (NP (NP (DT the) (JJ optimal) (VBG sampling) (NN distribution)) (SBAR (WHPP (IN of) (WHNP (WDT which))) (S (NP (DT the) (NN convergence)) (VP (VBZ is) (VP (VBN guaranteed) (ADVP (ADVP (RB as) (RB long)) (SBAR (IN as) (S (NP (NP (DT the) (NN set)) (PP (IN of) (NP (JJ admissible) (NNS estimators)))) (VP (VBZ is) (ADJP (JJ closed) (CC and) (NN convex))))))))))))))))) (. .))
(S (PP (IN For) (NP (NP (NNS estimators)) (PP (IN with) (NP (NP (JJ non-convex) (JJ admissible) (NNS sets)) (PP (JJ such) (IN as) (NP (JJ deep) (JJ neural) (NNS networks))))))) (, ,) (NP (PRP$ our) (JJ dual) (NN formulation)) (VP (NNS converges) (PP (TO to) (NP (NP (DT a) (NN solution)) (PP (IN of) (NP (DT the) (NN convex) (NN relaxation)))))) (. .))
(S (NP (PRP We)) (VP (VBP discuss) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN algorithm)) (VP (MD can) (VP (VB be) (VP (VBN implemented) (PP (IN in) (NP (NN practice))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (DT the) (NN algorithm)) (PP (IN on) (NP (NP (JJ linear) (NNS estimators)) (CC and) (NP (JJ deep) (NNS networks))))) (. .))
