(S (SBAR (WHADVP (WRB When)) (S (VP (VBG training) (NP (NP (DT an) (NN estimator)) (PP (JJ such) (IN as) (NP (NP (DT a) (JJ neural) (NN network)) (PP (IN for) (NP (NP (NNS tasks)) (PP (IN like) (NP (NN image) (NN denoising))))))))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADVP (RB often)) (VP (VBN preferred) (S (VP (TO to) (VP (VP (VB train) (NP (CD one) (NN estimator))) (CC and) (VP (VB apply) (NP (PRP it)) (PP (IN to) (NP (DT all) (NN noise) (NNS levels))))))))) (. .))
(S (NP (NP (DT The) (ADJP (FW de) (FW facto)) (NN training) (NN protocol)) (SBAR (S (VP (TO to) (VP (VB achieve) (NP (DT this) (NN goal))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB train) (NP (DT the) (NN estimator)) (PP (IN with) (NP (NP (JJ noisy) (NNS samples)) (SBAR (WHNP (WP$ whose)) (S (NP (NN noise) (NNS levels)) (VP (VBP are) (ADVP (RB uniformly)) (VP (VBN distributed) (PP (IN across) (NP (NP (DT the) (NN range)) (PP (IN of) (NP (NN interest))))))))))))))) (. .))
(SBARQ (ADVP (RB However)) (, ,) (WHADVP (WRB why)) (SQ (MD should) (NP (PRP we)) (VP (VB allocate) (NP (DT the) (NNS samples)) (ADVP (RB uniformly)))) (. ?))
(SQ (MD Can) (NP (PRP we)) (VP (VB have) (NP (NP (NP (JJR more) (NN training) (NNS samples)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RBR less) (JJ noisy)))))) (, ,) (CC and) (NP (NP (JJR fewer) (NNS samples)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RBR more) (JJ noisy)))))))) (. ?))
(SBARQ (WHNP (WP What)) (SQ (VBZ is) (NP (DT the) (JJ optimal) (NN distribution))) (. ?))
(SBARQ (WHADVP (WRB How)) (SQ (VBP do) (NP (PRP we)) (VP (VB obtain) (NP (PDT such) (DT a) (NN distribution)))) (. ?))
(S (NP (NP (DT The) (NN goal)) (PP (IN of) (NP (DT this) (NN paper)))) (VP (VBZ is) (S (VP (TO to) (VP (VB address) (NP (NP (DT this) (NN training) (NN sample) (NN distribution) (NN problem)) (PP (IN from) (NP (DT a) (NML (NN minimax) (NN risk)) (NN optimization) (NN perspective)))))))) (. .))
(S (NP (PRP We)) (VP (VBP derive) (NP (DT a) (JJ dual) (NN ascent) (NN algorithm)) (S (VP (TO to) (VP (VB determine) (NP (NP (NP (DT the) (JJ optimal) (NN sampling) (NN distribution)) (SBAR (WHPP (IN of) (WHNP (WDT which))) (S (NP (DT the) (NN convergence)) (VP (VBZ is) (VP (VBN guaranteed) (ADVP (ADVP (RB as) (RB long)) (SBAR (IN as) (S (NP (NP (DT the) (NN set)) (PP (IN of) (NP (ADJP (JJ admissible)) (NNS estimators)))) (VP (VBZ is) (ADJP (JJ closed))))))))))) (CC and) (NP (NN convex))))))) (. .))
(S (PP (IN For) (NP (NP (NNS estimators)) (PP (IN with) (NP (NP (JJ non-convex) (ADJP (JJ admissible)) (NNS sets)) (PP (JJ such) (IN as) (NP (JJ deep) (JJ neural) (NNS networks))))))) (, ,) (NP (PRP$ our) (JJ dual) (NN formulation)) (VP (VBZ converges) (PP (IN to) (NP (NP (DT a) (NN solution)) (PP (IN of) (NP (DT the) (NN convex) (NN relaxation)))))) (. .))
(S (NP (PRP We)) (VP (VBP discuss) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN algorithm)) (VP (MD can) (VP (VB be) (VP (VBN implemented) (PP (IN in) (NP (NN practice))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (DT the) (NN algorithm)) (PP (IN on) (NP (NP (JJ linear) (NNS estimators)) (CC and) (NP (JJ deep) (NNS networks))))) (. .))
