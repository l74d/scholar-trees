(S (NP (NP (DT The) (VBG learning) (NN speed)) (PP (IN of) (NP (JJ feed-forward) (JJ neural) (NNS networks)))) (VP (VP (VBZ is) (ADJP (RB notoriously) (JJ slow))) (CC and) (VP (VBZ has) (VP (VBN presented) (NP (DT a) (NN bottleneck)) (PP (IN in) (NP (JJ deep) (NN learning) (NNS applications))) (PP (IN for) (NP (JJ several) (NNS decades)))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (NP (NP (JJ gradient-based) (NN learning) (NN algorithms)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (VP (VBN used) (ADVP (RB extensively)) (S (VP (TO to) (VP (VB train) (NP (JJ neural) (NNS networks))))))))) (, ,)) (VP (VBP tend) (S (VP (TO to) (VP (VB work) (ADVP (RB slowly)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT all)) (PP (IN of) (NP (DT the) (NN network) (NNS parameters)))) (VP (MD must) (VP (VB be) (VP (ADVP (RB iteratively)) (VBN tuned)))))))))) (. .))
(S (S (VP (TO To) (VP (VB counter) (NP (DT this))))) (, ,) (NP (DT both) (NNS researchers) (CC and) (NNS practitioners)) (VP (VBP have) (VP (VBN tried) (S (VP (VBG introducing) (NP (NN randomness)) (S (VP (TO to) (VP (VB reduce) (NP (DT the) (NN learning) (NN requirement))))))))) (. .))
(S (S (PP (VBN Based) (PP (IN on) (NP (NP (DT the) (JJ original) (NN construction)) (PP (IN of) (NP (NNP Igelnik) (CC and) (NNP Pao)))))) (, ,) (NP (NP (JJ single) (NN layer) (NNS neural-networks)) (PP (IN with) (NP (JJ random) (JJ input-to-hidden) (NN layer) (NNS weights) (CC and) (NNS biases)))) (VP (VBP have) (VP (VBN seen) (NP (NN success)) (PP (IN in) (NP (NN practice)))))) (, ,) (CC but) (S (NP (DT the) (JJ necessary) (JJ theoretical) (NN justification)) (VP (VBZ is) (VP (VBG lacking)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP begin) (S (VP (TO to) (VP (VB fill) (NP (DT this) (JJ theoretical) (NN gap)))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VBP extend) (NP (DT this) (NN result)) (PP (TO to) (NP (DT the) (JJ non-asymptotic) (NN setting))) (, ,) (S (VP (VBG proving) (SBAR (IN that) (S (NP (CD one)) (VP (MD can) (VP (VB achieve) (NP (DT any) (JJ desired) (NN approximation) (NN error)) (PP (IN with) (NP (JJ high) (NN probability))) (PP (VBD provided) (SBAR (S (NP ($ $) (JJ n) ($ $)) (VP (VBZ is) (ADJP (RB sufficiently) (JJ large))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VBP adapt) (NP (DT this) (JJ randomized) (JJ neural) (NN network) (NN architecture)) (S (VP (TO to) (VP (VB approximate) (NP (NNS functions)) (PP (IN on) (NP (NP (NNS smooth) (, ,) (JJ compact) (NNS submanifolds)) (PP (IN of) (NP (JJ Euclidean) (NN space)))))))) (, ,) (S (VP (VBG providing) (NP (NP (JJ theoretical) (NNS guarantees)) (PP (IN in) (NP (DT both) (DT the) (ADJP (JJ asymptotic) (CC and) (JJ non-asymptotic)) (NNS forms))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP illustrate) (NP (NP (PRP$ our) (NNS results)) (PP (IN on) (NP (NNS manifolds)))) (PP (IN with) (NP (JJ numerical) (NNS experiments)))) (. .))
