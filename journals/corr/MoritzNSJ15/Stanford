(S (S (VP (VBG Training) (NP (JJ deep) (NNS networks)))) (VP (VBZ is) (NP (NP (DT a) (ADJP (NN time) (HYPH -) (VBG consuming)) (NN process)) (, ,) (PP (IN with) (S (NP (NP (NNS networks)) (PP (IN for) (NP (NN object) (NN recognition)))) (ADVP (RB often)) (VP (VBG requiring) (NP (JJ multiple) (NNS days)) (S (VP (TO to) (VP (VB train))))))))) (. .))
(S (PP (IN For) (NP (DT this) (NN reason))) (, ,) (S (VP (VBG leveraging) (NP (NP (DT the) (NNS resources)) (PP (IN of) (NP (DT a) (NN cluster)))) (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (NN training))))))) (VP (VBZ is) (NP (NP (DT an) (JJ important) (NN area)) (PP (IN of) (NP (NN work))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (ADJP (RB widely) (HYPH -) (JJ popular)) (ADJP (NP (NN batch) (HYPH -) (NN processing)) (JJ computational)) (NNS frameworks)) (PP (IN like) (NP (NNP MapReduce) (CC and) (NNP Spark)))) (VP (VBD were) (RB not) (VP (VBN designed) (S (VP (TO to) (VP (VB support) (NP (NP (DT the) (ADJP (UCP (ADJP (JJ asynchronous)) (CC and) (NML (NN communication))) (HYPH -) (JJ intensive)) (NNS workloads)) (PP (IN of) (NP (NP (VBG existing)) (VP (VBN distributed) (NP (NML (JJ deep) (NN learning)) (NNS systems))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (NNP SparkNet)) (, ,) (NP (NP (DT a) (NN framework)) (PP (IN for) (NP (NN training) (JJ deep) (NNS networks))))) (PP (IN in) (NP (NN Spark)))) (. .))
(S (NP (PRP$ Our) (NN implementation)) (VP (VBZ includes) (NP (DT a) (JJ convenient) (NN interface)) (PP (IN for) (S (VP (VBG reading) (NP (NP (NP (NNS data)) (PP (IN from) (NP (NNP Spark) (NNP RDDs)))) (, ,) (NP (NP (DT a) (NN Scala) (NN interface)) (PP (IN to) (NP (DT the) (NNP Caffe) (NML (JJ deep) (NN learning)) (NN framework)))) (, ,) (CC and) (NP (DT a) (JJ lightweight) (JJ multi-dimensional) (NN tensor) (NN library))))))) (. .))
(S (S (VP (VBG Using) (NP (DT a) (JJ simple) (NN parallelization) (NN scheme)) (PP (IN for) (NP (JJ stochastic) (NN gradient) (NN descent))))) (, ,) (NP (NNP SparkNet)) (VP (VP (VBZ scales) (ADVP (RB well)) (PP (IN with) (NP (DT the) (NN cluster) (NN size)))) (CC and) (VP (VBZ tolerates) (NP (ADJP (RB very) (JJ high) (HYPH -) (NN latency)) (NN communication)))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ easy) (S (VP (TO to) (VP (VB deploy) (CC and) (VB use) (PP (IN with) (NP (DT no) (NN parameter) (NN tuning))))))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ compatible) (PP (IN with) (NP (VBG existing) (NNP Caffe) (NNS models)))))) (. .))
(S (S (NP (PRP We)) (VP (VBP quantify) (NP (NP (DT the) (NN dependence)) (PP (IN of) (NP (NP (DT the) (NN speedup)) (VP (VBN obtained) (PP (IN by) (NP (NNP SparkNet))) (PP (IN on) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS machines)) (, ,) (NP (DT the) (NN communication) (NN frequency)) (, ,) (CC and) (NP (NP (DT the) (NN cluster) (POS 's)) (NN communication) (NN overhead)))))))))))) (, ,) (CC and) (S (NP (PRP we)) (NP (NP (NN benchmark)) (NP (NP (NP (PRP$ our) (NN system) (POS 's)) (NN performance)) (PP (IN on) (NP (DT the) (NNP ImageNet) (NN dataset)))))) (. .))
