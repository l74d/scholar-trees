(S (NP (NN Dropout)) (VP (VBZ is) (NP (NP (DT a) (ADJP (RB very) (JJ effective)) (NN way)) (PP (IN of) (S (VP (VBG regularizing) (NP (JJ neural) (NNS networks))))))) (. .))
(S (S (VP (ADVP (RB Stochastically)) (`` ``) (VBG dropping) (PRT (RP out)) ('' '') (NP (NP (NNS units)) (PP (IN with) (NP (DT a) (JJ certain) (NN probability)))))) (VP (VBZ discourages) (NP (NP (JJ over-specific) (NNS co-adaptations)) (PP (IN of) (NP (NN feature) (NNS detectors)))) (, ,) (S (VP (VP (VBG preventing) (NP (VBG overfitting))) (CC and) (VP (VBG improving) (NP (NN network) (NN generalization)))))) (. .))
(S (ADVP (IN Besides)) (, ,) (NP (NNP Dropout)) (VP (MD can) (VP (VB be) (VP (VBN interpreted) (PP (IN as) (NP (NP (DT an) (JJ approximate) (NN model) (NN aggregation) (NN technique)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT an) (JJ exponential) (NN number)) (PP (IN of) (NP (JJR smaller) (NNS networks)))) (VP (VBP are) (VP (VBN averaged) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB get) (NP (DT a) (ADJP (RBR more) (JJ powerful)) (JJ ensemble))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG using) (NP (DT a) (VBN fixed) (NN dropout) (NN probability)) (PP (IN during) (NP (NN training))))) (VP (VBZ is) (NP (DT a) (JJ suboptimal) (NN choice)))))) (. .))
(S (NP (PRP We)) (ADVP (RB thus)) (VP (VB propose) (NP (NP (DT a) (NN time) (VBG scheduling)) (PP (IN for) (NP (NP (DT the) (NN probability)) (PP (IN of) (S (VP (VBG retaining) (NP (NNS neurons)) (PP (IN in) (NP (DT the) (NN network)))))))))) (. .))
(S (NP (DT This)) (VP (VBZ induces) (NP (NP (DT an) (JJ adaptive) (NN regularization) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (VBZ smoothly)) (VBZ increases) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (NP (DT the) (NN optimization) (NN problem))))))))) (. .))
(S (NP (NP (DT This) (NN idea)) (PP (IN of) (S (VP (`` ``) (VP (VBG starting) (ADVP (JJ easy))) ('' '') (CC and) (VP (ADVP (RB adaptively)) (VBG increasing) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (NP (DT the) (NN learning) (NN problem))))))))) (VP (VP (VBZ has) (NP (PRP$ its) (NNS roots)) (PP (IN in) (NP (NN curriculum) (NN learning)))) (CC and) (VP (VBZ allows) (S (NP (CD one)) (VP (TO to) (VP (VB train) (NP (JJR better) (NNS models))))))) (. .))
(S (ADVP (RB Indeed)) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (PRP$ our) (NN optimization) (NN strategy)) (VP (VBZ implements) (NP (DT a) (ADJP (RB very) (JJ general)) (NN curriculum) (NN scheme)) (, ,) (PP (IN by) (S (VP (ADVP (RB gradually)) (VBG adding) (NP (NN noise)) (PP (TO to) (NP (NP (DT both) (DT the) (NN input) (CC and) (JJ intermediate) (NN feature) (NNS representations)) (PP (IN within) (NP (DT the) (NN network) (NN architecture)))))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NP (CD seven) (NN image) (NN classification) (NNS datasets)) (CC and) (NP (JJ different) (NN network) (NNS architectures))))) (VP (VBP show) (SBAR (IN that) (S (NP (NP (PRP$ our) (NN method)) (, ,) (VP (VBN named) (S (NP (NNP Curriculum) (NNP Dropout)))) (, ,)) (VP (VP (ADVP (RB frequently)) (VBZ yields) (PP (TO to) (NP (VB better) (NN generalization)))) (CC and) (VP (PRN (, ,) (PP (IN at) (JJS worst)) (, ,)) (VBZ performs) (ADVP (ADVP (RB just) (RB as) (RB well)) (PP (IN as) (NP (DT the) (NN standard) (NNP Dropout) (NN method))))))))) (. .))
