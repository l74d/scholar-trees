(S (NP (NN Dropout)) (VP (VBZ is) (NP (NP (DT a) (ADJP (RB very) (JJ effective)) (NN way)) (PP (IN of) (S (VP (VBG regularizing) (NP (JJ neural) (NNS networks))))))) (. .))
(S (S (ADVP (RB Stochastically)) (VP (`` ") (VBG dropping) (PRT (RP out)) (`` ") (NP (NNS units)) (PP (IN with) (NP (DT a) (JJ certain) (NN probability))))) (VP (VBZ discourages) (NP (NP (JJ over-specific) (NNS co-adaptations)) (PP (IN of) (NP (NN feature) (NNS detectors)))) (, ,) (S (VP (VP (VBG preventing) (NP (NN overfitting))) (CC and) (VP (VBG improving) (NP (NN network) (NN generalization)))))) (. .))
(S (ADVP (RB Besides)) (, ,) (NP (NN Dropout)) (VP (MD can) (VP (VB be) (VP (VBN interpreted) (PP (IN as) (NP (NP (DT an) (JJ approximate) (NML (NN model) (NN aggregation)) (NN technique)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT an) (JJ exponential) (NN number)) (PP (IN of) (NP (JJR smaller) (NNS networks)))) (VP (VBP are) (VP (VBN averaged) (PP (IN in) (NP (NN order))) (S (VP (TO to) (VP (VB get) (NP (DT a) (ADJP (RBR more) (JJ powerful)) (NN ensemble)))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG using) (NP (DT a) (VBN fixed) (NN dropout) (NN probability)) (PP (IN during) (NP (NN training))))) (VP (VBZ is) (NP (DT a) (JJ suboptimal) (NN choice)))))) (. .))
(S (NP (PRP We)) (ADVP (RB thus)) (VP (VB propose) (NP (DT a) (NN time) (NN scheduling)) (PP (IN for) (NP (NP (DT the) (NN probability)) (PP (IN of) (NP (NP (VBG retaining) (NNS neurons)) (PP (IN in) (NP (DT the) (NN network)))))))) (. .))
(S (NP (DT This)) (VP (VBZ induces) (NP (NP (DT an) (JJ adaptive) (NN regularization) (NN scheme)) (SBAR (WHNP (WDT that)) (S (ADVP (RB smoothly)) (VP (VBZ increases) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (NP (DT the) (NN optimization) (NN problem))))))))) (. .))
(S (NP (NP (DT This) (NN idea)) (PP (IN of) (S (S (`` ") (VP (VBG starting) (ADJP (JJ easy))) ('' ")) (CC and) (S (ADVP (RB adaptively)) (VP (VBG increasing) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (NP (DT the) (NN learning) (NN problem))))))))) (VP (VP (VBZ has) (NP (PRP$ its) (NNS roots)) (PP (IN in) (NP (NN curriculum) (NN learning)))) (CC and) (VP (VBZ allows) (NP (CD one)) (S (VP (TO to) (VP (VB train) (NP (JJR better) (NNS models))))))) (. .))
(S (ADVP (RB Indeed)) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (PRP$ our) (NN optimization) (NN strategy)) (VP (VBZ implements) (NP (DT a) (ADJP (RB very) (JJ general)) (NN curriculum) (NN scheme)) (, ,) (PP (IN by) (S (ADVP (RB gradually)) (VP (VBG adding) (NP (NN noise)) (PP (IN to) (NP (CC both) (NP (DT the) (NN input)) (CC and) (NP (JJ intermediate) (NN feature) (NNS representations)))) (PP (IN within) (NP (DT the) (NN network) (NN architecture)))))))))) (. .))
(S (S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NP (CD seven) (NML (NN image) (NN classification)) (NNS datasets)) (CC and) (NP (JJ different) (NN network) (NNS architectures))))) (VP (VBP show) (SBAR (IN that) (S (NP (NP (PRP$ our) (NN method)) (, ,) (VP (VBN named) (NP (NNP Curriculum) (NNP Dropout))) (, ,)) (ADVP (RB frequently)) (VP (VBZ yields) (PP (TO to) (NP (RBR better) (NN generalization)))))))) (CC and) (, ,) (S (ADVP (IN at) (JJS worst)) (, ,) (VP (VBZ performs) (UCP (ADVP (RB just)) (CONJP (RB as) (RB well) (IN as)) (NP (DT the) (JJ standard) (NN Dropout) (NN method))))) (. .))
