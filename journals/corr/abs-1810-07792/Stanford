(S (NP (DT This) (NN work)) (VP (VBZ develops) (NP (NP (DT a) (ADJP (RB fully) (VBN decentralized)) (JJ multi-agent) (NN algorithm)) (PP (IN for) (NP (NN policy) (NN evaluation))))) (. .))
(S (NP (DT The) (VBN proposed) (NN scheme)) (VP (MD can) (VP (VB be) (VP (VBN applied) (PP (IN to) (NP (CD two) (JJ distinct) (NNS scenarios)))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ first) (NN scenario))) (, ,) (NP (NP (DT a) (NN collection)) (PP (IN of) (NP (NNS agents)))) (VP (VBP have) (S (S (NP (JJ distinct) (NNS datasets)) (VP (VBD gathered) (PP (VBG following) (NP (NP (NP (JJ different) (NN behavior) (NNS policies)) (-LRB- -LRB-) (NP (NP (NN none)) (PP (IN of) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN required) (S (VP (TO to) (VP (VB explore) (NP (DT the) (JJ full) (NN state) (NN space))))))))))) (-RRB- -RRB-)) (PP (IN in) (NP (NP (JJ different) (NNS instances)) (PP (IN of) (NP (DT the) (JJ same) (NN environment))))))))) (CC and) (S (NP (PRP they)) (ADVP (DT all)) (VP (VBP collaborate) (S (VP (TO to) (VP (VB evaluate) (NP (DT a) (JJ common) (NN target) (NN policy))))))))) (. .))
(S (NP (DT The) (NN network) (NN approach)) (VP (VP (VBZ allows) (PP (IN for) (NP (NP (JJ efficient) (NN exploration)) (PP (IN of) (NP (DT the) (NN state) (NN space)))))) (CC and) (VP (VBZ allows) (NP (DT all) (NNS agents)) (S (VP (TO to) (VP (VB converge) (PP (IN to) (NP (DT the) (JJ optimal) (NN solution))) (PP (ADVP (RB even)) (IN in) (NP (NP (NNS situations)) (SBAR (WHADVP (WRB where)) (S (NP (CC neither) (NP (NN agent))) (VP (MD can) (VP (VB converge) (PP (IN on) (NP (PRP$ its) (JJ own))) (PP (IN without) (NP (NN cooperation)))))))))))))) (. .))
(S (S (NP (DT The) (JJ second) (NN scenario)) (VP (VBZ is) (SBAR (IN that) (FRAG (PP (IN of) (NP (NP (JJ multi-agent) (NNS games)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT the) (NN state)) (VP (VBZ is) (ADJP (JJ global))))))))))) (CC and) (S (NP (NNS rewards)) (VP (VBP are) (ADJP (JJ local)))) (. .))
(S (PP (IN In) (NP (DT this) (NN scenario))) (, ,) (NP (NNS agents)) (VP (VBP collaborate) (S (VP (TO to) (VP (VB estimate) (NP (NP (DT the) (NN value) (NN function)) (PP (IN of) (NP (DT a) (NN target) (NN team) (NN policy)))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN algorithm)) (VP (VBZ combines) (NP (NP (ADJP (IN off) (HYPH -) (NN policy)) (NML (NN learning) (, ,) (NN eligibility)) (NNS traces)) (CC and) (NP (NML (JJ linear) (NN function)) (NN approximation)))) (. .))
(S (NP (DT The) (VBN proposed) (NN algorithm)) (VP (VP (VBZ is) (PP (IN of) (NP (ADJP (NP (DT the) (NN variance)) (HYPH -) (VBN reduced)) (NN kind)))) (CC and) (VP (VBZ achieves) (NP (JJ linear) (NN convergence)) (PP (IN with) (NP (NML (FRAG (NP ($ $)) (NP (UH O) (NP (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (NP ($ $))))) (NN memory) (NNS requirements))))) (. .))
(S (S (NP (NP (DT The) (JJ linear) (NN convergence)) (PP (IN of) (NP (DT the) (NN algorithm)))) (VP (VBZ is) (VP (VBN established) (ADVP (RB analytically))))) (, ,) (CC and) (S (NP (NNS simulations)) (VP (VBP are) (VP (VBN used) (S (VP (TO to) (VP (VB illustrate) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (DT the) (NN method)))))))))) (. .))
