(S (NP (NP (NNS Advancements)) (PP (IN in) (NP (JJ parallel) (NN processing)))) (VP (VBP have) (VP (VBN lead) (PP (TO to) (NP (NP (DT a) (NN surge)) (PP (IN in) (NP (NP (NP (JJ multilayer) (NNS perceptrons) (POS â€º)) (PRN (-LRB- -LRB-) (NP (NNP MLP)) (-RRB- -RRB-)) (NNS applications)) (CC and) (NP (JJ deep) (NN learning)))))) (PP (IN in) (NP (DT the) (JJ past) (NNS decades))))) (. .))
(S (NP (NP (JJ Recurrent) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))) (VP (VBP give) (NP (JJ additional) (JJ representational) (NN power)) (PP (TO to) (NP (VB feedforward) (NNP MLPs))) (PP (IN by) (S (VP (VBG providing) (NP (NP (DT a) (NN way)) (SBAR (S (VP (TO to) (VP (VB treat) (NP (JJ sequential) (NNS data))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NNP RNNs)) (VP (VBP are) (ADJP (JJ hard) (SBAR (S (VP (TO to) (VP (VB train) (S (VP (VBG using) (NP (JJ conventional) (NN error) (NN backpropagation) (NNS methods))))))))) (PP (IN because) (IN of) (NP (NP (DT the) (NN difficulty)) (PP (IN in) (S (VP (VBG relating) (NP (NNS inputs)) (PP (IN over) (NP (JJ many) (NNS time-steps))))))))) (. .))
(S (NP (NP (NN Regularization) (NNS approaches)) (PP (IN from) (NP (NNP MLP) (RB sphere))) (, ,) (PP (IN like) (NP (NP (NN dropout)) (CC and) (NP (JJ noisy) (NN weight) (NN training)))) (, ,)) (VP (VBP have) (VP (VBN been) (VP (ADVP (RB insufficiently)) (VBN applied) (CC and) (VBN tested) (PP (IN on) (NP (JJ simple) (NNP RNNs)))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NNS solutions)) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (S (VP (S (VP (TO to) (VP (VB improve) (NP (NP (NN convergence)) (PP (IN in) (NP (NNP RNNs))))))) (CC but) (ADVP (RB not) (RB enough) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (JJ long) (NN term) (NN dependency) (VBG remembering) (NNS capabilities)) (ADVP (NN thereof)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN study))) (, ,) (NP (PRP we)) (VP (VBP aim) (S (VP (TO to) (VP (ADVP (RB empirically)) (VB evaluate) (NP (NP (DT the) (NN remembering) (CC and) (NN generalization) (NN ability)) (PP (IN of) (NP (NNP RNNs))) (PP (IN on) (NP (JJ polyphonic) (JJ musical) (NNS datasets)))))))) (. .))
(S (NP (DT The) (NNS models)) (VP (VBP are) (VP (VBN trained) (PP (IN with) (NP (NP (JJ injected) (NN noise)) (, ,) (NP (NN random) (NN dropout)) (, ,) (NP (JJ norm-based) (NNS regularizers)) (CC and) (NP (NP (PRP$ their) (JJ respective) (NNS performances)) (PP (VBN compared) (PP (TO to) (NP (NP (JJ well-initialized) (NN plain) (NNP RNNs)) (CC and) (NP (NP (JJ advanced) (NN regularization) (NNS methods)) (PP (IN like) (NP (NN fast-dropout)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP conclude) (PP (IN with) (NP (NN evidence) (SBAR (IN that) (S (S (VP (VBG training) (PP (IN with) (NP (NN noise))))) (VP (VBZ does) (RB not) (VP (VB improve) (NP (NN performance)) (SBAR (IN as) (S (VP (VBN conjectured) (PP (IN by) (NP (NP (DT a) (JJ few) (NNS works)) (PP (IN in) (NP (NNP RNN) (NN optimization))) (PP (IN before) (NP (NNS ours))))))))))))))) (. .))
