(S (NP (NP (NNS Advancements)) (PP (IN in) (NP (JJ parallel) (NN processing)))) (VP (VBP have) (NP (NN lead)) (PP (IN to) (NP (NP (DT a) (NN surge)) (PP (IN in) (NP (NP (NP (JJ multilayer) (NNS perceptrons) (POS ')) (NML (NML (NML (-LRB- -LRB-) (NNP MLP) (-RRB- -RRB-)) (NNS applications)) (CC and) (NML (JJ deep) (NN learning)))) (PP (IN in) (NP (DT the) (JJ past) (NNS decades)))))))) (. .))
(S (NP (NP (JJ Recurrent) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (VP (VBP give) (NP (JJ additional) (JJ representational) (NN power)) (S (VP (TO to) (VP (VB feedforward) (NP (NNS MLPs)) (PP (IN by) (S (VP (VBG providing) (NP (DT a) (NN way)) (S (VP (TO to) (VP (VB treat) (NP (JJ sequential) (NNS data)))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NNS RNNs)) (VP (VBP are) (ADJP (JJ hard) (S (VP (TO to) (VP (VB train) (S (VP (VBG using) (NP (JJ conventional) (NN error) (NN backpropagation) (NNS methods)) (PP (IN because) (IN of) (NP (NP (DT the) (NN difficulty)) (PP (IN in) (S (VP (VBG relating) (NP (NP (NNS inputs)) (PP (IN over) (NP (JJ many) (NN time) (HYPH -) (NNS steps)))))))))))))))) (. .))
(S (NP (NP (NN Regularization) (NNS approaches)) (PP (IN from) (NP (NNP MLP) (NN sphere)))) (, ,) (PP (IN like) (NP (NP (NN dropout)) (CC and) (NP (JJ noisy) (NN weight) (NN training)))) (, ,) (VP (VBP have) (VP (VBN been) (ADVP (RB insufficiently)) (VP (VBN applied) (CC and) (VBN tested) (PP (IN on) (NP (JJ simple) (NNS RNNs)))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NNS solutions)) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (S (VP (TO to) (VP (VB improve) (NP (NN convergence)) (PP (IN in) (NP (NNS RNNs))) (NAC (CC but) (ADJP (RB not) (JJ enough) (S (VP (TO to) (VP (VB improve) (NP (DT the) (NML (JJ long) (NN term) (NN dependency)) (NN remembering) (NNS capabilities)) (ADVP (RB thereof))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN study))) (, ,) (NP (PRP we)) (VP (VBP aim) (S (VP (TO to) (ADVP (RB empirically)) (VP (VB evaluate) (NP (NP (DT the) (NN remembering)) (CC and) (NP (NP (NN generalization) (NN ability)) (PP (IN of) (NP (NP (NNS RNNs)) (PP (IN on) (NP (JJ polyphonic) (JJ musical) (NNS datasets))))))))))) (. .))
(S (NP (DT The) (NNS models)) (VP (VBP are) (VP (VBN trained) (PP (IN with) (NP (NP (ADJP (VBN injected)) (NN noise)) (, ,) (NP (ADJP (NP (NP (JJ random) (NN dropout)) (, ,) (NP (NN norm))) (HYPH -) (VBN based)) (NNS regularizers)) (CC and) (NP (NP (NP (PRP$ their) (JJ respective) (NNS performances)) (PP (VBN compared) (PP (IN to) (ADVP (RB well))))) (HYPH -) (VP (VBN initialized) (NP (NP (JJ plain) (NNS RNNs)) (CC and) (NP (JJ advanced) (NN regularization) (NNS methods))) (PP (IN like) (NP (JJ fast) (HYPH -) (NN dropout))))))))) (. .))
(S (NP (PRP We)) (VP (VBP conclude) (PP (IN with) (NP (NN evidence))) (SBAR (IN that) (S (NP (NP (NN training)) (PP (IN with) (NP (NN noise)))) (VP (VBZ does) (RB not) (VP (VB improve) (NP (NN performance)) (SBAR (IN as) (S (VP (VBN conjectured) (PP (IN by) (NP (NP (DT a) (JJ few) (NNS works)) (PP (IN in) (NP (NN RNN) (NN optimization))))) (PP (IN before) (NP (PRP ours))))))))))) (. .))
