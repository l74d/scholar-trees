(S (NP (NP (JJ Current) (NML (JJ large) (NN scale)) (NNS implementations)) (PP (IN of) (NP (NML (NML (JJ deep) (NN learning)) (CC and) (NML (NNS data))) (NN mining)))) (VP (VP (VBP require) (NP (NP (NNS thousands)) (PP (IN of) (NP (NP (NNS processors)) (, ,) (NP (NP (JJ massive) (NNS amounts)) (PP (IN of) (NP (NML (RB off) (HYPH -) (NN chip)) (NN memory)))) (, ,))))) (CC and) (VP (VBP consume) (NP (NP (NNS gigajoules)) (PP (IN of) (NP (NN energy)))))) (. .))
(S (NP (NP (VBG Emerging) (NN memory) (NNS technologies)) (PP (JJ such) (IN as) (NP (ADJP (NP (NN nanoscale) (CD two)) (HYPH -) (JJ terminal)) (JJ resistive) (NN switching) (NN memory) (NNS devices)))) (VP (VBP offer) (NP (NP (DT a) (ADJP (JJ compact) (, ,) (JJ scalable) (CC and) (JJ low)) (NN power) (NN alternative)) (SBAR (WHNP (WDT that)) (S (VP (VBZ permits) (NP (NML (IN on) (HYPH -) (NN chip)) (JJ co-located) (NML (NN processing) (CC and) (NN memory))) (PP (IN in) (NP (NP (JJ fine) (HYPH -) (NN grain)) (VP (VBN distributed) (NP (JJ parallel) (NN architecture)))))))))) (. .))
(S (ADVP (RB Here)) (NP (PRP we)) (VP (VBP report) (NP (NP (JJ first) (NN use)) (PP (IN of) (NP (JJ resistive) (NN switching) (NN memory) (NNS devices)))) (PP (IN for) (S (VP (VP (VBG implementing)) (CC and) (VP (VBG training) (NP (DT a) (VBN Restricted) (NNP Boltzmann) (NNP Machine)))))) (PRN (-LRB- -LRB-) (NP (NNP RBM)) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (ADJP (JJ generative) (JJ probabilistic)) (JJ graphical) (NN model)) (PP (IN as) (NP (NP (DT a) (JJ key) (NN component)) (PP (IN for) (NP (NP (JJ unsupervised) (NN learning)) (PP (IN in) (NP (JJ deep) (NNS networks))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB experimentally)) (VP (VBP demonstrate) (SBAR (S (NP (DT a) (NML (CD 45) (HYPH -) (NN synapse)) (NNP RBM)) (VP (VBD realized) (PP (IN with) (NP (NP (CD 90) (JJ resistive) (NML (NN switching) (NN phase) (NN change) (NN memory) (-LRB- -LRB-) (NN PCM) (-RRB- -RRB-)) (NNS elements)) (VP (VBN trained) (PP (IN with) (NP (NP (DT a) (JJ bio-inspired) (NN variant)) (PP (IN of) (NP (DT the) (NNP Contrastive) (NML (NN Divergence) (-LRB- -LRB-) (NN CD) (-RRB- -RRB-)) (NN algorithm)))))))) (, ,) (S (VP (VBG implementing) (NP (NP (NNP Hebbian)) (CC and) (NP (JJ anti-Hebbian) (NN weight) (NNS updates))))))))) (. .))
(S (NP (DT The) (JJ resistive) (NN PCM) (NNS devices)) (VP (VBP show) (NP (QP (DT a) (JJ two-fold))) (PP (IN to) (NP (JJ ten-fold) (NN reduction))) (PP (IN in) (NP (NN error) (NN rate))) (PP (IN in) (NP (DT a) (JJ missing) (NN pixel) (NN pattern))) (NP (NP (NN completion) (NN task)) (VP (VBN trained) (PP (IN over) (NP (CD 30) (NNS epochs))) (, ,) (PP (VBN compared) (PP (IN to) (NP (JJ untrained) (NN case))))))) (. .))
(SINV (VP (VBN Measured) (NP (NML (NN programming) (NN energy)) (NN consumption))) (VP (VBZ is) (NP (NP (CD 6.1) (NN nJ)) (PP (IN per) (ADJP (NN epoch) (PP (IN with) (NP (DT the) (JJ resistive) (NN switching))))))) (NP (NP (NN PCM) (NNS devices)) (, ,) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (ADJP (ADJP (NP (QP (SYM ~) (CD 150)) (NNS times)) (JJR lower)) (PP (IN than) (NP (JJ conventional) (NN processor) (HYPH -) (NN memory)))) (NNS systems))))) (. .))
(S (NP (PRP We)) (VP (VBP analyze) (CC and) (VBP discuss) (NP (NP (DT the) (NN dependence)) (PP (IN of) (S (VP (VBG learning) (NP (NP (NP (NN performance)) (PP (IN on) (NP (NML (NN cycle) (HYPH -) (IN to) (HYPH -) (NN cycle)) (NNS variations)))) (CONJP (RB as) (RB well) (IN as)) (NP (NP (NN number)) (PP (IN of) (NP (JJ gradual) (NNS levels))))) (PP (IN in) (NP (NP (DT the) (NN PCM) (NN analog)) (NP (NN memory) (NNS devices))))))))) (. .))
