(S (NP (JJ Many) (JJ real) (NN world) (NNS tasks)) (VP (VBP require) (S (NP (JJ multiple) (NNS agents)) (VP (TO to) (VP (VB work) (ADVP (RB together)))))) (. .))
(S (S (NP (JJ Multi-agent) (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)) (NNS methods)) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN in) (NP (JJ recent) (NNS years))) (S (VP (TO to) (VP (VB solve) (NP (DT these) (NNS tasks))))))))) (, ,) (CC but) (S (NP (JJ current) (NNS methods)) (ADVP (RB often)) (VP (VBP fail) (S (VP (TO to) (VP (ADVP (RB efficiently)) (VB learn) (NP (NNS policies))))))) (. .))
(S (NP (PRP We)) (ADVP (RB thus)) (VP (VB investigate) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (NP (NP (DT a) (JJ common) (NN weakness)) (PP (IN in) (NP (JJ single-agent) (NNP RL)))) (, ,) (ADVP (RB namely)) (NP (NN value) (NN function) (NN overestimation) (NN bias)))) (, ,) (PP (IN in) (NP (DT the) (JJ multi-agent) (NN setting))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (PRP$ our) (NNS findings)))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ reduces) (NP (DT this) (NN bias)) (PP (IN by) (S (VP (VBG using) (NP (JJ double) (JJ centralized) (NNS critics)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (PRP it)) (PP (IN on) (NP (CD six) (JJ mixed) (JJ cooperative-competitive) (NNS tasks))) (, ,) (S (VP (VBG showing) (NP (NP (DT a) (JJ significant) (NN advantage)) (PP (IN over) (NP (JJ current) (NNS methods))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VP (VBP investigate) (NP (NP (DT the) (NN application)) (PP (IN of) (NP (JJ multi-agent) (NNS methods))) (PP (TO to) (NP (JJ high-dimensional) (JJ robotic) (NNS tasks))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB learn) (NP (JJ decentralized) (NNS policies)) (PP (IN in) (NP (DT this) (NN domain))))))))))))) (. .))
