(SINV (PP (IN At) (NP (NP (DT the) (NN heart)) (PP (IN of) (NP (JJ deep) (VBG learning) (NN training) (CC and) (NN inferencing))))) (VP (VBP are)) (NP (NP (ADJP (RB computationally) (JJ intensive)) (NNS primitives)) (PP (JJ such) (IN as) (NP (NNS convolutions))) (SBAR (WHNP (WDT which)) (S (VP (VBP form) (NP (NP (DT the) (NN building) (NNS blocks)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))))))) (. .))
(S (NP (NNS Researchers)) (VP (VBP have) (VP (VBN taken) (NP (NP (NP (CD two) (JJ distinct) (NNS approaches)) (PP (TO to) (S (VP (VBG creating) (NP (NP (JJ high) (NN performance) (NNS implementations)) (PP (IN of) (NP (JJ deep) (NN learning) (NNS kernels)))))))) (, ,) (ADVP (RB namely)) (, ,) (NP (CD 1) (-RRB- -RRB-) (NP (NP (NN library) (NN development)) (VP (VBN exemplified) (PP (IN by) (NP (NP (NNP Intel) (NNP MKL-DNN)) (PP (IN for) (NP (NNP CPUs))))))) (, ,) (VP (CD 2) (-RRB- -RRB-) (NP (NP (JJ automatic) (NN compilation)) (VP (VBN represented) (PP (IN by) (NP (DT the) (NNP TensorFlow) (NNP XLA) (NN compiler)))))))))) (. .))
(S (S (NP (DT The) (CD two) (NNS approaches)) (VP (VBP have) (NP (PRP$ their) (NNS drawbacks)))) (: :) (S (SBAR (RB even) (IN though) (S (NP (DT a) (ADJP (NN custom) (VBN built)) (JJ library)) (VP (MD can) (VP (VB deliver) (NP (ADJP (RB very) (JJ good)) (NN performance)))))) (, ,) (NP (NP (DT the) (NN cost) (CC and) (NN time)) (PP (IN of) (NP (NP (NN development)) (PP (IN of) (NP (DT the) (NN library)))))) (VP (MD can) (VP (VB be) (ADJP (JJ high))))) (. .))
(S (S (NP (NP (JJ Automatic) (NN compilation)) (PP (IN of) (NP (NNS kernels)))) (VP (VBZ is) (ADJP (JJ attractive)))) (CC but) (S (PP (IN in) (NP (NN practice))) (, ,) (PP (NN till) (NP (NN date))) (, ,) (NP (ADJP (RB automatically) (VBD generated)) (NNS implementations)) (VP (VBP lag) (NP (ADJP (NN expert) (VBN coded)) (NNS kernels)) (PP (IN in) (NP (NN performance))) (PP (IN by) (NP (NP (NNS orders)) (PP (IN of) (NP (NN magnitude))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (NP (DT a) (JJ hybrid) (NN solution)) (PP (TO to) (NP (NP (DT the) (NN development)) (PP (IN of) (NP (JJ deep) (NN learning) (NNS kernels))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ achieves) (NP (NP (DT the) (JJS best)) (PP (IN of) (NP (DT both) (NNS worlds)))))))) (: :) (S (S (NP (DT the) (NN expert) (VBD coded) (NNS microkernels)) (VP (VBP are) (VP (VBN utilized) (PP (IN for) (NP (NP (DT the) (NN innermost) (NNS loops)) (PP (IN of) (NP (NNS kernels)))))))) (CC and) (S (NP (PRP we)) (VP (VBP use) (NP (DT the) (JJ advanced) (JJ polyhedral) (NN technology)) (S (VP (TO to) (VP (ADVP (RB automatically)) (VB tune) (NP (DT the) (NN outer) (VBZ loops)) (PP (IN for) (NP (NN performance))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP design) (NP (DT a) (JJ novel) (ADJP (JJ polyhedral) (NN model) (VBN based)) (NNS data) (NN reuse) (NN algorithm)) (SBAR (S (VP (TO to) (VP (VB optimize) (NP (NP (DT the) (NN outer) (NN loops)) (PP (IN of) (NP (DT the) (NN kernel))))))))) (. .))
(S (PP (IN Through) (NP (NP (JJ experimental) (NN evaluation)) (PP (IN on) (NP (NP (DT an) (JJ important) (NN class)) (PP (IN of) (NP (JJ deep) (VBG learning) (NNS primitives))) (RB namely) (NP (NNS convolutions)))))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT the) (NN approach)) (SBAR (S (NP (PRP we)) (VP (VBP develop))))) (VP (VBZ attains) (NP (NP (DT the) (JJ same) (NNS levels)) (PP (IN of) (NP (NN performance))) (PP (IN as) (NP (NP (NNP Intel) (NNP MKL-DNN)) (, ,) (NP (DT a) (ADJP (NN hand) (VBD coded)) (JJ deep) (NN learning) (NN library))))))))) (. .))
