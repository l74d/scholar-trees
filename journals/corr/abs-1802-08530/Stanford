(S (PP (IN For) (NP (NP (ADJP (ADJP (JJ fast)) (CC and) (ADJP (NN energy) (HYPH -) (JJ efficient))) (NN deployment)) (PP (IN of) (NP (VBN trained) (JJ deep) (JJ neural) (NNS networks))) (PP (IN on) (NP (ADJP (ADJP (NP (NN resource)) (HYPH -) (VBN constrained)) (ADJP (VBN embedded))) (NN hardware))))) (, ,) (NP (DT each)) (VP (VBD learned) (SBAR (S (NP (NN weight) (NN parameter)) (VP (MD should) (ADVP (RB ideally)) (VP (VB be) (VP (VBN represented) (CC and) (VBN stored) (S (VP (VBG using) (NP (DT a) (JJ single) (NN bit)))))))))) (. .))
(S (NP (NN Error) (HYPH -) (NNS rates)) (ADVP (RB usually)) (VP (VBP increase) (SBAR (WHADVP (WRB when)) (S (NP (DT this) (NN requirement)) (VP (VBZ is) (VP (VBN imposed)))))) (. .))
(S (ADVP (RB Here)) (, ,) (NP (PRP we)) (VP (VBP report) (NP (NP (JJ large) (NNS improvements)) (PP (IN in) (NP (NP (NN error) (NNS rates)) (PP (IN on) (NP (JJ multiple) (NNS datasets)))))) (, ,) (PP (IN for) (NP (NP (JJ deep) (JJ convolutional) (JJ neural) (NNS networks)) (VP (VBN deployed) (PP (IN with) (NP (NML (NML (CD 1) (HYPH -) (NN bit)) (HYPH -) (IN per) (HYPH -) (NN weight)))))))) (. .))
(S (S (S (VP (VBG Using) (ADVP (RB wide) (NP (JJ residual) (NNS networks))) (PP (IN as) (NP (PRP$ our) (JJ main) (NN baseline))))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ simplifies) (NP (NP (VBG existing) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP binarize) (NP (NNS weights)) (PP (IN by) (S (VP (VBG applying) (NP (DT the) (NN sign) (NN function)) (PP (IN in) (NP (NN training)))))))))))) (: ;) (S (NP (PRP we)) (VP (VBP apply) (S (NP (NP (VBG scaling) (NNS factors)) (PP (IN for) (NP (NP (DT each) (NN layer)) (PP (IN with) (NP (JJ constant) (JJ unlearned) (NNS values)))))) (ADJP (JJ equal) (PP (IN to) (NP (NP (ADJP (NP (DT the) (NN layer)) (HYPH -) (JJ specific)) (JJ standard) (NNS deviations)) (VP (VBN used) (PP (IN for) (NP (NN initialization)))))))))) (. .))
(S (PP (IN For) (S (NP (NP (NN CIFAR) (HYPH -) (CD 10)) (, ,) (NML (NN CIFAR) (HYPH -) (CD 100)) (CC and) (NML (UCP (NP (NNP ImageNet)) (, ,) (CC and) (PP (NP (NNS models)) (IN with))) (NML (CD 1) (HYPH -) (NN bit)) (HYPH -) (IN per) (HYPH -) (NN weight))) (VP (VBG requiring) (NP (NP (QP (JJR less) (IN than) (CD 10)) (NN MB)) (PP (IN of) (NP (NN parameter) (NN memory))))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (NN error) (NNS rates)) (PP (IN of) (NP (NP (NP (CD 3.9) (NN %)) (, ,) (NP (NP (QP (CD 18.5) (NN %) (CC and) (CD 26.0) (NN %))) (PP (SYM /) (NP (CD 8.5) (NN %))))) (-LRB- -LRB-) (NP (NML (JJ Top) (HYPH -) (CD 1)) (HYPH /) (NML (JJ Top) (HYPH -) (CD 5))) (-RRB- -RRB-)))) (ADVP (RB respectively))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBD considered) (NP (NNP MNIST) (, ,) (NNP SVHN) (CC and) (NNP ImageNet32)) (, ,) (S (VP (VBG achieving) (NP (NP (NML (NML (CD 1) (HYPH -) (NN bit)) (HYPH -) (PP (IN per) (HYPH -) (NP (NN weight) (NN test)))) (NNS results)) (PP (IN of) (NP (NP (CD 0.27) (NN %)) (, ,) (NP (CD 1.9) (NN %)) (, ,) (CC and) (NP (QP (QP (CD 41.3) (NN %)) (SYM /) (CD 19.1)) (NN %))))) (ADVP (RB respectively))))) (. .))
(S (PP (IN For) (NP (NNP CIFAR))) (, ,) (NP (PRP$ our) (NN error) (NNS rates)) (VP (VP (VBP halve) (NP (ADJP (RB previously) (VBN reported)) (NNS values))) (, ,) (CC and) (VP (VBP are) (PP (IN within) (NP (NP (QP (RB about) (CD 1)) (NN %)) (PP (IN of) (NP (PRP$ our) (NML (NN error) (HYPH -) (NNS rates)))))) (PP (IN for) (NP (DT the) (JJ same) (NN network))) (PP (IN with) (NP (NML (JJ full) (HYPH -) (NN precision)) (NNS weights))))) (. .))
(S (PP (IN For) (NP (NP (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (VBP overfit)))))) (, ,) (NP (PRP we)) (VP (VP (ADVP (RB also)) (VBP show) (NP (NP (JJ significant) (NNS improvements)) (PP (IN in) (NP (NN error) (NN rate)))) (PP (IN by) (S (RB not) (VP (VBG learning) (NP (NN batch) (NN normalization) (NN scale)))))) (CC and) (VP (VBD offset) (NP (NNS parameters)))) (. .))
(S (NP (DT This)) (VP (VBZ applies) (PP (IN to) (NP (CC both) (NP (JJ full) (NN precision)) (CC and) (NP (NML (NML (CD 1) (HYPH -) (NN bit)) (HYPH -) (IN per) (HYPH -) (NN weight)) (NNS networks))))) (. .))
(S (S (VP (VBG Using) (NP (DT a) (ADJP (JJ warm) (HYPH -) (SBAR (S (VP (VB restart))))) (NML (NN learning) (HYPH -) (NN rate)) (NN schedule)))) (, ,) (NP (PRP we)) (VP (VBD found) (SBAR (IN that) (S (NP (NP (NN training)) (PP (IN for) (NP (NML (NML (CD 1) (HYPH -) (NN bit)) (HYPH -) (IN per) (HYPH -) (NN weight))))) (VP (VP (VBZ is) (ADVP (RB just) (RB as) (RB fast)) (PP (IN as) (NP (NML (JJ full) (HYPH -) (NN precision)) (NNS networks))) (, ,) (PP (IN with) (NP (NP (JJR better) (NN accuracy)) (PP (IN than) (NP (JJ standard) (NNS schedules)))))) (, ,) (CC and) (VP (VBD achieved) (NP (NP (QP (RB about) (CD 98) (NN %) (HYPH -) (CD 99) (NN %))) (PP (IN of) (NP (NN peak) (NN performance)))) (PP (IN in) (NP (NP (QP (RB just) (CD 62)) (NN training) (NNS epochs)) (PP (IN for) (NP (NN CIFAR) (HYPH -) (CD 10/100)))))))))) (. .))
(S (PP (IN For) (NP (NP (JJ full) (NN training) (NN code)) (CC and) (NP (NP (VBN trained) (NNS models)) (PP (IN in) (NP (NNP MATLAB)))))) (, ,) (NP (NNP Keras) (CC and) (NNP PyTorch)) (VP (VBP see) (SBAR (S (NP (DT this)) (VP (VBZ https) (NP (NN URL)))))) (. .))
