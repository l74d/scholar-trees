(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ stochastic) (NN variant)) (PP (IN of) (NP (NP (DT the) (JJ classical) (NNP Polyak) (NN step) (HYPH -) (NN size) (PRN (-LRB- -LRB-) (NP (NNP Polyak)) (, ,) (NP (CD 1987)) (-RRB- -RRB-))) (VP (ADVP (RB commonly)) (VBN used) (PP (IN in) (NP (DT the) (NN subgradient) (NN method)))))))) (. .))
(S (SBAR (IN Although) (S (S (VP (VBG computing) (NP (DT the) (NNP Polyak) (NN step) (HYPH -) (NN size)))) (VP (VBZ requires) (NP (NP (NN knowledge)) (PP (IN of) (NP (DT the) (JJ optimal) (NN function) (NNS values))))))) (, ,) (NP (DT this) (NN information)) (VP (VBZ is) (ADJP (RB readily) (JJ available) (PP (IN for) (NP (JJ typical) (JJ modern) (NML (NN machine) (NN learning)) (NNS applications))))) (. .))
(S (ADVP (RB Consequently)) (, ,) (NP (NP (DT the) (VBN proposed) (JJ stochastic) (NNP Polyak)) (NP (NN step) (HYPH -) (NN size) (PRN (-LRB- -LRB-) (NP (NN SPS)) (-RRB- -RRB-)))) (VP (VBZ is) (NP (NP (DT an) (JJ attractive) (NN choice)) (PP (IN for) (S (VP (VBG setting) (NP (DT the) (NN learning) (NN rate)) (PP (IN for) (NP (JJ stochastic) (NN gradient) (NN descent))))))) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (JJ theoretical) (NN convergence) (NNS guarantees)) (PP (IN for) (NP (NP (NNP SGD)) (VP (VBN equipped) (PP (IN with) (NP (NN SPS))) (PP (IN in) (NP (JJ different) (NNS settings))) (, ,) (PP (VBG including) (NP (NP (ADVP (RB strongly)) (NN convex)) (, ,) (NP (NN convex)) (CC and) (NP (JJ non-convex) (NNS functions)))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP$ our) (NN analysis)) (VP (VBZ results) (PP (IN in) (NP (NP (JJ novel) (NN convergence) (NNS guarantees)) (PP (IN for) (NP (NNP SGD))))) (PP (IN with) (NP (DT a) (JJ constant) (NN step) (HYPH -) (NN size)))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP SPS)) (VP (VBZ is) (ADJP (RB particularly) (JJ effective)) (SBAR (WHADVP (WRB when)) (S (NP (NP (NN training)) (VP (VBN over-parameterized) (NP (NNS models)))) (ADJP (JJ capable) (PP (IN of) (S (VP (VBG interpolating) (NP (DT the) (NN training) (NNS data)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN setting))) (, ,) (NP (PRP we)) (VP (VBP prove) (SBAR (IN that) (S (NP (NNP SPS)) (VP (VBZ enables) (S (NP (NNP SGD)) (VP (TO to) (VP (VB converge) (PP (IN to) (NP (NP (DT the) (JJ true) (NN solution)) (PP (IN at) (NP (DT a) (JJ fast) (NN rate))))) (PP (IN without) (S (VP (VBG requiring) (NP (NP (DT the) (NN knowledge)) (PP (IN of) (NP (NP (DT any) (ADJP (NN problem) (HYPH -) (JJ dependent)) (NNS constants)) (CC or) (NP (JJ additional) (JJ computational) (NN overhead))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB experimentally)) (VP (VBP validate) (NP (PRP$ our) (JJ theoretical) (NNS results)) (PP (IN via) (NP (NP (JJ extensive) (NNS experiments)) (PP (IN on) (NP (NML (JJ synthetic) (CC and) (JJ real)) (NNS datasets)))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (JJ strong) (NN performance)) (PP (IN of) (NP (NP (NNP SGD)) (PP (IN with) (NP (NNP SPS)))))) (PP (VBN compared) (PP (IN to) (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN optimization) (NNS methods)))) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (JJ over-parameterized) (NNS models)))))) (. .))
