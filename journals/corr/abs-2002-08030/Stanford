(S (NP (NN Transfer) (NN Learning)) (VP (VBZ has) (VP (VBN shown) (NP (JJ great) (NN potential)) (S (VP (TO to) (VP (VB enhance) (NP (DT the) (ADJP (NP (JJ single) (HYPH -) (NN agent)) (NN Reinforcement)) (NN Learning) (-LRB- -LRB-) (NN RL) (-RRB- -RRB-) (NN efficiency))))) (, ,) (PP (IN by) (S (VP (VBG sharing) (VP (ADVP (RB previously)) (VBN learned) (NP (NNS policies)))))))) (. .))
(S (S (VP (VBN Inspired) (PP (IN by) (NP (DT this))))) (, ,) (NP (NP (DT the) (NN team) (VBG learning) (NN performance)) (PP (IN in) (NP (JJ multiagent) (NNS settings)))) (VP (MD can) (VP (VP (VB be) (ADVP (RB potentially)) (VP (VBN promoted) (PP (IN with) (NP (NP (NNS agents)) (VP (VBG reusing) (NP (NP (NN knowledge)) (PP (IN between) (NP (DT each) (JJ other)))) (SBAR (WHADVP (WRB when)) (S (NP (DT all) (NNS agents)) (VP (VBP interact) (PP (IN with) (NP (DT the) (NN environment))))))))))) (CC and) (VP (VB learn) (ADVP (RB simultaneously))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (WHADVP (WRB how)) (S (NP (DT each) (JJ independent) (NN agent)) (ADVP (RB selectively)) (VP (VBZ learns) (PP (IN from) (NP (NP (JJ other) (NNS agents) (POS ')) (NN knowledge)))))) (VP (VBZ is) (ADVP (RB still)) (NP (DT a) (NN problem))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (JJ novel) (JJ multi-agent) (NN transfer)) (S (VP (VBG learning) (NP (NN framework)) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN learning) (NN efficiency)) (PP (IN of) (NP (NN multiagent) (NNS systems)))))))))) (. .))
(S (NP (PRP$ Our) (NN framework)) (VP (VBZ learns) (UCP (FRAG (WHADVP (WRB when))) (CC and) (SBAR (SBAR (WHNP (WP what)) (S (NP (NN advice)) (VP (TO to) (VP (VB give) (PP (IN to) (NP (DT each) (NN agent))))))) (CC and) (SBAR (WHADVP (WRB when)) (S (VP (TO to) (VP (VB terminate) (NP (PRP it)) (PP (IN by) (NP (NP (VBG modeling) (JJ multi-agent) (NN transfer)) (PP (IN as) (NP (DT the) (NML (NN option) (NN learning)) (NN problem)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN option) (VBG learning) (NN algorithm)) (, ,) (VP (VBN named) (PP (IN as) (NP (NP (DT the) (NN Successor) (NN Representation) (NN Option) (-LRB- -LRB-) (NN SRO) (-RRB- -RRB-) (NN learning)) (SBAR (WHNP (WDT that)) (S (VP (VBZ decouples) (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (NP (DT the) (NN environment)) (PP (IN from) (NP (DT the) (NNS rewards)))))) (S (VP (TO to) (VP (VB learn) (NP (DT the) (NML (NN option) (HYPH -) (NN value)) (NN function)) (PP (IN under) (NP (NP (DT each) (NN agent) (POS 's)) (NN preference)))))))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN framework)) (VP (MD can) (VP (VB be) (ADVP (RB easily)) (VP (VBN combined) (PP (IN with) (NP (VBG existing) (NML (JJ deep) (NN RL)) (NNS approaches)))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (S (NP (PRP it)) (ADVP (RB significantly)) (VP (VP (VBZ accelerates) (NP (DT the) (NN learning) (NN process))) (CC and) (VP (VBZ surpasses) (NP (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (JJ deep) (NN RL) (NNS methods)) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (VBG learning) (NN efficiency)) (CC and) (NP (NP (JJ final) (NN performance)) (PP (IN in) (NP (ADJP (CC both) (JJ discrete) (CC and) (JJ continuous)) (NN action) (NNS spaces)))))))))))))) (. .))
