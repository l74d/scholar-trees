(S (NP (PRP We)) (VP (VBP seek) (S (VP (TO to) (VP (VB align) (NP (NN agent) (NN behavior)) (PP (IN with) (NP (NP (DT a) (NN user) (POS 's)) (NNS objectives))) (PP (IN in) (NP (NP (DT a) (NN reinforcement)) (VP (VBG learning) (S (VP (VBG setting) (PP (IN with) (NP (NP (JJ unknown) (NNS dynamics)) (, ,) (NP (DT an) (JJ unknown) (NN reward) (NN function)) (, ,) (CC and) (NP (JJ unknown) (JJ unsafe) (NNS states))))))))))))) (. .))
(S (S (NP (DT The) (NN user)) (VP (VBZ knows) (NP (NP (DT the) (NNS rewards)) (CC and) (NP (JJ unsafe) (NNS states))))) (, ,) (CC but) (S (S (VP (VBG querying) (NP (DT the) (NN user)))) (VP (VBZ is) (ADJP (JJ expensive)))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this) (NN challenge))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (ADVP (ADVP (RB safely)) (CC and) (ADVP (RB interactively))) (VP (VBZ learns) (NP (NP (DT a) (NN model)) (PP (IN of) (NP (NP (DT the) (NN user) (POS 's)) (NN reward) (NN function))))))))) (. .))
(S (NP (PRP We)) (VP (VBP start) (PP (IN with) (NP (NP (NP (DT a) (JJ generative) (NN model)) (PP (IN of) (NP (JJ initial) (NNS states)))) (CC and) (NP (NP (DT a) (NML (JJ forward) (NNS dynamics)) (NN model)) (VP (VBN trained) (PP (IN on) (NP (ADJP (IN off) (HYPH -) (NN policy)) (NNS data)))))))) (. .))
(SINV (S (NP (PRP$ Our) (NN method)) (VP (VBZ uses) (NP (DT these) (NNS models)) (S (VP (TO to) (VP (VB synthesize) (NP (JJ hypothetical) (NNS behaviors))))))) (, ,) (VP (VBZ asks) (NP (DT the) (NN user)) (PP (IN to) (NP (NN label)))) (NP (NP (NP (DT the) (NNS behaviors)) (PP (IN with) (NP (NNS rewards)))) (, ,) (CC and) (NP (NP (NNS trains)) (SBAR (S (NP (DT a) (JJ neural) (NN network)) (VP (TO to) (VP (VB predict) (NP (DT the) (NNS rewards)))))))) (. .))
(S (NP (DT The) (JJ key) (NN idea)) (VP (VBZ is) (S (VP (TO to) (ADVP (RB actively)) (VP (VB synthesize) (NP (DT the) (JJ hypothetical) (NNS behaviors)) (PP (IN from) (NP (NN scratch))) (PP (IN by) (S (VP (VBG maximizing) (NP (ADJP (JJ tractable)) (NNS proxies)) (PP (IN for) (NP (NP (DT the) (NN value)) (PP (IN of) (NP (NN information)))))))) (, ,) (PP (IN without) (S (VP (VBG interacting) (PP (IN with) (NP (DT the) (NN environment)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP call) (NP (NP (DT this) (NN method) (NN reward) (NN query) (NN synthesis)) (PP (IN via) (NP (NN trajectory) (NN optimization)))) (PRN (-LRB- -LRB-) (NP (NN ReQueST)) (-RRB- -RRB-))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NN ReQueST)) (PP (IN with) (NP (NP (JJ simulated) (NNS users)) (PP (IN on) (NP (NP (DT a) (ADJP (NN state) (HYPH -) (VBN based)) (NN 2D) (ADJP (NP (NP (NN navigation) (NN task)) (CC and) (NP (DT the) (NN image))) (HYPH -) (VBN based)) (NN Car)) (VP (VBG Racing) (NP (NN video) (NN game)))))))) (. .))
(S (NP (DT The) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NN ReQueST)) (ADVP (RB significantly)) (VP (VBZ outperforms) (NP (JJ prior) (NNS methods)) (PP (IN in) (S (VP (VBG learning) (NP (NP (NN reward) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP transfer) (PP (IN to) (NP (JJ new) (NNS environments))) (PP (IN with) (NP (JJ different) (JJ initial) (NN state) (NNS distributions)))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NN ReQueST)) (ADVP (RB safely)) (VP (VP (VBZ trains) (NP (DT the) (NN reward) (NN model)) (S (VP (TO to) (VP (VB detect) (NP (JJ unsafe) (NNS states)))))) (, ,) (CC and) (VP (VBZ corrects) (NP (NN reward) (NN hacking)) (PP (IN before) (S (VP (VBG deploying) (NP (DT the) (NN agent))))))) (. .))
