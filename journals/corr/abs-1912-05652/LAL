(S (NP (PRP We)) (VP (VBP seek) (S (VP (TO to) (VP (VB align) (NP (JJ agent) (NN behavior)) (PP (IN with) (NP (NP (DT a) (NN user) (POS 's)) (NNS objectives))) (PP (IN in) (NP (DT a) (NN reinforcement) (VBG learning) (VBG setting))) (PP (IN with) (NP (NP (JJ unknown) (NNS dynamics)) (, ,) (NP (DT an) (JJ unknown) (NN reward) (NN function)) (, ,) (CC and) (NP (JJ unknown) (JJ unsafe) (NNS states)))))))) (. .))
(S (S (NP (DT The) (NN user)) (VP (VBZ knows) (NP (NP (DT the) (NNS rewards)) (CC and) (NP (JJ unsafe) (NNS states))))) (, ,) (CC but) (S (S (VP (VBG querying) (NP (DT the) (NN user)))) (VP (VBZ is) (ADJP (JJ expensive)))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this) (NN challenge))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB safely) (CC and) (RB interactively)) (VBZ learns) (NP (NP (DT a) (NN model)) (PP (IN of) (NP (NP (DT the) (NN user) (POS 's)) (NN reward) (NN function))))))))) (. .))
(S (NP (PRP We)) (VP (VBP start) (PP (IN with) (NP (NP (NP (DT a) (JJ generative) (NN model)) (PP (IN of) (NP (JJ initial) (NNS states)))) (CC and) (NP (NP (DT a) (NN forward) (NNS dynamics) (NN model)) (VP (VBN trained) (PP (IN on) (NP (NN off-policy) (NNS data)))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VP (VBZ uses) (NP (DT these) (NNS models)) (S (VP (TO to) (VP (VB synthesize) (NP (JJ hypothetical) (NNS behaviors)))))) (, ,) (VP (VBZ asks) (NP (DT the) (NN user)) (S (VP (TO to) (VP (VB label) (NP (DT the) (NNS behaviors)) (PP (IN with) (NP (NNS rewards))))))) (, ,) (CC and) (VP (VBZ trains) (S (NP (DT a) (JJ neural) (NN network)) (VP (TO to) (VP (VB predict) (NP (DT the) (NNS rewards))))))) (. .))
(S (NP (DT The) (JJ key) (NN idea)) (VP (VBZ is) (S (VP (TO to) (VP (ADVP (RB actively)) (VB synthesize) (NP (DT the) (JJ hypothetical) (NNS behaviors)) (PP (IN from) (NP (NN scratch))) (PP (IN by) (S (VP (VBG maximizing) (NP (NP (JJ tractable) (NNS proxies)) (PP (IN for) (NP (NP (DT the) (NN value)) (PP (IN of) (NP (NN information)))))) (, ,) (PP (IN without) (S (VP (VBG interacting) (PP (IN with) (NP (DT the) (NN environment))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP call) (S (NP (DT this) (NN method)) (NP (NP (NP (NN reward) (NN query) (NN synthesis)) (PP (IN via) (NP (NN trajectory) (NN optimization)))) (PRN (-LRB- -LRB-) (NP (NNP ReQueST)) (-RRB- -RRB-))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NNP ReQueST)) (PP (IN with) (NP (JJ simulated) (NNS users))) (PP (IN on) (NP (NP (DT a) (JJ state-based) (CD 2D) (NN navigation) (NN task)) (CC and) (NP (DT the) (JJ image-based) (NNP Car) (NNP Racing) (NN video) (NN game))))) (. .))
(S (NP (DT The) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP ReQueST)) (VP (ADVP (RB significantly)) (VBZ outperforms) (NP (JJ prior) (NNS methods)) (PP (IN in) (S (VP (VBG learning) (NP (NP (NN reward) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP transfer) (PP (TO to) (NP (NP (JJ new) (NNS environments)) (PP (IN with) (NP (JJ different) (JJ initial) (NN state) (NNS distributions)))))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NNP ReQueST)) (VP (VP (ADVP (RB safely)) (VBZ trains) (S (NP (DT the) (NN reward) (NN model)) (VP (TO to) (VP (VB detect) (NP (JJ unsafe) (NNS states)))))) (, ,) (CC and) (VP (VBZ corrects) (NP (JJ reward) (VBG hacking)) (PP (IN before) (S (VP (VBG deploying) (NP (DT the) (NN agent))))))) (. .))
