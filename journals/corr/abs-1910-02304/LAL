(S (NP (NP (DT The) (JJ new) (NN generation)) (PP (IN of) (NP (NN machine) (VBG learning) (NNS processors)))) (VP (VBP have) (VP (VBN evolved) (PP (IN from) (NP (NP (ADJP (NN multi-core) (CC and) (JJ parallel)) (NNS architectures)) (PRN (-LRB- -LRB-) (PP (IN for) (NP (NN example))) (NP (JJ graphical) (VBG processing) (NNS units)) (-RRB- -RRB-)) (SBAR (WHNP (WDT that)) (S (VP (VBD were) (VP (VBN designed) (S (VP (TO to) (ADVP (VB efficiently)) (VP (JJ implement) (NP (NP (NNS matrix-vector-multiplications)) (PRN (-LRB- -LRB-) (NP (NNP MVMs)) (-RRB- -RRB-)))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (SBAR (RB because) (S (PP (IN at) (NP (DT the) (JJ fundamental) (NN level))) (, ,) (S (NP (JJ neural) (NN network) (CC and) (NN machine) (NN learning) (NNS operations)) (VP (ADVP (RB extensively)) (VBP use) (NP (NNP MVM) (NNS operations)))) (CC and) (S (NP (NN hardware) (NNS compilers)) (VP (VBP exploit) (NP (NP (DT the) (JJ inherent) (NN parallelism)) (PP (IN in) (NP (NNP MVM) (NNS operations)))) (S (VP (TO to) (VP (VB achieve) (NP (NN hardware) (NN acceleration)) (PP (IN on) (NP (NNP GPUs) (, ,) (NNP TPUs) (CC and) (NNP FPGAs))))))))))) (. .))
(S (NP (NP (DT A) (JJ natural) (NN question)) (SBAR (S (VP (TO to) (VP (VB ask)))))) (VP (VBZ is) (SBAR (SBAR (IN whether) (S (NP (NNP MVM) (NNS operations)) (VP (VBP are) (ADVP (RB even)) (ADJP (JJ necessary) (S (VP (TO to) (VP (VB implement) (NP (NNP ML) (NN algorithms))))))))) (CC and) (SBAR (IN whether) (S (NP (NN simpler) (NN hardware) (NNS primitives)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB implement) (NP (DT an) (JJ ultra-energy-efficient) (NNP ML) (NN processor/architecture)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT an) (JJ alternate) (JJ hardware-software) (NN codesign)) (PP (IN of) (NP (NP (NNP ML)) (CC and) (NP (JJ neural) (NN network) (NNS architectures)))) (SBAR (WHADVP (WRB where)) (S (PP (RB instead) (IN of) (S (VP (VBG using) (NP (NP (NNP MVM) (NNS operations)) (CC and) (NP (JJ non-linear) (NN activation) (NNS functions)))))) (, ,) (NP (DT the) (NN architecture)) (ADVP (RB only)) (VP (VBZ uses) (NP (JJ simple) (NN addition) (CC and) (VBG thresholding) (NNS operations)) (S (VP (TO to) (VP (VB implement) (NP (NN inference) (CC and) (NN learning)))))))))) (. .))
(SINV (PP (IN At) (NP (NP (DT the) (NN core)) (PP (IN of) (NP (DT the) (VBN proposed) (NN approach))))) (VP (VBZ is)) (NP (NP (ADJP (NN margin-propagation) (VBN based)) (NN computation)) (SBAR (WHNP (IN that)) (S (VP (JJ maps) (NP (NNS multiplications)) (PP (IN into) (NP (NNS additions))) (CC and) (VP (NP (NNS additions)) (PP (IN into) (NP (DT a) (JJ dynamic) (NN rectifying-linear-unit) (PRN (-LRB- -LRB-) (NNP ReLU) (-RRB- -RRB-)) (NNS operations)))))))) (. .))
(S (NP (DT This) (NN mapping)) (VP (NNS results) (PP (IN in) (NP (NP (JJ significant) (NN improvement)) (PP (IN in) (NP (ADJP (ADJP (JJ computational)) (CC and) (RB hence) (ADJP (NN energy))) (NN cost)))))) (. .))
(S (NP (NP (DT The) (NN training)) (PP (IN of) (NP (DT a) (NN margin-propagation) (PRN (-LRB- -LRB-) (NNP MP) (-RRB- -RRB-)) (NN network)))) (VP (VBZ involves) (S (VP (VBG optimizing) (NP (NP (DT an) (ADJP ($ $) (NNP L_1) ($ $)) (NN cost) (NN function)) (, ,) (SBAR (WHNP (WDT which)) (S (PP (IN in) (NP (NP (NN conjunction)) (PP (IN with) (NP (NNP ReLU) (NNS operations))))) (VP (VBZ leads) (PP (TO to) (NP (NP (NP (NN network) (NN sparsity)) (CC and) (NP (NN weight) (NNS updates))) (VP (VBG using) (NP (RB only) (NNP Boolean) (NNS predicates)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NNP MP) (NN network) (NN formulation)) (VP (MD can) (VP (VB be) (VP (VBN applied) (PP (PP (IN for) (S (VP (VBG designing) (NP (NP (JJ linear) (NNS classifiers)) (, ,) (NP (JJ multi-layer) (NNS perceptrons)))))) (CC and) (PP (IN for) (S (VP (VBG designing) (NP (NN support) (NN vector) (NNS networks)))))))))))) (. .))
