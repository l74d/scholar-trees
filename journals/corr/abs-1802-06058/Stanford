(S (PP (IN Due) (PP (IN to) (NP (DT the) (JJ substantial) (JJ computational) (NN cost)))) (, ,) (S (VP (VBG training) (NP (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (JJ deep) (JJ neural) (NNS networks)) (PP (IN for) (NP (NML (JJ large) (HYPH -) (NN scale)) (NNS datasets)))))) (ADVP (RB often)) (VP (VBZ requires) (NP (NP (VBN distributed) (NN training)) (VP (VBG using) (NP (JJ multiple) (NN computation) (NNS workers))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN by) (NP (NN nature))) (, ,) (NP (NNS workers)) (VP (VBP need) (S (VP (TO to) (ADVP (RB frequently)) (VP (VB communicate) (NP (NNS gradients))))) (, ,) (S (VP (VBG causing) (NP (JJ severe) (NNS bottlenecks)))) (, ,) (PP (ADVP (RB especially)) (IN on) (NP (JJR lower) (NN bandwidth) (NNS connections)))) (. .))
(S (S (NP (DT A) (JJ few) (NNS methods)) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN to) (S (VP (VB compress) (NP (NN gradient)) (PP (IN for) (NP (JJ efficient) (NN communication)))))))))) (, ,) (CC but) (S (NP (PRP they)) (VP (CC either) (VP (VB suffer) (NP (DT a) (NML (JJ low) (NN compression)) (NN ratio))) (CC or) (VP (ADVP (RB significantly)) (VB harm) (NP (DT the) (VBG resulting) (NN model) (NN accuracy)) (, ,) (SBAR (RB particularly) (WHADVP (WRB when)) (S (VP (VBN applied) (PP (IN to) (NP (JJ convolutional) (JJ neural) (NNS networks))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS issues))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT a) (NN method)) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN communication) (NN overhead)) (PP (IN of) (NP (VBN distributed) (JJ deep) (NN learning)))))))) (. .))
(S (NP (PRP$ Our) (JJ key) (NN observation)) (VP (VBZ is) (SBAR (IN that) (S (NP (NN gradient) (NNS updates)) (VP (MD can) (VP (VB be) (VP (VBN delayed) (SBAR (IN until) (S (NP (DT an) (JJ unambiguous) (PRN (-LRB- -LRB-) (NP (NP (JJ high) (NN amplitude)) (, ,) (NP (JJ low) (NN variance))) (-RRB- -RRB-)) (NN gradient)) (VP (VBZ has) (VP (VBN been) (VP (VBN calculated)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP present) (NP (DT an) (JJ efficient) (NN algorithm)) (PP (IN to) (S (VP (VB compute) (NP (DT the) (NN variance)) (PP (IN with) (NP (JJ negligible) (JJ additional) (NN cost))))))) (. .))
(S (NP (PRP We)) (ADVP (RB experimentally)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (MD can) (VP (VB achieve) (NP (ADJP (RB very) (JJ high)) (NN compression) (NN ratio)) (PP (IN while) (S (VP (VBG maintaining) (NP (DT the) (NN result) (NN model) (NN accuracy)))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP analyze) (NP (DT the) (NN efficiency)) (S (VP (VBG using) (NP (NML (NN computation) (CC and) (NN communication)) (NN cost) (NNS models))))) (CC and) (VP (VB provide) (NP (DT the) (NN evidence)) (SBAR (IN that) (S (NP (DT this) (NN method)) (VP (VBZ enables) (NP (NP (VBN distributed) (JJ deep) (NN learning)) (PP (IN for) (NP (NP (JJ many) (NNS scenarios)) (PP (IN with) (NP (NN commodity) (NNS environments))))))))))) (. .))
