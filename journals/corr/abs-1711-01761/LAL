(S (NP (PRP We)) (VP (VBP study) (NP (NP (DT a) (JJ new) (NN aggregation) (NN operator)) (PP (IN for) (NP (NNS gradients))) (VP (VBG coming) (PP (IN from) (NP (NP (DT a) (NN mini-batch)) (PP (IN for) (NP (NP (JJ stochastic) (NN gradient) (PRN (-LRB- -LRB-) (NNP SG) (-RRB- -RRB-)) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBZ allows) (NP (DT a) (JJ significant) (NN speed-up)) (PP (IN in) (NP (NP (DT the) (NN case)) (PP (IN of) (NP (JJ sparse) (NN optimization) (NNS problems))))))))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP call) (S (NP (DT this) (NN method)) (NP (NNP AdaBatch))))) (CC and) (S (NP (PRP it)) (ADVP (RB only)) (VP (VBZ requires) (NP (NP (DT a) (JJ few) (NNS lines)) (PP (IN of) (NP (NN code) (NN change)))) (PP (VBN compared) (PP (TO to) (NP (VB regular) (JJ mini-batch) (NNP SGD) (NN algorithms)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP provide) (NP (NP (DT a) (JJ theoretical) (NN insight)) (SBAR (S (VP (TO to) (VP (VB understand) (SBAR (WHADVP (WRB how)) (S (NP (NP (DT this) (JJ new) (NN class)) (PP (IN of) (NP (NN algorithms)))) (VP (VBZ is) (VP (VBG performing))))))))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ equivalent) (PP (TO to) (NP (NP (DT an) (JJ implicit) (JJ per-coordinate) (NN rescaling)) (PP (IN of) (NP (DT the) (NNS gradients))) (, ,) (ADVP (RB similarly) (PP (TO to) (SBAR (WHNP (WP what)) (S (NP (NNP Adagrad) (NNS methods)) (VP (MD can) (VP (VB do))))))))))))))) (. .))
(S (PP (PP (IN In) (NP (NN theory))) (CC and) (PP (IN in) (NP (NN practice)))) (, ,) (NP (DT this) (JJ new) (NN aggregation)) (VP (VBZ allows) (S (VP (TO to) (VP (VB keep) (NP (NP (DT the) (JJ same) (JJ sample) (NN efficiency)) (PP (IN of) (NP (NNP SG) (NNS methods)))) (SBAR (IN while) (S (VP (VBG increasing) (NP (DT the) (NN batch) (NN size))))))))) (. .))
(S (ADVP (RB Experimentally)) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (PP (IN in) (NP (NP (DT the) (NN case)) (PP (IN of) (NP (JJ smooth) (JJ convex) (NN optimization))))) (, ,) (NP (PRP$ our) (NN procedure)) (VP (MD can) (ADVP (RB even)) (VP (VB obtain) (NP (DT a) (JJR better) (NN loss)) (SBAR (WHADVP (WRB when)) (S (VP (VBG increasing) (NP (DT the) (NN batch) (NN size)) (PP (IN for) (NP (NP (DT a) (JJ fixed) (NN number)) (PP (IN of) (NP (NNS samples))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VB apply) (NP (DT this) (JJ new) (NN algorithm)) (S (VP (TO to) (VP (VB obtain) (NP (NP (DT a) (JJ parallelizable) (JJ stochastic) (NN gradient) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ is) (ADJP (JJ synchronous))) (CC but) (VP (VBZ allows) (NP (NP (NN speed-up)) (PP (IN on) (NP (NP (NN par)) (PP (IN with) (NP (NNP Hogwild))))))))))))))) (. !))
(S (NP (NP (NNS methods)) (PP (IN as) (NP (NN convergence)))) (VP (VBZ does) (RB not) (VP (VB deteriorate) (PP (IN with) (NP (NP (DT the) (NN increase)) (PP (IN of) (NP (DT the) (NN batch) (NN size))))))) (. .))
(S (NP (DT The) (JJ same) (NN approach)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB make) (S (NP (NN mini-batch)) (ADJP (RB provably) (JJ efficient) (PP (IN for) (NP (NP (JJ variance-reduced) (NNP SG) (NNS methods)) (PP (JJ such) (IN as) (NP (NNP SVRG))))))))))))) (. .))
