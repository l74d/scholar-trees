(S (S (VP (VBG Working) (PP (IN with) (NP (DT any) (JJ gradient-based) (NN machine) (VBG learning) (JJ algorithm))))) (VP (VBZ involves) (NP (NP (DT the) (JJ tedious) (NN task)) (PP (IN of) (S (VP (VBG tuning) (NP (NP (NP (DT the) (NN optimizer) (POS 's)) (NNS hyperparameters)) (, ,) (PP (JJ such) (IN as) (NP (DT the) (NN learning) (NN rate))))))))) (. .))
(S (S (NP (EX There)) (VP (VBP exist) (NP (NP (JJ many) (NNS techniques)) (PP (IN for) (NP (JJ automated) (NN hyperparameter) (NN optimization)))))) (, ,) (CC but) (S (NP (PRP they)) (ADVP (RB typically)) (VP (VBP introduce) (NP (ADJP (RB even) (JJR more)) (NNS hyperparameters)) (S (VP (TO to) (VP (VB control) (NP (DT the) (NN hyperparameter) (NN optimization) (NN process))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (VP (VP (TO to) (ADVP (RB instead)) (VP (VB learn) (NP (NP (DT the) (NNS hyperparameters)) (NP (PRP themselves))) (PP (IN by) (NP (JJ gradient) (NN descent))))) (, ,) (CC and) (ADVP (RB furthermore)) (VP (TO to) (VP (VB learn) (NP (DT the) (NNS hyper-hyperparameters)) (PP (IN by) (NP (JJ gradient) (NN descent))) (ADVP (RB as) (RB well)))) (, ,) (CC and) (X (ADVP (RB so) (IN on)) (ADVP (NN ad) (NN infinitum)))))) (. .))
(S (SBAR (IN As) (S (NP (NP (DT these) (NNS towers)) (PP (IN of) (NP (JJ gradient-based) (NNS optimizers)))) (VP (VBP grow)))) (, ,) (NP (PRP they)) (VP (VBP become) (ADJP (RB significantly) (RBR less) (JJ sensitive) (PP (TO to) (NP (NP (DT the) (NN choice)) (PP (IN of) (NP (JJ top-level) (NNS hyperparameters)))))) (, ,) (S (ADVP (RB hence)) (VP (VBG decreasing) (NP (NP (DT the) (NN burden)) (PP (IN on) (NP (DT the) (NN user))) (S (VP (TO to) (VP (VB search) (PP (IN for) (NP (JJ optimal) (NNS values)))))))))) (. .))
