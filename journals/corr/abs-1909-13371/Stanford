(S (S (VP (VBG Working) (PP (IN with) (NP (ADJP (NP (DT any) (NN gradient)) (HYPH -) (VBN based)) (NML (NN machine) (NN learning)) (NN algorithm))))) (VP (VBZ involves) (NP (NP (DT the) (JJ tedious) (NN task)) (PP (IN of) (S (VP (VBG tuning) (NP (NP (DT the) (NN optimizer) (POS 's)) (NNS hyperparameters))))) (, ,) (PP (JJ such) (IN as) (NP (DT the) (NN learning) (NN rate))))) (. .))
(S (S (NP (EX There)) (VP (VBP exist) (NP (NP (JJ many) (NNS techniques)) (PP (IN for) (NP (VBN automated) (NN hyperparameter) (NN optimization)))))) (, ,) (CC but) (S (NP (PRP they)) (ADVP (RB typically)) (VP (VBP introduce) (NP (ADJP (RB even) (RBR more)) (NNS hyperparameters)) (S (VP (TO to) (VP (VB control) (NP (DT the) (NML (NN hyperparameter) (NN optimization)) (NN process))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (S (PP (IN to) (ADVP (RB instead))) (VP (VB learn) (NP (DT the) (NNS hyperparameters) (PRP themselves)) (PP (IN by) (NP (NN gradient) (NN descent))))) (, ,) (CC and) (S (ADVP (RB furthermore)) (VP (TO to) (VP (VB learn) (NP (DT the) (ADJP (JJ hyper) (HYPH -)) (NNS hyperparameters)) (PP (IN by) (NP (NN gradient) (NN descent))) (PP (ADVP (ADVP (RB as) (RB well)) (, ,) (CC and) (ADVP (RB so))) (IN on) (NP (NN ad) (NN infinitum)))))))) (. .))
(S (SBAR (IN As) (S (NP (ADJP (NP (NP (DT these) (NNS towers)) (PP (IN of) (NP (NN gradient)))) (HYPH -) (VBN based)) (NNS optimizers)) (VP (VBP grow)))) (, ,) (NP (PRP they)) (VP (VBP become) (ADJP (RB significantly) (RBR less) (JJ sensitive)) (PP (IN to) (NP (NP (DT the) (NN choice)) (PP (IN of) (NP (NML (JJ top) (HYPH -) (NN level)) (NNS hyperparameters))))) (, ,) (S (ADVP (RB hence)) (VP (VBG decreasing) (NP (DT the) (NN burden)) (PP (IN on) (NP (DT the) (NN user))) (S (VP (TO to) (VP (VB search) (PP (IN for) (NP (JJ optimal) (NNS values))))))))) (. .))
