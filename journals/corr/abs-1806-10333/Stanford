(S (NP (ADJP (NP (NP (JJ Deep) (NN learning)) (-LRB- -LRB-) (NP (NN DL))) (-RRB- -RRB-) (HYPH -) (VBN based)) (NN autoencoder)) (VP (VBZ is) (NP (DT a) (JJ potential) (NN architecture) (S (VP (TO to) (VP (VB implement) (NP (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end) (NN communication)))) (NNS systems))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN letter))) (, ,) (NP (PRP we)) (ADVP (RB first)) (VP (VB give) (NP (DT a) (JJ brief) (NN introduction)) (PP (IN to) (NP (ADJP (NP (DT the) (NN autoencoder)) (HYPH -) (VBN represented)) (NN communication) (NN system)))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (DT a) (JJ novel) (VBN generalized) (NML (NNS data)) (NN representation)) (-LRB- -LRB-) (NP (NNP GDR)) (-RRB- -RRB-)) (VP (VBG aiming) (S (VP (TO to) (VP (VB improve) (NP (NP (DT the) (NN data) (NN rate)) (PP (IN of) (NP (ADJP (NP (NN DL)) (HYPH -) (VBN based)) (NN communication) (NNS systems)))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (NN simulation) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NNP GDR) (NN scheme)) (VP (VBZ has) (NP (NP (JJR lower) (NN training) (NN complexity)) (, ,) (NP (JJ comparable) (NN block) (NN error) (NN rate) (NN performance)) (CC and) (NP (NP (JJR higher) (NN channel) (NN capacity)) (PP (IN than) (NP (DT the) (JJ conventional) (NML (CD one) (HYPH -) (JJ hot)) (NN vector) (NN scheme))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VP (VBP investigate) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (ADJP (NP (NP (NML (NML (NN signal)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN noise)))) (NN ratio) (PRN (-LRB- -LRB-) (NP (NN SNR)) (-RRB- -RRB-))) (PP (IN in) (NP (NN DL)))) (HYPH -) (VBN based)) (NN communication) (NNS systems))))) (CC and) (VP (VB prove) (SBAR (IN that) (S (NP (NP (NN training)) (PP (IN at) (NP (DT a) (JJ high) (NN SNR)))) (VP (MD could) (VP (VB produce) (NP (DT a) (JJ good) (NN training) (NN performance)) (PP (IN for) (NP (NN autoencoder))))))))) (. .))
