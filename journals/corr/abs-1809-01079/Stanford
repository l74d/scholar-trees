(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (NP (DT the) (ADJP (JJ chi) (HYPH -) (JJ square)) (NN test) (JJ neural) (NN network)) (: :) (NP (DT a) (NML (JJ single) (JJ hidden) (NN layer) (NN backpropagation)) (JJ neural) (NN network))) (VP (VBG using) (NP (ADJP (JJ chi) (HYPH -) (JJ square)) (NN test) (NN theorem)) (PP (IN to) (VP (VB redefine) (NP (NP (DT the) (NN cost) (NN function)) (CC and) (NP (DT the) (NN error) (NN function)))))))) (. .))
(S (NP (DT The) (NNS weights) (CC and) (NNS thresholds)) (VP (VBP are) (VP (VBN modified) (S (VP (VBG using) (NP (JJ standard) (NN backpropagation) (NN algorithm)))))) (. .))
(S (NP (DT The) (VBN proposed) (NN approach)) (VP (VBZ has) (NP (NP (DT the) (NN advantage)) (PP (IN of) (S (VP (VBG making) (NP (JJ consistent) (NNS data) (NN distribution)) (PP (IN over) (NP (NML (NN training) (CC and) (NN testing)) (NNS sets)))))))) (. .))
(S (NP (PRP It)) (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN for) (NP (JJ binary) (NN classification)))))) (. .))
(S (NP (NP (DT The) (JJ experimental) (NNS results)) (PP (IN on) (NP (NML (JJ real) (NN world) (NN data)) (NNS sets)))) (VP (VBP indicate) (SBAR (IN that) (S (NP (DT the) (VBN proposed) (NN algorithm)) (VP (MD can) (ADVP (RB significantly)) (VP (VB improve) (NP (NP (DT the) (NN classification) (NN accuracy)) (VP (VBG comparing) (PP (IN to) (NP (JJ related) (NNS approaches)))))))))) (. .))
