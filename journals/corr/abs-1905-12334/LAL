(S (NP (NP (VBN Reduced) (NN precision) (NN computation)) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks)))) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (JJ key) (NNS areas)) (VP (VBG addressing) (NP (NP (DT the) (VBG widening) (NN compute) (NN gap)) (VP (VBN driven) (PP (IN by) (NP (NP (DT an) (JJ exponential) (NN growth)) (PP (IN in) (NP (NN model) (NN size)))))))))))) (. .))
(S (PP (IN In) (NP (JJ recent) (NNS years))) (, ,) (NP (JJ deep) (NN learning) (NN training)) (VP (VBZ has) (VP (ADVP (RB largely)) (VBN migrated) (PP (TO to) (NP (JJ 16-bit) (NN precision))) (, ,) (PP (IN with) (NP (NP (JJ significant) (NNS gains)) (PP (IN in) (NP (NP (NN performance)) (CC and) (NP (NN energy) (NN efficiency)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NNS attempts) (S (VP (TO to) (VP (VB train) (NP (NNP DNNs)) (PP (IN at) (NP (JJ 8-bit) (NN precision))))))) (VP (VBP have) (VP (VBN met) (PP (IN with) (NP (JJ significant) (NNS challenges))) (PP (IN because) (IN of) (NP (NP (DT the) (JJR higher) (NN precision) (CC and) (JJ dynamic) (NN range) (NNS requirements)) (PP (IN of) (NP (NN back-propagation))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN method)) (SBAR (S (VP (TO to) (VP (VB train) (NP (JJ deep) (JJ neural) (NNS networks)) (S (VP (VBG using) (NP (NP (JJ 8-bit) (VBG floating) (NN point) (NN representation)) (PP (IN for) (NP (NNS weights) (, ,) (NNS activations) (, ,) (NNS errors) (, ,) (CC and) (NNS gradients)))))))))))) (. .))
(S (PP (IN In) (NP (NP (NN addition)) (PP (TO to) (S (VP (VBG reducing) (NP (JJ compute) (NN precision))))))) (, ,) (NP (PRP we)) (ADVP (RB also)) (VP (VBD reduced) (NP (NP (DT the) (NN precision) (NNS requirements)) (PP (IN for) (NP (NP (DT the) (NN master) (NN copy)) (PP (IN of) (NP (NNS weights)))))) (PP (IN from) (ADJP (JJ 32-bit))) (PP (TO to) (NP (JJ 16-bit)))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (JJ state-of-the-art) (NN accuracy)) (PP (IN across) (NP (NP (NP (JJ multiple) (NNS data) (NNS sets)) (PRN (-LRB- -LRB-) (NP (JJ imagenet-1K) (, ,) (NNP WMT16)) (-RRB- -RRB-))) (CC and) (NP (NP (DT a) (JJR broader) (NN set)) (PP (IN of) (NP (NNS workloads))) (PRN (-LRB- -LRB-) (NP (NP (NNP Resnet-18/34/50)) (, ,) (NP (NNP GNMT)) (, ,) (NP (NNP Transformer))) (-RRB- -RRB-)) (SBAR (IN than) (S (ADVP (RB previously)) (VP (VBN reported)))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT an) (JJ enhanced) (NN loss) (VBG scaling) (NN method)) (SBAR (S (VP (TO to) (VP (VB augment) (NP (NP (DT the) (VBN reduced) (JJ subnormal) (NN range)) (PP (IN of) (NP (JJ 8-bit) (VBG floating) (NN point)))) (PP (IN for) (NP (JJ improved) (NN error) (NN propagation))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP examine) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (NN quantization) (NN noise))) (PP (IN on) (NP (NN generalization))))) (CC and) (VP (VB propose) (NP (NP (DT a) (JJ stochastic) (NN rounding) (NN technique)) (SBAR (S (VP (TO to) (VP (VB address) (NP (JJ gradient) (NN noise))))))))) (. .))
(S (PP (IN As) (NP (NP (DT a) (NN result)) (PP (IN of) (S (VP (VBG applying) (NP (PDT all) (DT these) (NNS techniques))))))) (, ,) (NP (PRP we)) (VP (VBP report) (NP (NP (ADJP (RB slightly) (JJR higher)) (NN validation) (NN accuracy)) (PP (VBN compared) (PP (TO to) (NP (ADJP (JJ full) (NN precision)) (NN baseline)))))) (. .))
