(S (NP (NML (NML (NN End)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NNS approaches)) (VP (VBP have) (VP (VBN drawn) (NP (JJ much) (NN attention)) (ADVP (RB recently)) (PP (IN for) (S (ADVP (RB significantly)) (VP (VBG simplifying) (NP (NP (DT the) (NN construction)) (PP (IN of) (NP (DT an) (NML (NML (JJ automatic) (NN speech) (NN recognition)) (-LRB- -LRB-) (NML (NN ASR)) (-RRB- -RRB-)) (NN system))))))))) (. .))
(S (NP (NN RNN) (NN transducer) (PRN (-LRB- -LRB-) (NP (NN RNN) (HYPH -) (NN T)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (NML (NML (JJ popular) (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NNS methods))))) (. .))
(S (S (NP (JJ Previous) (NNS studies)) (VP (VBP have) (VP (VBN shown) (SBAR (IN that) (S (NP (NN RNN) (HYPH -) (NN T)) (VP (VBZ is) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB train))))))))))) (CC and) (S (NP (DT a) (ADJP (RB very) (JJ complex)) (NN training) (NN process)) (VP (VBZ is) (VP (VBN needed) (PP (IN for) (NP (DT a) (JJ reasonable) (NN performance)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP explore) (S (NP (NP (NML (NML (NN RNN) (HYPH -) (NN T)) (PP (IN for) (NP (DT a) (JJ Chinese) (JJ large) (NN vocabulary)))) (JJ continuous) (NN speech) (NN recognition) (PRN (-LRB- -LRB-) (NP (NN LVCSR)) (-RRB- -RRB-))) (NP (NN task) (CC and) (NN aim))) (VP (TO to) (VP (VB simplify) (NP (DT the) (NN training) (NN process)) (PP (IN while) (S (VP (VBG maintaining) (NP (NN performance))))))))) (. .))
(S (ADVP (RB First)) (, ,) (NP (NP (DT a) (JJ new) (NN strategy)) (PP (IN of) (NP (NML (NN learning) (NN rate)) (NN decay)))) (VP (VBZ is) (VP (VBN proposed) (S (VP (TO to) (VP (VB accelerate) (NP (DT the) (NN model) (NN convergence))))))) (. .))
(S (ADVP (RB Second)) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (S (VP (VP (VBG adding) (NP (JJ convolutional) (NNS layers)) (PP (IN at) (NP (NP (DT the) (NN beginning)) (PP (IN of) (NP (DT the) (NN network)))))) (CC and) (VP (VBG using) (NP (VBN ordered) (NNS data))))) (VP (MD can) (VP (VB discard) (NP (NP (DT the) (JJ pre-training) (NN process)) (PP (IN of) (NP (DT the) (NN encoder)))) (PP (IN without) (NP (NP (NN loss)) (PP (IN of) (NP (NN performance)))))))))) (. .))
(S (ADVP (RB Besides)) (, ,) (NP (PRP we)) (VP (VBP design) (NP (NNS experiments)) (S (VP (TO to) (VP (VB find) (NP (DT a) (NN balance)) (PP (IN among) (NP (NP (DT the) (NN usage)) (PP (IN of) (NP (NP (NNP GPU) (NN memory)) (, ,) (NP (NN training) (NN circle)) (CC and) (NP (NN model) (NN performance)))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (NP (NP (CD 16.9) (NN %)) (NN character) (NN error) (NN rate) (PRN (-LRB- -LRB-) (NP (NN CER)) (-RRB- -RRB-))) (PP (IN on) (NP (PRP$ our) (NN test) (NN set)))) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (NML (CD 2) (NN %)) (JJ absolute) (NN improvement)) (PP (IN from) (NP (NP (DT a) (JJ strong) (NML (NN BLSTM) (NN CE)) (NN system)) (PP (IN with) (NP (NP (NN language) (NN model)) (VP (VBN trained) (PP (IN on) (NP (DT the) (JJ same) (NN text) (NN corpus)))))))))))))) (. .))
