(S (NP (NP (DT A) (JJ low) (NN precision) (NML (JJ deep) (JJ neural) (NN network) (NN training)) (NN technique)) (PP (IN for) (S (VP (VBG producing) (NP (JJ sparse) (, ,) (JJ ternary) (JJ neural) (NNS networks)))))) (VP (VBZ is) (VP (VBN presented))) (. .))
(S (NP (DT The) (NN technique)) (VP (VBZ incorporates) (NP (NML (JJ hard) (HYPH -) (NN ware)) (NN implementation) (NNS costs)) (PP (IN during) (NP (NN training) (S (VP (TO to) (VP (VB achieve) (NP (JJ significant) (NN model) (NN compression)) (PP (IN for) (NP (NN inference))))))))) (. .))
(S (NP (NN Training)) (VP (VBZ involves) (NP (NP (CD three) (NNS stages)) (: :) (S (NP (NN network) (NN training)) (VP (VP (VBG using) (NP (NP (NN L2) (NN regularization)) (CC and) (NP (NP (DT a) (NN quantization) (NN threshold) (NN regularizer)) (, ,) (NP (NN quantization) (NN pruning)) (, ,)))) (CC and) (ADVP (RB finally)) (VP (VBG retraining)))))) (. .))
(S (NP (VBG Resulting) (NNS networks)) (VP (VB achieve) (NP (VBN improved) (NP (NP (NN accuracy)) (, ,) (NP (VBN reduced) (NN memory) (NN footprint)) (CC and) (NP (NP (VBN reduced) (JJ computational) (NN complexity)) (PP (VBN compared) (PP (IN with) (NP (JJ conventional) (NNS methods)))) (, ,) (PP (IN on) (NP (NNP MNIST)))) (CC and) (NP (NN CIFAR10) (NNS datasets))))) (. .))
(S (NP (PRP$ Our) (NNS networks)) (VP (VBP are) (ADVP (RB up) (PP (IN to) (NP (CD 98) (NN %)))) (ADJP (ADJP (JJ sparse)) (CC and) (ADJP (NP (NML (CD 5) (CC &) (CD 11)) (NNS times)) (JJR smaller))) (PP (IN than) (NP (JJ equivalent) (JJ binary) (CC and) (JJ ternary) (NNS models))) (, ,) (VP (VBG translating) (PP (IN to) (NP (JJ significant) (NML (NN resource) (CC and) (NN speed)) (NNS benefits))) (PP (IN for) (NP (NN hardware) (NNS implementations))))) (. .))
