(S (NP (JJ Previous) (NN work)) (VP (NNS shows) (SBAR (WDT that) (S (S (NP (ADJP (RB adversarially) (JJ robust)) (NN generalization)) (VP (VBZ requires) (NP (JJR larger) (JJ sample) (NN complexity)))) (, ,) (CC and) (S (NP (NP (DT the) (JJ same) (NN dataset)) (, ,) (NP (NN e.g.)) (, ,) (NP (NNP CIFAR-10)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ enables) (NP (JJ good) (NN standard) (NN accuracy)))))) (VP (MD may) (RB not) (VP (VB suffice) (S (VP (TO to) (VP (VB train) (NP (JJ robust) (NNS models))))))))))) (. .))
(S (SBAR (IN Since) (S (S (VP (VBG collecting) (NP (JJ new) (NN training) (NNS data)))) (VP (MD could) (VP (VB be) (ADJP (JJ costly)))))) (, ,) (NP (PRP we)) (VP (VBP focus) (PP (IN on) (S (VP (ADVP (JJR better)) (VBG utilizing) (NP (DT the) (VBN given) (NNS data)) (PP (IN by) (S (VP (VBG inducing) (NP (NP (DT the) (NNS regions)) (PP (IN with) (NP (NP (JJ high) (NN sample) (NN density)) (PP (IN in) (NP (DT the) (NN feature) (NN space))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD could) (VP (VB lead) (PP (TO to) (NP (NP (ADJP (RB locally) (JJ sufficient)) (NNS samples)) (PP (IN for) (NP (JJ robust) (NN learning))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB first)) (VP (ADVP (RB formally)) (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (JJ softmax) (NN cross-entropy) (PRN (-LRB- -LRB-) (NNP SCE) (-RRB- -RRB-)) (NN loss)) (CC and) (NP (PRP$ its) (NNS variants))) (VP (VB convey) (NP (NP (JJ inappropriate) (JJ supervisory) (NNS signals)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP encourage) (S (NP (DT the) (JJ learned) (NN feature) (NNS points)) (VP (TO to) (VP (VB spread) (PP (IN over) (NP (DT the) (NN space))) (ADVP (RB sparsely)) (PP (IN in) (NP (NN training)))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ inspires) (S (NP (PRP us)) (VP (TO to) (VP (VB propose) (NP (DT the) (NNP Max-Mahalanobis) (NN center) (PRN (-LRB- -LRB-) (NNP MMC) (-RRB- -RRB-)) (NN loss)) (S (VP (TO to) (VP (ADVP (RB explicitly)) (VB induce) (NP (JJ dense) (NN feature) (NNS regions)) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB benefit) (NP (NN robustness))))))))))))) (. .))
(S (ADVP (RB Namely)) (, ,) (NP (DT the) (NNP MMC) (NN loss)) (VP (VBZ encourages) (S (NP (DT the) (NN model)) (VP (TO to) (VP (VB concentrate) (PP (IN on) (S (VP (VBG learning) (NP (NP (ADJP (VBN ordered) (CC and) (JJ compact)) (NNS representations)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP gather) (PP (IN around) (NP (NP (DT the) (NN preset) (JJ optimal) (NNS centers)) (PP (IN for) (NP (JJ different) (NNS classes)))))))))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB empirically)) (VBP demonstrate) (SBAR (IN that) (S (S (VP (VBG applying) (NP (DT the) (NNP MMC) (NN loss)))) (VP (MD can) (VP (ADVP (RB significantly)) (VB improve) (NP (NN robustness)) (PP (ADVP (RB even)) (IN under) (NP (JJ strong) (JJ adaptive) (NNS attacks))) (, ,) (SBAR (IN while) (S (VP (VBG keeping) (NP (JJ state-of-the-art) (NN accuracy)) (PP (IN on) (NP (JJ clean) (NNS inputs))) (PP (IN with) (NP (NP (JJ little) (JJ extra) (NN computation)) (PP (VBN compared) (PP (TO to) (NP (DT the) (NNP SCE) (NN loss)))))))))))))) (. .))
