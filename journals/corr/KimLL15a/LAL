(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NP (DT an) (NN image) (NN super-resolution) (NN method)) (PRN (-LRB- -LRB-) (NP (NNP SR)) (-RRB- -RRB-))) (S (VP (VBG using) (NP (NP (DT a) (JJ deeply-recursive) (JJ convolutional) (NN network)) (PRN (-LRB- -LRB-) (NP (NNP DRCN)) (-RRB- -RRB-))))))) (. .))
(S (NP (PRP$ Our) (NN network)) (VP (VBZ has) (NP (NP (DT a) (ADJP (RB very) (JJ deep)) (NN recursive) (NN layer)) (PRN (-LRB- -LRB-) (NP (QP (IN up) (TO to) (CD 16)) (NNS recursions)) (-RRB- -RRB-)))) (. .))
(S (S (VP (VBG Increasing) (NP (NN recursion) (NN depth)))) (VP (MD can) (VP (VB improve) (NP (NN performance)) (PP (IN without) (S (VP (VBG introducing) (NP (NP (JJ new) (NNS parameters)) (PP (IN for) (NP (JJ additional) (NNS convolutions))))))))) (. .))
(S (PP (NNP Albeit) (NP (NNS advantages))) (, ,) (S (VP (VBG learning) (NP (DT a) (NNP DRCN)))) (VP (VBZ is) (ADJP (RB very) (JJ hard)) (PP (IN with) (NP (DT a) (JJ standard) (NN gradient) (NN descent) (NN method))) (PP (JJ due) (PP (TO to) (NP (VBG exploding/vanishing) (NNS gradients))))) (. .))
(S (S (VP (TO To) (VP (VB ease) (NP (NP (DT the) (NN difficulty)) (PP (IN of) (NP (NN training))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (CD two) (NNS extensions)) (: :) (NP (NN recursive-supervision) (CC and) (NN skip-connection)))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ outperforms) (NP (JJ previous) (NNS methods)) (PP (IN by) (NP (DT a) (JJ large) (NN margin)))) (. .))
