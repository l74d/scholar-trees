(S (NP (NP (JJ Convolutional) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS CNNs)) (-RRB- -RRB-)) (VP (VBP are) (ADVP (RB commonly)) (VP (VBN assumed) (S (VP (TO to) (VP (VB be) (ADJP (JJ invariant)) (PP (IN to) (NP (JJ small) (NN image) (NNS transformations))) (: :) (PP (CC either) (PP (IN because) (NP (UCP (PP (IN of) (NP (DT the) (JJ convolutional) (NN architecture))) (CC or) (SBAR (IN because) (S (NP (PRP they)) (VP (VBD were) (VP (VBN trained) (S (VP (VBG using) (NP (NNS data))))))))) (NN augmentation))))))))) (. .))
(S (S (ADVP (RB Recently)) (, ,) (NP (JJ several) (NNS authors)) (VP (VBP have) (VP (VBN shown) (SBAR (IN that) (S (NP (DT this)) (VP (VBZ is) (RB not) (NP (DT the) (NN case)))))))) (: :) (S (NP (NP (JJ small) (NNS translations) (CC or) (NNS rescalings)) (PP (IN of) (NP (DT the) (NN input) (NN image)))) (VP (MD can) (ADVP (RB drastically)) (VP (VB change) (NP (NP (DT the) (NN network) (POS 's)) (NN prediction))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP quantify) (NP (DT this) (NN phenomena))) (CC and) (VP (VB ask) (SBAR (WHADVP (WRB why)) (S (NP (CC neither) (NP (DT the) (JJ convolutional) (NN architecture)) (CC nor) (NP (NNS data) (NN augmentation))) (VP (VBP are) (ADJP (JJ sufficient) (S (VP (TO to) (VP (VB achieve) (NP (DT the) (VBN desired) (NN invariance))))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (S (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (JJ convolutional) (NN architecture)) (VP (VBZ does) (RB not) (VP (VB give) (NP (NN invariance)) (SBAR (IN since) (S (NP (NNS architectures)) (VP (VBP ignore) (NP (DT the) (JJ classical) (NN sampling) (NN theorem))))))))))) (, ,) (CC and) (S (NP (NNS data) (NN augmentation)) (VP (VBZ does) (RB not) (VP (VB give) (NP (NN invariance)) (SBAR (IN because) (S (NP (DT the) (NNS CNNs)) (VP (VBP learn) (S (VP (TO to) (VP (VB be) (ADJP (JJ invariant) (PP (IN to) (NP (NNS transformations)))) (ADVP (RB only)) (PP (IN for) (NP (NP (NNS images)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (RB very) (JJ similar) (PP (IN to) (NP (NP (JJ typical) (NNS images)) (PP (IN from) (NP (DT the) (NN training) (NN set)))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP discuss) (NP (NP (NP (CD two) (JJ possible) (NNS solutions)) (PP (IN to) (NP (DT this) (NN problem)))) (: :) (SBAR (S (S (LST (-LRB- -LRB-) (LS 1) (-RRB- -RRB-)) (VP (VBG antialiasing) (NP (DT the) (JJ intermediate) (NNS representations)))) (CC and) (S (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (VP (VBG increasing) (NP (NNS data)) (NP (NN augmentation)))))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP provide) (NP (RB only) (DT a) (JJ partial) (NN solution)) (ADVP (IN at) (JJS best))))))) (. .))
(S (S (VP (VBN Taken) (ADVP (RB together)))) (, ,) (NP (PRP$ our) (NNS results)) (VP (VBP indicate) (SBAR (IN that) (S (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (VBG insuring) (NP (NN invariance)) (PP (IN to) (NP (NP (JJ small) (NN image) (NNS transformations)) (PP (IN in) (NP (JJ neural) (NNS networks))))) (PP (IN while) (S (VP (VBG preserving) (NP (JJ high) (NN accuracy))))))))) (VP (VBZ remains) (NP (JJ unsolved)))))) (. .))
