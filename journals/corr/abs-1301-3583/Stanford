(S (NP (DT This) (NN article)) (VP (VBZ exposes) (SBAR (S (NP (NP (DT the) (NN failure)) (PP (IN of) (NP (NP (DT some) (JJ big) (JJ neural) (NNS networks)) (PP (IN to) (NP (NN leverage)))))) (VP (VBD added) (NP (NN capacity)) (S (VP (TO to) (VP (VB reduce) (NP (NN underfitting))))))))) (. .))
(S (NP (JJ Past) (NN research)) (VP (VBP suggest) (S (VP (VBG diminishing) (NP (NNS returns)) (SBAR (WHADVP (WRB when)) (S (VP (VBG increasing) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (PP (IN on) (NP (NP (NP (NNP ImageNet) (NNP LSVRC)) (HYPH -) (NP (CD 2010) (NN show))) (SBAR (IN that) (S (NP (DT this)) (VP (MD may) (VP (VB be) (ADJP (JJ due) (PP (IN to) (NP (DT the) (NN fact))))))))))) (ADVP (RB there)) (VP (VBP are) (ADVP (RB highly)) (VP (VBG diminishing) (NP (NP (NNS returns)) (PP (IN for) (NP (NN capacity)))) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NN training) (NN error))))) (, ,) (S (VP (VBG leading) (PP (IN to) (NP (NN underfitting))))))) (. .))
(S (NP (DT This)) (VP (VBZ suggests) (SBAR (IN that) (S (NP (DT the) (ADJP (NP (NN optimization) (NN method)) (HYPH -) (JJ first)) (NN order) (NN gradient)) (VP (NN descent) (HYPH -) (VBZ fails) (PP (IN at) (NP (DT this) (NN regime))))))) (. .))
(S (ADVP (RB Directly)) (S (VP (VBG attacking) (NP (DT this) (NN problem)) (, ,) (PP (CC either) (IN through) (NP (NP (DT the) (NN optimization) (NN method)) (CC or) (NP (NP (DT the) (NNS choices)) (PP (IN of) (NP (NN parametrization)))))))) (, ,) (VP (MD may) (VP (VB allow) (S (VP (TO to) (VP (VB improve) (NP (DT the) (NN generalization) (NN error)) (PP (IN on) (NP (NP (JJ large) (NNS datasets)) (, ,) (SBAR (WHPP (IN for) (WHNP (WDT which))) (S (NP (DT a) (JJ large) (NN capacity)) (VP (VBZ is) (VP (VBN required)))))))))))) (. .))
