(S (SBAR (IN While) (S (NP (NP (JJ deep) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-)) (VP (VBP have) (VP (VBN proven) (S (VP (TO to) (VP (VB be) (ADJP (JJ efficient) (PP (IN for) (NP (JJ numerous) (NNS tasks))))))))))) (, ,) (NP (PRP they)) (VP (VBP come) (PP (IN at) (NP (DT a) (NML (NML (JJ high) (NN memory)) (CC and) (NML (NN computation))) (NN cost))) (, ,) (S (ADVP (RB thus)) (VP (VBG making) (S (NP (PRP them)) (ADJP (JJ impractical) (PP (IN on) (NP (NML (NN resource) (HYPH -) (VBN limited)) (NNS devices)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT these) (NNS networks)) (VP (VBP are) (VP (VBN known) (S (VP (TO to) (VP (VB contain) (NP (NP (DT a) (JJ large) (NN number)) (PP (IN of) (NP (NNS parameters))))))))) (. .))
(S (NP (JJ Recent) (NN research)) (VP (VBZ has) (VP (VBN shown) (SBAR (IN that) (S (NP (PRP$ their) (NN structure)) (VP (MD can) (VP (VB be) (ADJP (RBR more) (JJ compact) (PP (IN without) (S (VP (VBG compromising) (NP (PRP$ their) (NN performance)))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (ADJP (NN sparsity) (HYPH -) (VBG inducing)) (NML (NN regularization) (NN term)) (ADJP (VBN based) (PP (IN on) (NP (DT the) (NN ratio)))) (NML (NN l1) (HYPH /) (NN l2)) (NN pseudo-norm)) (VP (VBN defined) (PP (IN on) (NP (DT the) (NN filter) (NNS coefficients)))))) (. .))
(S (PP (IN By) (S (VP (VP (VBG defining) (NP (DT this) (NN pseudo-norm)) (ADVP (RB appropriately)) (PP (IN for) (NP (DT the) (JJ different) (NN filter) (NNS kernels)))) (, ,) (CC and) (VP (VBG removing) (NP (ADJP (JJ irrelevant)) (NNS filters)))))) (, ,) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS kernels)) (PP (IN in) (NP (DT each) (NN layer)))))) (VP (MD can) (VP (VB be) (ADVP (RB drastically)) (VP (VBN reduced) (S (VP (VBG leading) (PP (IN to) (NP (ADJP (RB very) (JJ compact)) (JJ Deep) (JJ Convolutional) (JJ Neural) (NML (NML (NNS Networks)) (-LRB- -LRB-) (NML (NNP DCNN)) (-RRB- -RRB-)) (NNS structures)))))))) (. .))
(S (PP (IN Unlike) (NP (JJ numerous) (JJ existing) (NNS methods))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ does) (RB not) (VP (VP (VB require) (NP (DT an) (JJ iterative) (VBG retraining) (NN process))) (CC and) (, ,) (S (VP (VBG using) (NP (DT this) (NN regularization) (NN term)))) (, ,) (ADVP (RB directly)) (VP (VBZ produces) (NP (DT a) (JJ sparse) (NN model)) (PP (IN during) (NP (DT the) (NN training) (NN process)))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ is) (ADVP (RB also)) (ADJP (RB much) (JJR easier) (CC and) (JJR simpler)) (S (VP (TO to) (VP (VB implement) (PP (IN than) (NP (VBG existing) (NNS methods))))))) (. .))
(NP (NP (JJ Experimental) (NNS results)) (PP (IN on) (NP (NP (NML (NML (NN MNIST)) (CC and) (NML (NN CIFAR) (HYPH -) (CD 10))) (NN show)) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (ADVP (RB significantly)) (VP (VBZ reduces) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS filters)) (PP (IN of) (NP (NP (JJ classical) (NNS models)) (PP (JJ such) (IN as) (NP (NNP LeNet) (CC and) (NNP VGG)))))))) (PP (IN while) (S (VP (VBG reaching) (NP (DT the) (ADJP (ADJP (JJ same)) (CC or) (ADJP (RB even) (JJR better))) (NN accuracy)) (PP (IN than) (NP (DT the) (NN baseline) (NNS models))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (NP (DT the) (NN trade) (HYPH -) (NN off)) (PP (IN between) (NP (NP (DT the) (NN sparsity)) (CC and) (NP (DT the) (NN accuracy))))) (VP (VP (VBZ is) (VP (VBN compared) (PP (IN to) (NP (JJ other) (NN loss) (NN regularization) (NNS terms))) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (NML (NN l1) (CC or) (NN l2)) (NN norm)) (CONJP (RB as) (RB well) (IN as)) (NP (DT the) (NML (NN SSL) (, ,) (NN NISP) (CC and) (NN GAL)) (NNS methods))))))) (CC and) (VP (VBZ shows) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (VBZ is) (VP (VBG outperforming) (NP (PRP them)))))))) (. .))
