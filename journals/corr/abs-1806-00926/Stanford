(S (NP (NN Scene) (NN text) (NN recognition)) (VP (VBZ has) (VP (VBN attracted) (PP (NP (DT a) (JJ great) (JJ many) (NNS researches)) (IN due)) (PP (IN to) (NP (PRP$ its) (NN importance))) (PP (IN to) (NP (JJ various) (NNS applications))))) (. .))
(S (NP (VBG Existing) (NNS methods)) (ADVP (RB mainly)) (VP (VBP adopt) (NP (ADJP (NP (NN recurrence) (CC or) (NN convolution)) (VBN based)) (NNS networks))) (. .))
(S (SBAR (IN Though) (S (VP (VBP have) (VP (VBN obtained) (NP (JJ good) (NN performance)))))) (, ,) (NP (DT these) (NNS methods)) (ADVP (RB still)) (VP (VBP suffer) (PP (IN from) (NP (NP (CD two) (NNS limitations)) (: :) (NP (NP (JJ slow) (NN training) (NN speed)) (PP (PP (IN due) (PP (IN to) (NP (NP (DT the) (JJ internal) (NN recurrence)) (PP (IN of) (NP (NNS RNNs)))))) (, ,) (CC and) (PP (NP (JJ high) (NN complexity)) (IN due)))))) (PP (IN to) (NP (NP (VBN stacked) (JJ convolutional) (NNS layers)) (PP (IN for) (NP (NML (JJ long) (HYPH -) (NN term)) (NN feature) (NN extraction)))))) (. .))
(S (S (NP (NP (DT This) (NN paper)) (, ,) (PP (IN for) (NP (DT the) (JJ first) (NN time))) (, ,)) (VP (VBZ proposes) (NP (NP (DT a) (NML (NML (NML (DT no) (HYPH -) (NN recurrence)) (NN sequence)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN sequence) (NN text)))) (NN recognizer)) (, ,) (VP (VBN named) (NP (NNP NRTR)))))) (, ,) (NP (DT that)) (VP (VBZ dispenses) (PP (IN with) (NP (NNS recurrences) (CC and) (NNS convolutions))) (ADVP (RB entirely))) (. .))
(S (S (NP (NN NRTR)) (VP (VBZ follows) (NP (NP (DT the) (NML (NN encoder) (HYPH -) (NN decoder)) (NN paradigm)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN encoder)) (VP (VBZ uses) (VP (VBN stacked) (NP (NN self) (HYPH -) (NN attention)) (S (VP (TO to) (VP (VB extract) (NP (NN image) (NNS features)))))))))))) (, ,) (CC and) (S (NP (DT the) (NN decoder)) (VP (VBZ applies) (VP (VBN stacked) (NP (NN self) (HYPH -) (NN attention)) (S (VP (TO to) (VP (VB recognize) (NP (NNS texts)) (PP (VBN based) (PP (IN on) (NP (NN encoder) (NN output)))))))))) (. .))
(S (NP (NNP NRTR)) (VP (VBZ relies) (ADVP (RB solely)) (PP (IN on) (NP (NN self) (HYPH -) (NN attention))) (SBAR (S (NP (NN mechanism)) (ADVP (RB thus)) (VP (MD could) (VP (VB be) (VP (VBN trained) (PP (IN with) (NP (NP (JJR more) (NN parallelization)) (CC and) (NP (JJR less) (NN complexity)))))))))) (. .))
(S (S (VP (VBG Considering) (SBAR (S (NP (NN scene) (NN image)) (VP (VBZ has) (NP (NP (JJ large) (NN variation)) (PP (IN in) (NP (NN text) (CC and) (NN background))))))))) (, ,) (NP (PRP we)) (ADVP (RB further)) (VP (VB design) (NP (DT a) (NML (S (NP (NN modality)) (HYPH -) (VP (VB transform)))) (NN block)) (S (VP (TO to) (ADVP (RB effectively)) (VP (VB transform) (NP (NML (NN 2D) (NN input)) (NNS images)) (PP (IN to) (NP (NN 1D) (NNS sequences)))))) (, ,) (PP (VBN combined) (PP (IN with) (NP (DT the) (NN encoder) (S (VP (TO to) (VP (VB extract) (NP (JJR more) (JJ discriminative) (NNS features))))))))) (. .))
(S (NP (NNP NRTR)) (VP (VBZ achieves) (NP (NP (UCP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (CC or) (ADJP (RB highly) (JJ competitive))) (NN performance)) (PP (IN on) (NP (DT both) (ADJP (JJ regular) (CC and) (JJ irregular)) (NNS benchmarks)))) (, ,) (SBAR (IN while) (S (VP (VBZ requires) (NP (NP (RB only) (DT a) (JJ small) (NN fraction)) (PP (IN of) (NP (NN training) (NN time)))) (PP (VBN compared) (PP (IN to) (NP (NP (DT the) (JJS best) (NN model)) (PP (IN from) (NP (DT the) (NN literature)))))) (PRN (-LRB- -LRB-) (NP (NP (QP (ADVP (IN at) (RBS least)) (CD 8)) (NNS times)) (ADVP (RBR faster))) (-RRB- -RRB-)))))) (. .))
