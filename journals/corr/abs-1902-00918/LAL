(S (NP (JJ State-of-the-art) (JJ deep) (NN model) (NN compression) (NNS methods)) (VP (VBP exploit) (NP (NP (DT the) (JJ low-rank) (NN approximation)) (CC and) (NP (NN sparsity) (NN pruning))) (S (VP (TO to) (VP (VB remove) (NP (JJ redundant) (NNS parameters)) (PP (IN from) (NP (DT a) (JJ learned) (NN hidden) (NN layer))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP they)) (VP (VP (VBP process) (NP (DT each) (NN hidden) (NN layer)) (ADVP (RB individually)) (SBAR (IN while) (S (VP (VBG neglecting) (NP (NP (DT the) (JJ common) (NNS components)) (PP (IN across) (NP (NNS layers)))))))) (, ,) (CC and) (VP (ADVP (RB thus)) (VBP are) (RB not) (ADJP (JJ able) (S (VP (TO to) (VP (ADVP (RB fully)) (VB exploit) (NP (NP (DT the) (JJ potential) (NN redundancy) (NN space)) (PP (IN for) (NP (NN compression)))))))))) (. .))
(S (S (VP (TO To) (VP (VP (VB solve) (NP (DT the) (NN above) (NN problem))) (CC and) (VP (VB enable) (NP (NP (JJ further) (NN compression)) (PP (IN of) (NP (DT a) (NN model)))))))) (, ,) (S (VP (VP (VBG removing) (NP (DT the) (JJ cross-layer) (NN redundancy))) (CC and) (VP (VBG mining) (NP (DT the) (JJ layer-wise) (NN inheritance) (NN knowledge))))) (VP (VBZ is) (ADJP (JJ necessary))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ holistic) (NN model) (NN compression) (NN framework)) (, ,) (ADVP (RB namely)) (NP (NP (VBG MIning) (NNP Cross-layer) (NNP Inherent) (NN similarity) (NNP Knowledge)) (PRN (-LRB- -LRB-) (NP (NNP MICIK)) (-RRB- -RRB-)))) (, ,) (S (VP (TO to) (VP (ADVP (RB fully)) (VB excavate) (NP (DT the) (JJ potential) (NN redundancy) (NN space)))))) (. .))
(S (NP (DT The) (VBN proposed) (NNP MICIK) (NN framework)) (VP (ADVP (RB simultaneously)) (, ,) (VP (PRN (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (VP (VBZ learns) (NP (DT the) (ADJP (JJ common) (CC and) (JJ unique)) (NN weight) (NNS components)) (PP (IN across) (NP (JJ deep) (JJ neural) (NN network) (NNS layers))) (S (VP (TO to) (VP (VB increase) (NP (NN compression) (NN rate))))))) (: ;) (VP (PRN (-LRB- -LRB-) (CD 2) (-RRB- -RRB-)) (VP (VBZ preserves) (NP (NP (DT the) (JJ inherent) (NN similarity) (NN knowledge)) (PP (IN of) (NP (NP (JJ nearby) (NNS layers)) (CC and) (NP (JJ distant) (NNS layers))))) (S (VP (TO to) (VP (VB minimize) (NP (DT the) (NN accuracy) (NN loss))))))) (CC and) (VP (PRN (-LRB- -LRB-) (CD 3) (-RRB- -RRB-)) (VP (MD can) (VP (VB be) (ADJP (JJ complementary) (PP (TO to) (NP (NP (JJ other) (VBG existing) (NN compression) (NNS techniques)) (PP (JJ such) (IN as) (NP (NN knowledge) (NN distillation)))))))))) (. .))
(S (NP (NP (JJ Extensive) (NNS experiments)) (PP (IN on) (NP (JJ large-scale) (JJ convolutional) (JJ neural) (NNS networks)))) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NNP MICIK)) (VP (VBZ is) (ADJP (ADJP (JJ superior) (PP (IN over) (NP (JJ state-of-the-art) (NN model) (NN compression) (NNS approaches)))) (PP (IN with) (NP (NP (NP (NP (CD 16X) (NN parameter) (NN reduction)) (PP (IN on) (NP (NNP VGG-16)))) (CC and) (NP (NP (CD 6X)) (PP (IN on) (NP (NNP GoogLeNet))))) (, ,) (NP (NP (DT all)) (PP (IN without) (NP (JJ accuracy) (NN loss))))))))))) (. .))
