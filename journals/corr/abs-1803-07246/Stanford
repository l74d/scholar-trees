(S (NP (NML (NN Policy) (NN gradient)) (NNS methods)) (VP (VP (VBP have) (VP (VBN enjoyed) (NP (JJ great) (NN success)) (PP (IN in) (NP (JJ deep) (NN reinforcement) (NN learning))))) (CC but) (VP (VB suffer) (PP (IN from) (NP (NP (JJ high) (NN variance)) (PP (IN of) (NP (NN gradient) (NNS estimates))))))) (. .))
(S (NP (DT The) (JJ high) (NN variance) (NN problem)) (VP (VBZ is) (ADVP (RB particularly)) (VP (VBN exasperated) (PP (IN in) (NP (NNS problems))) (PP (IN with) (NP (NP (JJ long) (NNS horizons)) (CC or) (NP (ADJP (JJ high) (HYPH -) (JJ dimensional)) (NN action) (NNS spaces)))))) (. .))
(S (S (VP (TO To) (VP (VB mitigate) (NP (DT this) (NN issue))))) (, ,) (NP (PRP we)) (VP (VP (VBP derive) (NP (NP (NP (DT a) (ADJP (NP (NML (NN bias) (HYPH -) (JJ free)) (NN action)) (HYPH -) (JJ dependent)) (NN baseline)) (PP (IN for) (NP (NN variance) (NN reduction)))) (SBAR (WHNP (WDT which)) (S (ADVP (RB fully)) (VP (VBZ exploits) (NP (NP (DT the) (JJ structural) (NN form)) (PP (IN of) (NP (DT the) (JJ stochastic) (NN policy)))))))) (S (NP (PRP itself)))) (CC and) (VP (VBZ does) (RB not) (VP (VB make) (NP (DT any) (JJ additional) (NNS assumptions)) (PP (IN about) (NP (DT the) (NNP MDP)))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (CC and) (VBP quantify) (NP (NP (DT the) (NN benefit)) (PP (IN of) (NP (DT the) (ADJP (NN action) (HYPH -) (JJ dependent)) (NN baseline)))) (PP (IN through) (NP (NP (DT both) (JJ theoretical) (NN analysis)) (CONJP (RB as) (RB well) (IN as)) (NP (NP (JJ numerical) (NNS results)) (, ,) (PP (VBG including) (NP (NP (DT an) (NN analysis)) (PP (IN of) (NP (NP (DT the) (NN suboptimality)) (PP (IN of) (NP (DT the) (JJ optimal) (ADJP (NN state) (HYPH -) (JJ dependent)) (NN baseline))))))))))) (. .))
(S (NP (DT The) (NN result)) (VP (VBZ is) (NP (NP (DT a) (ADJP (ADVP (RB computationally)) (JJ efficient)) (NML (NN policy) (NN gradient)) (NN algorithm)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ scales) (PP (IN to) (NP (ADJP (JJ high) (HYPH -) (JJ dimensional)) (NN control) (NNS problems))) (, ,) (SBAR (IN as) (S (VP (VBN demonstrated) (PP (IN by) (NP (DT a) (JJ synthetic) (NML (CD 2000) (SYM -)) (ADJP (JJ dimensional) (NN target)) (VBG matching) (NN task))))))))))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP indicate) (SBAR (IN that) (S (NP (ADJP (NN action) (HYPH -) (JJ dependent)) (NNS baselines)) (VP (VBP allow) (PP (IN for) (S (ADVP (RBR faster)) (VP (VBG learning) (PP (IN on) (NP (JJ standard) (NN reinforcement))) (NP (NP (VBG learning) (NNS benchmarks)) (CC and) (NP (NP (ADJP (JJ high) (HYPH -) (JJ dimensional)) (NN hand) (NN manipulation)) (CC and) (NP (JJ synthetic) (NNS tasks))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (JJ general) (NN idea)) (PP (IN of) (S (VP (VBG including) (NP (JJ additional) (NN information)) (PP (IN in) (NP (NP (NNS baselines)) (PP (IN for) (NP (VBN improved) (NN variance) (NN reduction))))))))) (VP (MD can) (VP (VB be) (VP (VBN extended) (PP (IN to) (NP (ADJP (ADJP (RB partially) (VBN observed)) (CC and) (ADJP (JJ multi-agent))) (NNS tasks))))))))) (. .))
