(S (ADJP (RB Phenomenally) (JJ successful) (PP (IN in) (NP (JJ practical) (NN inference) (NNS problems)))) (, ,) (NP (NP (JJ convolutional) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP CNN)) (-RRB- -RRB-))) (VP (VBP are) (VP (ADVP (RB widely)) (VBN deployed) (PP (IN in) (NP (NP (JJ mobile) (NNS devices)) (, ,) (NP (NN data) (NNS centers)) (, ,) (CC and) (ADVP (RB even)) (NP (NNS supercomputers)))))) (. .))
(S (NP (NP (DT The) (NN number)) (PP (IN of) (NP (NP (NNS parameters)) (VP (VBN needed) (PP (IN in) (NP (NNP CNNs))))))) (, ,) (ADVP (RB however)) (, ,) (VP (VBP are) (ADVP (RB often)) (ADJP (JJ large) (CC and) (JJ undesirable))) (. .))
(S (ADVP (RB Consequently)) (, ,) (NP (JJ various) (NNS methods)) (VP (VBP have) (VP (VBN been) (VP (VBN developed) (S (VP (TO to) (VP (VB prune) (NP (DT a) (NNP CNN)) (SBAR (IN once) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN trained))))))))))) (. .))
(S (ADVP (RB Nevertheless)) (, ,) (NP (DT the) (VBG resulting) (NNP CNNs)) (VP (NN offer) (NP (VBD limited) (NNS benefits))) (. .))
(S (SBAR (IN While) (S (S (VP (VBG pruning) (NP (DT the) (ADJP (RB fully) (VBN connected)) (NNS layers)))) (VP (VBZ reduces) (NP (NP (DT a) (NNP CNN) (POS 's)) (NN size)) (ADVP (RB considerably))))) (, ,) (NP (PRP it)) (VP (VBZ does) (RB not) (VP (VB improve) (NP (NN inference) (NN speed)) (ADVP (RB noticeably)) (SBAR (IN as) (S (NP (DT the) (ADJP (NN compute) (JJ heavy)) (NNS parts)) (VP (VBP lie) (PP (IN in) (NP (NNS convolutions)))))))) (. .))
(S (S (VP (VBG Pruning) (NP (NNP CNNs)) (PP (IN in) (NP (NP (DT a) (NN way)) (SBAR (WHNP (IN that)) (S (VP (NN increase) (NP (NN inference) (NN speed))))))))) (ADVP (RB often)) (VP (VBZ imposes) (NP (JJ specific) (NN sparsity) (NNS structures)) (, ,) (S (ADVP (RB thus)) (VP (VBG limiting) (NP (DT the) (JJ achievable) (NN sparsity) (NNS levels))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT a) (NN method)) (SBAR (S (VP (TO to) (VP (VB realize) (ADVP (RB simultaneously)) (NP (NP (NN size) (NN economy)) (CC and) (NP (NN speed) (NN improvement))) (SBAR (IN while) (S (VP (VBG pruning) (NP (NNP CNNs))))))))))) (. .))
(SINV (ADJP (NNP Paramount) (PP (TO to) (NP (PRP$ our) (NN success)))) (VP (VBZ is)) (NP (NP (DT an) (JJ efficient) (JJ general) (NN sparse-with-dense) (NN matrix) (NN multiplication) (NN implementation)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ applicable) (PP (TO to) (NP (NP (NN convolution)) (PP (IN of) (NP (NN feature) (NNS maps))) (PP (IN with) (NP (NP (NNS kernels)) (PP (IN of) (NP (JJ arbitrary) (NN sparsity) (NNS patterns)))))))))))) (. .))
(S (S (VP (VBG Complementing) (NP (DT this)))) (, ,) (NP (PRP we)) (VP (VBD developed) (NP (NP (DT a) (NN performance) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (VBZ predicts) (NP (NP (JJ sweet) (NNS spots)) (PP (IN of) (NP (NN sparsity) (NNS levels))) (PP (PP (IN for) (NP (JJ different) (NNS layers))) (CC and) (PP (IN on) (NP (JJ different) (NN computer) (NNS architectures)))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP open) (NN source) (NP (PRP$ our) (NN project)) (PP (IN at) (NP (DT this) (NN https) (NNP URL)))))
