(S (NP (NP (JJ Neural) (NNS networks)) (VP (VBG using) (NP (JJ numerous) (NN text) (NNS data)))) (VP (VBP have) (VP (VBN been) (VP (ADVP (RB successfully)) (VBN applied) (PP (TO to) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS tasks)))))))) (. .))
(S (SBAR (IN While) (S (NP (JJ massive) (NN text) (NNS data)) (VP (VBZ is) (ADVP (RB usually)) (VP (VBN compressed) (S (VP (VBG using) (NP (NP (NNS techniques)) (PP (JJ such) (IN as) (NP (NN grammar) (NN compression)))))))))) (, ,) (NP (NP (RB almost) (DT all)) (PP (IN of) (NP (DT the) (JJ previous) (NN machine) (VBG learning) (NNS methods)))) (VP (VBP assume) (NP (ADJP (RB already) (VBN decompressed)) (NN sequence) (NNS data)) (PP (IN as) (NP (PRP$ their) (NN input)))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN method)) (SBAR (S (VP (TO to) (VP (ADVP (RB directly)) (VB apply) (NP (JJ neural) (NN sequence) (NNS models)) (PP (TO to) (NP (NP (VB text) (NNS data)) (VP (VBN compressed) (PP (IN with) (NP (NN grammar) (NN compression) (NN algorithms)))))) (PP (IN without) (NP (NN decompression))))))))) (. .))
(S (S (VP (TO To) (VP (VB encode) (NP (NP (DT the) (JJ unique) (NNS symbols)) (SBAR (WHNP (WDT that)) (S (VP (VBP appear) (PP (IN in) (NP (NN compression) (NNS rules)))))))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (JJR composer) (NNS modules)) (SBAR (S (VP (TO to) (VP (ADVP (RB incrementally)) (VB encode) (NP (DT the) (NNS symbols)) (PP (IN into) (NP (NN vector) (NNS representations))))))))) (. .))
(S (PP (IN Through) (NP (NP (NNS experiments)) (PP (IN on) (NP (JJ real) (NNS datasets))))) (, ,) (NP (PRP we)) (VP (ADVP (RB empirically)) (VBD showed) (SBAR (IN that) (S (NP (DT the) (NN proposal) (NN model)) (VP (MD can) (VP (VB achieve) (NP (DT both) (NP (NN memory)) (CC and) (NP (JJ computational) (NN efficiency))) (SBAR (IN while) (S (VP (VBG maintaining) (NP (JJ moderate) (NN performance)))))))))) (. .))
