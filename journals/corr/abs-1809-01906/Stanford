(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (JJ new) (NN optimization) (NN objective)) (PP (IN for) (NP (ADJP (NN value) (HYPH -) (VBN based)) (NML (JJ deep) (NN reinforcement)) (NN learning))))) (. .))
(S (NP (PRP We)) (VP (VBP extend) (NP (NP (JJ conventional) (JJ Deep) (NML (NN Q) (HYPH -) (NNS Networks))) (-LRB- -LRB-) (NP (NNS DQNs)) (-RRB- -RRB-)) (PP (IN by) (S (VP (VBG adding) (NP (DT a) (NML (NN model) (HYPH -) (NN learning)) (NN component)) (S (VP (VBG yielding) (NP (DT a) (NN transcoder) (NN network)))))))) (. .))
(S (NP (NP (DT The) (NN prediction) (NNS errors)) (PP (IN for) (NP (DT the) (NN model)))) (VP (VBP are) (VP (VBN included) (PP (IN in) (NP (NP (DT the) (JJ basic) (NN DQN) (NN loss)) (PP (IN as) (NP (JJ additional) (NNS regularizers))))))) (. .))
(S (NP (NP (DT This)) (VP (VBN augmented) (NP (NN objective)))) (VP (VBZ leads) (PP (IN to) (NP (NP (DT a) (JJR richer) (NN training) (NN signal)) (SBAR (WHNP (WDT that)) (S (VP (VBZ provides) (NP (NN feedback)) (PP (IN at) (NP (DT every) (NN time) (NN step))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (PP (IN because) (S (VP (VBG learning) (S (NP (DT an) (NN environment) (NN model) (NNS shares)) (NP (NP (DT a) (JJ common) (NN structure)) (PP (IN with) (NP (DT the) (NN RL) (NN problem)))))))) (, ,) (NP (PRP we)) (VP (VBP hypothesize) (SBAR (IN that) (S (NP (DT the) (VBG resulting) (NN objective)) (VP (VBZ improves) (NP (NP (DT both) (NN sample) (NN efficiency)) (CC and) (NP (NN performance))))))) (. .))
(S (NP (PRP We)) (ADVP (RB empirically)) (VP (VBP confirm) (NP (PRP$ our) (NN hypothesis)) (PP (IN on) (NP (NP (DT a) (NN range)) (PP (IN of) (NP (NP (CD 20) (NNS games)) (PP (IN from) (NP (DT the) (NNP Atari) (NN benchmark))))))) (S (VP (VBG attaining) (NP (NP (JJ superior) (NNS results)) (PP (IN over) (NP (ADJP (NP (NML (NN vanilla) (NN DQN)) (PP (IN without) (NP (NN model)))) (HYPH -) (VBN based)) (NN regularization))))))) (. .))
