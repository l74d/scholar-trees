(S (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (JJ deep) (PRN (-LRB- -LRB-) (NN reinforcement) (-RRB- -RRB-)) (VBG learning) (NNS systems)))) (VP (ADVP (RB crucially)) (VBZ depends) (PP (IN on) (NP (NP (DT the) (NN choice)) (PP (IN of) (NP (NNS hyperparameters)))))) (. .))
(S (NP (PRP$ Their) (NN tuning)) (VP (VBZ is) (ADJP (RB notoriously) (JJ expensive)) (, ,) (S (ADVP (RB typically)) (VP (VBG requiring) (S (NP (DT an) (JJ iterative) (NN training) (NN process)) (VP (TO to) (VP (VB run) (PP (IN for) (NP (NP (JJ numerous) (NNS steps)) (PP (TO to) (NP (VB convergence))))))))))) (. .))
(S (NP (JJ Traditional) (NN tuning) (NN algorithms)) (VP (VP (ADVP (RB only)) (VB consider) (NP (NP (DT the) (JJ final) (NN performance)) (PP (IN of) (NP (NP (NNS hyperparameters)) (VP (VBD acquired) (PP (IN after) (NP (JJ many) (JJ expensive) (NNS iterations)))))))) (CC and) (VP (VB ignore) (NP (NP (JJ intermediate) (NN information)) (PP (IN from) (NP (JJR earlier) (NN training) (NNS steps)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ Bayesian) (NN optimization) (PRN (-LRB- -LRB-) (NNP BO) (-RRB- -RRB-)) (NN approach)) (SBAR (WHNP (WDT which)) (S (VP (VBZ exploits) (NP (NP (DT the) (JJ iterative) (NN structure)) (PP (IN of) (NP (VBG learning) (NN algorithms)))) (PP (IN for) (NP (JJ efficient) (NN hyperparameter) (NN tuning)))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (S (VP (TO to) (VP (VB learn) (NP (NP (DT an) (NN evaluation) (NN function)) (VP (VBG compressing) (NP (NP (VBG learning) (NN progress)) (PP (IN at) (NP (NP (DT any) (NN stage)) (PP (IN of) (NP (DT the) (NN training) (NN process)))))) (PP (IN into) (NP (DT a) (JJ single) (NN numeric) (NN score))) (PP (VBG according) (PP (TO to) (NP (DT both) (NP (NN training) (NN success)) (CC and) (NP (NN stability))))))))))) (. .))
(S (NP (PRP$ Our) (NNP BO) (NN framework)) (VP (VBZ is) (ADVP (RB then)) (VP (IN tradeoff) (NP (NP (DT the) (NN benefit)) (PP (IN of) (S (VP (VBG assessing) (NP (DT a) (NN hyperparameter) (VBG setting))))) (PP (RP over) (NP (JJ additional) (NN training) (NNS steps)))) (PP (IN against) (NP (PRP$ their) (NN computation) (NN cost))))) (. .))
(S (NP (PRP We)) (ADVP (JJ further)) (VP (VB increase) (NP (NN model) (NN efficiency)) (PP (IN by) (S (VP (ADVP (RB selectively)) (VBG including) (NP (NP (NNS scores)) (PP (IN from) (NP (NP (JJ different) (VBG training) (NNS steps)) (PP (IN for) (NP (DT any) (JJ evaluated) (NN hyperparameter) (VBN set)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NN efficiency)) (PP (IN of) (NP (PRP$ our) (NN algorithm)))) (PP (IN by) (S (VP (VBG tuning) (NP (NNS hyperparameters)) (PP (IN for) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (NP (JJ deep) (NN reinforcement) (VBG learning) (NNS agents)) (CC and) (NP (JJ convolutional) (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (PRP$ Our) (NN algorithm)) (VP (VBZ outperforms) (NP (DT all) (VBG existing) (NNS baselines)) (PP (IN in) (S (VP (VBG identifying) (NP (JJ optimal) (NNS hyperparameters)) (PP (IN in) (NP (JJ minimal) (NN time))))))) (. .))
