(S (NP (JJ Recent) (NNS studies)) (VP (VBP have) (VP (VBN shown) (SBAR (IN that) (S (NP (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NNP RL) (-RRB- -RRB-)) (NNS models)) (VP (VBP are) (ADJP (JJ vulnerable)) (PP (IN in) (NP (JJ various) (JJ noisy) (NNS scenarios)))))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (NP (DT the) (JJ observed) (NN reward) (NN channel)) (VP (VP (VBZ is) (ADVP (RB often)) (ADJP (JJ subject) (PP (TO to) (NP (VB noise)))) (PP (IN in) (NP (NN practice))) (PRN (-LRB- -LRB-) (INTJ (UH e.g.)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NNS rewards)) (VP (VBP are) (VP (VBN collected) (PP (IN through) (NP (NNS sensors))))))) (-RRB- -RRB-))) (, ,) (CC and) (VP (VBZ is) (ADVP (RB therefore)) (RB not) (ADJP (JJ credible)))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (PP (IN for) (NP (NP (NNS applications)) (PP (JJ such) (IN as) (NP (NNS robotics))))) (, ,) (NP (DT a) (JJ deep) (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NNP DRL) (-RRB- -RRB-)) (NN algorithm)) (VP (MD can) (VP (VB be) (VP (VBN manipulated) (S (VP (TO to) (VP (VB produce) (NP (JJ arbitrary) (NNS errors)) (PP (IN by) (S (VP (VBG receiving) (NP (VBN corrupted) (NNS rewards))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (NP (JJ noisy) (NNP RL) (NNS problems)) (PP (IN with) (NP (JJ perturbed) (NNS rewards))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN approximated) (PP (IN with) (NP (DT a) (NN confusion) (NN matrix)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP develop) (NP (NP (DT a) (JJ robust) (NNP RL) (NN framework)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (S (NP (NNS agents)) (VP (TO to) (VP (VB learn) (PP (IN in) (NP (NP (JJ noisy) (NNS environments)) (SBAR (WHADVP (WRB where)) (S (NP (RB only) (JJ perturbed) (NNS rewards)) (VP (VBP are) (VP (VBN observed))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN solution) (NN framework)) (VP (VP (NNS builds) (PP (IN on) (NP (VBG existing) (NNP RL/DRL) (NN algorithms)))) (CC and) (VP (ADVP (RB firstly)) (VBZ addresses) (NP (DT the) (JJ biased) (JJ noisy) (NN reward) (VBG setting)) (PP (IN without) (NP (NP (DT any) (NNS assumptions)) (PP (IN on) (NP (NP (DT the) (JJ true) (NN distribution)) (PRN (-LRB- -LRB-) (ADVP (JJ e.g.)) (, ,) (NP (NP (JJ zero-mean) (JJ Gaussian) (NN noise)) (SBAR (IN as) (S (VP (VBN made) (PP (IN in) (NP (JJ previous) (NNS works))))))) (-RRB- -RRB-)))))))) (. .))
(S (NP (NP (DT The) (NN core) (NNS ideas)) (PP (IN of) (NP (PRP$ our) (NN solution)))) (VP (VBP include) (S (VP (VP (VBG estimating) (NP (DT a) (JJ reward) (NN confusion) (NN matrix))) (CC and) (VP (VBG defining) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ unbiased) (NN surrogate) (NNS rewards)))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (NP (NP (DT the) (NX (NX (NN convergence)) (CC and) (NX (JJ sample) (NN complexity)))) (PP (IN of) (NP (PRP$ our) (NN approach))))) (. .))
(S (NP (NP (JJ Extensive) (NNS experiments)) (PP (IN on) (NP (JJ different) (NNP DRL) (NNS platforms)))) (VP (VBP show) (SBAR (IN that) (S (NP (NP (JJ trained) (NNS policies)) (VP (VBN based) (PP (IN on) (NP (PRP$ our) (VBN estimated) (JJ surrogate) (NN reward))))) (VP (MD can) (VP (VP (VB achieve) (NP (JJR higher) (VBN expected) (NNS rewards))) (, ,) (CC and) (VP (NN converge) (ADVP (ADVP (RBR faster)) (PP (IN than) (NP (VBG existing) (NNS baselines)))))))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (NP (DT the) (JJ state-of-the-art) (NNP PPO) (NN algorithm)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB obtain) (NP (NP (ADJP (ADJP (CD 84.6) (NN %)) (CC and) (ADJP (CD 80.8) (NN %))) (NNS improvements)) (PP (IN on) (NP (JJ average) (NN score))) (PP (IN for) (NP (CD five) (NNP Atari) (NNS games)))) (, ,) (PP (IN with) (NP (NP (NN error) (NNS rates)) (PP (IN as) (NP (NP (QP (CD 10) (NN %) (CC and) (CD 30) (NN %))) (ADVP (RB respectively))))))))))) (. .))
