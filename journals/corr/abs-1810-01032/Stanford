(S (NP (JJ Recent) (NNS studies)) (VP (VBP have) (VP (VBN shown) (SBAR (IN that) (S (NP (NML (NML (NN reinforcement) (NN learning)) (-LRB- -LRB-) (NML (NN RL)) (-RRB- -RRB-)) (NNS models)) (VP (VBP are) (ADJP (JJ vulnerable) (PP (IN in) (NP (JJ various) (JJ noisy) (NNS scenarios))))))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (NP (DT the) (VBN observed) (NN reward) (NN channel)) (VP (VP (VBZ is) (ADJP (RB often) (JJ subject) (PP (IN to) (NP (NP (NN noise)) (PP (IN in) (NP (NN practice))) (PRN (-LRB- -LRB-) (ADVP (FW e.g.)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NNS rewards)) (VP (VBP are) (VP (VBN collected) (PP (IN through) (NP (NNS sensors))))))) (-RRB- -RRB-)))))) (, ,) (CC and) (VP (VBZ is) (ADVP (RB therefore)) (ADJP (RB not) (JJ credible)))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (PP (IN for) (NP (NP (NNS applications)) (PP (JJ such) (IN as) (NP (NNS robotics))))) (, ,) (NP (DT a) (NML (NML (JJ deep) (NN reinforcement)) (NN learning) (PRN (-LRB- -LRB-) (NP (NN DRL)) (-RRB- -RRB-))) (NN algorithm)) (VP (MD can) (VP (VB be) (VP (VBN manipulated) (S (VP (TO to) (VP (VB produce) (NP (JJ arbitrary) (NNS errors)) (PP (IN by) (S (VP (VBG receiving) (NP (JJ corrupted) (NNS rewards))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP consider) (NP (JJ noisy) (NN RL) (NNS problems)) (PP (IN with) (NP (NP (VBN perturbed) (NNS rewards)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN approximated) (PP (IN with) (NP (DT a) (NN confusion) (NN matrix))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP develop) (NP (NP (DT a) (JJ robust) (NN RL) (NN framework)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (NP (NNS agents)) (S (VP (TO to) (VP (VB learn) (PP (IN in) (NP (JJ noisy) (NNS environments))) (SBAR (WHADVP (WRB where)) (S (NP (ADJP (RB only) (VBN perturbed)) (NNS rewards)) (VP (VBP are) (VP (VBN observed))))))))))))) (. .))
(S (NP (PRP$ Our) (NN solution) (NN framework)) (VP (VP (VBZ builds) (PP (IN on) (NP (VBG existing) (NML (NN RL) (HYPH /) (NN DRL)) (NNS algorithms)))) (CC and) (VP (ADVP (RB firstly)) (VBZ addresses) (NP (DT the) (ADJP (JJ biased) (JJ noisy)) (NN reward) (NN setting)) (PP (IN without) (NP (DT any) (NNS assumptions))) (PP (IN on) (NP (NP (DT the) (JJ true) (NN distribution)) (-LRB- -LRB-) (NP (ADVP (FW e.g.)) (, ,) (NP (NP (NML (CD zero) (HYPH -) (NN mean)) (JJ Gaussian) (NN noise)) (SBAR (IN as) (S (VP (VBN made) (PP (IN in) (NP (JJ previous) (NNS works)))))))) (-RRB- -RRB-))))) (. .))
(S (NP (NP (DT The) (NN core) (NNS ideas)) (PP (IN of) (NP (PRP$ our) (NN solution)))) (VP (VBP include) (S (VP (VP (VBG estimating) (NP (DT a) (NN reward) (NN confusion) (NN matrix))) (CC and) (VP (VBG defining) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ unbiased) (JJ surrogate) (NNS rewards)))))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (NP (NP (DT the) (NN convergence)) (CC and) (NP (NP (NN sample) (NN complexity)) (PP (IN of) (NP (PRP$ our) (NN approach)))))) (. .))
(S (NP (NP (JJ Extensive) (NNS experiments)) (PP (IN on) (NP (JJ different) (NN DRL) (NNS platforms)))) (VP (VP (VBP show) (SBAR (IN that) (S (NP (NP (VBN trained) (NNS policies)) (PP (VBN based) (PP (IN on) (NP (PRP$ our) (VBN estimated) (JJ surrogate) (NN reward))))) (VP (MD can) (VP (VB achieve) (NP (NP (JJR higher)) (VP (VBN expected) (NP (NNS rewards))))))))) (, ,) (CC and) (VP (VBP converge) (NP (JJR faster)) (PP (IN than) (NP (VBG existing) (NNS baselines))))) (. .))
(S (PP (IN For) (NP (NN instance))) (, ,) (NP (DT the) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN PPO) (NN algorithm)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB obtain) (NP (NP (QP (CD 84.6) (NN %) (CC and) (CD 80.8) (NN %)) (NNS improvements)) (PP (IN on) (NP (NP (JJ average) (NN score)) (PP (IN for) (NP (CD five) (NNP Atari) (NNS games))))) (, ,) (PP (IN with) (NP (NN error) (NNS rates)))) (PP (IN as) (NP (QP (CD 10) (NN %) (CC and) (CD 30) (NN %))) (ADVP (RB respectively)))))))) (. .))
