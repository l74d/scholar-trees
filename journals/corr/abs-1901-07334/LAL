(S (NP (JJ Recurrent) (JJ neural) (NNS networks)) (VP (MD can) (VP (VB be) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB train) (PP (IN on) (NP (JJ long) (NN sequence) (NNS data)))))))) (PP (JJ due) (TO to) (NP (DT the) (JJ well-known) (NN vanishing) (NN gradient) (NN problem))))) (. .))
(S (NP (DT Some) (NNS architectures)) (VP (VBP incorporate) (NP (NP (NNS methods)) (SBAR (S (VP (TO to) (VP (VB reduce) (NP (NNP RNN) (NN state) (NNS updates))))))) (, ,) (S (ADVP (RB therefore)) (VP (VBG allowing) (S (NP (DT the) (NN network)) (VP (TO to) (VP (VB preserve) (NP (NN memory)) (PP (IN over) (NP (JJ long) (JJ temporal) (NNS intervals))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (NP (DT these) (NNS problems)) (PP (IN of) (NP (NN convergence))))))) (, ,) (NP (DT this) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (JJ timing-gated) (NNP LSTM) (NNP RNN) (NN model)) (, ,) (VP (VBD called) (S (NP (S (NP (DT the) (JJ Gaussian-gated) (NNP LSTM))) (PRN (-LRB- -LRB-) (NP (NN g-LSTM)) (-RRB- -RRB-))))))) (. .))
(S (NP (DT The) (NN time) (NN gate)) (VP (NNS controls) (SBAR (WHADVP (WRB when)) (S (NP (DT a) (NN neuron)) (VP (MD can) (VP (VB be) (VP (VBN updated) (PP (IN during) (NP (NN training)))))))) (, ,) (S (VP (VBG enabling) (NP (NP (JJR longer) (NN memory) (NN persistence)) (CC and) (NP (JJR better) (NN error-gradient) (NN flow)))))) (. .))
(S (S (NP (DT This) (NN model)) (VP (VBZ captures) (NP (JJ long-temporal) (NNS dependencies)) (ADVP (ADVP (RBR better)) (PP (IN than) (NP (DT an) (NNP LSTM)))))) (CC and) (S (NP (DT the) (NN time) (NN gate) (NNS parameters)) (VP (MD can) (VP (VB be) (VP (VBN learned) (PP (ADVP (RB even)) (IN from) (NP (JJ non-optimal) (NN initialization) (NNS values))))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NN time) (NN gate)) (VP (VBZ limits) (NP (NP (DT the) (NNS updates)) (PP (IN of) (NP (DT the) (NN neuron) (NN state))))))) (, ,) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS computes))) (VP (VBN needed) (PP (IN for) (NP (DT the) (NN network) (NN update))))) (VP (VBZ is) (ADVP (RB also)) (VP (VBN reduced))) (. .))
(S (PP (IN By) (S (VP (VBG adding) (NP (DT a) (JJ computational) (NN budget) (NN term)) (PP (TO to) (NP (DT the) (NN training) (NN loss)))))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB obtain) (NP (NP (DT a) (NN network)) (SBAR (WHNP (WDT which)) (S (VP (ADVP (RB further)) (VBZ reduces) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS computes)))) (PP (IN by) (NP (QP (IN at) (JJS least) (CD 10x)))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (PP (IN by) (S (VP (VBG employing) (NP (NP (DT a) (JJ temporal) (NN curriculum) (NN learning) (NN schedule)) (PP (IN for) (NP (DT the) (JJ g-LSTM))))))) (, ,) (NP (PRP we)) (VP (MD can) (VP (VB reduce) (NP (NP (DT the) (NN convergence) (NN time)) (PP (IN of) (NP (DT the) (NN equivalent) (NNP LSTM) (NN network))) (PP (IN on) (NP (JJ long) (NNS sequences)))))) (. .))
