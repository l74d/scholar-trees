(S (NP (VBG Boosting) (NNS algorithms)) (VP (VBP show) (NP (JJ high) (JJ predictive) (NN accuracy)) (PP (IN on) (NP (NP (DT a) (JJ wide) (NN array)) (PP (IN of) (NP (NNS datasets)))))) (. .))
(S (PP (IN To) (NP (NN date))) (, ,) (NP (NP (DT the) (NN distinction)) (PP (IN between) (S (VP (VBG boosting) (SBAR (IN with) (S (S (NP (CC either) (NP (NN gradient) (NN descent)) (CC or) (NP (NML (JJ second) (HYPH -) (NN order)) (NNS updates))) (VP (VBZ is) (ADVP (RB often)) (RB not) (VP (VBN made)))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBZ is) (ADVP (RB thus)) (ADVP (RB implicitly)))))))))) (VP (VBD assumed) (SBAR (IN that) (S (NP (DT the) (NN difference)) (VP (VBZ is) (ADJP (JJ irrelevant)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN article))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NP (NP (NN gradient)) (CC and) (NP (NNP Newton))) (VP (VBG boosting))) (, ,) (CONJP (RB as) (RB well) (IN as)) (NP (NP (DT a) (NN hybrid) (NN variant)) (PP (IN of) (NP (DT the) (CD two))))) (, ,) (PP (IN in) (NP (DT a) (JJ unified) (NN framework)))) (. .))
(S (NP (PRP We)) (VP (VBP compare) (NP (NP (NNS theses)) (VP (VBG boosting) (NP (NP (NNS algorithms)) (PP (IN with) (NP (NP (NNS trees)) (PP (IN as) (NP (NN base) (NNS learners)))))) (PP (IN on) (NP (NP (DT a) (JJ large) (NN set)) (PP (IN of) (NP (NML (NN regression) (CC and) (NN classification)) (NNS datasets))))) (S (VP (VBG using) (NP (NP (JJ various) (NNS choices)) (PP (IN of) (NP (NN loss) (NNS functions))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NNP Newton)) (VP (VBG boosting))) (VP (VBZ outperforms) (NP (NP (NML (NN gradient) (CC and) (NN hybrid)) (NN gradient) (HYPH -) (NNP Newton)) (VP (VBG boosting) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (JJ predictive) (NN accuracy))))) (PP (IN on) (NP (NP (DT the) (NN majority)) (PP (IN of) (NP (NNS datasets))))))))))) (. .))
(S (ADVP (RB Further)) (, ,) (NP (PRP we)) (VP (VBP present) (NP (JJ empirical) (NN evidence)) (SBAR (SBAR (IN that) (S (NP (NP (DT this) (NN difference)) (PP (IN in) (NP (JJ predictive) (NN accuracy)))) (VP (VBZ is) (RB not) (ADVP (RB primarily)) (PP (IN due) (IN to) (NP (NP (ADVP (RBR faster)) (NP (NN convergence)) (PP (IN of) (NP (NNP Newton)))) (VP (VBG boosting))))))) (, ,) (CONJP (CC but) (RB rather)) (SBAR (IN since) (S (NP (NP (NNP Newton)) (VP (VBG boosting) (ADVP (RB often)))) (VP (VBZ achieves) (NP (JJR lower) (NN test) (NNS errors)) (PP (IN while) (IN at) (NP (NP (DT the) (JJ same) (NN time)) (VP (VBG having) (NP (JJR lower) (NN training) (NNS losses)))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (PRP we)) (VP (VBP introduce) (S (NP (ADJP (NP (NP (DT a) (JJ novel) (NN tuning) (NN parameter)) (PP (IN for) (NP (NN tree)))) (HYPH -) (VBN based)) (NNP Newton)) (VP (VBG boosting) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ interpretable) (CC and) (JJ important)) (PP (IN for) (NP (JJ predictive) (NN accuracy))))))))) (. .))
