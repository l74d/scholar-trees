(S (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (NN imitation) (NN learning)))) (VP (VBZ is) (ADVP (RB typically)) (VP (JJ upper-bounded) (PP (IN by) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (NN demonstrator))))))) (. .))
(S (SBAR (IN While) (S (NP (JJ recent) (JJ empirical) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (VBD ranked) (NNS demonstrations)) (VP (VB allow) (PP (IN for) (NP (JJ better-than-demonstrator) (NN performance))))))))) (, ,) (S (NP (NP (NNS preferences)) (PP (IN over) (NP (NNS demonstrations)))) (VP (MD may) (VP (VB be) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB obtain))))))))) (, ,) (CC and) (S (NP (NP (JJ little))) (VP (VBZ is) (VP (VBN known) (ADVP (RB theoretically)) (PP (IN about) (SBAR (WHADVP (WRB when)) (S (NP (JJ such) (NNS methods)) (VP (MD can) (VP (VB be) (VP (VBN expected) (S (VP (TO to) (VP (ADVP (RB successfully)) (VB extrapolate) (PP (IN beyond) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (NN demonstrator))))))))))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS issues))))) (, ,) (NP (PRP we)) (VP (VP (ADVP (RB first)) (VBP contribute) (NP (NP (DT a) (JJ sufficient) (NN condition)) (PP (IN for) (NP (JJ better-than-demonstrator) (NN imitation) (NN learning))))) (CC and) (VP (VB provide) (NP (NP (JJ theoretical) (NNS results)) (VP (VBG showing) (SBAR (WHADVP (WRB why)) (S (NP (NP (NNS preferences)) (PP (IN over) (NP (NNS demonstrations)))) (VP (MD can) (VP (ADVP (VB better)) (VB reduce) (NP (JJ reward) (NN function) (NN ambiguity)) (SBAR (WHADVP (WRB when)) (S (VP (VBG performing) (NP (JJ inverse) (NN reinforcement) (NN learning))))))))))))) (. .))
(S (S (VP (VBG Building) (PP (IN on) (NP (DT this) (NN theory))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (NP (JJ Disturbance-based) (NNP Reward) (NNP Extrapolation)) (PRN (-LRB- -LRB-) (NP (NNP D-REX)) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (JJ ranking-based) (NN imitation) (VBG learning) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ injects) (NP (RB noise)) (PP (IN into) (NP (NP (DT a) (NN policy)) (VP (VBN learned) (PP (IN through) (NP (JJ behavioral) (NN cloning)))))) (S (VP (TO to) (ADVP (RB automatically)) (VP (VB generate) (NP (JJ ranked) (NNS demonstrations))))))))))) (. .))
(S (NP (DT These) (JJ ranked) (NNS demonstrations)) (VP (VBP are) (VP (VBN used) (S (VP (TO to) (VP (ADVP (RB efficiently)) (VB learn) (NP (NP (DT a) (NN reward) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (ADVP (RB then)) (VP (VB be) (VP (VBN optimized) (S (VP (VBG using) (NP (NN reinforcement) (NN learning))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (ADVP (RB empirically)) (VBP validate) (NP (PRP$ our) (NN approach)) (PP (IN on) (NP (JJ simulated) (NN robot) (CC and) (NNP Atari) (NN imitation) (VBG learning) (NNS benchmarks)))) (CC and) (VP (VB show) (SBAR (IN that) (S (NP (NNP D-REX)) (VP (VP (NNS outperforms) (NP (JJ standard) (NN imitation) (NN learning) (NNS approaches))) (CC and) (VP (MD can) (VP (ADVP (RB significantly)) (VB surpass) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (NN demonstrator))))))))))) (. .))
(S (NP (NNP D-REX)) (VP (VBZ is) (NP (NP (DT the) (JJ first) (NN imitation) (VBG learning) (NN approach)) (SBAR (S (VP (TO to) (VP (VB achieve) (NP (NP (JJ significant) (NN extrapolation)) (PP (IN beyond) (NP (NP (DT the) (NN demonstrator) (POS 's)) (NN performance)))) (PP (IN without) (NP (NP (JJ additional) (NN side-information) (CC or) (NN supervision)) (, ,) (PP (JJ such) (IN as) (NP (NP (NNS rewards)) (CC or) (NP (JJ human) (NNS preferences)))))))))))) (. .))
(S (PP (IN By) (S (VP (VBG generating) (NP (NNS rankings)) (ADVP (RB automatically))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ preference-based) (JJ inverse) (NN reinforcement) (NN learning)) (VP (MD can) (VP (VB be) (VP (VBN applied) (PP (IN in) (NP (NP (JJ traditional) (NN imitation) (NN learning) (NNS settings)) (SBAR (WHADVP (WRB where)) (S (NP (RB only) (JJ unlabeled) (NNS demonstrations)) (VP (VBP are) (ADJP (JJ available))))))))))))) (. .))
