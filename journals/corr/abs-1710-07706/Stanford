(S (NP (NP (ADJP (JJ Similar) (PP (IN to) (NP (NN convolution) (JJ neural) (NNS networks)))) (, ,) (ADJP (JJ recurrent)) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (ADVP (RB typically)) (VP (VBP suffer) (PP (IN from) (NP (NN over-parameterization)))) (. .))
(S (S (VP (VBG Quantizing) (NP (NP (NP (NN bit) (HYPH -) (NNS widths)) (PP (IN of) (NP (NNS weights)))) (CC and) (NP (NP (NNS activations) (NNS results)) (PP (IN in) (NP (NN runtime) (NN efficiency))))) (PP (IN on) (NP (NN hardware))))) (, ,) (CC yet) (S (NP (PRP it)) (ADVP (RB often)) (VP (VBZ comes) (PP (IN at) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (VBN reduced) (NN accuracy))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ proposes) (NP (NP (DT a) (NN quantization) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ increases) (NP (NN model) (NN size)) (PP (IN with) (NP (NN bit) (HYPH -) (NN width) (NN reduction)))))))) (. .))
(S (NP (DT This) (NN approach)) (VP (MD will) (VP (VB allow) (NP (NNS networks)) (S (VP (TO to) (VP (VB perform) (PP (IN at) (NP (PRP$ their) (NN baseline) (NN accuracy))) (SBAR (IN while) (S (ADVP (RB still)) (VP (VBG maintaining) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (NP (NP (VBN reduced) (NN precision)) (CC and) (NP (JJ overall) (NML (NN model) (NN size)) (NN reduction))))))))))))) (. .))
