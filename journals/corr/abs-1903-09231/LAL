(S (S (VP (VBG Giving) (NP (NP (JJ provable) (NNS guarantees)) (PP (IN for) (S (VP (VBG learning) (NP (JJ neural) (NNS networks)))))))) (VP (VBZ is) (NP (NP (DT a) (NN core) (NN challenge)) (PP (IN of) (NP (NN machine) (VBG learning) (NN theory))))) (. .))
(S (S (NP (JJS Most) (JJ prior) (NN work)) (VP (VBZ gives) (NP (JJ parameter) (NN recovery) (NNS guarantees)) (PP (IN for) (NP (CD one) (NN hidden) (NN layer) (NNS networks))))) (, ,) (S (ADVP (RB however)) (, ,) (NP (NP (DT the) (NNS networks)) (VP (VBN used) (PP (IN in) (NP (NN practice))))) (VP (VBP have) (NP (VBN multiple) (JJ non-linear) (NNS layers)))) (. .))
(S (S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (NP (PRP we)) (VP (MD can) (VP (VB strengthen) (NP (JJ such) (NNS results)) (PP (TO to) (NP (VB deeper) (NNS networks))))))))) (: â€”) (S (S (NP (PRP we)) (VP (VBP address) (NP (NP (DT the) (NN problem)) (PP (IN of) (S (VP (VBG uncovering) (NP (NP (DT the) (JJS lowest) (NN layer)) (PP (IN in) (NP (DT a) (JJ deep) (JJ neural) (NN network)))))))) (PP (IN under) (NP (DT the) (NN assumption) (SBAR (IN that) (S (NP (DT the) (JJS lowest) (NN layer)) (VP (VBZ uses) (NP (DT a) (JJ high) (NN threshold)) (PP (IN before) (S (VP (VBG applying) (NP (DT the) (NN activation)))))))))))) (, ,) (S (NP (DT the) (JJ upper) (NN network)) (VP (MD can) (VP (VB be) (VP (VBN modeled) (PP (IN as) (NP (DT a) (JJ well-behaved) (NN polynomial))))))) (CC and) (S (NP (DT the) (NN input) (NN distribution)) (VP (VBZ is) (ADJP (JJ Gaussian))))) (. .))
