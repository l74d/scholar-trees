(S (S (S (VP (VBG Training) (NP (JJ neural) (NNS networks)) (PP (IN with) (NP (JJ many) (NNS processors))))) (VP (MD can) (VP (VB reduce) (NP (NP (NN time)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN solution))))))) (: ;) (S (ADVP (RB however)) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBG challenging) (S (VP (TO to) (VP (VB maintain) (NP (NN convergence) (CC and) (NN efficiency)) (PP (IN at) (NP (JJ large) (NNS scales))))))))) (. .))
(S (NP (DT The) (NML (NML (NML (NNP Kronecker)) (HYPH -) (VP (VBN factored) (NP (JJ Approximate) (NN Curvature)))) (-LRB- -LRB-) (NML (NN K) (HYPH -) (NN FAC)) (-RRB- -RRB-))) (VP (VBD was) (ADVP (RB recently)) (VP (VBN proposed) (PP (IN as) (NP (NP (NP (DT an) (NN approximation)) (PP (IN of) (NP (DT the) (NNP Fisher) (NNP Information) (NNP Matrix)))) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN used) (PP (IN in) (NP (JJ natural) (NN gradient) (NNS optimizers)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP investigate) (NP (NP (RB here) (DT a) (ADJP (JJ scalable)) (NML (NN K) (HYPH -) (NN FAC)) (NN design)) (CC and) (NP (NP (PRP$ its) (NN applicability)) (PP (IN in) (NP (JJ convolutional) (NML (NML (JJ neural) (NN network)) (-LRB- -LRB-) (NML (NP (NNP CNN))) (-RRB- -RRB-)) (NN training))))) (PP (IN at) (NP (NN scale)))) (. .))
(S (NP (PRP We)) (VP (VBP study) (NP (NP (NP (NN optimization) (NNS techniques)) (PP (JJ such) (IN as) (NP (NP (JJ layer-wise) (NN distribution) (NNS strategies)) (, ,) (NP (ADJP (NN inverse) (HYPH -) (JJ free)) (NML (NN second) (HYPH -) (NN order)) (NN gradient) (NN evaluation)) (, ,) (CC and) (NP (JJ dynamic) (NML (NN K) (HYPH -) (NN FAC)) (NN update))))) (VP (VBG decoupling) (S (VP (TO to) (VP (VB reduce) (NP (NN training) (NN time)) (PP (IN while) (S (VP (VBG preserving) (NP (NN convergence))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (SBAR (S (NP (NP (JJ residual) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNP ResNet)) (-RRB- -RRB-)) (VP (VBD applied) (PP (IN to) (NP (DT the) (NML (NML (NN CIFAR) (HYPH -) (CD 10)) (CC and) (NML (NNP ImageNet) (HYPH -) (NNP 1k))) (NNS datasets))) (S (VP (TO to) (VP (VB evaluate) (NP (NP (DT the) (NN correctness) (CC and) (NN scalability)) (PP (IN of) (NP (PRP$ our) (NML (NN K) (HYPH -) (NN FAC)) (NN gradient) (NN preconditioner))))))))))) (. .))
(S (PP (IN With) (NP (NP (NNP ResNet) (HYPH -) (CD 50)) (PP (IN on) (NP (DT the) (NML (NNP ImageNet) (HYPH -) (NNP 1k)) (NN dataset))))) (, ,) (NP (PRP$ our) (VBN distributed) (NML (NN K) (HYPH -) (NN FAC)) (NN implementation)) (VP (VBZ converges) (PP (IN to) (NP (NP (DT the) (NML (CD 75.9) (NN %)) (NN MLPerf) (NN baseline)) (PP (IN in) (NP (ADJP (NP (QP (CD 18) (SYM -) (CD 25)) (NN %)) (JJR less)) (NN time))))) (SBAR (IN than) (S (VP (VBZ does) (NP (DT the) (JJ classic) (JJ stochastic) (NN gradient) (NN descent) (-LRB- -LRB-) (NNP SGD) (-RRB- -RRB-) (NN optimizer)) (PP (IN across) (NP (NP (NNS scales)) (PP (IN on) (NP (DT a) (NN GPU) (NN cluster))))))))) (. .))
