(S (NP (NP (NNP Modern) (JJ convolutional) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNPS ConvNets)) (-RRB- -RRB-))) (VP (VBP achieve) (NP (JJ state-of-the-art) (NN performance)) (PP (IN for) (NP (JJ many) (NN computer) (NN vision) (NNS tasks)))) (. .))
(S (ADVP (RB However)) (, ,) (NP (JJ such) (JJ high) (NN performance)) (VP (VBZ requires) (NP (NP (NP (NNS millions)) (PP (IN of) (NP (NNS parameters)))) (CC and) (NP (JJ high) (NN computational) (NNS costs)))) (. .))
(S (ADVP (RB Recently)) (, ,) (S (VP (VBN inspired) (PP (IN by) (NP (NP (DT the) (JJ iterative) (NN structure)) (PP (IN of) (NP (NP (JJ modern) (NNP ConvNets)) (, ,) (PP (JJ such) (IN as) (NP (NNS ResNets))))))))) (, ,) (NP (NP (NN parameter) (VBG sharing)) (PP (IN among) (NP (JJ repetitive) (NN convolution) (NNS layers)))) (VP (VBZ has) (VP (VBN been) (VP (VBN proposed) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (NNS parameters)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (JJ naive) (NN sharing)) (PP (IN of) (NP (NN convolution) (NNS filters)))) (VP (VBZ poses) (NP (NP (JJ many) (NNS challenges)) (PP (JJ such) (IN as) (S (VP (VP (VBG overfitting)) (CC and) (VBG vanishing/exploding) (NP (NNS gradients))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (NN parameter) (VBG sharing)) (ADVP (RB often)) (VP (VBZ increases) (NP (JJ computational) (NN complexity)) (ADVP (JJ due) (PP (TO to) (NP (JJ additional) (NNS operations))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB exploit) (NP (NP (DT the) (JJ linear) (NN structure)) (PP (IN of) (NP (NN convolution) (NNS filters)))) (PP (IN for) (NP (NP (ADJP (JJ effective) (CC and) (JJ efficient)) (NN sharing)) (PP (IN of) (NP (NNS parameters))) (PP (IN among) (NP (JJ iterative) (NN convolution) (NNS layers))))))))) (. .))
(S (PP (RB Instead) (IN of) (S (VP (VBG sharing) (NP (NP (NN convolution) (NNS filters)) (NP (PRP themselves)))))) (, ,) (NP (PRP we)) (VP (VBP hypothesize) (SBAR (IN that) (S (NP (NP (DT a) (JJ filter) (NN basis)) (PP (IN of) (NP (JJ linearly-decomposed) (NN convolution) (NNS layers)))) (VP (VBZ is) (NP (NP (DT a) (ADJP (RBR more) (JJ effective)) (NN unit)) (PP (IN for) (S (VP (VBG sharing) (NP (NNS parameters)))))) (SBAR (IN since) (S (NP (DT a) (JJ filter) (NN basis)) (VP (VBZ is) (NP (NP (DT an) (ADJP (JJ intrinsic) (CC and) (JJ reusable)) (NN building) (NN block)) (VP (VBG constituting) (NP (JJ diverse) (JJ high) (JJ dimensional) (NN convolution) (NNS filters))))))))))) (. .))
(S (NP (NP (DT The) (NN representation) (NN power) (CC and) (NN peculiarity)) (PP (IN of) (NP (JJ individual) (NN convolution) (NNS layers)))) (VP (VBP are) (VP (ADVP (RB further)) (VBN increased) (PP (IN by) (S (VP (VBG adding) (NP (NP (DT a) (JJ small) (NN number)) (PP (IN of) (NP (JJ layer-specific) (JJ non-shared) (NNS components)))) (PP (TO to) (NP (DT the) (JJ filter) (NN basis)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (ADVP (RB empirically)) (SBAR (IN that) (S (S (VP (VBG enforcing) (NP (NP (NN orthogonality)) (PP (TO to) (NP (VBN shared) (NN filter) (NNS bases)))))) (VP (MD can) (VP (VB mitigate) (NP (NP (DT the) (NN difficulty)) (PP (IN in) (S (VP (VBG training) (NP (JJ shared) (NNS parameters))))))))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (VBZ achieves) (NP (NP (JJ significant) (NNS reductions)) (PP (DT both) (IN in) (NP (NP (NN model) (NNS parameters)) (CC and) (NP (JJ computational) (NNS costs))))) (SBAR (IN while) (S (VP (VBG maintaining) (NP (NP (ADJP (JJ competitive) (, ,) (X (NP (CC and) (ADVP (RB often)) (RBR better))) (, ,)) (NN performance)) (PP (IN than) (NP (JJ non-shared) (NN baseline) (NNS networks))))))))))) (. .))
