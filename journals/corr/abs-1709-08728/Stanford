(S (NP (PRP We)) (VP (VBP study) (NP (NP (JJ stochastic) (NN optimization)) (PP (IN of) (NP (NP (JJ nonconvex) (NN loss) (NNS functions)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (NP (NP (JJ typical) (NNS objectives)) (PP (IN for) (NP (NN training) (JJ neural) (NNS networks))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (JJ stochastic) (NN approximation) (NNS algorithms)) (SBAR (WHNP (WDT which)) (S (VP (VBP optimize) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (VBN regularized) (, ,) (JJ nonlinearized) (NNS losses)))) (PP (IN on) (NP (NP (JJ large) (NNS minibatches)) (PP (IN of) (NP (NNS samples))))) (, ,) (S (VP (VBG using) (NP (NP (RB only) (RB first) (HYPH -) (NN order)) (NP (NN gradient) (NN information)))))))))) (. .))
(S (NP (PRP$ Our) (NNS algorithms)) (ADVP (RB provably)) (VP (VP (VBP converge) (PP (IN to) (NP (NP (DT an) (JJ approximate) (JJ critical) (NN point)) (PP (IN of) (NP (NP (DT the) (VBN expected) (NN objective)) (PP (IN with) (NP (NP (JJR faster) (NNS rates)) (PP (IN than) (NP (NN minibatch) (JJ stochastic) (NN gradient) (NN descent)))))))))) (, ,) (CC and) (VP (VB facilitate) (NP (JJR better) (NN parallelization)) (PP (IN by) (S (VP (VBG allowing) (NP (JJR larger) (NNS minibatches))))))) (. .))
