(S (S (NP (JJ Deep) (NN reinforcement) (NN learning)) (VP (VBZ has) (VP (VBN achieved) (NP (JJ great) (NNS successes)) (PP (IN in) (NP (JJ recent) (NNS years)))))) (, ,) (CC but) (S (NP (EX there)) (VP (VBP are) (ADVP (RB still)) (NP (NP (JJ open) (NNS challenges)) (, ,) (PP (JJ such) (IN as) (NP (NP (NN convergence)) (PP (IN to) (NP (NP (ADJP (RB locally) (JJ optimal)) (NNS policies)) (CC and) (NP (NN sample) (NN inefficiency))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP contribute) (S (NP (NP (NP (DT a) (JJ novel) (ADJP (NN self) (HYPH -) (JJ supervised)) (JJ auxiliary) (NN task)) (, ,) (ADVP (FW i.e.))) (, ,) (NP (NNP Terminal) (NNP Prediction) (-LRB- -LRB-) (NNP TP) (-RRB- -RRB-)) (, ,)) (VP (VBG estimating) (NP (JJ temporal) (NN closeness)) (PP (IN to) (NP (NP (JJ terminal) (NNS states)) (PP (IN for) (NP (JJ episodic) (NNS tasks)))))))) (. .))
(S (NP (DT The) (NN intuition)) (VP (VBZ is) (S (VP (TO to) (VP (VB help) (NP (NN representation) (NN learning)) (PP (IN by) (S (VP (VBG letting) (S (NP (DT the) (NN agent)) (VP (VB predict) (SBAR (WHADJP (WRB how) (JJ close)) (S (NP (PRP it)) (VP (VBZ is) (PP (IN to) (NP (DT a) (JJ terminal) (NN state))) (, ,) (PP (IN while) (S (VP (VBG learning) (NP (PRP$ its) (NN control) (NN policy))))))))))))))))) (. .))
(S (SBAR (IN Although) (S (NP (NNP TP)) (VP (MD could) (VP (VB be) (VP (VBN integrated) (PP (IN with) (NP (JJ multiple) (NNS algorithms)))))))) (, ,) (NP (DT this) (NN paper)) (VP (VBZ focuses) (PP (IN on) (NP (NP (NP (JJ Asynchronous) (NN Advantage)) (NP (NN Actor) (HYPH -) (NN Critic) (PRN (-LRB- -LRB-) (NP (NN A3C)) (-RRB- -RRB-)))) (CC and) (S (VP (VBG demonstrating) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (NP (NNP A3C) (HYPH -) (NNP TP))))))))) (. .))
(S (NP (PRP$ Our) (JJ extensive) (NN evaluation)) (VP (VP (VBZ includes)) (: :) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NP (NNP Atari) (NNS games)) (, ,) (NP (DT the) (NNP BipedalWalker) (NN domain)) (, ,) (CC and) (NP (NP (DT a) (JJ mini) (NN version)) (PP (IN of) (NP (DT the) (ADJP (RB recently) (VBN proposed)) (JJ multi-agent) (JJ Pommerman) (NN game)))))))) (. .))
(S (S (NP (NP (PRP$ Our) (NNS results)) (PP (IN on) (NP (NP (NNP Atari) (NNS games)) (CC and) (NP (DT the) (NNP BipedalWalker) (NN domain))))) (VP (VBP suggest) (SBAR (IN that) (S (NP (NNP A3C) (HYPH -) (NNP TP)) (VP (VBZ outperforms) (NP (JJ standard) (NN A3C)) (PP (IN in) (NP (NP (JJS most)) (PP (IN of) (NP (DT the) (VBN tested) (NNS domains)))))))))) (CC and) (S (PP (IN in) (NP (NNS others))) (NP (PRP it)) (VP (VBZ has) (NP (JJ similar) (NN performance)))) (. .))
(S (PP (IN In) (NP (NNP Pommerman))) (, ,) (NP (PRP$ our) (JJ proposed) (NN method)) (VP (VBZ provides) (NP (JJ significant) (NN improvement)) (PP (CC both) (IN in) (S (VP (VP (VBG learning) (NP (NN efficiency))) (CC and) (VP (VBG converging) (S (VP (TO to) (ADVP (RBR better)) (VP (NP (NNS policies)) (PP (IN against) (NP (JJ different) (NNS opponents))))))))))) (. .))
