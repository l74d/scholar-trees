(S (S (NP (JJ Deep) (NN reinforcement) (NN learning)) (VP (VBZ has) (VP (VBN achieved) (NP (JJ great) (NNS successes)) (PP (IN in) (NP (JJ recent) (NNS years)))))) (, ,) (CC but) (S (NP (EX there)) (VP (VBP are) (ADVP (RB still)) (NP (NP (JJ open) (NNS challenges)) (, ,) (PP (JJ such) (IN as) (NP (NP (NP (NN convergence)) (PP (TO to) (NP (ADJP (RB locally) (JJ optimal)) (NNS policies)))) (CC and) (NP (JJ sample) (NN inefficiency))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP contribute) (NP (NP (DT a) (JJ novel) (JJ self-supervised) (JJ auxiliary) (NN task)) (, ,) (INTJ (FW i.e.)) (, ,) (NP (NP (NP (NNP Terminal) (NNP Prediction)) (PRN (-LRB- -LRB-) (NP (NNP TP)) (-RRB- -RRB-))) (, ,) (VP (VBG estimating) (NP (NP (JJ temporal) (NN closeness)) (PP (TO to) (NP (VB terminal) (NNS states)))) (PP (IN for) (NP (JJ episodic) (NNS tasks))))))) (. .))
(S (NP (DT The) (NN intuition)) (VP (VBZ is) (S (VP (TO to) (VP (VB help) (NP (NN representation) (NN learning)) (PP (IN by) (S (VP (VBG letting) (S (NP (DT the) (NN agent)) (VP (VBP predict) (SBAR (WHADJP (WRB how) (JJ close)) (S (NP (PRP it)) (VP (VBZ is) (PP (TO to) (NP (DT a) (JJ terminal) (NN state)))))) (, ,) (SBAR (IN while) (S (VP (VBG learning) (NP (PRP$ its) (NN control) (NN policy)))))))))))))) (. .))
(S (SBAR (IN Although) (S (NP (NNP TP)) (VP (MD could) (VP (VB be) (VP (VBN integrated) (PP (IN with) (NP (JJ multiple) (NN algorithms)))))))) (, ,) (NP (DT this) (NN paper)) (VP (VBZ focuses) (PP (PP (IN on) (NP (NP (JJ Asynchronous) (NNP Advantage) (NNP Actor-Critic)) (PRN (-LRB- -LRB-) (NP (NNP A3C)) (-RRB- -RRB-)))) (CC and) (VP (VBG demonstrating) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (NP (NNP A3C-TP))))))) (. .))
(S (NP (PRP$ Our) (JJ extensive) (NN evaluation)) (VP (VBZ includes) (: :) (NP (NP (NP (DT a) (NN set)) (PP (IN of) (NP (NNP Atari) (NNS games)))) (, ,) (NP (DT the) (NNP BipedalWalker) (NN domain)) (, ,) (CC and) (NP (NP (DT a) (JJ mini) (NN version)) (PP (IN of) (NP (DT the) (ADJP (RB recently) (VBN proposed)) (JJ multi-agent) (NNP Pommerman) (NN game)))))) (. .))
(S (NP (NP (PRP$ Our) (NNS results)) (PP (IN on) (NP (NP (NNP Atari) (NNS games)) (CC and) (NP (DT the) (NNP BipedalWalker) (NN domain))))) (VP (VBP suggest) (SBAR (IN that) (S (S (NP (NNP A3C-TP)) (VP (NNS outperforms) (NP (JJ standard) (NNP A3C)) (PP (IN in) (NP (NP (JJS most)) (PP (IN of) (NP (DT the) (JJ tested) (NNS domains))))))) (CC and) (S (PP (IN in) (NP (NNS others))) (NP (PRP it)) (VP (VBZ has) (NP (JJ similar) (NN performance))))))) (. .))
(S (PP (IN In) (NP (NNP Pommerman))) (, ,) (NP (PRP$ our) (VBN proposed) (NN method)) (VP (VBZ provides) (NP (JJ significant) (NN improvement)) (PP (DT both) (IN in) (NP (S (VP (VBG learning) (NP (NN efficiency)))) (CC and) (S (VP (VBG converging) (PP (TO to) (NP (NP (JJR better) (NNS policies)) (PP (IN against) (NP (JJ different) (NNS opponents)))))))))) (. .))
