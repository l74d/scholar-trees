(S (NP (JJ Recurrent) (JJ neural) (NNS networks)) (VP (VBP have) (VP (VBN gained) (NP (NP (JJ widespread) (NN use)) (PP (IN in) (S (VP (VBG modeling) (NP (NN sequence) (NNS data)))))) (PP (IN across) (NP (JJ various) (NNS domains))))) (. .))
(S (SBAR (IN While) (S (NP (JJ many) (JJ successful) (NN recurrent) (VBZ architectures)) (VP (VBP employ) (NP (NP (DT a) (NN notion)) (PP (IN of) (NP (NN gating))))))) (, ,) (NP (NP (DT the) (JJ exact) (NN mechanism)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (NP (JJ such) (JJ remarkable) (NN performance)))))) (VP (VBZ is) (RB not) (VP (ADVP (RB well)) (RB understood))) (. .))
(S (NP (PRP We)) (VP (VBP develop) (NP (NP (DT a) (NN theory)) (PP (IN for) (NP (NP (JJ signal) (NN propagation)) (PP (IN in) (NP (NN recurrent) (NNS networks))) (PP (IN after) (NP (JJ random) (NN initialization)))))) (S (VP (VBG using) (NP (NP (DT a) (NN combination)) (PP (IN of) (NP (NP (JJ mean) (NN field) (NN theory)) (CC and) (NP (JJ random) (NN matrix) (NN theory)))))))) (. .))
(S (S (VP (TO To) (VP (VB simplify) (NP (PRP$ our) (NN discussion))))) (, ,) (NP (PRP we)) (VP (VP (VBP introduce) (NP (NP (DT a) (JJ new) (NNP RNN) (NN cell)) (PP (IN with) (NP (DT a) (JJ simple) (NN gating) (NN mechanism))) (SBAR (WHNP (IN that)) (S (NP (PRP we)) (VP (VBP call) (S (NP (DT the) (NN minimalRNN)))))))) (CC and) (VP (VB compare) (NP (PRP it)) (PP (IN with) (NP (NN vanilla) (NNP RNNs))))) (. .))
(S (NP (PRP$ Our) (NN theory)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB define) (NP (NP (DT a) (JJ maximum) (NN timescale)) (SBAR (WHPP (IN over) (WHNP (WDT which))) (S (NP (NNP RNNs)) (VP (MD can) (VP (VB remember) (NP (DT an) (NN input))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this) (NN theory)) (VP (VBZ predicts) (NP (NN trainability)) (PP (IN for) (NP (DT both) (JJ recurrent) (NNS architectures))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (VBD gated) (NN recurrent) (NNS networks)) (VP (VBP feature) (NP (NP (NP (DT a) (ADJP (RB much) (JJR broader)) (, ,) (ADJP (RBR more) (JJ robust)) (, ,) (JJ trainable) (NN region)) (PP (IN than) (NP (NN vanilla) (NNP RNNs)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ corroborates) (NP (JJ recent) (JJ experimental) (NNS findings)))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (DT a) (JJ closed-form) (JJ critical) (NN initialization) (NN scheme)) (SBAR (WHNP (WDT that)) (S (VP (VBZ achieves) (NP (JJ dynamical) (NN isometry)) (PP (IN in) (NP (DT both) (NP (NN vanilla) (NNP RNNs)) (CC and) (NP (NN minimalRNNs))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this)) (VP (NNS results) (PP (IN in) (NP (NP (RB significantly) (NN improvement)) (PP (IN in) (NP (VBG training) (NNS dynamics))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (DT the) (NN minimalRNN)) (VP (VBZ achieves) (NP (NP (JJ comparable) (NN performance)) (PP (TO to) (NP (NP (PRP$ its) (ADJP (JJR more) (JJ complex)) (NNS counterparts)) (, ,) (PP (JJ such) (IN as) (NP (NNP LSTMs) (CC or) (NNP GRUs))) (, ,)))) (PP (IN on) (NP (DT a) (NN language) (VBG modeling) (NN task))))))) (. .))
