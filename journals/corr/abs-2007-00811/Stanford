(S (PP (IN For) (S (VP (VBG deploying) (NP (DT a) (NML (JJ deep) (NN learning)) (NN model)) (PP (IN into) (NP (NN production)))))) (, ,) (NP (PRP it)) (VP (VBZ needs) (S (VP (TO to) (VP (VB be) (ADJP (DT both) (JJ accurate) (CC and) (JJ compact)) (S (VP (TO to) (VP (VB meet) (NP (NP (DT the) (NN latency)) (CC and) (NP (NN memory) (NNS constraints)))))))))) (. .))
(S (NP (DT This)) (ADVP (RB usually)) (VP (VBZ results) (PP (IN in) (NP (DT a) (NN network))) (NP (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (ADJP (JJ deep)) (PRN (-LRB- -LRB-) (S (VP (TO to) (VP (VB ensure) (NP (NN performance))))) (-RRB- -RRB-)) (CC and) (ADJP (RB yet) (JJ thin)))))) (-LRB- -LRB-) (S (VP (TO to) (VP (VB improve) (NP (JJ computational) (NN efficiency))))) (-RRB- -RRB-))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT an) (JJ efficient) (NN method)) (S (VP (TO to) (VP (VB train) (NP (DT a) (JJ deep) (JJ thin) (NN network)) (PP (IN with) (NP (DT a) (JJ theoretic) (NN guarantee))))))) (. .))
(S (NP (PRP$ Our) (NN method)) (VP (VBZ is) (VP (VBN motivated) (PP (IN by) (NP (NN model) (NN compression))))) (. .))
(S (NP (PRP It)) (VP (VBZ consists) (PP (IN of) (NP (CD three) (NNS stages)))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (ADVP (RB sufficiently)) (VP (VP (VBP widen) (NP (DT the) (JJ deep) (JJ thin) (NN network))) (CC and) (VP (VB train) (NP (PRP it)) (PP (IN until) (NP (NN convergence))))) (. .))
(S (ADVP (RB Then)) (, ,) (NP (PRP we)) (VP (VBP use) (NP (NP (DT this) (ADJP (RB well) (HYPH -) (VBN trained)) (JJ deep) (JJ wide) (NN network) (S (VP (TO to) (VP (VB warm) (PRT (RP up))) (-LRB- -LRB-) (CC or) (VP (VB initialize)) (-RRB- -RRB-)))) (NP (DT the) (JJ original) (JJ deep) (JJ thin) (NN network)))) (. .))
(S (S (NP (DT This)) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (NP (NN layerwise) (NN imitation)))))) (, ,) (NP (DT that)) (VP (VBZ is) (, ,) (S (VP (VBG forcing) (NP (DT the) (JJ thin) (NN network)) (S (VP (TO to) (VP (VB mimic) (NP (NP (DT the) (JJ intermediate) (NNS outputs)) (PP (IN of) (NP (NP (DT the) (JJ wide) (NN network)) (PP (IN from) (NP (NN layer)))))) (PP (IN to) (NP (NN layer))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (NP (NP (NP (ADJP (RB further) (JJ fine)) (NN tune)) (NP (NP (DT this)) (ADVP (RB already)))) (VP (RB well) (HYPH -) (VBN initialized) (S (NP (JJ deep) (JJ thin) (NN network))))) (. .))
(S (NP (DT The) (JJ theoretical) (NN guarantee)) (VP (VBZ is) (VP (VBN established) (PP (IN by) (S (VP (VBG using) (NP (DT the) (JJ neural) (JJ mean) (NN field) (NN analysis))))))) (. .))
(S (NP (PRP It)) (VP (VBZ demonstrates) (NP (NP (DT the) (NN advantage)) (PP (IN of) (NP (NP (PRP$ our) (JJ layerwise) (NN imitation) (NN approach)) (PP (IN over) (NP (NN backpropagation))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP conduct) (NP (NML (JJ large) (HYPH -) (NN scale)) (JJ empirical) (NNS experiments)) (S (VP (TO to) (VP (VB validate) (NP (DT the) (JJ proposed) (NN method)))))) (. .))
(S (PP (IN By) (S (VP (VBG training) (PP (IN with) (NP (PRP$ our) (NN method)))))) (, ,) (S (NP (NN ResNet50)) (VP (MD can) (VP (VB outperform) (NP (NN ResNet101))))) (, ,) (CC and) (S (NP (NNP BERT) (NNP Base)) (VP (MD can) (VP (VB be) (ADJP (JJ comparable) (PP (IN with) (NP (NNP BERT) (JJ Large)))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (NN ResNet101)) (CC and) (NP (NNP BERT) (JJ Large))) (VP (VBP are) (VP (VBN trained) (PP (IN under) (NP (DT the) (JJ standard) (NN training) (NNS procedures))) (PP (IN as) (PP (IN in) (NP (DT the) (NN literature))))))))))) (. .))
