(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBD present) (NP (NP (DT a) (JJ deep) (JJ neural) (NN network) (NN topology)) (SBAR (WHNP (WDT that)) (S (VP (VBZ incorporates) (NP (NP (DT a) (ADJP (JJ simple) (S (VP (TO to) (VP (VB implement))))) (NN transformation) (JJ invariant) (NN pooling) (NN operator)) (PRN (-LRB- -LRB-) (NP (NN TI-POOLING)) (-RRB- -RRB-)))))))) (. .))
(S (NP (DT This) (NN operator)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (ADVP (RB efficiently)) (VB handle) (NP (NP (JJ prior) (NN knowledge)) (PP (IN on) (NP (NP (NN nuisance) (NNS variations)) (PP (IN in) (NP (DT the) (NNS data))) (, ,) (PP (JJ such) (IN as) (NP (NP (NN rotation)) (CC or) (NP (NN scale) (NNS changes)))))))))))) (. .))
(S (S (NP (JJS Most) (JJ current) (NNS methods)) (ADVP (RB usually)) (VP (VBP make) (NP (NP (NN use)) (PP (IN of) (NP (NN dataset) (NN augmentation)))) (S (VP (TO to) (VP (VB address) (NP (DT this) (NN issue))))))) (, ,) (CC but) (S (NP (DT this)) (VP (VP (VBZ requires) (NP (NP (NP (JJR larger) (NN number)) (PP (IN of) (NP (NN model) (NNS parameters)))) (CC and) (NP (JJR more) (NN training) (NNS data)))) (, ,) (CC and) (VP (NNS results) (PP (IN in) (NP (NP (ADJP (RB significantly) (VBN increased)) (NN training) (NN time)) (CC and) (NP (NP (JJR larger) (NN chance)) (PP (IN of) (NP (JJ under-) (CC or) (VBG overfitting))))))))) (. .))
(S (NP (NP (DT The) (JJ main) (NN reason)) (PP (IN for) (NP (DT these) (NNS drawbacks)))) (VP (VBZ is) (SBAR (IN that) (S (NP (DT the) (JJ learned) (NN model)) (VP (NNS needs) (S (VP (TO to) (VP (VB capture) (NP (NP (JJ adequate) (NNS features)) (PP (IN for) (NP (NP (PDT all) (DT the) (JJ possible) (NNS transformations)) (PP (IN of) (NP (DT the) (NN input))))))))))))) (. .))
(S (PP (IN On) (NP (DT the) (JJ other) (NN hand))) (, ,) (NP (PRP we)) (VP (VBP formulate) (NP (NP (NNS features)) (PP (IN in) (NP (JJ convolutional) (JJ neural) (NNS networks)))) (S (VP (TO to) (VP (VB be) (ADJP (JJ transformation-invariant)))))) (. .))
(S (NP (PRP We)) (VP (VBP achieve) (NP (IN that)) (S (VP (VP (VBG using) (NP (JJ parallel) (JJ siamese) (NNS architectures)) (PP (IN for) (NP (X (NP (DT the) (VBN considered) (NN transformation))) (VBN set)))) (CC and) (VP (VBG applying) (NP (DT the) (NN TI-POOLING) (NN operator)) (PP (IN on) (NP (PRP$ their) (NNS outputs))) (PP (IN before) (NP (DT the) (JJ fully-connected) (NNS layers))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT this) (NN topology)) (VP (VP (ADVP (RB internally)) (VBZ finds) (NP (NP (DT the) (ADJP (RBS most) (JJ optimal)) (`` ``) (JJ canonical) ('' '') (NN instance)) (PP (IN of) (NP (DT the) (NN input) (NN image))) (PP (IN for) (NP (NN training))))) (CC and) (ADVP (RB therefore)) (VP (VBZ limits) (NP (NP (DT the) (NN redundancy)) (PP (IN in) (NP (JJ learned) (NNS features))))))))) (. .))
(S (NP (NP (DT This) (ADJP (RBR more) (JJ efficient)) (NN use)) (PP (IN of) (NP (VBG training) (NNS data)))) (VP (NNS results) (PP (IN in) (NP (NP (JJR better) (NN performance)) (PP (IN on) (NP (NP (JJ popular) (NN benchmark) (NNS datasets)) (PP (IN with) (NP (NP (JJR smaller) (NN number)) (PP (IN of) (NP (NNS parameters))))))))) (SBAR (WHADVP (WRB when)) (S (VP (VBG comparing) (PP (PP (TO to) (NP (NP (VB standard) (JJ convolutional) (JJ neural) (NNS networks)) (PP (IN with) (NP (JJ dataset) (NN augmentation))))) (CC and) (PP (TO to) (NP (JJ other) (NNS baselines)))))))) (. .))
