(S (NP (DT The) (NN ability) (S (VP (TO to) (VP (VB discover) (NP (RB approximately) (JJ optimal) (NNS policies)) (PP (IN in) (NP (NP (NNS domains)) (PP (IN with) (NP (JJ sparse) (NNS rewards))))))))) (VP (VBZ is) (ADJP (JJ crucial) (PP (IN to) (S (VP (VBG applying) (NP (NP (NN reinforcement) (NN learning) (PRN (-LRB- -LRB-) (NP (NN RL)) (-RRB- -RRB-))) (PP (IN in) (NP (JJ many) (NML (JJ real) (HYPH -) (NN world)) (NNS scenarios))))))))) (. .))
(S (NP (NP (NNS Approaches)) (PP (JJ such) (IN as) (NP (NP (JJ neural) (NN density) (NNS models)) (CC and) (NP (JJ continuous) (NN exploration)))) (PRN (-LRB- -LRB-) (S (ADVP (FW e.g.)) (, ,) (VP (VB Go) (HYPH -) (VB Explore))) (-RRB- -RRB-))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (S (VP (TO to) (VP (VB maintain) (S (NP (DT the) (NML (JJ high) (NN exploration)) (NN rate)) (ADJP (JJ necessary) (S (VP (TO to) (VP (VB find) (NP (JJ high) (ADJP (VBG performing) (CC and) (JJ generalizable)) (NNS policies))))))))))))) (. .))
(S (NP (NP (JJ Soft) (NN actor) (HYPH -) (NN critic)) (-LRB- -LRB-) (NP (NN SAC)) (-RRB- -RRB-)) (VP (VBZ is) (NP (NP (DT another) (NN method)) (PP (IN for) (S (VP (VBG improving) (NP (NP (NN exploration)) (SBAR (WHNP (WDT that)) (S (VP (VBZ aims) (S (VP (TO to) (VP (VB combine) (NP (NP (JJ efficient) (NN learning)) (PP (IN via) (NP (ADJP (IN off) (HYPH -) (NN policy)) (NNS updates)))) (PP (IN while) (S (VP (VBG maximizing) (NP (DT the) (NN policy) (NN entropy))))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VP (VBP extend) (NP (NN SAC)) (PP (IN to) (NP (NP (DT a) (JJR richer) (NN class)) (PP (IN of) (NP (NN probability) (NNS distributions) (PRN (-LRB- -LRB-) (FRAG (ADVP (FW e.g.)) (, ,) (ADJP (JJ multimodal))) (-RRB- -RRB-)))))) (PP (IN through) (S (VP (VBG normalizing) (NP (NNS flows)) (PRN (-LRB- -LRB-) (NP (NN NF)) (-RRB- -RRB-)))))) (CC and) (VP (VB show) (SBAR (IN that) (S (NP (DT this)) (ADVP (RB significantly)) (VP (VBZ improves) (NP (NN performance)) (PP (IN by) (S (VP (VBG accelerating) (NP (NP (DT the) (NN discovery)) (PP (IN of) (NP (JJ good) (NNS policies)))) (PP (IN while) (S (VP (VBG using) (NP (ADJP (RB much) (JJR smaller)) (NN policy) (NNS representations))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NN approach)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP call) (NP (NN SAC) (HYPH -) (NN NF))))) (, ,)) (VP (VBZ is) (NP (DT a) (JJ simple) (, ,) (ADJP (JJ efficient,easy) (HYPH -) (S (VP (TO to) (HYPH -) (VP (VB implement) (NP (NN modification) (CC and) (NN improvement)) (PP (IN to) (NP (NNP SAC))) (PP (IN on) (NP (NP (JJ continuous) (NN control) (NNS baselines)) (PP (JJ such) (IN as) (NP (NP (NNP MuJoCo)) (CC and) (NP (NNP PyBullet) (NNP Roboschool)))))))))) (NNS domains))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (NN SAC) (HYPH -) (NN NF)) (VP (VBZ does) (NP (DT this)) (SBAR (IN while) (S (S (VP (VBG being) (ADJP (RB significantly) (NN parameter) (JJ efficient)))) (, ,) (S (VP (VBG using) (NP (NP (QP (IN as) (JJ few) (IN as) (CD 5.5) (NN %)) (DT the) (NNS parameters)) (PP (IN for) (NP (DT an) (JJ equivalent) (NN SAC) (NN model))))))))) (. .))
