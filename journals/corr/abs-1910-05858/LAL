(S (NP (NP (JJ Gaussian) (NNP Processes)) (PRN (-LRB- -LRB-) (NP (NNP GPs)) (-RRB- -RRB-)) (PP (IN with) (NP (DT an) (JJ appropriate) (NNS kernel)))) (VP (VBP are) (VP (VBN known) (S (VP (TO to) (VP (VB provide) (NP (NP (JJ accurate) (NNS predictions)) (CC and) (NP (NN uncertainty) (NNS estimates))) (PP (ADVP (RB even)) (IN with) (NP (NP (ADJP (RB very) (JJ small)) (NNS amounts)) (PP (IN of) (NP (VBN labeled) (NNS data)))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NNP GPs)) (VP (VBP are) (ADVP (RB generally)) (ADJP (JJ unable) (S (VP (TO to) (VP (VB learn) (NP (NP (DT a) (JJ good) (NN representation)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB encode) (NP (JJ intricate) (NNS structures)) (PP (IN in) (NP (ADJP (JJ high) (JJ dimensional)) (NNS data))))))))))))) (. .))
(S (NP (NP (DT The) (NN representation) (NN power)) (PP (IN of) (NP (NNP GPs)))) (VP (VBZ depends) (ADVP (RB heavily)) (PP (IN on) (NP (NP (NNS kernel) (NNS functions)) (VP (VBD used) (S (VP (TO to) (VP (VB quantify) (NP (NP (DT the) (NN similarity)) (PP (IN between) (NP (NNS data) (NNS points))))))))))) (. .))
(S (NP (JJ Traditional) (NNP GP) (NNS kernels)) (VP (VBP are) (RB not) (ADJP (RB very) (JJ effective) (PP (IN at) (S (VP (VBG capturing) (NP (NP (NN similarity)) (PP (IN between) (NP (ADJP (JJ high) (JJ dimensional)) (NN data) (NNS points)))))))) (, ,) (SBAR (IN while) (S (NP (NP (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (JJ deep) (JJ neural) (NNS networks)) (S (VP (TO to) (VP (VB learn) (NP (DT a) (NNS kernel))))))))) (VP (VBP are) (RB not) (ADJP (JJ sample-efficient)))))) (. .))
(S (S (VP (TO To) (VP (VB overcome) (NP (DT these) (NNS drawbacks))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (JJ deep) (NN probabilistic) (NNS kernels)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBP use) (NP (DT a) (JJ probabilistic) (JJ neural) (NN network)) (S (VP (TO to) (VP (VB map) (NP (JJ high-dimensional) (NNS data)) (PP (TO to) (NP (NP (DT a) (NN probability) (NN distribution)) (PP (IN in) (NP (DT a) (ADJP (JJ low) (JJ dimensional)) (NN subspace))))))))) (, ,) (CC and) (VP (VB leverage) (NP (NP (DT the) (JJ rich) (NN work)) (PP (IN on) (NP (NNS kernels))) (PP (IN between) (NP (NNS distributions)))) (S (VP (TO to) (VP (VB capture) (NP (NP (DT the) (NN similarity)) (PP (IN between) (NP (DT these) (NNS distributions))))))))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS datasets)))))) (VP (VBP show) (SBAR (IN that) (S (S (VP (VBG building) (NP (DT a) (NNP GP)) (S (VP (VBG using) (NP (DT this) (NN covariance) (NN kernel)))))) (VP (VBZ solves) (NP (NP (DT the) (VBG conflicting) (NNS problems)) (PP (IN of) (NP (NP (NN representation) (NN learning)) (CC and) (NP (JJ sample) (NN efficiency))))))))) (. .))
(S (NP (PRP$ Our) (NN model)) (VP (MD can) (VP (VB be) (VP (VBN extended) (PP (IN beyond) (NP (NNP GPs))) (PP (TO to) (NP (NP (JJ other) (JJ small-data) (NNS paradigms)) (PP (JJ such) (IN as) (NP (NP (JJ few-shot) (NN classification)) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP show) (NP (NP (JJ competitive) (NN performance)) (PP (IN with) (NP (JJ state-of-the-art) (NNS models))) (PP (IN on) (NP (DT the) (JJ mini-Imagenet) (NN dataset)))))))))))))) (. .))
