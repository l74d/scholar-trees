(S (NP (PRP We)) (VP (VBP study) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NN mini-batching)))) (PP (IN on) (NP (NP (DT the) (NN loss) (NN landscape)) (PP (IN of) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (VP (VBG using) (NP (ADJP (NP (NP (JJ spiked)) (, ,) (NP (NN field))) (HYPH -) (JJ dependent)) (NML (JJ random) (NN matrix)) (NN theory)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN magnitude)) (PP (IN of) (NP (NP (DT the) (JJ extremal) (NNS values)) (PP (IN of) (NP (DT the) (NN batch) (JJ Hessian)))))) (VP (VBP are) (ADJP (ADJP (JJR larger)) (PP (IN than) (NP (NP (DT those)) (PP (IN of) (NP (DT the) (JJ empirical) (JJ Hessian)))))))))) (. .))
(S (NP (PRP$ Our) (NN framework)) (VP (VBZ yields) (NP (NP (DT an) (JJ analytical) (NN expression)) (PP (IN for) (NP (NP (DT the) (JJ maximal) (NNP SGD) (NN learning) (NN rate)) (PP (IN as) (NP (NP (DT a) (NN function)) (PP (IN of) (NP (NN batch) (NN size)))))))) (, ,) (S (VP (VBG informing) (NP (JJ practical) (NN optimisation) (NNS schemes))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (NP (DT this) (NN framework) (S (VP (TO to) (VP (VB demonstrate) (SBAR (IN that) (S (VP (VBN accepted)))))))) (CC and) (NP (ADJP (RB empirically) (HYPH -) (VBN proven)) (NNS schemes))) (PP (IN for) (S (VP (VBG adapting) (S (NP (DT the) (NN learning) (NN rate)) (VP (VB emerge) (PP (IN as) (NP (NP (JJ special) (NNS cases)) (PP (IN of) (NP (PRP$ our) (ADJP (JJR more) (JJ general)) (NN framework))))))))))) (. .))
(S (PP (IN For) (NP (NP (JJ stochastic) (JJ second) (NN order) (NNS methods)) (CC and) (NP (JJ adaptive) (NNS methods)))) (, ,) (NP (PRP we)) (VP (VBP derive) (SBAR (IN that) (S (NP (DT the) (ADJP (JJ minimal) (VBG damping)) (NN coefficient)) (VP (VBZ is) (ADJP (JJ proportional) (PP (IN to) (NP (NP (DT the) (NN ratio)) (PP (IN of) (NP (DT the) (NN learning) (NN rate)))))) (PP (IN to) (NP (NN batch) (NN size))))))) (. .))
(S (PP (IN For) (NP (JJ adaptive) (NNS methods))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (IN for) (S (NP (NP (DT the) (JJ typical) (NN setup)) (PP (IN of) (NP (NP (NML (JJ small) (NN learning)) (NML (ADJP (NP (NN rate) (CC and) (JJ small)) (VBG damping)) (, ,) (NML (JJ square) (NN root)) (NN learning)) (NN rate) (NNS scalings)) (PP (IN with) (S (VP (VBG increasing) (NP (NN batch) (HYPH -) (NN size)))))))) (VP (MD should) (VP (VB be) (VP (VBN employed))))))) (. .))
(S (NP (PRP We)) (VP (VBP validate) (NP (PRP$ our) (NNS claims)) (PP (IN on) (NP (NP (DT the) (NML (NN VGG) (HYPH /) (NN WideResNet)) (NNS architectures)) (PP (IN on) (NP (NP (DT the) (NN CIFAR)) (: -) (NP (NML ($ $) (CD 100)) (NML (NML ($ $)) (CC and) (NML (NNP ImageNet))) (NNS datasets))))))) (. .))
