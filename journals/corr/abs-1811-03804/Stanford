(S (NP (NN Gradient) (NN descent)) (VP (VBZ finds) (NP (NP (DT a) (JJ global) (NN minimum)) (PP (IN in) (NP (NN training) (JJ deep) (JJ neural) (NNS networks)))) (PP (IN despite) (NP (NP (DT the) (JJ objective) (NN function)) (VP (VBG being) (ADJP (JJ non-convex)))))) (. .))
(S (NP (DT The) (JJ current) (NN paper)) (VP (VBZ proves) (SBAR (S (NP (NN gradient) (NN descent)) (VP (VBZ achieves) (NP (NP (NML (CD zero) (NN training)) (NN loss)) (PP (IN in) (NP (NP (JJ polynomial) (NN time)) (PP (IN for) (NP (NP (DT a) (JJ deep) (JJ over-parameterized) (JJ neural) (NN network)) (PP (IN with) (NP (JJ residual) (NNS connections)))))))) (PRN (-LRB- -LRB-) (NP (NNP ResNet)) (-RRB- -RRB-)))))) (. .))
(S (NP (PRP$ Our) (NN analysis)) (VP (VBZ relies) (PP (IN on) (NP (NP (DT the) (JJ particular) (NN structure)) (PP (IN of) (NP (NP (DT the) (NNP Gram) (NN matrix)) (VP (VBN induced) (PP (IN by) (NP (DT the) (JJ neural) (NN network) (NN architecture))))))))) (. .))
(S (S (NP (DT This) (NN structure)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB show) (SBAR (S (NP (DT the) (NNP Gram) (NN matrix)) (VP (VBZ is) (ADJP (JJ stable) (PP (IN throughout) (NP (DT the) (NN training) (NN process)))))))))))) (CC and) (S (NP (DT this) (NN stability)) (VP (VBZ implies) (NP (NP (DT the) (JJ global) (NN optimality)) (PP (IN of) (NP (DT the) (NN gradient) (NN descent) (NN algorithm)))))) (. .))
(S (NP (PRP We)) (ADVP (RB further)) (VP (VP (VBP extend) (NP (PRP$ our) (NN analysis)) (PP (IN to) (NP (JJ deep) (JJ residual) (JJ convolutional) (JJ neural) (NNS networks)))) (CC and) (VP (VB obtain) (NP (DT a) (JJ similar) (NN convergence) (NN result)))) (. .))
