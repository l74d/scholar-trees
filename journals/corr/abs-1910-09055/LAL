(S (NP (NNP Image) (NN classification) (NNS problems)) (VP (VBP are) (ADVP (RB typically)) (VP (VBN addressed) (PP (IN by) (S (VP (VP (ADVP (JJ first)) (VBG collecting) (NP (NP (NNS examples)) (PP (IN with) (NP (NN candidate) (NNS labels))))) (, ,) (VP (ADVP (JJ second)) (VBG cleaning) (NP (DT the) (NN candidate) (NNS labels)) (ADVP (RB manually))) (, ,) (CC and) (VP (ADVP (JJ third)) (VBG training) (NP (DT a) (JJ deep) (JJ neural) (NN network)) (PP (IN on) (NP (DT the) (JJ clean) (NNS examples))))))))) (. .))
(S (NP (DT The) (JJ manual) (JJ labeling) (NN step)) (VP (VBZ is) (ADVP (RB often)) (NP (DT the) (ADJP (RBS most) (JJ expensive)) (CD one)) (SBAR (IN as) (S (NP (PRP it)) (VP (VBZ requires) (S (NP (NNS workers)) (VP (TO to) (VP (VB label) (NP (NP (NNS millions)) (PP (IN of) (NP (NNS images))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB work) (PP (IN without) (NP (DT any) (ADJP (RB explicitly) (VBN labeled)) (NNS data))) (PP (IN by) (S (VP (VP (NN i) (-RRB- -RRB-) (VP (ADVP (RB directly)) (VBG training) (NP (DT the) (JJ deep) (JJ neural) (NN network)) (PP (IN on) (NP (DT the) (JJ noisy) (NN candidate) (NNS labels))))) (, ,) (CC and) (VP (NN ii) (-RRB- -RRB-) (VP (ADVP (RB early)) (VBG stopping) (NP (DT the) (NN training)) (S (VP (TO to) (VP (VB avoid) (NP (NN overfitting)))))))))))))) (. .))
(S (PP (IN With) (NP (DT this) (NN procedure))) (NP (PRP we)) (VP (VBP exploit) (NP (NP (NP (DT an) (JJ intriguing) (NN property)) (PP (IN of) (NP (NP (JJ standard) (VBN overparameterized) (JJ convolutional) (JJ neural) (NNS networks)) (VP (VBN trained) (PP (IN with) (NP (PRN (-LRB- -LRB-) (JJ stochastic) (-RRB- -RRB-)) (JJ gradient) (NN descent))))))) (: :) (S (NP (JJ Clean) (NNS labels)) (VP (VBP are) (VP (VBN fitted) (ADVP (ADVP (RBR faster)) (PP (IN than) (NP (JJ noisy) (NNS ones))))))))) (. .))
(S (NP (PRP We)) (VP (VBP consider) (NP (NP (CD two) (NN classification) (NNS problems)) (, ,) (NP (NP (DT a) (NN subset)) (PP (IN of) (NP (NP (NNP ImageNet)) (CC and) (NP (NNP CIFAR-10))))))) (. .))
(S (PP (IN For) (NP (DT both))) (, ,) (NP (PRP we)) (VP (VBP construct) (NP (NP (JJ large) (NN candidate) (NNS datasets)) (PP (IN without) (NP (DT any) (JJ explicit) (JJ human) (NNS annotations))) (, ,) (SBAR (WHNP (IN that)) (S (ADVP (RB only)) (VP (VB contain) (NP (NP (QP (CD 10) (NN %) (CD -50) (NN %)) (ADJP (RB correctly) (VBD labeled)) (NNS examples)) (PP (IN per) (NP (NN class))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (S (VP (VP (VBG training) (PP (IN on) (NP (DT the) (NN candidate) (NNS examples)))) (CC and) (VP (VBG regularizing) (PP (IN through) (NP (JJ early) (NN stopping)))))) (VP (VBZ gives) (NP (NP (JJR higher) (NN test) (NN performance)) (PP (IN for) (NP (DT both) (NNS problems))) (PP (IN than) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (PP (IN on) (NP (DT the) (JJ original) (, ,) (JJ clean) (NNS data)))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ is) (ADJP (JJ possible)) (SBAR (SBAR (IN because) (S (NP (DT the) (NN candidate) (NNS datasets)) (VP (VBP contain) (NP (NP (DT a) (JJ huge) (NN number)) (PP (IN of) (NP (JJ clean) (NNS examples))))))) (, ,) (CC and) (, ,) (S (SBAR (IN as) (S (NP (PRP we)) (VP (VBP show) (PP (IN in) (NP (DT this) (NN paper)))))) (, ,) (NP (NP (DT the) (NN noise)) (VP (VBN generated) (PP (IN through) (NP (DT the) (JJ label) (NN collection) (NN process))))) (VP (VBZ is) (ADJP (RB not) (RB nearly) (IN as) (JJ adversarial) (PP (IN for) (NP (VBG learning))) (PP (IN as) (NP (NP (DT the) (NN noise)) (VP (VBN generated) (PP (IN by) (S (VP (ADVP (RB randomly)) (VBG flipping) (NP (NNS labels))))))))))))) (. .))
