(S (PP (JJ Due) (TO to) (NP (PRP$ their) (NX (NX (VBG growing) (NN popularity)) (CC and) (NX (JJ computational) (NN cost))))) (, ,) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP DNNs)) (-RRB- -RRB-))) (VP (VBP are) (VP (VBG being) (VP (VBN targeted) (PP (IN for) (NP (NN hardware) (NN acceleration)))))) (. .))
(S (NP (NP (DT A) (JJ popular) (NN architecture)) (PP (IN for) (NP (NNP DNN) (NN acceleration))) (, ,) (VP (VBN adopted) (PP (IN by) (NP (NP (DT the) (NNP Google) (NNP Tensor) (NNP Processing) (NNP Unit)) (PRN (-LRB- -LRB-) (NP (NNP TPU)) (-RRB- -RRB-))))) (, ,)) (VP (VBZ utilizes) (NP (DT a) (JJ systolic) (ADJP (NN array) (VBN based)) (JJ matrix) (NN multiplication) (NN unit)) (PP (IN at) (NP (PRP$ its) (NN core)))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ deals) (PP (IN with) (NP (NP (DT the) (NN design)) (PP (IN of) (NP (JJ fault-tolerant) (, ,) (JJ systolic) (NN array) (VBN based) (NNP DNN) (NNS accelerators))) (PP (IN for) (NP (JJ high) (NN defect) (NN rate) (NNS technologies)))))) (. .))
(S (S (NP (DT The) (NNP FAP+T)) (VP (VBZ does) (VP (VB introduce) (NP (NP (DT a) (JJ one-time) (NN retraining) (NN penalty)) (PP (IN per) (NP (NNP TPU) (NN chip)))) (SBAR (IN before) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN deployed)))))))) (, ,) (CC but) (S (NP (PRP we)) (VP (VBP propose) (NP (NP (NNS optimizations)) (SBAR (WHNP (WDT that)) (S (VP (VB reduce) (NP (DT this) (JJ one-time) (NN penalty)) (PP (TO to) (NP (QP (IN under) (CD 12)) (NNS minutes))))))))) (. .))
(S (NP (DT The) (NN penalty)) (VP (VBZ is) (ADVP (RB then)) (VP (VBN amortized) (PP (IN over) (NP (NP (DT the) (JJ entire) (NN lifetime)) (PP (IN of) (NP (NP (DT the) (NNP TPU) (POS 's)) (NN operation))))))) (. .))
