(S (NP (NP (JJ Effective) (NN regularisation)) (PP (IN during) (NP (NN training)))) (VP (MD can) (VP (VB mean) (NP (NP (DT the) (NN difference)) (PP (IN between) (NP (NN success) (CC and) (NN failure)))) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks))))) (. .))
(S (ADVP (RB Recently)) (, ,) (NP (NN dither)) (VP (VBZ has) (VP (VBN been) (VP (VBN suggested) (PP (IN as) (NP (NN alternative))) (PP (IN to) (NP (NP (NN dropout)) (PP (IN for) (NP (NN regularisation))))) (PP (IN during) (NP (ADJP (NP (NN batch)) (HYPH -) (VBN averaged)) (JJ stochastic) (NN gradient) (NN descent))) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))))) (. .))
(S (PP (IN In) (NP (DT this) (NN article))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (S (NP (DT these) (NNS methods)) (VP (VBP fail) (PP (IN without) (NP (NN batch) (NN averaging))))) (CC and) (S (NP (PRP we)) (VP (VBP introduce) (NP (NP (DT a) (JJ new) (, ,) (JJ parallel) (NN regularisation) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (MD may) (VP (VB be) (VP (VBN used) (PP (IN without) (NP (NN batch) (NN averaging)))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS results)) (PP (IN for) (NP (NP (ADJP (JJ parallel) (HYPH -))) (VP (VBN regularised) (S (ADJP (JJ non-batch-SGD))))))) (VP (VBP are) (ADJP (ADJP (RB substantially) (JJR better)) (PP (IN than) (SBAR (WHNP (WP what)) (S (VP (VBZ is) (ADJP (JJ possible) (PP (IN with) (NP (NN batch) (HYPH -) (NN SGD)))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP$ our) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NN dither) (CC and) (NN dropout)) (VP (VBP are) (ADJP (JJ complimentary)))))) (. .))
