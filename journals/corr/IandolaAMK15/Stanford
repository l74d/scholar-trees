(S (NP (NP (NML (JJ Long) (NN training)) (NNS times)) (PP (IN for) (NP (NML (JJ high) (HYPH -) (NN accuracy)) (JJ deep) (JJ neural) (NNS networks) (PRN (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-))))) (VP (VP (VBP impede) (NP (NN research)) (PP (IN into) (NP (JJ new) (NNP DNN) (NNS architectures)))) (CC and) (VP (VB slow) (NP (NP (DT the) (NN development)) (PP (IN of) (NP (NML (JJ high) (HYPH -) (NN accuracy)) (NNS DNNs)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP present) (NP (NP (NNP FireCaffe)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB successfully)) (VP (VBZ scales) (NP (NP (JJ deep) (JJ neural) (NN network) (NN training)) (PP (IN across) (NP (NP (DT a) (NN cluster)) (PP (IN of) (NP (NNS GPUs))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP present) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (JJS best) (NNS practices)))) (S (VP (TO to) (VP (VB aid) (PP (IN in) (S (VP (VP (VBG comparing) (NP (NNS advancements)) (PP (IN in) (NP (NP (NNS methods)) (PP (IN for) (NP (NN scaling)))))) (CC and) (VP (VBG accelerating) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))))))))))) (. .))
(S (S (NP (NP (DT The) (NN speed) (CC and) (NN scalability)) (PP (IN of) (NP (VBN distributed) (NNS algorithms)))) (VP (VBZ is) (ADVP (RB almost)) (ADVP (RB always)) (VP (VBN limited) (PP (IN by) (NP (NP (DT the) (NN overhead)) (PP (IN of) (S (VP (VBG communicating) (PP (IN between) (NP (NNS servers))))))))))) (: ;) (S (NP (NN DNN) (NN training)) (VP (VBZ is) (RB not) (NP (NP (DT an) (NN exception)) (PP (IN to) (NP (DT this) (NN rule)))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (DT the) (JJ key) (NN consideration)) (ADVP (RB here)) (VP (VBZ is) (S (VP (TO to) (VP (VB reduce) (NP (NN communication) (NN overhead)) (SBAR (WHADVP (WRB wherever)) (FRAG (ADJP (JJ possible)))) (, ,) (PP (IN while) (NP (NP (NP (RB not) (JJ degrading)) (NP (NP (DT the) (NN accuracy)) (PP (IN of) (NP (DT the) (NN DNN) (NNS models))))) (SBAR (WHNP (WDT that)) (S (NP (PRP we)) (VP (VBP train)))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ has) (NP (CD three) (JJ key) (NNS pillars))) (. .))
(S (S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP select) (NP (NP (NN network) (NN hardware)) (SBAR (WHNP (WDT that)) (S (VP (VBZ achieves) (NP (NP (JJ high) (NN bandwidth)) (PP (IN between) (NP (NNP GPU) (NNS servers)))))))))) (: --) (S (NP (NML (NNP Infiniband) (CC or) (NNP Cray)) (NNS interconnects)) (VP (VBP are) (ADJP (JJ ideal) (PP (IN for) (NP (DT this)))))) (. .))
(S (ADVP (RB Second)) (, ,) (S (NP (PRP we)) (VP (VBP consider) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (NN communication) (NNS algorithms)))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (NN reduction) (NNS trees)) (VP (VBP are) (ADJP (RBR more) (JJ efficient) (CC and) (JJ scalable)) (PP (IN than) (NP (DT the) (JJ traditional) (NN parameter) (NN server) (NN approach)))))))) (. .))
(S (ADVP (JJ Third)) (, ,) (S (NP (PRP we)) (ADVP (RB optionally)) (VP (VB increase) (NP (DT the) (NN batch) (NN size)) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (JJ total) (NN quantity)) (PP (IN of) (NP (NN communication)))) (PP (IN during) (NP (NN DNN) (NN training)))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP identify) (NP (NP (NNS hyperparameters)) (SBAR (WHNP (WDT that)) (S (VP (VBP allow) (S (NP (PRP us)) (VP (TO to) (VP (VB reproduce) (NP (DT the) (JJ small) (HYPH -) (NN batch) (NN accuracy)) (PP (IN while) (NP (NP (NN training)) (PP (IN with) (NP (JJ large) (NN batch) (NNS sizes)))))))))))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (VP (VBG training) (NP (NML (NNP GoogLeNet) (CC and) (NNP Network)) (HYPH -) (NML (IN in) (HYPH -) (NN Network))) (PP (IN on) (NP (NNP ImageNet)))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (DT a) (NN 47x)) (CC and) (NP (NN 39x) (NN speedup))) (, ,) (ADVP (RB respectively)) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (PP (IN on) (NP (NP (DT a) (NN cluster)) (PP (IN of) (NP (CD 128) (NNS GPUs))))))))) (. .))
