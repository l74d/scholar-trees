(S (NP (NP (ADJP (NN Encoder-decoder) (VBN based)) (NAC (NNP Sequence) (PP (TO to) (NP (NNP Sequence)))) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP S2S)) (-RRB- -RRB-))) (VP (VBZ has) (VP (VBN made) (NP (JJ remarkable) (NN progress)) (PP (IN in) (NP (JJ recent) (NNS years))))) (. .))
(S (NP (NNP Different) (NN network) (NNS architectures)) (VP (VBP have) (VP (VBN been) (VP (VBN used) (PP (IN in) (NP (DT the) (NN encoder/decoder)))))) (. .))
(S (PP (IN Among) (NP (PRP them))) (, ,) (NP (NP (NP (NNP Convolutional) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP CNN)) (-RRB- -RRB-))) (CC and) (NP (NP (NNP Self) (NNP Attention) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP SAN)) (-RRB- -RRB-)))) (VP (VBP are) (NP (DT the) (JJ prominent) (NNS ones))) (. .))
(S (S (NP (DT The) (CD two) (NNS architectures)) (VP (VP (VBP achieve) (NP (JJ similar) (NNS performances))) (CC but) (VP (VBP use) (NP (ADJP (RB very) (JJ different)) (NNS ways)) (S (VP (TO to) (VP (VB encode) (CC and) (VB decode) (NP (NN context)))))))) (: :) (S (NP (NNP CNN)) (VP (VBP use) (NP (JJ convolutional) (NNS layers)) (S (VP (TO to) (VP (VB focus) (PP (IN on) (NP (NP (DT the) (JJ local) (NN connectivity)) (PP (IN of) (NP (DT the) (NN sequence)))))))) (, ,) (SBAR (IN while) (S (NP (JJ SAN)) (VP (NNS uses) (NP (NN self-attention) (NNS layers)) (S (VP (TO to) (VP (VB focus) (PP (IN on) (NP (JJ global) (NNS semantics))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (JJ Double) (NNP Path) (NNP Networks)) (PP (IN for) (NP (ADJP (NNP Sequence) (TO to) (NP (NNP Sequence))) (NN learning)))) (PRN (-LRB- -LRB-) (NP (NNP DPN-S2S)) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP leverage) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (NP (DT both) (NNS models)))) (PP (IN by) (S (VP (VBG using) (NP (JJ double) (NN path) (NN information) (NN fusion)))))))))) (. .))
(S (PP (IN During) (NP (DT the) (JJ encoding) (NN step))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (DT a) (JJ double) (NN path) (NN architecture)) (SBAR (S (VP (TO to) (VP (VB maintain) (NP (NP (DT the) (NN information)) (VP (VBG coming) (PP (IN from) (NP (NP (JJ different) (NNS paths)) (PP (IN with) (NP (NP (JJ convolutional) (NNS layers)) (CC and) (NP (NN self-attention) (NNS layers))) (ADVP (RB separately)))))))))))) (. .))
(S (S (VP (TO To) (VP (ADVP (RB effectively)) (VB use) (NP (DT the) (JJ encoded) (NN context))))) (, ,) (NP (PRP we)) (VP (VP (VBP develop) (NP (NP (DT a) (NN cross) (NN attention) (NN module)) (PP (IN with) (NP (NN gating))))) (CC and) (VP (VB use) (NP (PRP it)) (S (VP (TO to) (VP (ADVP (RB automatically)) (VB pick) (PRT (RP up)) (NP (NP (DT the) (NN information)) (VP (VBD needed) (PP (IN during) (NP (DT the) (JJ decoding) (NN step)))))))))) (. .))
(S (PP (IN By) (S (VP (ADVP (RB deeply)) (VBG integrating) (NP (DT the) (CD two) (NNS paths)) (PP (IN with) (NP (NN cross) (NN attention)))))) (, ,) (NP (NP (DT both) (NNS types)) (PP (IN of) (NP (NN information)))) (VP (VBP are) (VP (VP (VBN combined)) (CC and) (VP (ADVP (RB well)) (VBN exploited)))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (VBN proposed) (NN method)) (VP (MD can) (VP (ADVP (RB significantly)) (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN sequence) (TO to) (VB sequence) (NN learning))) (PP (IN over) (NP (JJ state-of-the-art) (NNS systems))))))))) (. .))
