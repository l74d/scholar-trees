(S (NP (NP (NN Graph) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS GNNs)) (-RRB- -RRB-)) (VP (VBP tend) (S (VP (TO to) (VP (VB suffer) (NP (NN performance) (NN degradation)) (PP (IN as) (NP (NP (NN model) (NN depth) (NNS increases)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADVP (RB usually)) (VP (VBN attributed) (PP (IN in) (NP (JJ previous) (NNS works))) (PP (IN to) (NP (DT the) (NN oversmoothing) (NN problem))))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (SBAR (IN although) (S (NP (NN oversmoothing)) (VP (VBZ is) (NP (DT a) (VBG contributing) (NN factor))))) (, ,) (NP (NP (DT the) (JJ main) (NNS reasons)) (PP (IN for) (NP (DT this) (NN phenomenon)))) (VP (VBP are) (VP (VBG training) (NP (NP (NN difficulty) (CC and) (NN overfitting)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP study) (PP (IN by) (S (ADVP (RB experimentally)) (VP (VBG investigating) (NP (NP (NP (NNP Graph) (NNP Convolutional) (NNP Networks)) (-LRB- -LRB-) (NP (NNS GCNs)) (-RRB- -RRB-)) (, ,) (NP (DT a) (JJ representative) (NNP GNN) (NN architecture))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NN training) (NN difficulty)) (VP (VP (VBZ is) (VP (VBN caused) (PP (IN by) (NP (NN gradient) (VBG vanishing))))) (CC and) (VP (MD can) (VP (VB be) (VP (VBN solved) (PP (IN by) (S (VP (VBG adding) (NP (JJ residual) (NNS connections)))))))))))) (. .))
(S (ADVP (RBR More) (RB importantly)) (, ,) (NP (NN overfitting)) (VP (VP (VBZ is) (NP (NP (DT the) (JJ major) (NN obstacle)) (PP (IN for) (NP (JJ deep) (NNS GCNs))))) (CC and) (VP (MD can) (RB not) (VP (VB be) (ADVP (RB effectively)) (VP (VBN solved) (PP (IN by) (NP (VBG existing) (NN regularization) (NNS techniques))))))) (. .))
(S (NP (JJ Deep) (NNS GCNs)) (ADVP (RB also)) (VP (VBP suffer) (NP (NP (NN training) (NN instability)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ slows) (PRT (RP down)) (NP (DT the) (NN training) (NN process))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (NML (NN overfitting) (CC and) (NN training)) (NN instability))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NNP Node) (NNP Normalization) (-LRB- -LRB-) (NNP NodeNorm) (-RRB- -RRB-)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ normalizes) (NP (NP (DT each) (NN node)) (VP (VBG using) (NP (PRP$ its) (JJ own) (NNS statistics)) (PP (IN in) (NP (NN model) (NN training)))))))))) (. .))
(S (NP (NP (NP (DT The) (VBN proposed) (NNP NodeNorm) (NNS regularizes)) (NP (JJ deep) (NNS GCNs))) (PP (IN by) (S (VP (VP (VBG discouraging) (NP (NP (JJ feature-wise) (NN correlation)) (PP (IN of) (NP (JJ hidden) (NNS embeddings))))) (CC and) (VP (VBG increasing) (NP (NN model) (NN smoothness)) (PP (IN with) (NP (NN respect))) (PP (IN to) (NP (NML (NN input) (NN node)) (NNS features))) (, ,) (NAC (CC and) (ADVP (RB thus)) (ADVP (RB effectively)))))))) (VP (VBZ reduces) (NP (NN overfitting))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (PRP it)) (VP (VP (VBZ stabilizes) (NP (DT the) (NN training) (NN process))) (CC and) (ADVP (RB hence)) (VP (VBZ speeds) (PRT (RP up)) (NP (DT the) (NN training)))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (PRP$ our) (NN NodeNorm) (NN method)) (VP (VP (VBZ generalizes) (ADVP (RB well)) (PP (IN to) (NP (JJ other) (NNP GNN) (NNS architectures))) (, ,) (S (VP (VBG enabling) (NP (JJ deep) (NNS GNNs)) (S (VP (TO to) (VP (VB compete) (PP (IN with)))))))) (CC and) (ADVP (RB even)) (VP (VBP outperform) (NP (JJ shallow) (NNS ones))))))) (. .))
(S (NP (NN Code)) (VP (VBZ is) (ADJP (RB publicly) (JJ available))) (. .))
