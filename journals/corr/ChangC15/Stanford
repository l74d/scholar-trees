(S (NP (DT This) (NN paper)) (VP (VBZ reports) (NP (NP (NP (DT a) (JJ novel) (JJ deep) (NN architecture)) (VP (VBN referred) (PP (IN to) (PP (IN as) (NP (NNP Maxout) (NN network)))) (PP (IN In) (NP (NN Network))) (PRN (-LRB- -LRB-) (NP (NN MIN)) (-RRB- -RRB-)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VP (VB enhance) (NP (NN model) (NN discriminability))) (CC and) (VP (VB facilitate) (NP (NP (DT the) (NN process)) (PP (IN of) (NP (NN information) (NN abstraction)))) (PP (IN within) (NP (DT the) (ADJP (JJ receptive)) (NN field)))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN network)) (VP (VBZ adopts) (NP (NP (DT the) (NN framework)) (PP (IN of) (NP (NP (DT the) (ADJP (RB recently) (VBN developed)) (NML (NNP Network) (NNP In) (NNP Network)) (NN structure)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ slides) (NP (NP (DT a) (JJ universal) (NN approximator)) (, ,) (NP (NP (JJ multilayer) (NN perceptron) (-LRB- -LRB-) (NN MLP) (-RRB- -RRB-)) (PP (IN with) (NP (NN rectifier) (NNS units)))) (, ,)) (PP (IN to) (NP (JJ exact) (NNS features)))))))))) (. .))
(S (PP (RB Instead) (PP (IN of) (NP (NNP MLP)))) (, ,) (NP (PRP we)) (VP (VBP employ) (NP (NN maxout) (NN MLP)) (S (VP (VP (TO to) (VP (VB learn) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (JJ piecewise) (NML (JJ linear) (NN activation)) (NNS functions)))))) (CC and) (VP (TO to) (VP (VB mediate) (NP (NP (DT the) (NN problem)) (PP (IN of) (NP (NP (VBG vanishing) (NNS gradients)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB occur) (SBAR (WHADVP (WRB when)) (S (VP (VBG using) (NP (NN rectifier) (NNS units))))))))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (S (NP (NN batch) (NN normalization)) (VP (VBZ is) (VP (VBN applied) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN saturation)) (PP (IN of) (NP (JJ maxout) (NNS units)))) (PP (IN by) (S (VP (VBG pre-conditioning) (NP (DT the) (NN model))))))))))) (CC and) (S (NP (NN dropout)) (VP (VBZ is) (VP (VBN applied) (S (VP (TO to) (VP (VB prevent) (NP (NN overfitting)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (NP (JJ average)) (VP (VBG pooling))) (VP (VBZ is) (VP (VBN used) (PP (IN in) (NP (NP (DT all)) (VP (VBG pooling) (NP (NNS layers)) (S (VP (TO to) (VP (VB regularize) (NP (NP (NN maxout) (NNP MLP)) (PP (IN in) (NP (NN order)))) (S (VP (TO to) (VP (VB facilitate) (NP (NP (NN information) (NN abstraction)) (PP (IN in) (NP (DT every) (ADJP (JJ receptive)) (NN field)))) (PP (IN while) (S (VP (VBG tolerating) (NP (NP (DT the) (NN change)) (PP (IN of) (NP (NN object) (NN position)))))))))))))))))) (. .))
(S (SBAR (IN Because) (S (NP (NP (JJ average)) (VP (VBG pooling))) (VP (VBZ preserves) (NP (NP (DT all) (NNS features)) (PP (IN in) (NP (DT the) (JJ local) (NN patch))))))) (, ,) (NP (DT the) (VBN proposed) (NN MIN) (NN model)) (VP (MD can) (VP (VB enforce) (NP (NP (DT the) (NN suppression)) (PP (IN of) (NP (ADJP (JJ irrelevant)) (NN information)))) (PP (IN during) (NP (NN training))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBD demonstrated) (NP (NP (DT the) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN classification) (NN performance)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NNP MIN) (NN model)) (VP (VBD was) (VP (VBN applied) (PP (IN to) (NP (NP (NML (NML (NN MNIST)) (, ,) (NML (NN CIFAR) (HYPH -) (CD 10)) (, ,) (CC and) (NML (NN CIFAR) (HYPH -) (CD 100))) (NNS datasets)) (CC and) (NP (NP (JJ comparable) (NN performance)) (PP (IN for) (NP (NN SVHN) (NN dataset)))))))))))) (. .))
