(S (NP (NP (DT The) (NN use)) (PP (IN of) (NP (JJR lower) (NN precision)))) (VP (VBZ has) (VP (VBN emerged) (PP (IN as) (NP (NP (DT a) (JJ popular) (NN technique)) (SBAR (S (VP (TO to) (VP (VB optimize) (NP (NP (DT the) (NN compute) (CC and) (NN storage) (NNS requirements)) (PP (IN of) (NP (NP (JJ complex) (NNP Deep) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP DNNs)) (-RRB- -RRB-))))))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (NN quest)) (PP (IN for) (NP (JJR lower) (NN precision))))) (, ,) (NP (JJ recent) (NNS studies)) (VP (VBP have) (VP (VBN shown) (SBAR (IN that) (S (NP (NP (JJ ternary) (NNP DNNs)) (PRN (-LRB- -LRB-) (SBAR (WHNP (WDT which)) (S (VP (VBP represent) (NP (NNS weights) (CC and) (NNS activations)) (PP (IN by) (NP (JJ signed) (JJ ternary) (NNS values)))))) (-RRB- -RRB-))) (VP (VBP represent) (NP (DT a) (JJ promising) (JJ sweet) (NN spot)) (, ,) (S (VP (VBG achieving) (NP (NP (NN accuracy)) (ADJP (RB close) (PP (TO to) (NP (NN full-precision) (NNS networks)))) (PP (IN on) (NP (JJ complex) (NNS tasks))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (NNP TiM-DNN)) (, ,) (NP (NP (DT a) (JJ programmable) (JJ in-memory) (NN accelerator)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (ADVP (RB specifically)) (VBN designed) (S (VP (TO to) (VP (VB execute) (NP (JJ ternary) (NNP DNNs)))))))))))) (. .))
(S (NP (JJ TiM-DNN)) (VP (NNS supports) (NP (NP (JJ various) (JJ ternary) (NNS representations)) (PP (VBG including) (NP (NP (JJ unweighted) (PRN (-LRB- -LCB-) (JJ -1,0,1) (-RRB- -RCB-))) (, ,) (NP (ADJP (RB symmetric) (VBD weighted)) (PRN (-LRB- -LCB-) (NN -a,0) (, ,) (DT a) (-RRB- -RCB-))) (, ,) (CC and) (NP (ADJP (ADJP (RB asymmetric) (VBD weighted)) (PRN (-LRB- -LCB-) (NN -a,0) (PRN (PP (, ,) (NN b))) (-RRB- -RCB-))) (JJ ternary) (NNS systems)))))) (. .))
(S (NP (NP (DT The) (NN building) (NNS blocks)) (PP (IN of) (NP (NNP TiM-DNN)))) (VP (VBP are) (NP (NP (NNP TiM) (NNS tiles)) (: â€”) (NP (NP (JJ specialized) (NN memory) (NNS arrays)) (SBAR (WHNP (WDT that)) (S (VP (VBP perform) (NP (ADJP (RB massively) (JJ parallel)) (VBD signed) (JJ ternary) (JJ vector-matrix) (NNS multiplications)) (PP (IN with) (NP (DT a) (JJ single) (NN access))))))))) (. .))
(S (NP (NNP TiM) (NNS tiles)) (VP (VBP are) (PP (IN in) (NP (NN turn))) (VP (VBN composed) (PP (IN of) (NP (NP (NNP Ternary) (NNP Processing) (NNP Cells)) (PRN (-LRB- -LRB-) (NP (NNP TPCs)) (-RRB- -RRB-)) (, ,) (NP (NP (NNS bit-cells)) (SBAR (WHNP (DT that)) (S (VP (NN function) (PP (IN as) (NP (DT both) (NP (JJ ternary) (NN storage) (NNS units)) (CC and) (NP (VBD signed) (JJ ternary) (NN multiplication) (NNS units)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (NP (DT an) (NN implementation)) (PP (IN of) (NP (NNP TiM-DNN))) (PP (IN in) (NP (CD 32nm) (NN technology)))) (S (VP (VBG using) (NP (NP (DT an) (JJ architectural) (NN simulator)) (VP (VBD calibrated) (PP (IN with) (NP (NP (NNP SPICE) (NNS simulations)) (CC and) (NP (NNP RTL) (NN synthesis))))))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (JJ TiM-DNN)) (PP (IN across) (NP (NP (DT a) (NN suite)) (PP (IN of) (NP (JJ state-of-the-art) (NNP DNN) (NN benchmarks))) (PP (VBG including) (NP (DT both) (UCP (JJ deep) (NN convolutional) (CC and) (JJ recurrent)) (JJ neural) (NNS networks)))))) (. .))
(S (NP (NP (DT A) (JJ 32-tile) (NN instance)) (PP (IN of) (NP (NNP TiM-DNN)))) (VP (VP (VBZ achieves) (NP (NP (DT a) (JJ peak) (NN performance)) (PP (IN of) (NP (CD 114) (NNP TOPs/s))))) (, ,) (VP (VBZ consumes) (NP (CD 0.9W) (NN power))) (, ,) (CC and) (VP (VBZ occupies) (NP (CD 1.96mm2) (NN chip) (NN area))) (, ,) (S (VP (VBG representing) (NP (NP (DT a) (CD 300X) (CC and) (CD 388X) (NN improvement)) (PP (IN in) (NP (NP (NNP TOPS/W) (CC and) (NNP TOPS/mm2)) (, ,) (ADVP (RB respectively)) (, ,))) (PP (VBN compared) (PP (TO to) (NP (DT an) (NNP NVIDIA) (NNP Tesla) (NNP V100) (NNP GPU)))))))) (. .))
(S (PP (IN In) (NP (NP (NN comparison)) (PP (TO to) (NP (VB specialized) (NNP DNN) (NNS accelerators))))) (, ,) (NP (JJ TiM-DNN)) (VP (NNS achieves) (NP (NP (ADJP (JJ 55X-240X) (CC and) (JJ 160X-291X)) (NN improvement)) (PP (IN in) (NP (NP (NNP TOPS/W) (CC and) (NNP TOPS/mm2)) (, ,) (ADVP (RB respectively)))))) (. .))
(S (ADVP (RB Finally)) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBN compared) (PP (TO to) (NP (NP (DT a) (JJ well-optimized) (JJ near-memory) (NN accelerator)) (PP (IN for) (NP (JJ ternary) (NNP DNNs)))))))) (, ,) (NP (NNP TiM-DNN)) (VP (VBZ demonstrates) (NP (NP (NP (ADJP (JJ 3.9x-4.7x)) (NN improvement)) (PP (IN in) (NP (JJ system-level) (NN energy)))) (CC and) (NP (ADJP (JJ 3.2x-4.2x)) (NN speedup))) (, ,) (S (VP (VBG underscoring) (NP (NP (DT the) (NN potential)) (PP (IN of) (NP (JJ in-memory) (VBG computing))) (PP (IN for) (NP (JJ ternary) (NNP DNNs))))))) (. .))
