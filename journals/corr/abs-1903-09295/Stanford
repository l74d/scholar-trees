(S (NP (PRP We)) (VP (VBP propose) (NP (NP (ADJP (NP (NP (NNP Deep) (NNP Q) (HYPH -) (NNP Networks) (-LRB- -LRB-) (NNP DQN) (-RRB- -RRB-)) (PP (IN with) (NP (NN model)))) (HYPH -) (VBN based)) (NN exploration)) (, ,) (NP (NP (DT an) (NN algorithm)) (VP (VBG combining) (NP (NP (ADJP (NP (CC both) (NML (NN model) (HYPH -) (JJ free)) (CC and) (NP (NN model))) (HYPH -) (VBN based)) (NNS approaches)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ explores) (ADJP (JJR better))) (CC and) (VP (VBZ learns) (NP (NNS environments)) (PP (IN with) (NP (JJ sparse) (NNS rewards))) (ADVP (RBR more) (RB efficiently))))))))))) (. .))
(S (NP (NN DQN)) (VP (VP (VBZ is) (NP (DT a) (NML (JJ general) (HYPH -) (NN purpose)) (, ,) (NML (NN model) (HYPH -) (JJ free)) (NN algorithm))) (CC and) (VP (VBZ has) (VP (VBN been) (VP (VBN proven) (S (VP (TO to) (VP (VB perform) (ADVP (RB well)) (PP (IN in) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NP (NNS tasks)) (PP (VBG including) (NP (NNP Atari)))))))))) (SBAR (NP (CD 2600) (NNS games)) (IN since) (S (NP (PRP it)) (VP (VBZ 's) (ADVP (RB first)) (VP (VBN proposed) (PP (IN by) (NP (NNP Minh) (NNP et) (NNP el))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN like) (NP (JJ many) (JJ other) (NML (NML (NN reinforcement) (NN learning)) (-LRB- -LRB-) (NML (NN RL)) (-RRB- -RRB-)) (NNS algorithms))) (, ,) (NP (NNP DQN)) (VP (VBZ suffers) (PP (IN from) (NP (JJ poor) (NN sample) (NN efficiency))) (SBAR (WHADVP (WRB when)) (S (NP (NNS rewards)) (VP (VBP are) (ADJP (JJ sparse) (PP (IN in) (NP (DT an) (NN environment)))))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (NP (NP (JJS most)) (PP (IN of) (NP (NP (DT the) (NNS transitions)) (VP (VBN stored) (PP (IN in) (NP (DT the) (NN replay) (NN memory))))))) (VP (VP (VBP have) (NP (DT no) (JJ informative) (NN reward) (NN signal))) (, ,) (CC and) (VP (VB provide) (NP (JJ limited) (NN value)) (PP (IN to) (NP (NP (DT the) (NN convergence) (CC and) (NN training)) (PP (IN of) (NP (DT the) (NML (NN Q) (HYPH -) (NN Network)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (CD one) (NN insight)) (VP (VBZ is) (SBAR (IN that) (S (NP (DT these) (NNS transitions)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB learn) (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (NP (DT the) (NN environment)) (PP (IN as) (NP (DT a) (JJ supervised) (NN learning) (NN problem))))))))))))))) (. .))
(S (NP (DT The) (NNS transitions)) (ADVP (RB also)) (VP (VBP provide) (NP (NP (NN information)) (PP (IN of) (NP (NP (DT the) (NN distribution)) (PP (IN of) (S (VP (VBN visited) (NP (NNS states))))))))) (. .))
(S (NP (PRP$ Our) (NN algorithm)) (VP (VBZ utilizes) (S (NP (DT these) (CD two) (NNS observations)) (VP (TO to) (VP (VB perform) (NP (DT a) (NML (CD one) (HYPH -) (NN step)) (NN planning)) (PP (IN during) (NP (NN exploration) (S (VP (TO to) (VP (VB pick) (NP (NP (DT an) (NN action)) (SBAR (WHNP (WDT that)) (S (VP (VBZ leads) (PP (IN to) (NP (NNS states))))))) (ADVP (RBS least) (JJ likely) (S (VP (TO to) (VP (VB be) (VP (VBN seen))))))))))) (, ,) (S (ADVP (RB thus)) (VP (VBG improving) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NN exploration)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (NP (PRP$ our) (NN agent) (POS 's)) (NN performance)) (PP (IN in) (NP (NP (CD two) (JJ classic) (NNS environments)) (PP (IN with) (NP (NP (JJ sparse) (NNS rewards)) (PP (IN in) (NP (NNP OpenAI)))))))) (FRAG (FRAG (NP (NN gym)) (: :) (NP (NNP Mountain) (NNP Car))) (CC and) (NP (NNP Lunar) (NNP Lander)))) (. .))
