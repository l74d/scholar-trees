(S (NP (NP (JJ Recent) (NNS advances)) (PP (IN in) (NP (NP (NN policy) (NN gradient) (NNS methods)) (CC and) (NP (JJ deep) (NN learning))))) (VP (VBP have) (VP (VBN demonstrated) (NP (NP (PRP$ their) (NN applicability)) (PP (IN for) (NP (JJ complex) (NN reinforcement) (VBG learning) (NNS problems)))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN variance)) (PP (IN of) (NP (NP (DT the) (NN performance) (NN gradient) (NNS estimates)) (VP (VBN obtained) (PP (IN from) (NP (DT the) (NN simulation))))))) (VP (VBZ is) (ADVP (RB often)) (ADJP (JJ excessive)) (, ,) (S (VP (VBG leading) (PP (TO to) (NP (JJ poor) (JJ sample) (NN efficiency)))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP apply) (NP (NP (DT the) (JJ stochastic) (NN variance) (VBD reduced) (JJ gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SVRG)) (-RRB- -RRB-))) (PP (TO to) (NP (JJ model-free) (NN policy) (NN gradient))) (S (VP (TO to) (VP (ADVP (RB significantly)) (VB improve) (NP (DT the) (NN sample-efficiency)))))) (. .))
(S (NP (DT The) (NNP SVRG) (NN estimation)) (VP (VBZ is) (VP (VBN incorporated) (PP (IN into) (NP (NP (DT a) (JJ trust-region) (NNP Newton) (NN conjugate) (NN gradient) (NN framework)) (PP (IN for) (NP (DT the) (NN policy) (NN optimization))))))) (. .))
(S (PP (IN On) (NP (JJ several) (NNP Mujoco) (NNS tasks))) (, ,) (NP (PRP$ our) (NN method)) (VP (VBZ achieves) (NP (NP (ADJP (RB significantly) (JJR better)) (NN performance)) (PP (VBN compared) (PP (TO to) (NP (NP (DT the) (JJ state-of-the-art) (JJ model-free) (NN policy) (NN gradient) (NNS methods)) (PP (IN in) (NP (JJ robotic) (JJ continuous) (NN control))) (PP (JJ such) (IN as) (NP (NP (JJ trust) (NN region) (NN policy) (NN optimization)) (PRN (-LRB- -LRB-) (NP (NNP TRPO)) (-RRB- -RRB-))))))))))
