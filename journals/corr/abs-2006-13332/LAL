(S (NP (PRP We)) (VP (VBP study) (NP (NP (VBG learning)) (PP (IN of) (NP (NP (JJ recurrent) (JJ neural) (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (VBP produce) (NP (NP (JJ temporal) (NNS sequences)) (VP (VBG consisting) (PP (IN of) (NP (NP (DT the) (NN concatenation)) (PP (IN of) (NP (JJ re-usable) (`` ``) (NNS motifs) ('' '')))))))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (NN neuroscience) (CC or) (NNS robotics))))) (, ,) (NP (DT these) (NNS motifs)) (VP (MD would) (VP (VB be) (NP (NP (DT the) (NN motor) (NNS primitives)) (SBAR (WHPP (IN from) (WHNP (WDT which))) (S (NP (JJ complex) (NN behavior)) (VP (VBZ is) (VP (VBN generated)))))))) (. .))
(SQ (PP (VBN Given) (NP (NP (DT a) (JJ known) (NN set)) (PP (IN of) (NP (NNS motifs))))) (, ,) (MD can) (NP (DT a) (JJ new) (NN motif)) (VP (VB be) (VP (VP (VBN learned) (PP (IN without) (S (VP (VBG affecting) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (VBN known) (NN set)))))))) (CC and) (VP (ADVP (RB then)) (VBN used) (PP (IN in) (NP (JJ new) (NNS sequences))) (PP (IN without) (S (VP (ADVP (JJ first)) (VP (ADVP (RB explicitly)) (VBG learning) (NP (DT every) (JJ possible) (NN transition))))))))) (. ?))
(S (NP (NP (CD Two) (NNS requirements))) (VP (JJ enable) (NP (DT this)) (: :) (S (S (PRN (-LRB- -LRB-) (NN i) (-RRB- -RRB-)) (NP (NP (NN parameter) (NNS updates)) (SBAR (IN while) (S (VP (VBG learning) (NP (DT a) (JJ new) (NN motif)))))) (VP (VBP do) (RB not) (VP (VB interfere) (PP (IN with) (NP (NP (DT the) (NNS parameters)) (VP (VBN used) (PP (IN for) (NP (DT the) (ADJP (RB previously) (VBN acquired)) (NNS ones))))))))) (: ;) (CC and) (S (PRN (-LRB- -LRB-) (NN ii) (-RRB- -RRB-)) (S (NP (DT a) (JJ new) (NN motif)) (VP (MD can) (VP (VB be) (VP (ADVP (RB robustly)) (VBN generated) (SBAR (WHADVP (WRB when)) (S (VP (VBG starting) (PP (IN from) (NP (NP (DT the) (NN network) (NN state)) (VP (VBD reached) (PP (IN at) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NP (DT any)) (PP (IN of) (NP (DT the) (JJ other) (NNS motifs))))))))))))) (, ,) (SBAR (RB even) (IN if) (S (NP (DT that) (NN state)) (VP (VBD was) (RB not) (ADJP (JJ present)) (PP (IN during) (NP (NN training))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP meet) (NP (DT the) (JJ first) (NN requirement)) (PP (IN by) (S (VP (VBG investigating) (NP (NP (JJ artificial) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP ANNs)) (-RRB- -RRB-)) (PP (IN with) (NP (JJ specific) (NNS architectures)))))))) (, ,) (CC and) (VP (NN attempt) (S (VP (TO to) (VP (VB meet) (NP (DT the) (JJ second)) (PP (IN by) (S (VP (VBG training) (S (NP (PRP them)) (S (VP (TO to) (VP (VB generate) (NP (NNS motifs)) (PP (IN from) (NP (JJ random) (JJ initial) (NNS states))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (SBAR (IN that) (S (NP (NP (NN learning)) (PP (IN of) (NP (JJ single) (NNS motifs)))) (VP (VBZ succeeds)))) (CC but) (SBAR (DT that) (S (NP (NN sequence) (NN generation)) (VP (VBZ is) (RB not) (ADJP (JJ robust)))))) (: :) (S (NP (NN transition) (NNS failures)) (VP (VBP are) (VP (VBN observed))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VB compare) (NP (DT these) (NNS results)) (PP (IN with) (NP (NP (DT a) (NN model)) (SBAR (SBAR (WHNP (WP$ whose) (NN architecture) (CC and) (NP (JJ analytically-tractable) (NNS dynamics))) (S (VP (VBP are) (VP (VBN inspired) (PP (IN by) (NP (DT the) (NN motor) (JJ thalamocortical) (NN circuit))))))) (, ,) (CC and) (SBAR (WHNP (DT that)) (S (VP (VBZ includes) (NP (NP (DT a) (JJ specific) (NN module)) (VP (VBN used) (S (VP (TO to) (VP (VB implement) (NP (JJ motif) (NNS transitions)))))))))))))) (. .))
(S (S (NP (NP (DT The) (JJ synaptic) (NNS weights)) (PP (IN of) (NP (DT this) (NN model)))) (VP (MD can) (VP (VB be) (VP (VBN adjusted) (PP (IN without) (S (VP (VBG requiring) (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)) (PP (IN on) (NP (DT the) (JJ simulated) (NN network) (NNS outputs))))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP have) (NP (JJ asymptotic) (NNS guarantees) (SBAR (IN that) (S (NP (NNS transitions)) (VP (MD will) (RB not) (VP (VB fail)))))))) (. .))
(S (ADVP (RB Indeed)) (, ,) (PP (IN in) (NP (NNS simulations))) (, ,) (NP (PRP we)) (VP (VP (VBP achieve) (NP (JJ single-motif) (NN accuracy)) (PP (IN on) (NP (NP (NN par)) (PP (IN with) (NP (DT the) (ADJP (RB previously) (VBN studied)) (NNP ANNs)))))) (CC and) (VP (VBP have) (NP (VBN improved) (JJ sequencing) (NN robustness)) (PP (IN with) (NP (DT no) (NN transition) (NNS failures))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NNS insights)) (VP (VBN obtained) (PP (IN by) (S (VP (VBG studying) (NP (NP (DT the) (NN transition) (NN subnetwork)) (PP (IN of) (NP (DT this) (NN model))))))))) (VP (MD can) (ADVP (RB also)) (VP (VB improve) (NP (NP (DT the) (NN robustness)) (PP (IN of) (NP (VBG transitioning))) (PP (IN in) (NP (NP (DT the) (JJ traditional) (NNP ANNs)) (VP (ADVP (RB previously)) (VBD studied)))))))))) (. .))
