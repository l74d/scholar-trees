(S (NP (PRP We)) (VP (VBP study) (NP (NP (NN learning)) (PP (IN of) (NP (NP (ADJP (JJ recurrent)) (JJ neural) (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (VBP produce) (NP (NP (JJ temporal) (NNS sequences)) (VP (VBG consisting) (PP (IN of) (NP (NP (DT the) (NN concatenation)) (PP (IN of) (NP (JJ re-usable) (`` ") (NNS motifs) ('' ")))))))))))))) (. .))
(S (PP (IN In) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (NN neuroscience) (CC or) (NNS robotics))))) (, ,) (NP (DT these) (NNS motifs)) (VP (MD would) (VP (VB be) (NP (NP (DT the) (NN motor) (NNS primitives)) (SBAR (WHPP (IN from) (WHNP (WDT which))) (S (NP (JJ complex) (NN behavior)) (VP (VBZ is) (VP (VBN generated)))))))) (. .))
(SQ (PP (VBN Given) (SBAR (S (NP (NP (DT a) (VBN known) (NN set)) (PP (IN of) (NP (NNS motifs))))))) (, ,) (MD can) (NP (DT a) (JJ new) (NN motif)) (VP (VB be) (VP (VP (VBN learned) (PP (IN without) (S (VP (VBG affecting) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (VBN known) (NN set)))))))) (CC and) (ADVP (RB then)) (VP (VBN used) (PP (IN in) (NP (JJ new) (NNS sequences))) (PP (IN without) (NP (NP (JJ first)) (VP (ADVP (RB explicitly)) (VBG learning) (NP (DT every) (JJ possible) (NN transition)))))))) (. ?))
(S (S (NP (CD Two) (NNS requirements)) (VP (VBP enable) (NP (DT this)))) (: :) (S (LST (-LRB- -LRB-) (LS i) (-RRB- -RRB-)) (NP (NP (NN parameter) (NNS updates)) (SBAR (IN while) (S (VP (VBG learning) (NP (DT a) (JJ new) (NN motif)))))) (VP (VBP do) (RB not) (VP (VB interfere) (PP (IN with) (NP (NP (DT the) (NNS parameters)) (VP (VBN used) (PP (IN for) (NP (DT the) (ADJP (RB previously) (VBN acquired)) (NNS ones))))))))) (: ;) (CC and) (S (LST (-LRB- -LRB-) (LS ii) (-RRB- -RRB-)) (NP (DT a) (JJ new) (NN motif)) (VP (MD can) (VP (VB be) (ADVP (RB robustly)) (VP (VBN generated) (SBAR (SBAR (WHADVP (WRB when)) (S (S (VP (VBG starting) (PP (IN from) (NP (DT the) (NN network) (NN state))))) (VP (VBD reached) (PP (IN at) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NP (DT any)) (PP (IN of) (NP (DT the) (JJ other) (NNS motifs)))))))))) (, ,) (RB even) (SBAR (IN if) (S (NP (DT that) (NN state)) (VP (VBD was) (RB not) (ADJP (JJ present) (PP (IN during) (NP (NN training)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP meet) (NP (DT the) (JJ first) (NN requirement)) (PP (IN by) (S (VP (VBG investigating) (NP (NP (NP (JJ artificial) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS ANNs)) (-RRB- -RRB-)) (PP (IN with) (NP (JJ specific) (NNS architectures)))) (, ,) (NAC (CC and) (NP (NN attempt) (S (VP (TO to) (VP (VB meet) (NP (DT the) (JJ second)) (PP (IN by) (S (VP (VBG training) (NP (PRP them)) (S (VP (TO to) (VP (VB generate) (NP (NNS motifs)) (PP (IN from) (NP (JJ random) (JJ initial) (NNS states)))))))))))))))))) (. .))
(S (S (NP (PRP We)) (VP (VBP find) (SBAR (SBAR (IN that) (S (NP (NP (NN learning)) (PP (IN of) (NP (JJ single) (NNS motifs)))) (VP (VBZ succeeds)))) (CC but) (SBAR (WHNP (WDT that)) (S (NP (NN sequence) (NN generation)) (VP (VBZ is) (RB not) (ADJP (JJ robust)))))))) (: :) (S (NP (NN transition) (NNS failures)) (VP (VBP are) (VP (VBN observed)))) (. .))
(S (S (NP (PRP We)) (ADVP (RB then)) (VP (VBP compare) (NP (DT these) (NNS results)) (PP (IN with) (NP (NP (DT a) (NN model)) (SBAR (S (NP (NP (WP$ whose) (NN architecture)) (CC and) (NP (ADJP (RB analytically) (HYPH -) (JJ tractable)) (NNS dynamics))) (VP (VBP are) (VP (VBN inspired) (PP (IN by) (NP (DT the) (NN motor) (JJ thalamocortical) (NN circuit))))))))))) (, ,) (CC and) (S (NP (DT that)) (VP (VBZ includes) (NP (NP (DT a) (JJ specific) (NN module)) (VP (VBN used) (S (VP (TO to) (VP (VB implement) (NP (NN motif) (NNS transitions))))))))) (. .))
(S (S (NP (NP (DT The) (JJ synaptic) (NNS weights)) (PP (IN of) (NP (DT this) (NN model)))) (VP (MD can) (VP (VB be) (VP (VBN adjusted) (PP (IN without) (S (VP (VBG requiring) (NP (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-)) (PP (IN on) (NP (DT the) (JJ simulated) (NN network) (NNS outputs))))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP have) (NP (NP (JJ asymptotic) (NNS guarantees)) (SBAR (WHNP (WDT that)) (S (NP (NNS transitions)) (VP (MD will) (RB not) (VP (VB fail)))))))) (. .))
(S (ADVP (RB Indeed)) (, ,) (PP (IN in) (NP (NNS simulations))) (, ,) (NP (PRP we)) (VP (VP (VBP achieve) (NP (NP (NML (JJ single) (HYPH -) (NN motif)) (NN accuracy)) (PP (IN on) (NP (NN par)))) (PP (IN with) (NP (DT the) (ADJP (RB previously) (VBN studied)) (NNS ANNs)))) (CC and) (VP (VBP have) (NP (VBN improved) (NN sequencing) (NN robustness)) (PP (IN with) (NP (DT no) (NN transition) (NNS failures))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NNS insights)) (VP (VBN obtained) (PP (IN by) (S (VP (VBG studying) (NP (NP (DT the) (NN transition) (NN subnetwork)) (PP (IN of) (NP (DT this) (NN model))))))))) (VP (MD can) (ADVP (RB also)) (VP (VB improve) (NP (NP (DT the) (NN robustness)) (PP (IN of) (S (VP (VBG transitioning) (PP (IN in) (NP (NP (DT the) (JJ traditional) (NNS ANNs)) (ADJP (RB previously) (VBN studied))))))))))))) (. .))
