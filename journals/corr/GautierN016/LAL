(S (NP (NP (DT The) (NN optimization) (NN problem)) (PP (IN behind) (NP (JJ neural) (NNS networks)))) (VP (VBZ is) (ADJP (RB highly) (JJ non-convex))) (. .))
(S (NP (NP (VBG Training)) (PP (IN with) (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (CC and) (NP (NNS variants))))) (VP (VP (VBZ requires) (NP (JJ careful) (NN parameter) (NN tuning))) (CC and) (VP (VBZ provides) (NP (DT no) (NN guarantee) (S (VP (TO to) (VP (VB achieve) (NP (DT the) (JJ global) (NN optimum)))))))) (. .))
(S (PP (IN In) (NP (NN contrast))) (NP (PRP we)) (VP (VBP show) (PP (IN under) (NP (NP (ADJP (RB quite) (JJ weak)) (NNS assumptions)) (PP (IN on) (NP (DT the) (NNS data))))) (SBAR (IN that) (S (NP (NP (DT a) (JJ particular) (NN class)) (PP (IN of) (NP (JJ feedforward) (JJ neural) (NNS networks)))) (VP (MD can) (VP (VB be) (VP (VBN trained) (S (ADJP (RB globally) (JJ optimal))) (PP (IN with) (NP (DT a) (JJ linear) (NN convergence) (NN rate))) (PP (IN with) (NP (PRP$ our) (JJ nonlinear) (JJ spectral) (NN method))))))))) (. .))
(S (PP (RB Up) (PP (TO to) (NP (PRP$ our) (NN knowledge)))) (NP (DT this)) (VP (VBZ is) (NP (NP (DT the) (JJ first) (ADJP (RB practically) (JJ feasible)) (NN method)) (SBAR (WHNP (WDT which)) (S (VP (VBZ achieves) (NP (PDT such) (DT a) (NN guarantee))))))) (. .))
(S (SBAR (IN While) (S (NP (DT the) (NN method)) (VP (MD can) (PP (IN in) (NP (NN principle))) (VP (VB be) (VP (VBN applied) (PP (TO to) (NP (VB deep) (NNS networks)))))))) (, ,) (NP (PRP we)) (VP (VBP restrict) (NP (PRP ourselves)) (PP (IN for) (NP (NN simplicity))) (PP (IN in) (NP (DT this) (NN paper))) (PP (TO to) (NP (QP (CD one) (CC and) (CD two)) (JJ hidden) (NN layer) (NNS networks)))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP confirm) (SBAR (IN that) (S (NP (DT these) (NNS models)) (VP (VBP are) (ADJP (JJ rich) (RB enough) (S (VP (TO to) (VP (VB achieve) (NP (NP (JJ good) (NN performance)) (PP (IN on) (NP (NP (DT a) (NN series)) (PP (IN of) (NP (JJ real-world) (NNS datasets)))))))))))))) (. .))
