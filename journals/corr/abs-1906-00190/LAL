(S (NP (NP (NN Policy) (NN gradient)) (CC and) (NP (JJ actor-critic) (NN algorithms))) (VP (VB form) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (NP (JJ many) (ADJP (RB commonly) (VBD used)) (VBG training) (NNS techniques)) (PP (IN in) (NP (JJ deep) (NN reinforcement) (NN learning))))))) (. .))
(S (S (VP (VBG Using) (NP (DT these) (NNS algorithms)) (PP (IN in) (NP (JJ multiagent) (NNS environments))))) (VP (VBZ poses) (NP (NP (NNS problems)) (PP (JJ such) (IN as) (NP (NN nonstationarity) (CC and) (NN instability))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (ADVP (RB first)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (JJ standard) (JJ softmax-based) (NN policy) (NN gradient)) (VP (MD can) (VP (VB be) (ADJP (VBN prone) (PP (TO to) (NP (JJ poor) (NN performance)))) (PP (IN in) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (RB even) (DT the) (ADJP (RBS most) (JJ benign)) (NN nonstationarity)))))))))) (. .))
(S (PP (IN By) (NP (NN contrast))) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBN known) (SBAR (IN that) (S (NP (NP (DT the) (NN replicator) (NNS dynamics)) (, ,) (NP (NP (DT a) (JJ well-studied) (NN model)) (PP (IN from) (NP (JJ evolutionary) (NN game) (NN theory)))) (, ,)) (VP (VP (VBZ eliminates) (NP (JJ dominated) (NNS strategies))) (CC and) (VP (NNS exhibits) (NP (NP (NN convergence)) (PP (IN of) (NP (DT the) (JJ time-averaged) (NNS trajectories))) (PP (TO to) (NP (NP (VB interior) (NNP Nash) (NN equilibria)) (PP (IN in) (NP (JJ zero-sum) (NNS games)))))))))))) (. .))
(S (ADVP (RB Thus)) (, ,) (S (VP (VBG using) (NP (DT the) (NN replicator) (NNS dynamics)) (PP (IN as) (NP (DT a) (NN foundation))))) (, ,) (NP (PRP we)) (VP (VBP derive) (NP (NP (DT an) (JJ elegant) (JJ one-line) (NN change)) (PP (TO to) (NP (NN policy) (NN gradient) (NNS methods))) (SBAR (WHNP (WDT that)) (S (ADVP (RB simply)) (VP (VBZ bypasses) (NP (NP (DT the) (JJ gradient) (NN step)) (PP (IN through) (NP (DT the) (NN softmax)))))))) (, ,) (S (VP (VBG yielding) (NP (NP (DT a) (JJ new) (NN algorithm)) (VP (VBN titled) (S (NP (S (NP (NNP Neural) (NNP Replicator) (NNP Dynamics))) (PRN (-LRB- -LRB-) (NP (NNP NeuRD)) (-RRB- -RRB-))))))))) (. .))
(S (NP (NNP NeuRD)) (VP (VBZ reduces) (PP (TO to) (NP (DT the) (JJ exponential) (NN weights/Hedge) (NN algorithm))) (PP (IN in) (NP (DT the) (JJ single-state) (NNS all-actions) (NN case)))) (. .))
(S (ADVP (RB Additionally)) (, ,) (NP (NNP NeuRD)) (VP (VBZ has) (NP (NP (JJ formal) (NN equivalence)) (PP (TO to) (NP (NP (VB softmax) (JJ counterfactual) (NN regret) (NN minimization)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ guarantees) (NP (NN convergence)) (PP (IN in) (NP (DT the) (JJ sequential) (JJ tabular) (NN case)))))))))) (. .))
(S (ADVP (RB Importantly)) (, ,) (NP (PRP$ our) (NN algorithm)) (VP (VBZ provides) (NP (NP (DT a) (JJ straightforward) (NN way)) (PP (IN of) (S (VP (VBG extending) (NP (DT the) (NN replicator) (NNS dynamics)) (PP (TO to) (NP (DT the) (NN function) (NN approximation) (NN setting)))))))) (. .))
(S (NP (JJ Empirical) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP NeuRD)) (VP (ADVP (RB quickly)) (VBZ adapts) (PP (TO to) (NP (NNS nonstationarities))) (, ,) (S (VP (VBG outperforming) (NP (NN policy) (NN gradient)) (ADVP (RB significantly)) (PP (IN in) (NP (UCP (DT both) (JJ tabular) (CC and) (JJ function)) (NN approximation) (NNS settings))))) (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBN evaluated) (PP (IN on) (NP (NP (DT the) (JJ standard) (NN imperfect) (NN information) (NNS benchmarks)) (PP (IN of) (NP (NP (NNP Kuhn) (NNP Poker)) (, ,) (NP (NNP Leduc) (NNP Poker)) (, ,) (CC and) (NP (NNP Goofspiel))))))))))))) (. .))
