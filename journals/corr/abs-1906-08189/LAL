(S (NP (NP (DT A) (JJ major) (NN challenge)) (PP (IN in) (NP (NN reinforcement) (NN learning)))) (VP (VBZ is) (NP (NN exploration)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (JJ local) (VBG dithering) (NNS methods)) (PP (JJ such) (IN as) (NP (JJ epsilon-greedy) (NN sampling)))) (VP (VBP are) (ADJP (JJ insufficient) (S (VP (TO to) (VP (VB solve) (NP (DT a) (VBN given) (NN task)))))))))) (. .))
(S (NP (JJ Many) (JJ recent) (NNS methods)) (VP (VBP have) (VP (VBN proposed) (S (VP (TO to) (VP (ADVP (RB intrinsically)) (VB motivate) (S (NP (DT an) (NN agent)) (VP (TO to) (VP (VB seek) (NP (JJ novel) (NNS states))))) (, ,) (S (VP (VBG driving) (S (NP (DT the) (NN agent)) (VP (TO to) (VP (VB discover) (NP (JJ improved) (NN reward)))))))))))) (. .))
(S (ADVP (RB However)) (, ,) (SBAR (IN while) (S (NP (JJ state-novelty) (NN exploration) (NNS methods)) (VP (VBP are) (ADJP (JJ suitable) (PP (IN for) (NP (NP (NNS tasks)) (SBAR (WHADVP (WRB where)) (S (NP (JJ novel) (NNS observations)) (VP (VBP correlate) (ADVP (RB well)) (PP (IN with) (NP (VBN improved) (NN reward)))))))))))) (, ,) (NP (PRP they)) (VP (MD may) (RB not) (VP (VB explore) (ADVP (ADVP (RBR more) (RB efficiently)) (PP (IN than) (NP (JJ epsilon-greedy) (NNS approaches)))) (PP (IN in) (NP (NP (NNS environments)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (CD two)) (VP (VBP are) (RB not) (ADJP (JJ well-correlated))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP distinguish) (PP (IN between) (NP (NP (NP (NN exploration) (NNS tasks)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (S (VP (VBG seeking) (NP (NN novel) (NNS states)))) (VP (NNS aids) (PP (IN in) (S (VP (VBG finding) (NP (JJ new) (NN reward))))))))) (, ,) (CC and) (NP (NP (DT those)) (SBAR (WHADVP (WRB where)) (S (NP (PRP it)) (VP (VBZ does) (RB not)))) (, ,) (PP (JJ such) (IN as) (NP (NP (JJ goal-conditioned) (NNS tasks)) (CC and) (S (VP (VBG escaping) (NP (JJ local) (NN reward) (NN maxima)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN exploration) (NN objective)) (, ,) (S (VP (VBG maximizing) (NP (NP (DT the) (NN reward) (NN prediction) (NN error)) (PRN (-LRB- -LRB-) (NP (NNP RPE)) (-RRB- -RRB-)) (PP (IN of) (NP (NP (DT a) (NN value) (NN function)) (VP (VBD trained) (S (VP (TO to) (VP (VB predict) (NP (JJ extrinsic) (NN reward))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VBD propose) (NP (NP (DT a) (JJ deep) (NN reinforcement) (VBG learning) (NN method)) (, ,) (NP (NNP QXplore)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ exploits) (NP (NP (DT the) (JJ temporal) (NN difference) (NN error)) (PP (IN of) (NP (DT a) (NN Q-function)))) (S (VP (TO to) (VP (VB solve) (NP (JJ hard) (NN exploration) (NNS tasks)) (PP (IN in) (NP (JJ high-dimensional) (NNP MDPs))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP demonstrate) (NP (NP (DT the) (NN exploration) (NN behavior)) (PP (IN of) (NP (NNP QXplore)))) (PP (IN on) (NP (NP (JJ several) (NNP OpenAI) (NNP Gym) (NNP MuJoCo) (NNS tasks)) (CC and) (NP (NNP Atari) (NNS games))))) (CC and) (VP (VBP observe) (SBAR (IN that) (S (NP (NNP QXplore)) (VP (VBZ is) (ADJP (ADJP (JJ comparable) (PP (TO to))) (CC or) (ADJP (JJR better) (PP (PP (IN than)) (NP (DT a) (JJ baseline) (NN state-novelty) (NN method))))) (PP (IN in) (NP (DT all) (NNS cases))) (, ,) (S (VP (VBG outperforming) (NP (DT the) (NN baseline)) (PP (IN on) (NP (NP (NNS tasks)) (SBAR (WHADVP (WRB where)) (S (NP (NN state) (NN novelty)) (VP (VBZ is) (RB not) (ADJP (JJ well-correlated) (PP (IN with) (NP (JJ improved) (NN reward)))))))))))))))) (. .))
