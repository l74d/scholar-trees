(S (NP (DT A) (JJ multilayer) (NN perceptron)) (VP (MD can) (VP (VB behave) (PP (IN as) (NP (DT a) (JJ generative) (NN classifier))) (PP (IN by) (S (VP (VBG applying) (NP (NP (JJ bidirectional) (NN learning)) (PRN (-LRB- -LRB-) (NP (NNP BL)) (-RRB- -RRB-)))))))) (. .))
(S (S (NP (PRP It)) (VP (VBZ consists) (PP (IN of) (S (VP (VBG training) (S (NP (DT an) (JJ undirected) (JJ neural) (NN network)) (S (VP (TO to) (VP (VP (VB map) (NP (NN input)) (PP (TO to) (NP (NN output)))) (CC and) (ADVP (NN vice-versa))))))))))) (: ;) (S (ADVP (IN therefore)) (NP (PRP it)) (VP (MD can) (VP (VB produce) (NP (NP (NP (DT a) (JJR classifier)) (PP (IN in) (NP (CD one) (NN direction)))) (, ,) (CC and) (NP (NP (DT a) (NN generator)) (PP (IN in) (NP (DT the) (JJ opposite) (NN direction))))) (PP (IN for) (NP (DT the) (JJ same) (NN data)))))) (. .))
(S (NP (NP (DT The) (JJ learning) (NN process)) (PP (IN of) (NP (NNP BL)))) (VP (NNS tries) (S (VP (TO to) (VP (VB reproduce) (NP (NP (DT the) (NN neuroplasticity)) (VP (VBN stated) (PP (IN in) (NP (NNP Hebbian) (NN theory))))) (S (VP (VBG using) (NP (NP (RB only) (JJ backward) (NN propagation)) (PP (IN of) (NP (NNS errors)))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (NP (CD two) (NN novel) (VBG learning) (NNS techniques))) (VP (VBP are) (VP (VBN introduced) (SBAR (WHNP (WDT which)) (S (VP (VBP use) (NP (NNP BL)) (PP (IN for) (S (VP (VBG improving) (NP (NP (NN robustness)) (PP (TO to) (NP (JJ white) (NN noise) (ADJP (JJ static) (CC and) (JJ adversarial)) (NNS examples)))))))))))) (. .))
(S (NP (DT The) (JJ first) (NN method)) (VP (VBZ is) (NP (NP (JJ bidirectional) (NN propagation)) (PP (IN of) (NP (NNS errors))) (, ,) (SBAR (WHNP (WDT which)) (S (NP (DT the) (NN error) (NN propagation)) (VP (VBZ occurs) (PP (IN in) (NP (ADJP (NN backward) (CC and) (JJ forward)) (NNS directions)))))))) (. .))
(S (S (VP (VBN Motivated) (PP (IN by) (NP (DT the) (NN fact) (SBAR (IN that) (S (NP (PRP$ its) (JJ generative) (NN model)) (VP (NNS receives) (PP (IN as) (NP (NN input))) (NP (NP (DT a) (JJ constant) (NN vector)) (PP (IN per) (NP (NN class))))))))))) (, ,) (NP (PRP we)) (VP (VBP introduce) (PP (IN as) (NP (DT a) (JJ second) (NN method))) (NP (NP (DT the) (JJ hybrid) (JJ adversarial) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP HAN)) (-RRB- -RRB-)))) (. .))
(S (S (NP (PRP$ Its) (JJ generative) (NN model)) (VP (VBZ receives) (NP (DT a) (JJ random) (NN vector)) (PP (IN as) (NP (NN input))))) (CC and) (S (NP (PRP$ its) (NN training)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (NP (JJ generative) (JJ adversarial) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP GAN)) (-RRB- -RRB-))))))) (. .))
(S (S (VP (TO To) (VP (VB assess) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NNP BL))))))) (, ,) (NP (PRP we)) (VP (VBP perform) (NP (NP (NNS experiments)) (VP (VBG using) (NP (NP (JJ several) (NNS architectures)) (PP (IN with) (NP (ADJP (RB fully) (CC and) (JJ convolutional)) (NNS layers))) (, ,) (PP (IN with) (CC and) (IN without) (NP (NN bias))))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (DT both) (NNS methods)) (VP (VP (VBP improve) (NP (NP (NN robustness)) (PP (TO to) (NP (JJ white) (NN noise) (ADJP (JJ static) (CC and) (JJ adversarial)) (NNS examples))))) (, ,) (CC and) (VP (ADVP (RB even)) (VB increase) (NP (NN accuracy))) (, ,) (CC but) (VP (VBP have) (NP (JJ different) (NN behavior)) (PP (VBG depending) (PP (IN on) (NP (DT the) (NN architecture) (CC and) (NN task)))) (, ,) (S (VP (VBG being) (ADJP (RBR more) (JJ beneficial)) (S (VP (TO to) (VP (VB use) (NP (NP (DT the) (CD one)) (CC or) (NP (DT the) (JJ other))))))))))))) (. .))
(S (ADVP (RB Nevertheless)) (, ,) (NP (NP (NNP HAN)) (VP (VBG using) (NP (DT a) (JJ convolutional) (NN architecture)) (PP (IN with) (NP (NN batch) (NN normalization))))) (VP (NNS presents) (NP (JJ outstanding) (NN robustness)) (, ,) (S (VP (VBG reaching) (NP (JJ state-of-the-art) (NN accuracy)) (PP (IN on) (NP (NP (JJ adversarial) (NNS examples)) (PP (IN of) (NP (JJ hand-written) (NNS digits)))))))) (. .))
