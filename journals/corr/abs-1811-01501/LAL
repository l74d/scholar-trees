(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN optimization) (NN method)) (PP (IN for) (S (VP (VBG training) (NP (JJ feed-forward) (JJ neural) (NNS networks))))))) (. .))
(S (S (PP (IN By) (S (VP (VBG rewriting) (NP (DT the) (NN activation) (NN function)) (PP (IN as) (NP (DT an) (JJ equivalent) (NN proximal) (NN operator)))))) (, ,) (NP (PRP we)) (VP (VBP approximate) (NP (DT a) (JJ feed-forward) (JJ neural) (NN network)) (PP (IN by) (S (VP (VBG adding) (NP (DT the) (NN proximal) (NNS operators)) (PP (TO to) (NP (DT the) (JJ objective) (NN function))) (PP (IN as) (NP (NNS penalties)))))))) (, ,) (S (ADVP (NN hence)) (NP (PRP we)) (VP (VBP call) (NP (NP (DT the) (JJ lifted) (NN proximal) (NN operator) (NN machine)) (PRN (-LRB- -LRB-) (NP (NNP LPOM)) (-RRB- -RRB-))))) (. .))
(S (NP (NNP LPOM)) (VP (VBZ is) (ADJP (JJ block) (NNS multi-convex)) (PP (IN in) (NP (DT all) (JJ layer-wise) (NNS weights) (CC and) (NNS activations)))) (. .))
(S (NP (DT This)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VB use) (NP (NN block) (NN coordinate) (NN descent)) (S (VP (TO to) (VP (VB update) (NP (DT the) (JJ layer-wise) (NNS weights) (CC and) (NNS activations)) (PP (IN in) (NP (NN parallel)))))))))) (. .))
(S (ADVP (JJS Most) (RB notably)) (, ,) (NP (PRP we)) (VP (ADVP (RB only)) (VBP use) (NP (NP (DT the) (NN mapping)) (PP (IN of) (NP (NP (NP (DT the) (NN activation) (NN function)) (NP (PRP itself))) (, ,) (CONJP (RB rather) (IN than)) (NP (PRP$ its) (NNS derivatives))))) (, ,) (S (ADVP (RB thus)) (VP (VBG avoiding) (NP (NP (DT the) (NN gradient) (NN vanishing) (CC or) (JJ blow-up) (NNS issues)) (PP (IN in) (NP (NN gradient) (VBN based) (NN training) (NNS methods))))))) (. .))
(S (RB So) (NP (PRP$ our) (NN method)) (VP (VBZ is) (ADJP (JJ applicable) (PP (TO to) (NP (NP (JJ various) (JJ non-decreasing) (NNP Lipschitz) (JJ continuous) (NN activation) (NNS functions)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (ADJP (VBG saturating) (CC and) (JJ non-differentiable)))))))))) (. .))
(S (NP (NNP LPOM)) (VP (VBZ does) (RB not) (VP (VB require) (NP (NP (JJR more) (JJ auxiliary) (NNS variables)) (PP (IN than) (NP (DT the) (JJ layer-wise) (NNS activations)))) (, ,) (S (ADVP (RB thus)) (VP (VBG using) (NP (NP (RB roughly) (DT the) (JJ same) (NN amount)) (PP (IN of) (NP (NN memory))) (SBAR (IN as) (S (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))) (VP (VBZ does))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB further)) (VBD prove) (NP (NP (DT the) (NN convergence)) (PP (IN of) (S (VP (VBG updating) (NP (DT the) (JJ layer-wise) (NNS weights) (CC and) (NNS activations))))))) (. .))
(S (NP (NP (NNS Experiments)) (PP (IN on) (NP (NNP MNIST) (CC and) (NNP CIFAR-10) (NNS datasets)))) (VP (VBP testify) (PP (TO to) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (NP (NNP LPOM)))))) (. .))
