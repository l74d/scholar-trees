(S (NP (NP (NNP Actor) (JJ critic) (NNS methods)) (PP (IN with) (NP (JJ sparse) (NNS rewards))) (PP (IN in) (NP (JJ model-based) (JJ deep) (NN reinforcement) (VBG learning)))) (ADVP (RB typically)) (VP (VB require) (NP (NP (DT a) (JJ deterministic) (JJ binary) (NN reward) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (VBZ reflects) (NP (NP (QP (RB only) (CD two)) (JJ possible) (NNS outcomes)) (: :) (SBAR (IN if) (, ,) (PP (IN for) (NP (DT each) (NN step))) (, ,) (S (NP (DT the) (NN goal)) (VP (VBZ has) (VP (VBN been) (VP (VBN achieved))))) (CC or) (RB not)))))))) (. .))
(S (NP (PRP$ Our) (NN hypothesis)) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VB influence) (S (NP (DT an) (NN agent)) (VP (TO to) (VP (VB learn) (ADVP (JJR faster))))) (PP (IN by) (S (VP (VBG applying) (NP (NP (DT an) (JJ external) (JJ environmental) (NN pressure))) (PP (IN during) (NP (NN training))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (ADVP (RB adversely)) (VBZ impacts) (NP (PRP$ its) (NN ability) (S (VP (TO to) (VP (VB get) (NP (JJR higher) (NNS rewards))))))))))))))))) (. .))
(S (PP (IN As) (NP (JJ such))) (, ,) (NP (PRP we)) (VP (VP (VBP deviate) (PP (IN from) (NP (NP (DT the) (JJ classical) (NN paradigm)) (PP (IN of) (NP (NN sparse) (NNS rewards)))))) (CC and) (VP (VB add) (NP (DT a) (ADJP (JJ uniformly) (VBN sampled)) (NN reward) (NN value)) (PP (TO to) (NP (DT the) (NN baseline) (NN reward)))) (S (VP (TO to) (VP (VB show) (SBAR (IN that) (S (S (PRN (-LRB- -LRB-) (CD 1) (-RRB- -RRB-)) (NP (NP (NN sample) (NN efficiency)) (PP (IN of) (NP (DT the) (NN training) (NN process)))) (VP (MD can) (VP (VB be) (VP (VBN correlated) (PP (TO to) (NP (NP (DT the) (NN adversity)) (VP (VBD experienced) (PP (IN during) (NP (NN training)))))))))) (, ,) (S (PRN (-LRB- -LRB-) (CD 2) (-RRB- -RRB-)) (NP (NP (PRP it))) (VP (VBZ is) (ADJP (JJ possible)) (S (VP (TO to) (VP (VB achieve) (NP (JJR higher) (NN performance)) (PP (PP (IN in) (NP (JJR less) (NN time))) (CC and) (PP (IN with) (NP (JJR less) (NNS resources))))))))) (, ,) (S (PRN (-LRB- -LRB-) (CD 3) (-RRB- -RRB-)) (NP (PRP we)) (VP (MD can) (VP (VB reduce) (NP (NP (DT the) (NN performance) (NN variability)) (VP (VBD experienced) (NP (NP (NN seed)) (PP (IN over) (NP (NN seed))))))))) (, ,) (S (PRN (-LRB- -LRB-) (CD 4) (-RRB- -RRB-)) (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (JJ maximum) (NN point)) (SBAR (WHPP (IN after) (WHNP (WDT which))) (S (NP (JJR more) (NN pressure)) (VP (MD will) (RB not) (VP (VB generate) (NP (JJR better) (NNS results))))))))) (, ,) (CC and) (S (PRN (-LRB- -LRB-) (CD 5) (-RRB- -RRB-)) (SBAR (WDT that) (S (NP (VBP random) (JJ positive) (NNS incentives)) (VP (VBP have) (NP (DT an) (JJ adverse) (NN effect)) (SBAR (WHADVP (WRB when)) (S (VP (VBG using) (NP (DT a) (JJ negative) (NN reward) (NN strategy))))) (, ,) (S (VP (VBG making) (S (NP (NP (DT an) (NN agent)) (PP (IN under) (NP (DT those) (NNS conditions)))) (VP (VBP learn) (ADVP (ADVP (RB poorly)) (CC and) (ADVP (RBR more) (RB slowly))))))))))))))))) (. .))
(S (S (NP (DT These) (NNS results)) (VP (VBP have) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (JJ valid)) (PP (IN for) (NP (NP (NNP Deep) (NNP Deterministic) (NNP Policy) (NNP Gradients)) (VP (VBG using) (NP (NNP Hindsight) (NNP Experience) (NNP Replay)) (PP (IN in) (NP (DT a) (ADJP (NN well) (VBN known)) (NNP Mujoco) (NN environment))))))))))))) (, ,) (CC but) (S (NP (PRP we)) (VP (VBP argue) (SBAR (IN that) (S (NP (PRP they)) (VP (MD could) (VP (VB be) (VP (VBN generalized) (PP (TO to) (NP (JJ other) (NNS methods) (CC and) (NNS environments))) (ADVP (RB as) (RB well))))))))) (. .))
