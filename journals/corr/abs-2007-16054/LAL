(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBD present) (NP (NP (DT an) (JJ end-to-end) (JJ meta-learned) (NN system)) (PP (IN for) (NP (NN image) (NN compression))))) (. .))
(S (NP (NP (JJ Traditional) (ADJP (NN machine) (NN learning) (VBN based)) (NNS approaches)) (PP (TO to) (NP (NN image) (NN compression)))) (VP (VBP train) (NP (QP (CD one) (CC or) (JJR more)) (JJ neural) (NN network)) (PP (IN for) (NP (NN generalization) (NN performance)))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN at) (NP (NN inference) (NN time))) (, ,) (NP (NP (DT the) (NN encoder)) (CC or) (NP (NP (DT the) (NN latent) (NN tensor)) (VP (NN output) (PP (IN by) (NP (DT the) (NN encoder)))))) (VP (MD can) (VP (VB be) (VP (VBN optimized) (PP (IN for) (NP (DT each) (NN test) (NN image)))))) (. .))
(S (NP (DT This) (NN optimization)) (VP (MD can) (VP (VB be) (VP (VBN regarded) (PP (IN as) (NP (NP (DT a) (NN form)) (PP (IN of) (NP (NP (NP (NN adaptation)) (CC or) (NP (NN benevolent) (VBG overfitting))) (PP (TO to) (NP (DT the) (NN input) (NN content)))))))))) (. .))
(S (SBAR (IN In) (NN order) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN gap)) (PP (IN between) (NP (NN training) (CC and) (NN inference) (NNS conditions)))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN training) (NN paradigm)) (PP (IN for) (NP (JJ learned) (NN image) (NN compression))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (NN meta-learning))))))))) (. .))
(S (PP (IN In) (NP (DT a) (JJ first) (NN phase))) (, ,) (NP (DT the) (JJ neural) (NNS networks)) (VP (VBP are) (VP (VBN trained) (ADVP (RB normally)))) (. .))
(S (PP (IN In) (NP (DT a) (JJ second) (NN phase))) (, ,) (NP (DT the) (JJ Model-Agnostic) (NNP Meta-learning) (NN approach)) (VP (VBZ is) (VP (VBN adapted) (PP (TO to) (NP (NP (DT the) (JJ specific) (NN case)) (PP (IN of) (NP (NN image) (NN compression))) (, ,) (SBAR (WHADVP (WRB where)) (S (S (NP (DT the) (JJ inner-loop)) (VP (NNS performs) (NP (NN latent) (NN tensor) (NN overfitting)))) (, ,) (CC and) (S (NP (DT the) (NN outer) (NN loop)) (VP (VBZ updates) (NP (DT both) (NN encoder) (CC and) (VB decoder) (JJ neural) (NNS networks)) (PP (VBN based) (PP (IN on) (NP (DT the) (JJ overfitting) (NN performance)))))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (PP (IN after) (NP (JJ meta-learning))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB overfit) (CC and) (VB cluster) (NP (NP (DT the) (NN bias) (NNS terms)) (PP (IN of) (NP (DT the) (NN decoder)))) (PP (IN on) (NP (NN training) (NN image) (NNS patches))) (, ,) (SBAR (IN so) (DT that) (S (PP (IN at) (NP (NN inference) (NN time))) (NP (DT the) (JJ optimal) (JJ content-specific) (NN bias) (NNS terms)) (VP (MD can) (VP (VB be) (VP (VBN selected) (PP (IN at) (NP (JJ encoder-side)))))))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN probability) (NN model)) (PP (IN for) (NP (JJ lossless) (NN compression))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ combines) (NP (NP (NNS concepts)) (PP (IN from) (NP (DT both) (JJ multi-scale) (CC and) (JJ super-resolution) (NN probability) (NN model) (NNS approaches))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (NP (DT all) (PRP$ our) (VBN proposed) (NNS ideas)))) (PP (IN via) (NP (ADJP (RB carefully) (VBN designed)) (NNS experiments)))) (. .))
