(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (CD two) (ADJP (JJ novel) (NP (NN p) (HYPH -) (NN norm))) (NN penalty)) (FRAG (ADJP (JJS least)) (S (VP (VB mean) (NP (JJ square) (-LRB- -LRB-) (NML (NN Lp) (HYPH -) (NN LMS)) (-RRB- -RRB-) (NNS algorithms)))) (PP (IN as) (NP (NP (NNS supplements)) (PP (IN of) (NP (NP (DT the) (JJ conventional) (NML (NN Lp) (HYPH -) (NN LMS)) (NN algorithm)) (VP (VBN established) (PP (IN for) (NP (JJ sparse) (JJ adaptive) (NN filtering)))))))) (ADVP (RB recently))))) (. .))
(S (NP (DT A) (NN gradient) (NN comparator)) (VP (VBZ is) (VP (VBN employed) (S (VP (TO to) (ADVP (RB selectively)) (VP (VB apply) (NP (DT the) (NML (NML (CD zero) (NN attractor)) (PP (IN of) (NP (NN p) (HYPH -) (NN norm)))) (NN constraint)) (PP (IN for) (NP (NP (RB only) (DT those) (NNS taps)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (NP (NP (DT the) (JJ same) (NN polarity)) (PP (IN as) (NP (NP (DT that)) (PP (IN of) (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (NP (DT the) (ADJP (JJ squared) (JJ instantaneous)) (NN error)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ leads) (PP (IN to) (NP (NP (DT the) (JJ new) (VBN proposed) (NN gradient)) (PP (VBN compared) (NP (NP (NN p) (HYPH -) (NN norm) (NN constraint) (NN LMS) (NN algorithm)) (-LRB- -LRB-) (NP (NN LpGC) (HYPH -) (NN LMS)) (-RRB- -RRB-))))))))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP explain) (SBAR (IN that) (S (NP (DT the) (NN LpGC) (HYPH -) (NN LMS)) (VP (MD can) (VP (VB achieve) (NP (NP (ADJP (JJR lower) (JJ mean)) (JJ square) (NN error)) (PP (IN than) (NP (DT the) (JJ standard) (NML (NN Lp) (HYPH -) (NN LMS)) (NN algorithm)))) (ADVP (ADVP (RB theoretically)) (CC and) (ADVP (RB experimentally)))))))) (. .))
(S (S (VP (TO To) (ADVP (RB further)) (VP (VB improve) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (NN filter))))))) (, ,) (NP (DT the) (NML (NN LpNGC) (HYPH -) (NN LMS)) (NN algorithm)) (VP (VBZ is) (VP (VBN derived) (S (VP (VBG using) (NP (NP (DT a) (JJ new) (NN gradient) (NN comparator)) (SBAR (WHNP (WDT which)) (S (VP (VBZ takes) (NP (NP (DT the) (ADJP (NP (NN sign)) (HYPH -) (VBN smoothed)) (NN version)) (PP (IN of) (NP (DT the) (JJ previous) (NN one)))))))))))) (. .))
(S (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (DT the) (NN LpNGC) (HYPH -) (NN LMS)))) (VP (VBZ is) (ADJP (JJ superior) (PP (PP (IN to) (NP (NP (DT that)) (PP (IN of) (NP (NP (DT the) (NN LpGC) (HYPH -) (NN LMS)) (PP (IN in) (NP (NN theory))))))) (CC and) (PP (IN in) (NP (NNS simulations)))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (DT these) (CD two) (NNS comparators)) (VP (MD can) (VP (VB be) (ADVP (RB easily)) (VP (VBN applied) (PP (IN to) (NP (NP (JJ other) (NN norm) (NN constraint)) (NP (NNP LMS) (NNS algorithms)))) (S (VP (TO to) (VP (VB derive) (NP (NP (DT some) (JJ new) (NNS approaches)) (PP (IN for) (NP (JJ sparse) (JJ adaptive) (NN filtering)))))))))) (. .))
(S (NP (DT The) (JJ numerical) (NN simulation) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (CD two) (VBN proposed) (NNS algorithms)) (VP (VB achieve) (NP (JJR better) (NN performance)) (PP (IN than) (NP (NP (DT the) (JJ standard) (NNP LMS) (NN algorithm)) (CC and) (NP (NP (NML (NN Lp) (HYPH -) (NN LMS)) (NN algorithm)) (PP (IN in) (NP (NP (NP (NNS terms)) (PP (IN of) (NP (NN convergence) (NN rate)))) (CC and) (NP (NP (NML (JJ steady) (HYPH -) (NN state)) (NN behavior)) (PP (IN in) (NP (JJ sparse) (NN system) (NN identification) (NNS settings))))))))))))) (. .))
