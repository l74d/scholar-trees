(S (PP (IN In) (NP (NN reinforcement))) (S (VP (VBG learning) (NP (DT an) (NN agent)))) (VP (VBZ interacts) (PP (IN with) (NP (DT the) (NN environment))) (PP (IN by) (S (VP (VP (VBG taking) (NP (NNS actions))) (CC and) (VP (VBG observing) (NP (DT the) (JJ next) (NN state) (CC and) (NN reward))))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (VP (VBN sampled) (ADVP (RB probabilistically))))) (, ,) (NP (NP (DT these) (NN state)) (NP (NNS transitions) (, ,) (NNS rewards) (, ,) (CC and) (NNS actions))) (VP (MD can) (ADVP (DT all)) (VP (VB induce) (NP (NN randomness)) (PP (IN in) (NP (DT the) (VBN observed) (NML (RB long) (HYPH -) (NN term)) (NN return))))) (. .))
(S (ADVP (RB Traditionally)) (, ,) (NP (NML (NN reinforcement) (NN learning)) (NNS algorithms)) (VP (VBP average) (PP (IN over) (NP (DT this) (NN randomness) (S (VP (TO to) (VP (VB estimate) (NP (DT the) (NN value) (NN function)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP build) (PP (IN on) (NP (NP (JJ recent) (NN work)) (VP (VBG advocating) (NP (DT a) (JJ distributional) (NN approach)) (PP (IN to) (NP (NP (NN reinforcement) (NN learning)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (DT the) (NN distribution)) (PP (IN over) (NP (NNS returns)))) (VP (VBZ is) (VP (VBN modeled) (ADVP (RB explicitly)) (PP (RB instead) (IN of) (S (ADVP (RB only)) (VP (VBG estimating) (NP (DT the) (NN mean))))))))))))))) (. .))
(S (NP (DT That)) (VP (VBZ is) (, ,) (SBAR (S (NP (PRP we)) (VP (VBP examine) (NP (NP (NNS methods)) (PP (IN of) (S (VP (VBG learning) (NP (NP (DT the) (NN value) (NN distribution)) (PP (RB instead) (IN of) (NP (DT the) (NN value) (NN function)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP give) (NP (NP (NNS results)) (SBAR (WHNP (WDT that)) (S (VP (VBP close) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (NP (NNS gaps)) (PP (IN between) (NP (DT the) (ADJP (JJ theoretical) (CC and) (JJ algorithmic)) (NNS results)))))) (PP (VBN given) (PP (IN by) (NP (NNP Bellemare) (, ,) (NNP Dabney) (, ,) (CC and) (NNP Munos)))))))) (PRN (-LRB- -LRB-) (NP (CD 2017)) (-RRB- -RRB-))) (. .))
(S (ADVP (RB First)) (, ,) (NP (PRP we)) (VP (VBP extend) (NP (VBG existing) (NNS results)) (PP (IN to) (NP (DT the) (JJ approximate) (NN distribution) (NN setting)))) (. .))
(S (ADVP (RB Second)) (, ,) (NP (PRP we)) (VP (VBP present) (NP (DT a) (JJ novel) (JJ distributional) (NN reinforcement)) (S (VP (VBG learning) (NP (NN algorithm)) (S (ADJP (JJ consistent) (PP (IN with) (NP (PRP$ our) (JJ theoretical) (NN formulation)))))))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP evaluate) (NP (DT this) (JJ new) (NN algorithm)) (PP (IN on) (NP (NP (DT the) (NNP Atari)) (NP-TMP (CD 2600) (NNS games)))) (, ,) (S (VP (VBG observing) (SBAR (IN that) (S (NP (PRP it)) (ADVP (RB significantly)) (VP (VBZ outperforms) (NP (NP (JJ many)) (PP (IN of) (NP (NP (DT the) (JJ recent) (NNS improvements)) (PP (IN on) (NP (NNP DQN))))) (, ,) (PP (VBG including) (NP (DT the) (JJ related) (JJ distributional) (NN algorithm) (NN C51)))))))))) (. .))
