(S (S (VP (VBG Using) (NP (NP (NN back-propagation)) (CC and) (NP (PRP$ its) (NNS variants))) (S (VP (TO to) (VP (VB train) (NP (JJ deep) (NNS networks))))))) (VP (VBZ is) (ADVP (RB often)) (ADJP (JJ problematic)) (PP (IN for) (NP (JJ new) (NNS users)))) (. .))
(S (NP (NP (NNS Issues)) (PP (JJ such) (IN as) (NP (NP (VBG exploding) (NNS gradients)) (, ,) (NP (VBG vanishing) (NNS gradients)) (, ,) (CC and) (NP (NP (JJ high) (NN sensitivity)) (PP (TO to) (NP (VB weight) (NN initialization) (NNS strategies))))))) (ADVP (RB often)) (VP (VBP make) (S (NP (NNS networks)) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB train))))))) (, ,) (SBAR (WHADVP (ADVP (RB especially)) (WRB when)) (S (NP (NNS users)) (VP (VBP are) (VP (VBG experimenting) (PP (IN with) (NP (JJ new) (NNS architectures)))))))) (. .))
(S (ADVP (RB Here)) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (JJ Local) (NNP Representation) (NNP Alignment)) (PRN (-LRB- -LRB-) (NP (NNP LRA)) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (NN training) (NN procedure)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ is) (ADJP (ADVP (RB much) (RBR less)) (JJ sensitive) (PP (TO to) (NP (JJ bad) (NNS initializations))))) (, ,) (VP (VBZ does) (RB not) (VP (VB require) (NP (NP (NNS modifications)) (PP (TO to) (NP (DT the) (NN network) (NN architecture)))))) (, ,) (CC and) (VP (MD can) (VP (VB be) (VP (VBN adapted) (PP (TO to) (NP (NP (NNS networks)) (PP (IN with) (NP (ADJP (ADJP (RB highly) (JJ nonlinear)) (CC and) (ADJP (JJ discrete-valued))) (NN activation) (NNS functions)))))))))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (CD one) (NN variation)) (PP (IN of) (NP (NNP LRA)))) (VP (MD can) (VP (VP (VB start) (PP (IN with) (NP (NP (DT a) (JJ null) (NN initialization)) (PP (IN of) (NP (NN network) (NNS weights)))))) (CC and) (VP (ADVP (ADVP (RB still)) (ADVP (RB successfully))) (VB train) (NP (NNS networks)) (PP (IN with) (NP (NP (DT a) (JJ wide) (NN variety)) (PP (IN of) (NP (NP (NNS nonlinearities)) (, ,) (PP (VBG including) (NP (NP (NN tanh)) (, ,) (NP (NNP ReLU-6)) (, ,) (NP (NN softplus)) (, ,) (NP (NN signum)) (CC and) (NP (NP (NNS others)) (SBAR (WHNP (WDT that)) (S (VP (MD may) (VP (VB draw) (NP (PRP$ their) (NN inspiration)) (PP (IN from) (NP (NN biology)))))))))))))))))))) (. .))
(S (NP (NP (NP (DT A) (JJ comprehensive) (NN set)) (PP (IN of) (NP (NP (NNS experiments)) (PP (IN on) (NP (NNP MNIST)))))) (CC and) (NP (DT the) (ADJP (JJ much) (JJR harder)) (NNP Fashion) (NNP MNIST) (NNS data) (NNS sets))) (VP (VBP show) (SBAR (IN that) (S (NP (NNP LRA)) (VP (MD can) (VP (VB be) (VP (VBN used) (S (VP (TO to) (VP (VB train) (NP (NNS networks)) (ADVP (RB robustly) (CC and) (RB effectively))))) (, ,) (S (VP (VP (VBG succeeding) (SBAR (WHADVP (RB even) (WRB when)) (S (NP (NN back-propagation)) (VP (NNS fails))))) (CC and) (VP (VBG outperforming) (NP (NP (JJ other) (JJ alternative) (VBG learning) (NN algorithms)) (, ,) (PP (JJ such) (IN as) (NP (NP (NN target) (NN propagation)) (CC and) (NP (NN feedback) (NN alignment)))))))))))))) (. .))
