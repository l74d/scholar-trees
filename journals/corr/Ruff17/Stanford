(S (S (VP (VBG Training) (NP (DT a) (JJ deep) (JJ convolutional) (JJ neural) (NN net)) (ADVP (RB typically)))) (VP (VBZ starts) (PP (IN with) (NP (NP (DT a) (JJ random) (NN initialisation)) (PP (IN of) (NP (NP (DT all) (NNS filters)) (PP (IN in) (NP (NP (NP (DT all) (NNS layers)) (SBAR (WHNP (WDT which)) (S (ADVP (RB severely)) (VP (VP (VBZ reduces) (NP (DT the) (ADJP (UCP (NP (JJ forward) (NN signal)) (CC and) (ADVP (RB back))) (HYPH -) (VBN propagated)) (NN error))) (CC and) (VP (VBZ leads) (S (VP (TO to) (VP (VB slow))))))))) (CC and) (NP (JJ sub-optimal) (NN training))))))))) (. .))
(S (NP (NP (NNS Techniques)) (SBAR (WHNP (WDT that)) (S (VP (VBP counter) (NP (DT that) (NN focus)) (PP (IN on) (S (VP (CC either) (VP (VBG increasing) (NP (DT the) (NN signal))) (CC or) (VP (VBG increasing) (NP (DT the) (NNS gradients)) (ADVP (RB adaptively)) (PP (CC but) (NP (DT the) (NN model))))))))))) (VP (VBZ behaves) (ADVP (ADVP (RB very) (RB differently)) (PP (IN at) (NP (NP (DT the) (NN beginning)) (PP (IN of) (NP (NP (NN training)) (PP (VBN compared) (PP (IN to) (ADVP (RB later))))))))) (SBAR (WHADVP (WRB when)) (S (NP (NP (JJ stable) (NNS pathways)) (PP (IN through) (NP (DT the) (NN net)))) (VP (VBP have) (VP (VBN been) (VP (VBN established))))))) (. .))
(S (S (VP (TO To) (VP (VB compound) (NP (DT this) (NN problem))))) (NP (DT the) (JJ effective) (NN minibatch) (NN size)) (VP (VBZ varies) (PP (PP (ADVP (RB greatly)) (IN between) (NP (NP (NNS layers)) (PP (IN at) (NP (JJ different) (NNS depths))))) (CC and) (PP (IN between) (NP (JJ individual) (NNS filters)))) (SBAR (IN as) (S (S (NP (NN activation) (NN sparsity)) (ADVP (RB typically)) (VP (VBZ increases) (PP (IN with) (NP (NP (NN depth)) (VP (VBG leading) (PP (IN to) (NP (NP (DT a) (NN reduction)) (PP (IN in) (NP (JJ effective) (NN learning) (NN rate))))) (SBAR (IN since) (S (NP (NNS gradients)) (VP (MD may) (VP (VP (VB superpose)) (CONJP (RB rather) (IN than)) (VP (VB add))))))))))) (CC and) (S (NP (NP (DT this) (JJ further) (NNS compounds)) (NP (NP (DT the) (NN covariate) (NN shift) (NN problem)) (PP (IN as) (NP (JJR deeper) (NNS neurons))))) (VP (VBP are) (ADJP (RBR less) (JJ able) (S (VP (TO to) (VP (VB adapt) (PP (IN to) (NP (JJ upstream) (NN shift)))))))))))) (. .))
(S (NP (VBN Proposed)) (ADVP (RB here)) (VP (VBZ is) (NP (NP (DT a) (NN method)) (PP (IN of) (NP (NP (JJ automatic) (NN gain) (NN control)) (PP (IN of) (NP (NP (DT the) (NN signal)) (VP (VBN built) (PP (IN into) (NP (NP (DT each) (JJ convolutional) (NN neuron)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ achieves) (NP (ADJP (JJ equivalent) (CC or) (JJ superior)) (NN performance)) (PP (IN than) (NP (NN batch) (NN normalisation)))) (CC and) (VP (VBZ is) (ADJP (JJ compatible) (PP (IN with) (NP (NP (JJ single) (NN sample)) (CC or) (NP (NN minibatch) (NN gradient) (NN descent)))))))))))))))))) (. .))
(S (NP (DT The) (JJ same) (NN model)) (VP (VBZ is) (VP (VBN used) (PP (DT both) (IN for) (NP (NN training) (CC and) (NN inference))))) (. .))
(S (NP (DT The) (NN technique)) (VP (VBZ comprises) (SBAR (S (NP (DT a) (ADJP (VBN scaled) (PP (IN per) (NP (NN sample)))) (NN map)) (VP (VBP mean) (NP (NN subtraction)) (PP (IN from) (NP (NP (DT the) (JJ raw) (JJ convolutional) (NN filter) (NN output)) (VP (VBN followed) (PP (IN by) (NP (NP (NN scaling)) (PP (IN of) (NP (DT the) (NN difference)))))))))))) (. .))
