(S (S (NP (PRP We)) (VP (VBP propose) (NP (DT a) (VBN distributed) (NN architecture)) (PP (IN for) (NP (NP (JJ deep) (NN reinforcement)) (VP (VBG learning) (PP (IN at) (NP (NN scale)))))))) (, ,) (NP (DT that)) (VP (VBZ enables) (NP (NNS agents)) (S (VP (TO to) (VP (VB learn) (NP (NP (ADVP (RB effectively) (PP (IN from) (NP (NP (NNS orders)) (PP (IN of) (NP (NN magnitude)))))) (ADVP (RBR more)) (NNS data)) (SBAR (IN than) (FRAG (ADJP (RB previously) (JJ possible))))))))) (. .))
(S (S (NP (DT The) (NN algorithm)) (VP (VBZ decouples) (S (VP (VBG acting) (PP (IN from) (NP (NN learning))))))) (: :) (S (S (NP (DT the) (NNS actors)) (VP (VP (VBP interact) (PP (IN with) (NP (NP (PRP$ their) (JJ own) (NNS instances)) (PP (IN of) (NP (DT the) (NN environment))))) (PP (IN by) (S (VP (VBG selecting) (NP (NNS actions)) (PP (VBG according) (PP (IN to) (NP (DT a) (VBN shared) (JJ neural) (NN network)))))))) (, ,) (CC and) (VP (VBP accumulate) (NP (NP (DT the) (VBG resulting) (NN experience)) (PP (IN in) (NP (DT a) (VBN shared) (NN experience) (NN replay) (NN memory))))))) (: ;) (S (NP (DT the) (NN learner) (NNS replays)) (NP (NP (NNS samples)) (PP (IN of) (NP (NN experience))))) (CC and) (S (NP (NNS updates)) (NP (DT the) (JJ neural) (NN network)))) (. .))
(S (NP (DT The) (NN architecture)) (VP (VBZ relies) (PP (IN on) (S (VP (VBN prioritized) (NP (NN experience) (NN replay)) (S (VP (TO to) (VP (VB focus) (ADVP (RB only)) (PP (IN on) (NP (NP (DT the) (ADJP (RBS most) (JJ significant)) (NNS data)) (VP (VBN generated) (PP (IN by) (NP (DT the) (NNS actors))))))))))))) (. .))
(S (NP (PRP$ Our) (NN architecture)) (ADVP (RB substantially)) (VP (VBZ improves) (NP (NP (DT the) (NN state)) (PP (IN of) (NP (NP (DT the) (NN art)) (PP (IN on) (NP (DT the) (NNP Arcade) (NNP Learning) (NNP Environment)))))) (, ,) (S (VP (VBG achieving) (NP (JJR better) (JJ final) (NN performance)) (PP (IN in) (NP (NP (DT a) (NN fraction)) (PP (IN of) (NP (DT the) (NML (NN wall) (HYPH -) (NN clock)) (NN training) (NN time)))))))) (. .))
