(S (SBAR (WHADVP (WRB When)) (S (NP (JJ multiple) (NNS agents)) (VP (VBP learn) (PP (IN in) (NP (DT a) (JJ decentralized) (NN manner)))))) (, ,) (NP (DT the) (NN environment)) (VP (VBZ appears) (ADJP (JJ non-stationary)) (PP (IN from) (NP (NP (DT the) (NN perspective)) (PP (IN of) (NP (DT an) (JJ individual) (NN agent))))) (PP (JJ due) (PP (TO to) (NP (NP (DT the) (NN exploration) (CC and) (NN learning)) (PP (IN of) (NP (DT the) (JJ other) (NNS agents))))))) (. .))
(S (NP (ADJP (RB Recently) (VBN proposed)) (JJ deep) (JJ multi-agent) (NN reinforcement) (VBG learning) (NNS methods)) (VP (VBP have) (VP (VBN tried) (S (VP (TO to) (VP (VB mitigate) (NP (DT this) (NN non-stationarity)) (PP (IN by) (S (VP (VBG attempting) (S (VP (TO to) (VP (VP (VB determine) (SBAR (WHNP (WDT which) (NNS samples)) (S (VP (VBP are) (PP (IN from) (NP (JJ other) (JJ agent) (NN exploration) (CC or) (NN suboptimality))))))) (CC and) (VP (VB take) (NP (PRP them)) (ADVP (RBR less)) (PP (IN into) (NP (NN account))) (PP (IN during) (NP (NN learning))))))))))))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (DT the) (JJ same) (NN philosophy)))) (, ,) (NP (DT this) (NN paper)) (VP (VBZ introduces) (NP (NP (DT a) (VBN decentralized) (NN quantile) (NN estimator)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ aims) (S (VP (TO to) (VP (VB improve) (NP (NN performance)) (PP (IN by) (S (VP (VBG distinguishing) (NP (JJ non-stationary) (NNS samples)) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (NN likelihood)) (PP (IN of) (NP (NNS returns))))))))))))))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (NP (DT each) (NN agent)) (VP (VBZ considers) (NP (DT the) (NN likelihood) (SBAR (IN that) (S (NP (JJ other) (JJ agent) (NN exploration) (CC and) (NN policy) (NNS changes)) (VP (VBP are) (VP (VBG occurring)))))) (, ,) (S (ADVP (RB essentially)) (VP (VBG utilizing) (NP (NP (DT the) (NN agent) (POS 's)) (JJ own) (NNS estimations)) (S (VP (TO to) (VP (VB weigh) (NP (NP (DT the) (NN learning) (NN rate)) (SBAR (WHNP (WDT that)) (S (VP (MD should) (VP (VB be) (VP (VBN applied) (PP (IN towards) (NP (DT the) (VBN given) (NNS samples))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (NP (DT a) (JJ formal) (NN method)) (PP (IN of) (S (VP (VBG calculating) (NP (NP (NNS differences)) (PP (IN of) (NP (PRP$ our) (NN return) (NN distribution) (NNS representations)))))))) (CC and) (NP (NP (NNS methods)) (PP (IN for) (S (VP (VBG utilizing) (NP (PRP it)) (S (VP (TO to) (VP (VB guide) (NP (NNS updates))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VP (VBP explore) (NP (NP (DT the) (NN effect)) (PP (IN of) (NP (NN risk-seeking) (NNS strategies))) (PP (IN for) (S (VP (VBG adjusting) (NP (VBG learning)) (PP (IN over) (NP (NN time)))))))) (CC and) (VP (VB propose) (NP (NP (JJ adaptive) (NN risk) (NN distortion) (NNS functions)) (SBAR (WHNP (WDT which)) (S (VP (VBP guides) (NP (NN risk) (NN sensitivity)))))))) (. .))
(S (NP (NP (PRP$ Our) (NNS experiments)) (, ,) (PP (IN on) (NP (NP (JJ traditional) (NNS benchmarks)) (CC and) (NP (JJ new) (NNS domains)))) (, ,)) (VP (VBP show) (SBAR (S (NP (PRP$ our) (NNS methods)) (VP (VBP are) (ADJP (ADJP (ADJP (RBR more) (JJ stable)) (, ,) (ADJP (JJ sample) (NN efficient)) (CC and) (ADJP (RBR more) (JJ likely) (S (VP (TO to) (VP (VB converge) (PP (TO to) (NP (DT a) (JJ joint) (NN optimal) (NN policy)))))))) (PP (IN than) (NP (JJ previous) (NNS methods)))))))) (. .))
