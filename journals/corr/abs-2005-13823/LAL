(S (NP (NNP GPUs)) (VP (VBP are) (ADVP (RB currently)) (NP (NP (DT the) (NN platform)) (PP (IN of) (NP (NN choice))) (PP (IN for) (S (VP (VBG training) (NP (JJ neural) (NNS networks))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG training) (NP (NP (DT a) (JJ deep) (JJ neural) (NN network)) (PRN (-LRB- -LRB-) (NP (NNP DNN)) (-RRB- -RRB-))))) (VP (VBZ is) (NP (DT a) (JJ time-consuming) (NN process)) (PP (ADVP (RB even)) (IN on) (NP (NNP GPUs))) (PP (IN because) (IN of) (NP (NP (DT the) (JJ massive) (NN number)) (PP (IN of) (NP (NP (NNS parameters)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (S (VP (TO to) (VP (VB be) (VP (VBN learned))))))))))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (S (VP (VBG accelerating) (NP (NNP DNN) (NN training)))) (VP (VBZ has) (VP (VBN been) (NP (NP (DT an) (NN area)) (PP (IN of) (NP (JJ significant) (NN research)))) (PP (IN in) (NP (NP (DT the) (JJ last) (NN couple)) (PP (IN of) (NP (NNS years))))))) (. .))
(S (SBAR (IN While) (S (NP (NP (JJR earlier) (NNS networks)) (PP (JJ such) (IN as) (NP (NNP AlexNet)))) (VP (VBD had) (NP (NP (DT a) (JJ linear) (NN dependency)) (PP (IN between) (NP (NNS layers) (CC and) (NNS operations))))))) (, ,) (NP (NP (JJ state-of-the-art) (NNS networks)) (PP (JJ such) (IN as) (NP (NP (NNP ResNet)) (, ,) (NP (NNP PathNet)) (, ,) (CC and) (NP (NNP GoogleNet))))) (VP (VBP have) (NP (NP (DT a) (JJ non-linear) (NN structure)) (SBAR (WHNP (WDT that)) (S (VP (VBZ exhibits) (NP (NP (DT a) (JJR higher) (NN level)) (PP (IN of) (NP (JJ inter-operation) (NN parallelism))))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (JJ popular) (JJ deep) (NN learning) (PRN (-LRB- -LRB-) (NNP DL) (-RRB- -RRB-)) (VBZ frameworks)) (PP (JJ such) (IN as) (NP (NP (NNP TensorFlow)) (CC and) (NP (NNP PyTorch))))) (VP (VP (VBP launch) (NP (NP (DT the) (NN majority)) (PP (IN of) (NP (NP (JJ neural) (NN network) (NNS operations)) (, ,) (NP (ADVP (RB especially)) (NNS convolutions)) (, ,)))) (ADVP (RB serially)) (PP (IN on) (NP (NNP GPUs)))) (CC and) (VP (VBP do) (RB not) (VP (VB exploit) (NP (DT this) (JJ inter-op) (NN parallelism))))) (. .))
(S (PP (IN In) (NP (DT this) (JJ brief) (NN announcement))) (, ,) (NP (PRP we)) (VP (VBP make) (NP (DT a) (NN case)) (PP (IN for) (NP (NP (DT the) (NX (NX (NN need)) (CC and) (NX (JJ potential) (NN benefit)))) (PP (IN of) (S (VP (VBG exploiting) (NP (NP (DT this) (JJ rich) (NN parallelism)) (PP (IN in) (NP (JJ state-of-the-art) (JJ non-linear) (NNS networks)))) (PP (IN for) (S (VP (VBG reducing) (NP (DT the) (NN training) (NN time))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP identify) (NP (NP (DT the) (NNS challenges) (CC and) (NNS limitations)) (PP (IN in) (S (VP (VBG enabling) (NP (JJ concurrent) (NN layer) (NN execution)) (PP (IN on) (NP (NP (NP (NNP GPU) (NNS backends)) (PRN (-LRB- -LRB-) (PP (JJ such) (IN as) (NP (NN cuDNN))) (-RRB- -RRB-))) (PP (IN of) (NP (NNP DL) (NNS frameworks)))))))))) (CC and) (VP (JJ propose) (NP (JJ potential) (NNS solutions)))) (. .))
