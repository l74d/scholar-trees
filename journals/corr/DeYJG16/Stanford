(S (NP (NP (JJ Classical) (JJ stochastic) (NN gradient) (NNS methods)) (PP (IN for) (NP (NN optimization)))) (VP (VBP rely) (PP (IN on) (NP (NP (JJ noisy) (NN gradient) (NNS approximations)) (SBAR (WHNP (WDT that)) (S (VP (VBP become) (ADJP (ADJP (RB progressively) (RBR less) (JJ accurate)) (SBAR (IN as) (S (NP (NNS iterates)) (VP (VBP approach) (NP (DT a) (NN solution)))))))))))) (. .))
(S (NP (NP (DT The) (JJ large) (NN noise)) (CC and) (NP (NP (JJ small) (NN signal)) (PP (IN in) (NP (DT the) (VBG resulting) (NNS gradients))))) (VP (VBZ makes) (S (NP (PRP it)) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB use) (NP (PRP them)) (PP (IN for) (NP (NP (JJ adaptive) (NN stepsize) (NN selection)) (CC and) (NP (JJ automatic) (NN stopping)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (JJ alternative) (`` ") (JJ big) (NN batch) ('' ") (NNP SGD) (NNS schemes)) (SBAR (WHNP (WDT that)) (S (ADVP (RB adaptively)) (VP (VBP grow) (NP (NP (DT the) (NN batch) (NN size)) (PP (IN over) (NP (NN time)))) (S (VP (TO to) (VP (VB maintain) (NP (NP (DT a) (ADJP (RB nearly) (JJ constant)) (NML (NML (NN signal)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN noise)))) (NN ratio)) (PP (IN in) (NP (DT the) (NN gradient) (NN approximation))))))))))) (. .))
(S (NP (DT The) (VBG resulting) (NNS methods)) (VP (VP (VBP have) (NP (JJ similar) (NN convergence) (NNS rates)) (PP (IN to) (NP (JJ classical) (NNP SGD)))) (, ,) (CC and) (VP (VBP do) (RB not) (VP (VB require) (NP (NP (NN convexity)) (PP (IN of) (NP (DT the) (NN objective))))))) (. .))
(S (NP (DT The) (NML (JJ high) (NN fidelity)) (NNS gradients)) (VP (VP (VBP enable) (NP (VBN automated) (NML (NN learning) (NN rate)) (NN selection))) (CC and) (VP (VBP do) (RB not) (VP (VB require) (NP (JJ stepsize) (NN decay))))) (. .))
(S (NP (JJ Big) (NN batch) (NNS methods)) (VP (VP (VBP are) (ADVP (RB thus) (RB easily)) (NP (VBN automated))) (CC and) (VP (MD can) (VP (VB run) (PP (IN with) (NP (QP (JJ little) (CC or) (DT no)) (NN oversight)))))) (. .))
