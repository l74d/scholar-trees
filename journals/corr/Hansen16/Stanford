(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT a) (JJ novel) (NN definition)) (PP (IN of) (NP (NP (DT the) (NN reinforcement)) (VP (VBG learning) (NP (NP (NP (NN state)) (, ,) (NP (NNS actions)) (CC and) (NP (NN reward) (NN function))) (SBAR (WHNP (WDT that)) (S (VP (VBZ allows) (S (NP (DT a) (NML (JJ deep) (NN Q)) (HYPH -) (NN network) (PRN (-LRB- -LRB-) (NP (NN DQN)) (-RRB- -RRB-))) (VP (TO to) (VP (VB learn) (S (VP (TO to) (VP (VB control) (NP (DT an) (NN optimization) (NN hyperparameter))))))))))))))))) (. .))
(S (S (VP (VBG Using) (NP (NML (NML (NN Q) (HYPH -) (NN learning)) (PP (IN with) (NP (NN experience)))) (NN replay)))) (, ,) (NP (PRP we)) (VP (VBP train) (NP (CD two) (NNS DQNs)) (S (VP (TO to) (VP (VB accept) (NP (NP (DT a) (NN state) (NN representation)) (PP (IN of) (NP (DT an) (JJ objective) (NN function)))) (PP (IN as) (NP (NP (NN input) (CC and) (NN output)) (NP (NP (DT the) (VBN expected) (VBN discounted) (NN return)) (PP (IN of) (NP (NNS rewards)))) (, ,) (CC or) (NP (NP (NN q) (HYPH -) (NNS values)) (, ,) (VP (VBN connected) (PP (IN to) (NP (NP (DT the) (NNS actions)) (PP (IN of) (S (VP (CC either) (VP (VBG adjusting) (NP (DT the) (NN learning) (NN rate))) (CC or) (VP (VBG leaving) (S (NP (PRP it)) (ADJP (JJ unchanged))))))))))))))))) (. .))
(S (NP (DT The) (CD two) (NNS DQNs)) (VP (VP (VBP learn) (S (NP (DT a) (NN policy)) (ADJP (JJ similar) (PP (IN to) (NP (DT a) (NN line) (NN search)))))) (, ,) (CC but) (VP (VBP differ) (PP (IN in) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (VBN allowed) (NNS actions))))))) (. .))
(NP (NP (DT The) (VBN trained) (NNS DQNs)) (PP (IN in) (NP (NN combination))) (PP (IN with) (NP (NP (ADJP (NP (DT a) (NN gradient)) (HYPH -) (VBN based)) (NN update) (JJ routine) (NN form)) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (DT the) (NML (NN Q) (HYPH -) (NN gradient)) (NN descent) (NNS algorithms)))))) (. .))
(S (S (VP (TO To) (VP (VB demonstrate) (NP (NP (DT the) (NN viability)) (PP (IN of) (NP (DT this) (NN framework))))))) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (SBAR (IN that) (S (NP (NP (NP (DT the) (NNP DQN) (POS 's)) (NN q) (HYPH -) (NNS values)) (VP (VBN associated) (PP (IN with) (NP (JJ optimal) (NN action))))) (VP (VBP converge)))) (CC and) (SBAR (IN that) (S (NP (DT the) (NML (NN Q) (HYPH -) (NN gradient)) (NN descent) (NNS algorithms)) (VP (VBP outperform) (NP (NN gradient) (NN descent)) (PP (IN with) (NP (NP (DT an) (NNP Armijo)) (CC or) (NP (JJ nonmonotone) (NN line) (NN search))))))))) (. .))
(S (S (PP (IN Unlike) (NP (JJ traditional) (NN optimization) (NNS methods))) (, ,) (NP (NML (NN Q) (HYPH -) (NN gradient)) (NN descent)) (VP (MD can) (VP (VB incorporate) (NP (DT any) (JJ objective) (NN statistic))))) (CC and) (S (PP (IN by) (S (VP (VBG varying) (NP (DT the) (NNS actions))))) (NP (PRP we)) (VP (VBP gain) (NP (NN insight)) (PP (IN into) (NP (NP (NP (DT the) (NN type)) (PP (IN of) (NP (NML (NN learning) (NN rate)) (NN adjustment) (NNS strategies)))) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (JJ successful) (PP (IN for) (NP (JJ neural) (NN network) (NN optimization))))))))))) (. .))
