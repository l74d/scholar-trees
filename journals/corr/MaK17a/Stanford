(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN generalization)) (PP (IN of) (NP (DT the) (NN Batch) (NN Normalization) (PRN (-LRB- -LRB-) (NP (NN BN)) (-RRB- -RRB-)) (NN algorithm)))) (, ,) (S (VP (VBG diminishing) (NP (NP (NN batch) (NN normalization) (PRN (-LRB- -LRB-) (NP (NN DBN)) (-RRB- -RRB-))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP update) (NP (DT the) (NN BN) (NNS parameters)) (PP (IN in) (NP (NP (DT a)) (VP (VBG diminishing) (S (VP (VBG moving) (NP (JJ average) (NN way)))))))))))))) (. .))
(S (NP (NNP BN)) (VP (VBZ is) (ADJP (RB very) (JJ effective) (PP (IN in) (S (VP (VBG accelerating) (NP (NP (DT the) (NN convergence)) (PP (IN of) (NP (NP (DT a) (NML (JJ neural) (NN network)) (NN training) (NN phase)) (SBAR (WHNP (WDT that)) (S (NP (PRP it)) (VP (VBZ has) (VP (VBN become) (NP (DT a) (JJ common) (NN practice)))))))))))))) (. .))
(S (NP (PRP$ Our) (VBN proposed) (NN DBN) (NN algorithm)) (VP (VBZ remains) (NP (NP (DT the) (JJ overall) (NN structure)) (PP (IN of) (NP (DT the) (JJ original) (NN BN) (NN algorithm)))) (SBAR (IN while) (S (VP (VBZ introduces) (NP (DT a) (JJ weighted) (NN averaging) (NN update)) (PP (IN to) (NP (DT some) (ADJP (JJ trainable)) (NNS parameters))))))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (NP (NP (DT an) (NN analysis)) (PP (IN of) (NP (NP (DT the) (NN convergence)) (PP (IN of) (NP (DT the) (NNP DBN) (NN algorithm)))))) (SBAR (WHNP (WDT that)) (S (VP (VBZ converges) (PP (IN to) (NP (NP (DT a) (JJ stationary) (NN point)) (PP (IN with) (NP (NN respect))))) (PP (IN to) (NP (ADJP (JJ trainable)) (NNS parameters)))))))) (. .))
(S (NP (PRP$ Our) (NN analysis)) (VP (MD can) (VP (VB be) (ADVP (RB easily)) (VP (VBN generalized) (PP (IN for) (NP (JJ original) (NN BN) (NN algorithm))) (PP (IN by) (S (VP (VBG setting) (NP (DT some) (NNS parameters)) (PP (IN to) (ADJP (JJ constant))))))))) (. .))
(S (PP (IN To) (NP (NP (DT the) (JJS best) (NN knowledge)) (PP (IN of) (NP (NNS authors))))) (, ,) (NP (DT this) (NN analysis)) (VP (VBZ is) (NP (NP (DT the) (JJ first)) (PP (IN of) (NP (NP (PRP$ its) (NN kind)) (PP (IN for) (NP (NP (NN convergence)) (PP (IN with) (NP (NP (NN Batch) (NN Normalization)) (VP (VBN introduced)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP analyze) (NP (NP (DT a) (NML (CD two) (HYPH -) (NN layer)) (NN model)) (PP (IN with) (NP (JJ arbitrary) (NN activation) (NN function))))) (. .))
(S (NP (NP (DT The) (JJ primary) (NN challenge)) (PP (IN of) (NP (DT the) (NN analysis)))) (VP (VBZ is) (NP (DT the) (NN fact)) (SBAR (IN that) (S (NP (DT some) (NNS parameters)) (VP (VBP are) (VP (VBN updated) (PP (IN by) (NP (NN gradient))) (SBAR (IN while) (S (NP (NNS others)) (VP (VBP are) (RB not))))))))) (. .))
(S (NP (DT The) (NN convergence) (NN analysis)) (VP (VBZ applies) (PP (IN to) (NP (NP (DT any) (NN activation) (NN function)) (SBAR (WHNP (WDT that)) (S (VP (VBZ satisfies) (NP (PRP$ our) (JJ common) (NNS assumptions)))))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ numerical) (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBP test) (NP (DT the) (VBN proposed) (NN algorithm)) (PP (IN on) (NP (NP (JJ complex) (JJ modern) (NNP CNN) (NNS models)) (PP (IN with) (NP (NP (JJ stochastic) (NNS gradients)) (CC and) (NP (NN ReLU) (NN activation))))))) (. .))
(S (NP (PRP We)) (VP (VBP observe) (SBAR (IN that) (S (NP (NNP DBN)) (VP (VBZ outperforms) (NP (NP (DT the) (JJ original) (NN BN) (NN algorithm)) (PP (IN on) (NP (NP (NNP MNIST) (, ,) (NNP NI) (CC and) (NNP CIFAR)) (HYPH -) (NP (CD 10) (NNS datasets))))) (PP (IN with) (NP (JJ reasonable) (JJ complex) (NML (NNP FNN) (CC and) (NNP CNN)) (NNS models))))))) (. .))
