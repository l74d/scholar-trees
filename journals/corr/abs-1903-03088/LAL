(S (NP (NNP Hyperparameter) (NN optimization)) (VP (MD can) (VP (VB be) (VP (VBN formulated) (PP (IN as) (NP (NP (DT a) (NN bilevel) (NN optimization) (NN problem)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (JJ optimal) (NNS parameters)) (PP (IN on) (NP (DT the) (NN training) (VBN set)))) (VP (VBP depend) (PP (IN on) (NP (DT the) (NNS hyperparameters))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP aim) (S (VP (TO to) (VP (VB adapt) (NP (NN regularization) (NNS hyperparameters)) (PP (IN for) (NP (JJ neural) (NNS networks))) (PP (IN by) (S (VP (VBG fitting) (NP (JJ compact) (NNS approximations)) (PP (TO to) (NP (NP (DT the) (JJ best-response) (NN function)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ maps) (NP (NNS hyperparameters)) (PP (TO to) (NP (VB optimal) (NNS weights) (CC and) (NNS biases))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB construct) (NP (NP (JJ scalable) (JJ best-response) (NNS approximations)) (PP (IN for) (NP (JJ neural) (NNS networks)))) (PP (IN by) (S (VP (VBG modeling) (NP (DT the) (NN best-response)) (PP (IN as) (NP (NP (DT a) (JJ single) (NN network)) (SBAR (WHNP (WP$ whose) (JJ hidden) (NNS units)) (S (VP (VBP are) (VP (VBN gated) (ADVP (RB conditionally)) (PP (IN on) (NP (DT the) (NN regularizer))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP justify) (NP (DT this) (NN approximation)) (PP (IN by) (S (VP (VBG showing) (SBAR (S (NP (NP (DT the) (JJ exact) (NN best-response)) (PP (IN for) (NP (NP (DT a) (JJ shallow) (JJ linear) (NN network)) (PP (IN with) (NP (JJ L2-regularized) (JJ Jacobian)))))) (VP (MD can) (VP (VB be) (VP (VBN represented) (PP (IN by) (NP (DT a) (JJ similar) (NN gating) (NN mechanism)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP fit) (NP (DT this) (NN model)) (S (VP (VBG using) (NP (NP (DT a) (JJ gradient-based) (NN hyperparameter) (NN optimization) (NN algorithm)) (SBAR (WHNP (WDT which)) (S (VP (VBZ alternates) (PP (IN between) (S (VP (VP (VBG approximating) (NP (NP (DT the) (NN best-response)) (PP (IN around) (NP (DT the) (JJ current) (NNS hyperparameters))))) (CC and) (VP (VBG optimizing) (NP (DT the) (NNS hyperparameters)) (S (VP (VBG using) (NP (DT the) (JJ approximate) (JJ best-response) (NN function))))))))))))))) (. .))
(S (PP (IN Unlike) (NP (JJ other) (JJ gradient-based) (NNS approaches))) (, ,) (NP (PRP we)) (VP (VBP do) (RB not) (VP (VB require) (S (VP (VBG differentiating) (NP (DT the) (NN training) (NN loss)) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (DT the) (NNS hyperparameters))))))) (, ,) (S (VP (VBG allowing) (S (NP (PRP us)) (VP (TO to) (VP (VB tune) (NP (NP (JJ discrete) (NNS hyperparameters)) (, ,) (NP (NNS data) (NN augmentation) (NNS hyperparameters)) (, ,) (CC and) (NP (NN dropout) (NNS probabilities)))))))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NNS hyperparameters)) (VP (VBP are) (VP (VBN adapted) (ADVP (NN online)))))) (, ,) (NP (PRP$ our) (NN approach)) (VP (NNS discovers) (NP (NP (VBP hyperparameter) (NNS schedules)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB outperform) (NP (VBN fixed) (NN hyperparameter) (NNS values)))))))) (. .))
(S (ADVP (RB Empirically)) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ outperforms) (NP (VBG competing) (JJ hyperparameter) (NN optimization) (NNS methods)) (PP (IN on) (NP (JJ large-scale) (JJ deep) (NN learning) (NNS problems)))) (. .))
(S (NP (PRP We)) (VP (VBP call) (S (NP (NP (PRP$ our) (NNS networks)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP update) (NP (PRP$ their) (JJ own) (NNS hyperparameters)) (ADVP (VBP online)) (PP (IN during) (NP (NN training)))))) (, ,)) (NP (NP (JJ Self-Tuning) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP STNs)) (-RRB- -RRB-))))) (. .))
