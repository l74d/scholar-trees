(S (NP (NN Hyperparameter) (NN optimization)) (VP (MD can) (VP (VB be) (VP (VBN formulated) (PP (IN as) (NP (NP (DT a) (NML (NN bilevel) (NN optimization)) (NN problem)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (JJ optimal) (NNS parameters)) (PP (IN on) (NP (DT the) (NN training) (NN set)))) (VP (VBP depend) (PP (IN on) (NP (DT the) (NNS hyperparameters))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP aim) (S (VP (TO to) (VP (VB adapt) (NP (NP (NN regularization) (NNS hyperparameters)) (PP (IN for) (NP (JJ neural) (NNS networks)))) (PP (IN by) (NP (JJ fitting) (JJ compact) (NNS approximations))) (PP (IN to) (NP (NP (NP (DT the) (RBS best)) (HYPH -) (NP (NN response) (NN function))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ maps) (NP (NNS hyperparameters)) (PP (IN to) (NP (JJ optimal) (NNS weights) (CC and) (NNS biases)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB construct) (NP (ADJP (JJ scalable) (NP (NP (RBS best)) (HYPH -) (NP (NN response)))) (NNS approximations)) (PP (IN for) (NP (JJ neural) (NNS networks))) (PP (IN by) (S (VP (VBG modeling) (NP (NP (DT the) (RBS best)) (PP (HYPH -) (NP (NN response)))) (PP (IN as) (NP (NP (DT a) (JJ single) (NN network)) (SBAR (WHNP (WP$ whose) (NML (JJ hidden) (NNS units))) (S (VP (VBP are) (ADJP (VBN gated) (PP (ADVP (RB conditionally)) (IN on) (NP (DT the) (NN regularizer))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP justify) (NP (DT this) (NN approximation)) (PP (IN by) (S (VP (VBG showing) (NP (DT the) (JJ exact)) (NP (NP (NP (RBS best)) (HYPH -) (NP (NN response))) (PP (IN for) (NP (DT a) (NML (NML (NML (NML (JJ shallow) (JJ linear) (NN network)) (PP (IN with) (NP (NN L2)))) (HYPH -) (VP (VBN regularized) (SBAR (S (NP (NNP Jacobian)) (VP (MD can) (VP (VB be) (VP (VBN represented) (PP (IN by) (NP (DT a) (JJ similar)))))))))) (NN gating)) (NN mechanism)))))))) (. .))
(S (NP (PRP We)) (VP (VBP fit) (NP (DT this) (NN model)) (S (VP (VBG using) (NP (NP (NP (DT a) (ADJP (NP (NN gradient)) (HYPH -) (VBN based)) (NML (NN hyperparameter) (NN optimization)) (NN algorithm)) (SBAR (WHNP (WDT which)) (S (VP (VBZ alternates) (PP (IN between) (S (VP (VP (VBG approximating) (NP (NP (NP (DT the) (RBS best)) (HYPH -) (NP (NN response))) (PP (IN around) (NP (DT the) (JJ current) (NNS hyperparameters))))) (CC and) (VP (VBG optimizing) (NP (DT the) (NNS hyperparameters)) (S (VP (VBG using) (NP (DT the) (JJ approximate)) (ADVP (RBS best)))))))))))) (PP (HYPH -) (NP (NN response) (NN function))))))) (. .))
(S (PP (IN Unlike) (NP (ADJP (NP (JJ other) (NN gradient)) (HYPH -) (VBN based)) (NNS approaches))) (, ,) (NP (PRP we)) (VP (VBP do) (RB not) (VP (VB require) (S (VP (VBG differentiating) (NP (NP (DT the) (NN training) (NN loss)) (PP (IN with) (NP (NN respect)))) (PP (IN to) (NP (DT the) (NNS hyperparameters))) (, ,) (S (VP (VBG allowing) (NP (PRP us)) (S (VP (TO to) (VP (VB tune) (NP (NP (JJ discrete) (NNS hyperparameters)) (, ,) (NP (NML (NNS data) (NN augmentation)) (NNS hyperparameters)) (, ,) (CC and) (NP (NN dropout) (NNS probabilities)))))))))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NNS hyperparameters)) (VP (VBP are) (VP (VBN adapted) (ADVP (RB online)))))) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ discovers) (NP (NP (NN hyperparameter) (NNS schedules)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB outperform) (NP (VBN fixed) (NN hyperparameter) (NNS values)))))))) (. .))
(S (ADVP (RB Empirically)) (, ,) (NP (PRP$ our) (NN approach)) (VP (VBZ outperforms) (NP (NP (VBG competing) (NN hyperparameter) (NN optimization) (NNS methods)) (PP (IN on) (NP (NML (JJ large) (HYPH -) (NN scale)) (NML (JJ deep) (NN learning)) (NNS problems))))) (. .))
(S (NP (PRP We)) (VP (VBP call) (NP (NP (PRP$ our) (NNS networks)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP update) (NP (PRP$ their) (JJ own) (NNS hyperparameters)) (ADVP (RB online)) (PP (IN during) (NP (NP (NN training)) (, ,) (NP (NP (ADJP (NN Self) (HYPH -) (VBG Tuning)) (NNS Networks)) (-LRB- -LRB-) (NP (NNS STNs)) (-RRB- -RRB-))))))))) (. .))
