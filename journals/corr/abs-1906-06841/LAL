(S (NP (PRP We)) (VP (VBP present) (NP (DT a) (JJ novel) (ADJP (NN reinforcement) (JJ learning-based)) (JJ natural) (NNS media) (VBG painting) (NN algorithm))) (. .))
(S (S (NP (PRP$ Our) (NN goal)) (VP (VBZ is) (S (VP (TO to) (VP (VB reproduce) (NP (DT a) (NN reference) (NN image)) (S (VP (VBG using) (NP (JJ brush) (NNS strokes))))))))) (CC and) (S (NP (PRP we)) (VP (VBP encode) (NP (DT the) (NN objective)) (PP (IN through) (NP (NNS observations))))) (. .))
(S (NP (PRP$ Our) (NN formulation)) (VP (VBZ takes) (PP (IN into) (NP (NN account))) (SBAR (IN that) (S (S (NP (NP (DT the) (NN distribution)) (PP (IN of) (NP (DT the) (NN reward))) (PP (IN in) (NP (DT the) (NN action) (NN space)))) (VP (VBZ is) (ADJP (JJ sparse)))) (CC and) (S (S (VP (VBG training) (NP (DT a) (NN reinforcement) (VBG learning) (NN algorithm)) (PP (IN from) (NP (NN scratch))))) (VP (MD can) (VP (VB be) (ADJP (JJ difficult)))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT an) (NN approach)) (SBAR (WHNP (WDT that)) (S (VP (VBZ combines) (NP (NP (JJ self-supervised) (NN learning)) (CC and) (NP (NN reinforcement) (NN learning))) (S (VP (TO to) (VP (VP (ADVP (RB effectively)) (VB transfer) (NP (JJ negative) (NNS samples)) (PP (IN into) (NP (JJ positive) (NNS ones)))) (CC and) (VP (VB change) (NP (DT the) (NN reward) (NN distribution))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (NP (NP (DT the) (NNS benefits)) (PP (IN of) (NP (PRP$ our) (VBG painting) (NN agent))) (S (VP (TO to) (VP (VB reproduce) (NP (NN reference) (NNS images)) (PP (IN with) (NP (JJ brush) (NNS strokes)))))))) (. .))
(S (S (NP (DT The) (NN training) (NN phase)) (VP (VBZ takes) (NP (QP (IN about) (CD one)) (NN hour)))) (CC and) (S (NP (DT the) (NN runtime) (NN algorithm)) (VP (VBZ takes) (NP (QP (IN about) (CD 30)) (NNS seconds)) (PP (IN on) (NP (NP (DT a) (NNP GTX1080) (NNP GPU)) (VP (VBG reproducing) (NP (DT a) (CD 1000x800) (NN image)) (PP (IN with) (NP (CD 20,000) (NNS strokes)))))))) (. .))
