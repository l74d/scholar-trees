(S (NP (NP (JJ Recurrent) (JJ neural) (NNS networks)) (PRN (-LRB- -LRB-) (NP (NNP RNNs)) (-RRB- -RRB-))) (VP (VBP are) (NP (NP (JJ important) (NN class)) (PP (IN of) (NP (NNS architectures))) (PP (IN among) (NP (NP (JJ neural) (NNS networks)) (ADJP (JJ useful) (PP (IN for) (NP (NP (NN language) (NN modeling)) (CC and) (NP (JJ sequential) (NN prediction))))))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG optimizing) (NP (NNP RNNs)))) (VP (VBZ is) (VP (VBN known) (S (VP (TO to) (VP (VB be) (ADJP (JJR harder)) (PP (VBN compared) (PP (TO to) (NP (JJ feed-forward) (JJ neural) (NNS networks))))))))) (. .))
(S (NP (NP (DT A) (NN number)) (PP (IN of) (NP (NNS techniques)))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN in) (NP (NN literature))) (S (VP (TO to) (VP (VB address) (NP (DT this) (NN problem)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN simple) (NN technique)) (VP (VBD called) (S (NP (JJ fraternal) (NN dropout)))) (SBAR (WHNP (WDT that)) (S (VP (VBZ takes) (NP (NN advantage)) (PP (IN of) (NP (NN dropout))) (S (VP (TO to) (VP (VB achieve) (NP (DT this) (NN goal)))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB train) (NP (NP (CD two) (JJ identical) (NNS copies)) (PP (IN of) (NP (DT an) (NNP RNN))) (PRN (-LRB- -LRB-) (SBAR (WHNP (IN that)) (S (VP (NN share) (NP (NNS parameters))))) (-RRB- -RRB-))) (PP (IN with) (NP (JJ different) (NN dropout) (NNS masks))) (SBAR (IN while) (S (VP (VBG minimizing) (NP (NP (DT the) (NN difference)) (PP (IN between) (NP (PRP$ their) (PRN (-LRB- -LRB-) (NN pre-softmax) (-RRB- -RRB-)) (NNS predictions))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN way))) (NP (PRP$ our) (NN regularization)) (VP (VBZ encourages) (S (NP (NP (DT the) (NNS representations)) (PP (IN of) (NP (NNP RNNs)))) (VP (TO to) (VP (VB be) (ADJP (JJ invariant) (S (VP (TO to) (VP (VB dropout) (NN mask))))) (, ,) (S (ADVP (RB thus)) (VP (VBG being) (ADJP (JJ robust)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN regularization) (NN term)) (VP (VBZ is) (ADJP (JJ upper) (VBN bounded) (PP (IN by) (NP (NP (DT the) (JJ expectation-linear) (NN dropout) (NN objective)) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB address) (NP (NP (DT the) (NN gap)) (PP (JJ due) (PP (TO to) (NP (NP (DT the) (NN difference)) (PP (IN between) (NP (NP (DT the) (NN train) (CC and) (NN inference) (NNS phases)) (PP (IN of) (NP (NN dropout)))))))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (PRP$ our) (NN model))) (CC and) (VP (VB achieve) (NP (JJ state-of-the-art) (NNS results)) (PP (IN in) (NP (NN sequence) (NN modeling) (NNS tasks)))) (PP (IN on) (NP (NP (CD two) (NN benchmark) (NNS datasets)) (: -) (NP (NP (NNP Penn) (NNP Treebank)) (CC and) (NP (NNP Wikitext-2)))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (VBZ leads) (PP (TO to) (NP (NP (NN performance) (NN improvement)) (PP (IN by) (NP (DT a) (JJ significant) (NN margin))) (PP (IN in) (NP (NP (NP (NN image) (NN captioning)) (PRN (-LRB- -LRB-) (NP (NNP Microsoft) (NNP COCO)) (-RRB- -RRB-))) (CC and) (NP (JJ semi-supervised) (PRN (-LRB- -LRB-) (NNP CIFAR-10) (-RRB- -RRB-)) (NNS tasks)))))))))) (. .))
