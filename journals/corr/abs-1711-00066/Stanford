(S (NP (NP (JJ Recurrent) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (VP (VBP are) (NP (NP (JJ important) (NN class)) (PP (IN of) (NP (NNS architectures)))) (PP (IN among) (NP (JJ neural) (NNS networks))) (ADJP (JJ useful) (PP (IN for) (NP (NP (NN language) (NN modeling)) (CC and) (NP (JJ sequential) (NN prediction)))))) (. .))
(S (ADVP (RB However)) (, ,) (S (VP (VBG optimizing) (NP (NNS RNNs)))) (VP (VBZ is) (VP (VBN known) (S (VP (TO to) (VP (VB be) (ADVP (RBR harder)) (VP (VBN compared) (PP (IN to) (NP (NML (NN feed) (HYPH -) (JJ forward)) (JJ neural) (NNS networks))))))))) (. .))
(S (NP (NP (DT A) (NN number)) (PP (IN of) (NP (NNS techniques)))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (PP (IN in) (NP (NN literature))) (S (VP (TO to) (VP (VB address) (NP (DT this) (NN problem)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ simple) (NN technique)) (VP (VBN called) (NP (NP (JJ fraternal) (NN dropout)) (SBAR (WHNP (WDT that)) (S (VP (VBZ takes) (NP (NP (NN advantage)) (PP (IN of) (NP (NN dropout) (S (VP (TO to) (VP (VB achieve) (NP (DT this) (NN goal))))))))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (NP (PRP we)) (VP (VBP propose) (PP (IN to) (NP (NN train))) (NP (NP (CD two) (JJ identical) (NNS copies)) (PP (IN of) (NP (DT an) (NN RNN) (PRN (-LRB- -LRB-) (SBAR (IN that) (FRAG (NP (NN share) (NNS parameters)))) (-RRB- -RRB-))))) (PP (IN with) (NP (JJ different) (NN dropout) (NNS masks))) (PP (IN while) (S (VP (VBG minimizing) (NP (NP (DT the) (NN difference)) (PP (IN between) (NP (PRP$ their) (-LRB- -LRB-) (NN pre-softmax) (-RRB- -RRB-) (NNS predictions)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN way))) (NP (PRP$ our) (NN regularization)) (VP (VBZ encourages) (NP (NP (DT the) (NNS representations)) (PP (IN of) (NP (NNS RNNs) (S (VP (TO to) (VP (VB be) (ADJP (JJ invariant) (PP (IN to) (NP (NN dropout) (NN mask)))))))))) (, ,) (S (ADVP (RB thus)) (VP (VBG being) (ADJP (JJ robust))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN regularization) (NN term)) (VP (VBZ is) (ADJP (JJ upper)) (S (VP (VBN bounded) (PP (IN by) (NP (NP (DT the) (ADJP (NP (NN expectation)) (HYPH -) (JJ linear)) (NN dropout) (NN objective)) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB address) (NP (DT the) (NN gap)) (PP (IN due) (PP (IN to) (NP (NP (NP (DT the) (NN difference)) (PP (IN between) (NP (DT the) (NN train)))) (CC and) (NP (NP (NN inference) (NNS phases)) (PP (IN of) (NP (NN dropout))))))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (PRP$ our) (NN model))) (CC and) (VP (VB achieve) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NNS results)) (PP (IN in) (NP (NML (NN sequence) (NN modeling)) (NNS tasks))) (PP (IN on) (NP (NP (CD two) (NN benchmark) (NNS datasets)) (, -) (NP (NNP Penn) (NNP Treebank)) (CC and) (NP (NNP Wikitext) (HYPH -) (NNP 2)))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (VP (VBZ leads) (PP (IN to) (NP (NN performance) (NN improvement))) (PP (IN by) (NP (NP (DT a) (JJ significant) (NN margin)) (PP (IN in) (NP (NN image) (NN captioning))))) (PRN (-LRB- -LRB-) (NP (NNP Microsoft) (NNP COCO)) (-RRB- -RRB-))) (CC and) (VP (VBN semi-supervised) (S (NP (-LRB- -LRB-) (NML (NN CIFAR) (HYPH -) (CD 10)) (-RRB- -RRB-) (NNS tasks)))))))) (. .))
