(S (PP (VBN Based) (PP (IN on) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (ADJP (JJ different) (JJ exponential)) (NNS bases))) (S (VP (TO to) (VP (VB define) (NP (ADJP (NN class) (HYPH -) (JJ dependent)) (NN error) (NNS bounds)))))))) (, ,) (NP (NP (DT a) (ADJP (ADJP (JJ new)) (CC and) (ADJP (RB highly) (JJ efficient))) (ADJP (NP (JJ asymmetric)) (VBG boosting)) (NN scheme)) (, ,) (VP (VBN coined) (PP (IN as) (NP (NN AdaBoostDB))) (PRN (-LRB- -LRB-) (NML (JJ Double) (HYPH -) (NN Base)) (-RRB- -RRB-))) (, ,)) (VP (VBZ is) (VP (VBN proposed))) (. .))
(S (S (VP (VBN Supported) (PP (IN by) (NP (DT a) (ADJP (RB fully) (JJ theoretical)) (NN derivation) (NN procedure))))) (, ,) (PP (IN unlike) (NP (NP (JJS most)) (PP (IN of) (NP (NP (DT the) (JJ other) (NNS approaches)) (PP (IN in) (NP (DT the) (NN literature))))))) (, ,) (NP (PRP$ our) (NN algorithm)) (VP (VBZ preserves) (NP (NP (PDT all) (DT the) (JJ formal) (NNS guarantees) (CC and) (NNS properties)) (PP (IN of) (NP (NP (NP (NP (JJ original)) (-LRB- -LRB-) (ADJP (NN cost) (HYPH -) (JJ insensitive)) (-RRB- -RRB-)) (NP (NNP AdaBoost)) (, ,) (ADVP (RB similarly))) (PP (IN to) (NP (DT the) (ADJP (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NN Cost)) (HYPH -) (JJ Sensitive)) (NNP AdaBoost) (NN algorithm))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (JJ key) (NN advantage)) (PP (IN of) (NP (NNP AdaBoostDB)))) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP$ our) (JJ novel) (NN derivation) (NN scheme)) (VP (VBZ enables) (NP (DT an) (ADJP (RB extremely) (JJ efficient)) (NML (JJ conditional) (NN search)) (NN procedure)) (, ,) (ADVP (RB dramatically)) (S (VP (VBG improving) (CC and) (VBG simplifying) (NP (NP (DT the) (NN training) (NN phase)) (PP (IN of) (NP (DT the) (NN algorithm)))))))))) (. .))
(S (NP (NP (NNS Experiments)) (, ,) (NP (CC both) (NP (IN over) (JJ synthetic)) (CC and) (NP (JJ real) (NNS datasets))) (, ,)) (VP (VBP reveal) (SBAR (IN that) (S (NP (NNP AdaBoostDB)) (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB save) (PP (IN over) (NP (NP (NML (CD 99) (NN %)) (NN training) (NN time)) (PP (IN with) (NP (NN regard))))) (PP (IN to) (NP (ADJP (NP (NN Cost)) (HYPH -) (JJ Sensitive)) (NNP AdaBoost))) (, ,) (S (VP (VBG providing) (NP (DT the) (JJ same) (ADJP (NN cost) (HYPH -) (JJ sensitive)) (NNS results)))))))))))) (. .))
(S (NP (NP (DT This) (JJ computational) (NN advantage)) (PP (IN of) (NP (NNP AdaBoostDB)))) (VP (MD can) (VP (VB make) (NP (DT a) (NN difference)) (PP (IN in) (NP (NP (NNS problems)) (VP (VBG managing) (NP (NP (JJ huge) (NNS pools)) (PP (IN of) (NP (NP (JJ weak) (NNS classifiers)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (S (VP (VBG boosting) (NP (NNS techniques)))) (VP (VBP are) (ADVP (RB commonly)) (VP (VBN used))))))))))))) (. .))
