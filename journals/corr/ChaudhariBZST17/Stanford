(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN algorithm)) (VP (VBN called) (NP (NP (NNP Parle)) (PP (IN for) (NP (NP (JJ parallel) (NN training)) (PP (IN of) (NP (NP (JJ deep) (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (VBZ converges) (ADJP (ADJP (NP (CD 2) (HYPH -) (NN 4x)) (RBR faster)) (PP (IN than) (NP (NP (DT a) (NML (NN data) (HYPH -) (NN parallel)) (NN implementation)) (PP (IN of) (NP (NNP SGD)))))) (, ,) (PP (IN while) (S (VP (VBG achieving) (NP (NP (ADJP (RB significantly) (VBN improved)) (NN error) (NNS rates)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (NP (RB nearly) (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art))))))) (PP (IN on) (NP (NP (JJ several) (NNS benchmarks)) (PP (VBG including) (NP (NP (NN CIFAR) (HYPH -) (CD 10)) (CC and) (NP (NN CIFAR) (HYPH -) (CD 100)))))) (, ,) (PP (IN without) (S (VP (VBG introducing) (NP (DT any) (JJ additional) (ADJP (JJ hyper) (HYPH -)) (NNS parameters))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP exploit) (NP (NP (DT the) (NN phenomenon)) (PP (IN of) (NP (NP (JJ flat) (NN minima)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN shown) (S (VP (TO to) (VP (VB lead) (PP (IN to) (NP (NP (VBN improved) (NN generalization) (NN error)) (PP (IN for) (NP (JJ deep) (NNS networks))))))))))))))))) (. .))
(S (NP (NNP Parle)) (VP (VP (VBZ requires) (NP (ADJP (RB very) (JJ infrequent)) (NN communication)) (PP (IN with) (NP (DT the) (NN parameter) (NN server)))) (CC and) (VP (ADVP (RB instead)) (VBZ performs) (NP (JJR more) (NN computation)) (PP (IN on) (NP (NP (DT each) (NN client)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (S (NP (PRP it)) (ADJP (ADJP (RB well) (HYPH -) (VBN suited)) (PP (IN to) (NP (NP (DT both) (NML (JJ single) (HYPH -) (NN machine))) (, ,) (NP (NP (JJ multi-GPU) (NNS settings)) (CC and) (NP (VBN distributed) (NNS implementations)))))))))))))) (. .))
