(S (NP (PRP We)) (VP (VBP give) (NP (DT a) (JJ new) (NN algorithm)) (PP (IN for) (S (VP (VBG learning) (NP (DT a) (NML (CD two) (HYPH -) (NN layer)) (JJ neural) (NN network)) (PP (IN under) (NP (NP (DT a) (JJ general) (NN class)) (PP (IN of) (NP (NN input) (NNS distributions))))))))) (. .))
(FRAG (NP (NP (DT The) (JJ only) (NN requirement)) (PP (IN on) (NP (DT the) (NN input)))) (NP ($ $)) (PP (SYM x) (NP (NP ($ $)) (SBAR (S (VP (VBZ is) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (NP (NP (JJ symmetric)) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB still)) (VP (VBZ allows) (NP (ADJP (RB highly) (JJ complicated) (CC and) (JJ structured)) (NN input)))))))))))))) (. .))
(S (NP (PRP$ Our) (NN algorithm)) (VP (VP (VBZ is) (VP (VBN based) (PP (IN on) (NP (DT the) (NML (NML (NN method)) (HYPH -) (PP (IN of) (HYPH -) (NP (NNS moments)))) (NN framework))))) (CC and) (VP (VBZ extends) (NP (JJ several) (NNS results)) (PP (IN in) (NP (NN tensor) (NNS decompositions))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (JJ spectral) (NNS algorithms)) (S (VP (TO to) (VP (VB avoid) (NP (DT the) (JJ complicated) (JJ non-convex) (NN optimization)) (PP (IN in) (S (VP (VBG learning) (NP (JJ neural) (NNS networks))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN algorithm)) (VP (MD can) (ADVP (RB robustly)) (VP (VB learn) (NP (DT the) (ADJP (NP (NN ground) (HYPH -) (NN truth)) (JJ neural)) (NN network)) (PP (IN with) (NP (NP (DT a) (JJ small) (NN number)) (PP (IN of) (NP (NP (NNS samples)) (PP (IN for) (NP (JJ many) (JJ symmetric) (NN input) (NNS distributions)))))))))))) (. .))
