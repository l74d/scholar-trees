(S (S (VP (VBG Training) (NP (JJ deep) (NNS networks)))) (VP (VBZ is) (UCP (ADJP (JJ expensive)) (CC and) (ADJP (NN time) (HYPH -) (VBG consuming)) (PP (IN with) (NP (NP (DT the) (NN training) (NN period)) (VP (VBG increasing) (PP (IN with) (NP (NNS data) (NML (NN size) (CC and) (NN growth)))) (PP (IN in) (NP (NN model) (NNS parameters)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP provide) (NP (NP (DT a) (NN framework)) (PP (IN for) (NP (NP (VBN distributed) (NN training)) (PP (IN of) (NP (NP (JJ deep) (NNS networks)) (PP (IN over) (NP (NP (DT a) (NN cluster)) (PP (IN of) (NP (NP (NNS CPUs)) (PP (IN in) (NP (NNP Apache) (NNP Spark))))))))))))) (. .))
(S (NP (DT The) (NN framework)) (VP (VBZ implements) (S (NP (NP (DT both) (NNS Data) (NN Parallelism)) (CC and) (NP (NN Model) (NN Parallelism))) (VP (VBG making) (S (NP (PRP it)) (ADJP (JJ suitable) (S (VP (TO to) (VP (VB use) (PP (IN for) (NP (NP (JJ deep) (NNS networks)) (SBAR (WHNP (WDT which)) (S (VP (VBP require) (NP (NP (NP (JJ huge) (NN training) (NNS data)) (CC and) (NP (NN model) (NNS parameters))) (SBAR (WHNP (WDT which)) (S (VP (VBP are) (ADJP (RB too) (JJ big) (S (VP (TO to) (VP (VB fit) (PP (IN into) (NP (NP (DT the) (NN memory)) (PP (IN of) (NP (DT a) (JJ single) (NN machine)))))))))))))))))))))))))) (. .))
(S (NP (PRP It)) (VP (MD can) (VP (VB be) (VP (VBN scaled) (ADVP (RB easily)) (PP (IN over) (NP (NP (DT a) (NN cluster)) (PP (IN of) (NP (JJ cheap) (NN commodity) (NN hardware))))) (S (VP (TO to) (VP (VP (VB attain) (NP (JJ significant) (NN speedup))) (CC and) (VP (VB obtain) (NP (JJR better) (NNS results)) (S (VP (VBG making) (S (NP (PRP it)) (ADJP (RB quite) (JJ economical) (PP (IN as)))))))))) (PP (VBN compared) (PP (IN to) (NP (NP (NN farm)) (PP (IN of) (NP (NNS GPUs) (CC and) (NNS supercomputers))))))))) (. .))
(S (NP (PRP We)) (VP (VBP have) (VP (VBN proposed) (NP (NP (DT a) (JJ new) (NN algorithm)) (PP (IN for) (NP (NP (NN training)) (PP (IN of) (NP (JJ deep) (NNS networks)))))) (PP (IN for) (NP (NP (DT the) (NN case)) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN network)) (VP (VBZ is) (VP (VBN partitioned) (PP (IN across) (NP (NP (NP (NP (DT the) (NNS machines)) (-LRB- -LRB-) (NP (NNP Model) (NNP Parallelism)) (-RRB- -RRB-)) (ADVP (IN along) (PP (IN with) (NP (JJ detailed) (NN cost) (NN analysis) (CC and) (NN proof))))) (PP (IN of) (NP (NP (NN convergence)) (PP (IN of) (NP (DT the) (JJ same))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP have) (VP (VBN developed) (NP (NP (NP (NNS implementations)) (PP (IN for))) (VP (RB Fully) (HYPH -) (VBN Connected) (S (NP (NP (NNP Feedforward) (NNP Networks)) (, ,) (NP (NNP Convolutional) (JJ Neural) (NNS Networks)) (, ,) (NP (JJ Recurrent) (JJ Neural) (NNS Networks)) (CC and) (NP (JJ Long) (NML (JJ Short) (HYPH -) (NN Term)) (NN Memory) (NNS architectures)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP present) (NP (NP (DT the) (NNS results)) (PP (IN of) (NP (NP (JJ extensive) (NNS simulations)) (VP (VBG demonstrating) (NP (NP (DT the) (NN speedup) (CC and) (NN accuracy)) (VP (VBN obtained) (PP (IN by) (NP (PRP$ our) (NN framework))) (PP (IN for) (NP (NP (JJ different) (NNS sizes)) (PP (IN of) (NP (NP (DT the) (NNS data) (CC and) (NN model) (NNS parameters)) (PP (IN with) (NP (NN variation))))))))) (FRAG (PP (IN in) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NN worker) (NNS cores))))) (, /) (NP (NP (NNS partitions)) (: ;) (FRAG (ADVP (RB thereby)) (VP (VBG showing) (SBAR (IN that) (S (NP (PRP$ our) (VBN proposed) (NN framework)) (VP (MD can) (VP (VB achieve) (NP (JJ significant) (NN speedup)))))))))))))) (PRN (-LRB- -LRB-) (NP (NP (NN upto) (NN 11X)) (PP (IN for) (NP (NNP CNN)))) (-RRB- -RRB-))) (CC and) (VP (VBZ is) (ADVP (RB also)) (ADJP (RB quite) (JJ scalable)))) (. .))
