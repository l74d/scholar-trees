(S (PP (IN With) (NP (NP (DT the) (VBG growing) (NN attention)) (PP (IN on) (NP (NML (NML (NN learning)) (HYPH -) (SBAR (IN to) (HYPH -) (FRAG (S (VP (VB learn) (NP (NP (JJ new) (NNS tasks)) (VP (VBG using) (NP (QP (RB only) (DT a) (JJ few)))))))))) (NNS examples))))) (, ,) (NP (NN meta) (HYPH -) (NN learning)) (VP (VBZ has) (VP (VBN been) (ADVP (RB widely)) (VP (VBN used) (PP (IN in) (NP (NP (JJ numerous) (NNS problems)) (PP (JJ such) (IN as) (NP (NML (JJ few) (HYPH -) (NN shot)) (NML (NML (NN classification)) (, ,) (NML (NN reinforcement) (NN learning)) (, ,) (CC and) (NML (NN domain))) (NN generalization)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NML (NN meta) (HYPH -) (NN learning)) (NNS models)) (VP (VBP are) (ADJP (JJ prone) (PP (IN to) (S (VP (VBG overfitting) (SBAR (WHADVP (WRB when)) (S (NP (EX there)) (VP (VBP are) (NP (NP (DT no) (JJ sufficient) (NN training) (NNS tasks)) (PP (IN for) (NP (DT the) (NN meta) (HYPH -) (NNS learners))) (S (VP (TO to) (VP (VB generalize))))))))))))) (. .))
(S (SBAR (IN Although) (S (NP (NP (VBG existing) (NNS approaches)) (PP (JJ such) (IN as) (NP (NN Dropout)))) (VP (VBP are) (ADVP (RB widely)) (VP (VBN used) (S (VP (TO to) (VP (VB address) (NP (DT the) (NN overfitting) (NN problem))))))))) (, ,) (NP (DT these) (NNS methods)) (VP (VBP are) (ADVP (RB typically)) (VP (VBN designed) (PP (IN for) (NP (NP (VBG regularizing) (NNS models)) (PP (IN of) (NP (NP (DT a) (JJ single) (NN task)) (PP (IN in) (NP (JJ supervised) (NN training))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (DT a) (ADJP (JJ simple) (CC yet) (JJ effective)) (NN method)) (S (VP (TO to) (VP (VB alleviate) (NP (NP (DT the) (NN risk)) (PP (IN of) (S (VP (VBG overfitting) (PP (IN for) (NP (ADJP (NP (NN gradient)) (HYPH -) (VBN based)) (NML (NN meta) (HYPH -) (NN learning)))))))))))) (. .))
(S (ADVP (RB Specifically)) (, ,) (PP (IN during) (NP (ADJP (NP (DT the) (NN gradient)) (HYPH -) (VBN based)) (NN adaptation) (NN stage))) (, ,) (S (NP (PRP we)) (ADVP (RB randomly)) (VP (VB drop) (NP (DT the) (NN gradient)) (PP (IN in) (NP (NP (DT the) (NML (JJ inner) (HYPH -) (NN loop)) (NN optimization)) (PP (IN of) (NP (NP (DT each) (NN parameter)) (PP (IN in) (NP (JJ deep) (JJ neural) (NNS networks))))))) (, ,) (SBAR (JJ such) (IN that) (S (NP (DT the) (VBN augmented) (NNS gradients)) (VP (VBP improve) (NP (NN generalization)) (PP (IN to) (NP (JJ new) (NNS tasks)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP present) (NP (NP (DT a) (JJ general) (NN form)) (PP (IN of) (NP (DT the) (VBN proposed) (NN gradient) (NN dropout) (NN regularization))))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (DT this) (NN term)) (VP (MD can) (VP (VB be) (VP (VBN sampled) (PP (IN from) (NP (CC either) (NP (DT the) (NNP Bernoulli)) (CC or) (NP (NNP Gaussian) (NN distribution))))))))))) (. .))
(S (S (VP (TO To) (VP (VB validate) (NP (DT the) (JJ proposed) (NN method))))) (, ,) (NP (PRP we)) (VP (VBP conduct) (NP (JJ extensive) (NNS experiments) (CC and) (NN analysis)) (PP (IN on) (NP (JJ numerous) (NML (NN computer) (NN vision)) (NNS tasks))) (, ,) (S (VP (VBG demonstrating) (SBAR (IN that) (S (NP (DT the) (NN gradient) (NN dropout) (NN regularization)) (VP (VP (VBZ mitigates) (NP (DT the) (NN overfitting) (NN problem))) (CC and) (VP (VBZ improves) (NP (DT the) (NN performance)) (PP (IN upon) (NP (ADJP (NP (JJ various) (NN gradient)) (HYPH -) (VBN based)) (NML (NN meta) (HYPH -) (NN learning)) (NNS frameworks)))))))))) (. .))
