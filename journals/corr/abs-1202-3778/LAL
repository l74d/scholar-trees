(S (NP (PRP We)) (VP (JJ present) (NP (NP (NP (JJ sparse) (JJ topical) (NN coding)) (PRN (-LRB- -LRB-) (NP (NNP STC)) (-RRB- -RRB-))) (, ,) (NP (NP (DT a) (JJ non-probabilistic) (NN formulation)) (PP (IN of) (NP (NN topic) (NNS models))) (PP (IN for) (S (VP (VBG discovering) (NP (NP (JJ latent) (NNS representations)) (PP (IN of) (NP (NP (JJ large) (NNS collections)) (PP (IN of) (NP (NNS data)))))))))))) (. .))
(S (PP (IN Unlike) (NP (JJ probabilistic) (NN topic) (NNS models))) (, ,) (NP (NNP STC)) (VP (VBZ relaxes) (NP (NP (NP (DT the) (NN normalization) (NN constraint)) (PP (IN of) (NP (NN admixture) (NNS proportions)))) (CC and) (NP (NP (DT the) (NN constraint)) (PP (IN of) (S (VP (VBG defining) (NP (DT a) (JJ normalized) (NN likelihood) (NN function)))))))) (. .))
(S (NP (JJ Such) (NNS relaxations)) (VP (VBP make) (S (NP (NNP STC)) (ADJP (ADJP (JJ amenable) (TO to) (: :)) (S (VP (CD 1) (-RRB- -RRB-) (VP (ADVP (RB directly)) (VBP control) (NP (NP (DT the) (NN sparsity)) (PP (IN of) (NP (JJ inferred) (NNS representations)))) (PP (IN by) (S (VP (VBG using) (NP (JJ sparsity-inducing) (NNS regularizers))))))) (: ;) (VP (CD 2) (-RRB- -RRB-) (VP (VB be) (VP (ADVP (RB seamlessly)) (VBN integrated) (PP (IN with) (NP (NP (DT a) (NN convex) (NN error) (NN function)) (PRN (-LRB- -LRB-) (JJ e.g.) (, ,) (NP (NNP SVM) (NN hinge) (NN loss)) (-RRB- -RRB-)))) (PP (IN for) (NP (VBN supervised) (NN learning)))))) (: ;) (CC and) (VP (CD 3) (-RRB- -RRB-) (S (VP (VB be) (VP (ADVP (RB efficiently)) (VBN learned) (PP (IN with) (NP (DT a) (ADJP (RB simply) (JJ structured)) (NN coordinate) (NN descent) (NN algorithm))))))))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VB demonstrate) (NP (NP (DT the) (NNS advantages)) (PP (IN of) (NP (NP (NNP STC)) (CC and) (NP (VBD supervised) (NNP MedSTC)))) (PP (IN on) (S (VP (VP (VBG identifying) (NP (NP (JJ topical) (NNS meanings)) (PP (IN of) (NP (NNS words))))) (CC and) (VP (VBG improving) (NP (NX (NN classification) (NX (NN accuracy))) (CC and) (NX (NN time) (NN efficiency))))))))) (. .))
