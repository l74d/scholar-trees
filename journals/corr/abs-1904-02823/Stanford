(S (S (NP (VBN Binarized) (JJ Neural) (NNS Networks) (PRN (-LRB- -LRB-) (NP (NNS BNNs)) (-RRB- -RRB-))) (VP (MD can) (ADVP (RB significantly)) (VP (VB reduce) (NP (NP (DT the) (NN inference) (NN latency)) (CC and) (NP (ADJP (NP (NP (NN energy) (NN consumption)) (PP (IN in) (NP (NN resource)))) (HYPH -) (VBN constrained)) (NNS devices))) (PP (IN due) (PP (IN to) (NP (PRP$ their) (ADJP (JJ pure) (HYPH -) (JJ logical)) (NN computation))))))) (CC and) (S (NP (JJR fewer) (NN memory)) (VP (VBZ accesses))) (. .))
(S (ADVP (RB However)) (, ,) (NP (VBG training) (NNS BNNs)) (VP (VBZ is) (ADJP (JJ difficult)) (SBAR (IN since) (S (NP (DT the) (NN activation) (NN flow)) (VP (VBZ encounters) (NP (NML (NN degeneration) (, ,) (NN saturation) (, ,) (CC and) (NN gradient)) (NN mismatch) (NNS problems)))))) (. .))
(SINV (PP (JJ Prior) (NP (NN work))) (VP (VBZ alleviates)) (NP (NP (DT these) (NNS issues)) (PP (IN by) (S (VP (VP (VP (VBG increasing) (NP (NN activation) (NNS bits))) (CC and) (VP (VBG adding) (NP (NML (VBG floating) (HYPH -) (NN point)) (NN scaling) (NNS factors)))) (, ,) (ADVP (RB thereby)) (VP (VBG sacrificing) (NP (NP (NNP BNN) (POS 's)) (NN energy) (NN efficiency))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (S (VP (TO to) (VP (VB use) (NP (NN distribution) (NN loss)) (PP (IN to) (S (ADVP (RB explicitly)) (VP (VP (VB regularize) (NP (DT the) (NN activation) (NN flow))) (, ,) (CC and) (VP (VB develop) (NP (DT a) (NN framework)) (PP (IN to))) (ADVP (RB systematically)) (VP (VB formulate) (NP (DT the) (NN loss)))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NN distribution) (NN loss)) (VP (MD can) (ADVP (RB consistently)) (VP (VB improve) (NP (NP (DT the) (NN accuracy)) (PP (IN of) (NP (NNS BNNs)))) (PP (IN without) (S (VP (VBG losing) (NP (PRP$ their) (NN energy) (NNS benefits)))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (S (VP (VBN equipped) (PP (IN with) (NP (DT the) (VBN proposed) (NN regularization))))) (, ,) (NP (NN BNN) (NN training)) (VP (VBZ is) (VP (VBN shown) (S (VP (TO to) (VP (VB be) (ADJP (JJ robust) (PP (IN to) (NP (NP (DT the) (NN selection)) (PP (IN of) (NP (NP (ADJP (JJ hyper) (HYPH -)) (NNS parameters)) (PP (VBG including) (NP (NML (NN optimizer) (CC and) (NN learning)) (NN rate))))))))))))) (. .))
