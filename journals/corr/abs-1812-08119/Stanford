(S (PP (IN In) (NP (JJ recent) (NNS years))) (, ,) (NP (NP (JJ deep) (JJ neural) (NNS networks)) (-LRB- -LRB-) (NP (NNS DNNs)) (-RRB- -RRB-)) (VP (VBP have) (VP (VBN been) (VP (VBN applied) (PP (IN to) (NP (JJ various) (NN machine))) (S (VP (VBG leaning) (NP (NNS tasks)))) (, ,) (PP (VBG including) (NP (NML (NML (NN image) (NN recognition)) (, ,) (NML (NN speech) (NN recognition)) (, ,) (CC and) (NML (NN machine))) (NN translation)))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (JJ large) (NN DNN) (NNS models)) (VP (VBP are) (VP (VBN needed) (S (VP (TO to) (VP (VB achieve) (NP (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art)) (NN performance)) (, ,) (S (VP (VBG exceeding) (NP (NP (DT the) (NNS capabilities)) (PP (IN of) (NP (NN edge) (NNS devices))))))))))) (. .))
(S (NP (NNP Model) (NN reduction)) (VP (VBZ is) (ADVP (RB thus)) (VP (VBN needed) (PP (IN for) (NP (JJ practical) (NN use))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP point) (PRT (RP out)) (SBAR (IN that) (S (NP (JJ deep) (NN learning)) (ADVP (RB automatically)) (VP (VBZ induces) (NP (NP (NP (NN group) (NN sparsity)) (PP (IN of) (NP (NP (NP (NNS weights)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (DT all) (NNS weights)) (VP (VBN connected) (PP (IN to) (NP (DT an) (NN output) (NN channel))) (PRN (-LRB- -LRB-) (NP (NN node)) (-RRB- -RRB-)))) (VP (VBP are) (NP (CD zero)))))) (, ,) (PP (WHADVP (WRB when)) (S (S (VP (VBG training) (NP (NNS DNNs)) (PP (IN under) (NP (DT the) (VBG following) (CD three) (NNS conditions))))) (: :) (S (VP (LST (-LRB- -LRB-) (LS 1) (-RRB- -RRB-)) (VP (VBN rectified) (HYPH -) (S (NP (NP (NML (JJ linear) (HYPH -) (NN unit)) (PRN (-LRB- -LRB-) (NP (NN ReLU)) (-RRB- -RRB-)) (NNS activations)) (, ,) (NP (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (NP (DT an) ($ $) (CD L_2)))))))))) (NP (NP ($ $)) (HYPH -) (VP (VBN regularized) (NP (JJ objective) (NN function))))))) (, ,) (CC and) (NP (LST (-LRB- -LRB-) (LS 3) (-RRB- -RRB-)) (NP (DT the) (NNP Adam) (NN optimizer)))))))) (. .))
(S (ADVP (RB Next)) (, ,) (NP (PRP we)) (VP (VP (VBP analyze) (NP (DT this) (NN behavior)) (ADVP (CC both) (ADVP (RB theoretically)) (CC and) (ADVP (RB experimentally)))) (, ,) (CC and) (VP (VP (VB propose) (NP (DT a) (JJ simple) (NML (NN model) (NN reduction)) (NN method))) (: :) (VP (VB eliminate) (NP (DT the) (CD zero) (NNS weights)) (PP (IN after) (S (VP (VBG training) (NP (DT the) (NN DNN)))))))) (. .))
(S (PP (IN In) (NP (NP (NNS experiments)) (PP (IN on) (NP (NML (NML (NN MNIST)) (CC and) (NML (NN CIFAR) (HYPH -) (CD 10))) (NNS datasets))))) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (NP (DT the) (NN sparsity)) (PP (IN with) (NP (JJ various) (NN training) (NNS setups)))) (. .))
(S (ADVP (RB Finally)) (, ,) (NP (PRP we)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN method)) (VP (VP (MD can) (ADVP (RB efficiently)) (VP (VB reduce) (NP (DT the) (NN model) (NN size)))) (CC and) (VP (VBZ performs) (ADVP (RB well) (JJ relative) (PP (IN to) (NP (NP (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP use) (NP (DT a) (ADJP (NN sparsity) (HYPH -) (VBG inducing)) (NN regularizer))))))))))))) (. .))
