(S (NP (PRP We)) (VP (JJ present) (NP (NP (NNP Tiny-Transfer-Learning)) (PRN (-LRB- -LRB-) (NP (NNP TinyTL)) (-RRB- -RRB-)) (, ,) (NP (NP (DT an) (JJ efficient) (JJ on-device) (VBG learning) (NN method)) (SBAR (S (VP (TO to) (VP (VB adapt) (NP (JJ pre-trained) (NNS models)) (PP (TO to) (NP (NP (ADJP (RB newly) (VBN collected)) (NNS data)) (PP (IN on) (NP (NN edge) (NNS devices)))))))))))) (. .))
(S (S (ADJP (NN Different) (PP (IN from) (NP (NP (JJ conventional) (NN transfer) (VBG learning) (NNS methods)) (SBAR (WHNP (IN that)) (S (VP (VBP fine-tune) (NP (NP (DT the) (JJ full) (NN network)) (CC or) (NP (DT the) (JJ last) (NN layer)))))))))) (, ,) (NP (NNP TinyTL)) (VP (VP (VBZ freezes) (NP (NP (DT the) (NNS weights)) (PP (IN of) (NP (DT the) (NN feature) (NN extractor)))) (SBAR (IN while) (S (ADVP (RB only)) (VP (VBG learning) (NP (DT the) (NNS biases)))))) (, ,) (VP (ADVP (RB thus)) (VBZ does) (RB n't) (VP (VB require) (S (VP (VP (VBG storing) (NP (DT the) (JJ intermediate) (NNS activations))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (DT the) (JJ major) (NN memory) (NN bottleneck)) (PP (IN for) (NP (JJ on-device) (NN learning)))))))))))) (. .))
(S (S (VP (TO To) (VP (VB maintain) (NP (DT the) (NN adaptation) (NN capacity)) (PP (IN without) (S (VP (VBG updating) (NP (DT the) (NNS weights)))))))) (, ,) (NP (NNP TinyTL)) (VP (VBZ introduces) (NP (NP (JJ memory-efficient) (JJ lite) (JJ residual) (NNS modules)) (SBAR (S (VP (TO to) (VP (VB refine) (NP (DT the) (NN feature) (NN extractor)) (PP (IN by) (S (VP (VBG learning) (NP (JJ small) (JJ residual) (NN feature) (NNS maps)) (PP (IN in) (NP (DT the) (NN middle)))))))))))) (. .))
(S (S (ADVP (IN Besides)) (, ,) (PP (RB instead) (IN of) (S (VP (VBG using) (NP (DT the) (JJ same) (NN feature) (NN extractor))))) (, ,) (NP (NNP TinyTL)) (VP (VBZ adapts) (NP (NP (DT the) (NN architecture)) (PP (IN of) (NP (DT the) (NN feature) (NN extractor)))) (S (VP (TO to) (VP (VB fit) (NP (JJ different) (NN target) (NNS datasets))))) (SBAR (IN while) (S (VP (VBG fixing) (NP (DT the) (NNS weights))))))) (: :) (S (S (NP (NNP TinyTL)) (VP (VBZ pre-trains) (NP (NP (DT a) (JJ large) (NN super-net)) (SBAR (WHNP (WDT that)) (S (VP (VBZ contains) (NP (NP (JJ many) (JJ weight-shared) (NNS sub-nets)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (ADVP (RB individually)) (VP (VB operate)))))))))))) (: ;) (S (NP (JJ different) (NN target) (NN dataset)) (VP (VBZ selects) (NP (NP (DT the) (NN sub-net)) (SBAR (WHNP (WDT that)) (S (VP (ADVP (JJS best)) (VBP match) (NP (DT the) (NN dataset))))))))) (. .))
(S (NP (DT This) (JJ backpropagation-free) (JJ discrete) (JJ sub-net) (NN selection)) (VP (VBZ incurs) (NP (DT no) (NN memory) (NN overhead))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP TinyTL)) (VP (MD can) (VP (VB reduce) (NP (DT the) (NN training) (NN memory) (NN cost)) (PP (IN by) (NP (NP (NP (NN order)) (PP (IN of) (NP (NN magnitude)))) (PRN (-LRB- -LRB-) (NP (QP (IN up) (TO to) (CD 13.3x))) (-RRB- -RRB-)))) (PP (IN without) (S (VP (VBG sacrificing) (NP (NN accuracy))))) (PP (VBN compared) (PP (TO to) (S (VP (VBG fine-tuning) (NP (DT the) (JJ full) (NN network))))))))))) (. .))
