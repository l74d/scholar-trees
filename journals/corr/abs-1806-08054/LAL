(S (NP (JJ Large-scale) (JJ distributed) (NN optimization)) (VP (VBZ is) (PP (IN of) (NP (JJ great) (NN importance))) (PP (IN in) (NP (JJ various) (NNS applications)))) (. .))
(S (PP (IN For) (NP (ADJP (JJ data-parallel) (VBN based)) (JJ distributed) (NN learning))) (, ,) (NP (DT the) (JJ inter-node) (NN gradient) (NN communication)) (ADVP (RB often)) (VP (VBZ becomes) (NP (DT the) (NN performance) (NN bottleneck))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (DT the) (ADJP (NN error) (VBD compensated)) (JJ quantized) (JJ stochastic) (NN gradient) (NN descent) (NN algorithm)) (S (VP (TO to) (VP (VB improve) (NP (DT the) (NN training) (NN efficiency)))))) (. .))
(S (S (NP (JJ Local) (NNS gradients)) (VP (VBP are) (VP (VBN quantized) (S (VP (TO to) (VP (VB reduce) (NP (DT the) (NN communication) (NN overhead)))))))) (, ,) (CC and) (S (NP (VBD accumulated) (NN quantization) (NN error)) (VP (VBZ is) (VP (VBN utilized) (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (DT the) (NN convergence)))))))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VP (VBP present) (NP (NP (JJ theoretical) (NN analysis)) (PP (IN on) (NP (DT the) (NN convergence) (NN behaviour))))) (, ,) (CC and) (VP (VB demonstrate) (NP (NP (PRP$ its) (NN advantage)) (PP (IN over) (NP (NNS competitors)))))) (. .))
(S (NP (JJ Extensive) (NNS experiments)) (VP (VBP indicate) (SBAR (IN that) (S (NP (PRP$ our) (NN algorithm)) (VP (MD can) (VP (VB compress) (NP (NNS gradients)) (PP (IN by) (NP (NP (DT a) (NN factor)) (PP (IN of) (NP (QP (IN up) (TO to) (CD two)) (NNS magnitudes))))) (PP (IN without) (NP (NN performance) (NN degradation)))))))) (. .))
