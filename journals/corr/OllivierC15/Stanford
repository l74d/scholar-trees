(S (NP (PRP We)) (VP (VBP introduce) (NP (DT the) (`` ") (NNP NoBackTrack) ('' ") (NN algorithm)) (S (VP (TO to) (VP (VB train) (NP (NP (DT the) (NNS parameters)) (PP (IN of) (NP (NP (JJ dynamical) (NNS systems)) (PP (JJ such) (IN as) (NP (ADJP (JJ recurrent)) (JJ neural) (NNS networks)))))))))) (. .))
(S (NP (DT This) (NN algorithm)) (VP (VBZ works) (PP (IN in) (NP (DT an) (JJ online) (, ,) (JJ memoryless) (NN setting))) (, ,) (S (ADVP (RB thus)) (VP (VBG requiring) (NP (DT no) (NN backpropagation)) (PP (IN through) (NP (NN time)))))) (, ,) (CC and) (VP (VBZ is) (ADJP (JJ scalable))) (, ,) (S (VP (VBG avoiding) (NP (NP (DT the) (JJ large) (NML (JJ computational) (CC and) (NN memory)) (NN cost)) (PP (IN of) (S (VP (VBG maintaining) (NP (NP (DT the) (JJ full) (NN gradient)) (PP (IN of) (NP (NP (DT the) (JJ current) (NN state)) (PP (IN with) (NP (NN respect)))))) (PP (IN to) (NP (DT the) (NNS parameters))))))))) (. .))
(S (NP (DT The) (NN algorithm)) (ADVP (RB essentially)) (VP (VBZ maintains) (, ,) (PP (IN at) (NP (DT each) (NN time))) (, ,) (NP (NP (DT a) (JJ single) (NN search) (NN direction)) (PP (IN in) (NP (NN parameter) (NN space))))) (. .))
(S (NP (NP (DT The) (NN evolution)) (PP (IN of) (NP (DT this) (NN search) (NN direction)))) (VP (VP (VBZ is) (ADJP (RB partly) (JJ stochastic))) (CC and) (VP (VBZ is) (VP (VBN constructed) (PP (IN in) (NP (PDT such) (DT a) (NN way))) (S (VP (TO to) (VP (VB provide) (, ,) (ADVP (IN at) (NP (DT every) (NN time))) (, ,) (NP (NP (DT an) (JJ unbiased) (JJ random) (NN estimate)) (PP (IN of) (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (DT the) (NN loss) (NN function)))))) (PP (IN with) (NP (NN respect))) (PP (IN to) (NP (DT the) (NNS parameters))))))))) (. .))
(S (SBAR (IN Because) (S (NP (DT the) (NN gradient) (NN estimate)) (VP (VBZ is) (ADJP (JJ unbiased)) (, ,) (PP (IN on) (NP (NP (JJ average)) (PP (IN over) (NP (NN time)))))))) (NP (DT the) (NN parameter)) (VP (VBZ is) (VP (VBN updated) (SBAR (IN as) (S (NP (PRP it)) (VP (MD should)))))) (. .))
(S (NP (DT The) (VBG resulting) (NN gradient) (NN estimate)) (VP (MD can) (ADVP (RB then)) (VP (VB be) (VP (VBN fed) (PP (IN to) (NP (DT a) (ADJP (NP (JJ lightweight) (NNP Kalman)) (HYPH -) (JJ like)) (NN filter))) (S (VP (TO to) (VP (VB yield) (NP (DT an) (JJ improved) (NN algorithm)))))))) (. .))
(S (PP (IN For) (NP (ADJP (JJ recurrent)) (JJ neural) (NNS networks))) (, ,) (NP (NP (DT the) (VBG resulting) (NNS algorithms) (NN scale)) (PP (ADVP (RB linearly)) (IN with) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS parameters)))))) (. .))
(S (NP (NML (JJ Small) (HYPH -) (NN scale)) (NNS experiments)) (VP (VBP confirm) (NP (NP (DT the) (NN suitability)) (PP (IN of) (NP (DT the) (NN approach)))) (, ,) (S (VP (VBG showing) (SBAR (IN that) (S (NP (NP (DT the) (JJ stochastic) (NN approximation)) (PP (IN of) (NP (NP (DT the) (NN gradient)) (VP (VBN introduced) (PP (IN in) (NP (DT the) (NN algorithm))))))) (VP (VBZ is) (RB not) (ADJP (JJ detrimental) (PP (IN to) (NP (NN learning)))))))))) (. .))
(S (PP (IN In) (ADJP (JJ particular))) (, ,) (NP (NP (DT the) (ADJP (NP (NNP Kalman)) (HYPH -) (JJ like)) (NN version)) (PP (IN of) (NP (NNP NoBackTrack)))) (VP (VBZ is) (ADJP (JJ superior) (PP (IN to) (NP (NN backpropagation)))) (PP (IN through) (NP (NP (NN time) (-LRB- -LRB-) (NN BPTT) (-RRB- -RRB-)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (NN time) (NN span)) (PP (IN of) (NP (NP (NNS dependencies)) (PP (IN in) (NP (DT the) (NNS data)))))) (VP (VBZ is) (ADJP (ADJP (JJR longer)) (PP (IN than) (NP (NP (DT the) (NN truncation) (NN span)) (PP (IN for) (NP (NNP BPTT)))))))))))) (. .))
