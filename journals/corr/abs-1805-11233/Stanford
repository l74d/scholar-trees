(S (NP (NNP Model) (NN compression)) (VP (VBZ has) (VP (VBN gained) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NN attention)))) (PP (IN due) (IN to) (NP (PRP$ its) (NN ability) (S (VP (TO to) (VP (VB reduce) (NP (NML (NN hardware) (NN resource)) (NNS requirements)) (PP (ADVP (RB significantly)) (IN while) (S (VP (VBG maintaining) (NP (NP (NN accuracy)) (PP (IN of) (NP (NNS DNNs)))))))))))))) (. .))
(S (NP (NNP Model) (NN compression)) (VP (VBZ is) (ADJP (RB especially) (JJ useful) (PP (IN for) (NP (ADJP (NN memory) (HYPH -) (JJ intensive)) (ADJP (JJ recurrent)) (JJ neural) (NNS networks)))) (PP (PP (IN because) (NP (NP (JJR smaller) (NN memory) (NN footprint)) (SBAR (S (VP (VBZ is) (ADJP (JJ crucial))))))) (CONJP (RB not) (RB only)) (PP (PP (IN for) (S (VP (VBG reducing) (NP (NN storage) (NN requirement))))) (CONJP (CC but) (RB also)) (PP (IN for) (NP (NML (JJ fast) (NN inference)) (NNS operations)))))) (. .))
(S (S (NP (NN Quantization)) (VP (VBZ is) (VP (VBN known) (S (VP (TO to) (VP (VB be) (NP (DT an) (JJ effective) (NML (NN model) (NN compression)) (NN method)))))))) (CC and) (S (NP (NNS researchers)) (VP (VBP are) (ADJP (JJ interested) (PP (IN in) (S (VP (VBG minimizing) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS bits)))) (S (VP (TO to) (VP (VB represent) (NP (NNS parameters))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP introduce) (NP (DT an) (JJ iterative) (NN technique)) (S (VP (TO to) (VP (VB apply) (NP (NN quantization))))) (, ,) (S (VP (VBG presenting) (NP (NML (JJ high) (NN compression)) (NN ratio)) (PP (IN without) (NP (DT any) (NNS modifications))) (PP (IN to) (NP (DT the) (NN training) (NN algorithm)))))) (. .))
(S (PP (IN In) (NP (DT the) (VBN proposed) (NN technique))) (, ,) (NP (NN weight) (NN quantization)) (VP (VBZ is) (VP (VBN followed) (PP (IN by) (S (VP (VBG retraining) (NP (DT the) (NN model)) (PP (IN with) (NP (JJ full) (NN precision) (NNS weights)))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (JJ iterative) (VBG retraining)) (VP (VBZ generates) (NP (NP (JJ new) (NNS sets)) (PP (IN of) (NP (NP (NNS weights)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (VBN quantized) (PP (IN with) (S (VP (VBG decreasing) (NP (NN quantization) (NN loss)) (PP (IN at) (NP (DT each) (NN iteration)))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP show) (SBAR (IN that) (S (NP (NN quantization)) (VP (VBZ is) (ADVP (RB efficiently)) (ADJP (JJ able) (S (VP (TO to) (VP (VB leverage) (NP (NP (NN pruning)) (, ,) (NP (DT another) (JJ effective) (NML (NN model) (NN compression)) (NN method))))))))))) (. .))
(S (NP (NP (NN Implementation) (NNS issues)) (PP (IN on) (S (VP (VBG combining) (NP (DT the) (CD two) (NNS methods)))))) (VP (VBP are) (ADVP (RB also)) (VP (VBN addressed))) (. .))
(S (NP (PRP$ Our) (JJ experimental) (NNS results)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT an) (NN LSTM) (NN model)) (VP (VBG using) (NP (ADJP (NP (CD 1) (HYPH -) (NN bit)) (JJ quantized)) (NNS weights)))) (VP (VBZ is) (ADJP (JJ sufficient) (PP (IN for) (NP (NP (NNP PTB) (NN dataset)) (PP (IN without) (NP (DT any) (NN accuracy) (NN degradation)))))) (SBAR (IN while) (S (NP (JJ previous) (NNS methods)) (VP (VBP demand) (NP (NP (ADVP (IN at) (JJS least)) (QP (CD 2) (HYPH -) (CD 4)) (NNS bits)) (PP (IN for) (NP (JJ quantized) (NNS weights))))))))))) (. .))
