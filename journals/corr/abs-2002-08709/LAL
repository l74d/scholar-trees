(S (NP (VBN Overparameterized) (JJ deep) (NNS networks)) (VP (VBP have) (NP (DT the) (NN capacity) (S (VP (TO to) (VP (VB memorize) (NP (NN training) (NNS data)) (PP (IN with) (NP (CD zero) (VBG training) (NN error)))))))) (. .))
(S (PP (ADVP (RB Even)) (IN after) (NP (NN memorization))) (, ,) (NP (DT the) (NN training) (NN loss)) (VP (VBZ continues) (S (VP (TO to) (VP (VB approach) (NP (CD zero))))) (, ,) (S (VP (VBG making) (S (S (NP (DT the) (NN model)) (ADJP (NN overconfident))) (CC and) (S (NP (DT the) (NN test) (NN performance)) (ADJP (VBD degraded))))))) (. .))
(S (SBAR (IN Since) (S (NP (VBG existing) (NNS regularizers)) (VP (VBP do) (RB not) (VP (ADVP (RB directly)) (VBP aim) (S (VP (TO to) (VP (VB avoid) (NP (CD zero) (NN training) (NN loss))))))))) (, ,) (NP (PRP they)) (ADVP (RB often)) (VP (VBP fail) (S (VP (TO to) (VP (VB maintain) (NP (NP (DT a) (JJ moderate) (NN level)) (PP (IN of) (NP (NN training) (NN loss))))))) (, ,) (S (VP (VBG ending) (PRT (RP up)) (PP (IN with) (NP (DT a) (ADJP (ADJP (RB too) (JJ small)) (CC or) (ADJP (RB too) (JJ large))) (NN loss)))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ direct) (NN solution)) (VP (VBD called) (S (NP (NN flooding)))) (SBAR (WHNP (IN that)) (S (ADVP (RB intentionally)) (VP (VBZ prevents) (NP (NP (JJ further) (NN reduction)) (PP (IN of) (NP (DT the) (NN training) (NN loss)))) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBZ reaches) (NP (NP (DT a) (ADJP (RB reasonably) (JJ small)) (NN value)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP we)) (VP (VBP call) (S (NP (DT the) (NN flooding) (NN level))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ makes) (S (NP (DT the) (NN loss)) (VP (NN float) (PP (IN around) (NP (DT the) (VBG flooding) (NN level))))) (PP (IN by) (S (VP (VP (VBG doing) (NP (JJ mini-batched) (JJ gradient) (NN descent)) (SBAR (IN as) (ADJP (JJ usual)))) (CC but) (VP (NP (JJ gradient) (NN ascent)) (SBAR (IN if) (S (NP (DT the) (NN training) (NN loss)) (VP (VBZ is) (PP (IN below) (NP (DT the) (JJ flooding) (NN level))))))))))) (. .))
(S (NP (DT This)) (VP (VP (MD can) (VP (VB be) (VP (VBN implemented) (PP (IN with) (NP (NP (CD one) (NN line)) (PP (IN of) (NP (NN code)))))))) (, ,) (CC and) (VP (VBZ is) (ADJP (JJ compatible) (PP (IN with) (NP (NP (DT any) (JJ stochastic) (NN optimizer)) (CC and) (NP (JJ other) (NNS regularizers))))))) (. .))
(S (S (PP (IN With) (NP (NN flooding))) (, ,) (NP (DT the) (NN model)) (VP (MD will) (VP (VB continue) (S (VP (TO to) (VP (`` ``) (VB random) (NN walk) ('' '') (PP (IN with) (NP (DT the) (JJ same) (JJ non-zero) (NN training) (NN loss))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP expect) (S (NP (PRP it)) (VP (TO to) (VP (VB drift) (PP (IN into) (NP (NP (DT an) (NN area)) (PP (IN with) (NP (DT a) (JJ flat) (NN loss) (NN landscape))) (SBAR (WHNP (WDT that)) (S (VP (VBZ leads) (PP (TO to) (NP (JJR better) (NN generalization))))))))))))) (. .))
(S (NP (PRP We)) (VP (ADVP (RB experimentally)) (VBP show) (SBAR (IN that) (S (NP (VBG flooding)) (VP (VP (NNS improves) (NP (NN performance))) (CC and) (VP (PP (IN as) (NP (DT a) (NN byproduct))) (, ,) (VBZ induces) (NP (NP (DT a) (JJ double) (NN descent) (NN curve)) (PP (IN of) (NP (DT the) (NN test) (NN loss))))))))) (. .))
