(S (NP (NP (DT The) (NN training) (NN process)) (PP (IN of) (NP (JJ Deep) (JJ Neural) (NN Network))) (PRN (-LRB- -LRB-) (NP (NN DNN)) (-RRB- -RRB-))) (VP (VBZ is) (S (VP (VB compute) (HYPH -) (NP (JJ intensive)) (, ,) (S (ADVP (RB often)) (VP (VBG taking) (NP (NNS days)) (PP (TO to) (NP (NNS weeks))) (S (VP (TO to) (VP (VB train) (NP (DT a) (NN DNN) (NN model)))))))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (NP (JJ parallel) (NN execution)) (PP (IN of) (NP (NP (NN DNN) (NN training)) (PP (IN on) (NP (NNS GPUs)))))) (VP (VBZ is) (NP (DT a) (ADJP (RB widely) (VBN adopted)) (NN approach) (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (DT the) (NN process)) (ADVP (RB nowadays))))))) (. .))
(S (PP (IN Due) (PP (IN to) (NP (DT the) (NN implementation) (NN simplicity)))) (, ,) (NP (NNS data) (NN parallelism)) (VP (VBZ is) (ADVP (RB currently)) (NP (DT the) (ADJP (RBS most) (RB commonly) (VBN used)) (NN parallelization) (NN method))) (. .))
(S (ADVP (RB Nonetheless)) (, ,) (NP (NNS data) (NN parallelism)) (VP (VBZ suffers) (PP (IN from) (NP (JJ excessive) (JJ inter-GPU) (NN communication))) (PP (ADVP (RB overhead)) (IN due) (IN to) (NP (NP (JJ frequent) (NN weight) (NN synchronization)) (PP (IN among) (NP (NNS GPUs)))))) (. .))
(S (NP (DT Another) (NN approach)) (VP (VBZ is) (NP (NP (ADJP (JJ pipelined)) (NN model) (NN parallelism)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ partitions) (NP (NP (NP (DT a) (NN DNN) (NN model)) (PP (IN among) (NP (NNS GPUs)))) (, ,) (CC and) (NP (NP (NNS processes)) (NP (JJ multiple) (NNS mini-batches)))) (ADVP (RB concurrently))))))) (. .))
(S (NP (DT This) (NN approach)) (VP (MD can) (ADVP (RB significantly)) (VP (VB reduce) (NP (NN inter-GPU) (NN communication) (NN cost)) (PP (VBN compared) (PP (IN to) (NP (NNS data) (NN parallelism)))))) (. .))
(S (S (ADVP (RB However)) (, ,) (NP (JJ pipelined) (NN model) (NN parallelism)) (VP (VBZ faces) (NP (DT the) (NN weight) (NN staleness) (NN issue)))) (: ;) (S (NP (DT that)) (VP (VBZ is) (PRN (, ,) (S (NP (NNS gradients)) (VP (VBP are) (VP (VBN computed) (PP (IN with) (NP (JJ stale) (NNS weights)))))) (, ,)) (VP (VBG leading) (PP (IN to) (NP (NP (NN training) (NN instability)) (CC and) (NP (NN accuracy) (NN loss))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (NML (JJ pipelined) (NN model)) (JJ parallel) (NN execution) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (NP (NML (JJ high) (NNP GPU)) (NN utilization)) (PP (IN while) (S (VP (VBG maintaining) (NP (NP (JJ robust) (NN training) (NN accuracy)) (PP (IN via) (NP (NP (DT a) (JJ novel) (NML (NN weight) (NN prediction)) (NN technique)) (, ,) (NP (NNP SpecTrain))))))))))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN proposal)) (VP (VBZ achieves) (PRT (RP up)) (PP (IN to) (NP (NP (CD 8.91) (SYM x) (NN speedup)) (PP (VBN compared) (PP (IN to) (NP (NP (NNS data) (NN parallelism)) (PP (IN on) (NP (DT a) (NML (CD 4) (HYPH -) (NN GPU)) (NN platform)))))))) (PP (IN while) (S (VP (VBG maintaining) (NP (JJ comparable) (NN model) (NN accuracy))))))))) (. .))
