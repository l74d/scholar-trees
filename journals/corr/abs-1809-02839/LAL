(S (NP (NP (DT The) (NN training) (NN process)) (PP (IN of) (NP (NP (NNP Deep) (NNP Neural) (NNP Network)) (PRN (-LRB- -LRB-) (NP (NNP DNN)) (-RRB- -RRB-))))) (VP (VBZ is) (ADJP (JJ compute-intensive)) (, ,) (S (ADVP (RB often)) (VP (VBG taking) (NP (NNS days) (PP (TO to) (NNS weeks))) (S (VP (TO to) (VP (VB train) (NP (DT a) (NNP DNN) (NN model)))))))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (NP (JJ parallel) (NN execution)) (PP (IN of) (NP (NNP DNN) (VBG training))) (PP (IN on) (NP (NNP GPUs)))) (VP (VBZ is) (NP (NP (DT a) (ADJP (RB widely) (VBN adopted)) (NN approach)) (SBAR (S (VP (TO to) (VP (VB speed) (PRT (RP up)) (NP (DT the) (NN process))))))) (ADVP (RB nowadays))) (. .))
(S (PP (JJ Due) (TO to) (NP (DT the) (NN implementation) (NN simplicity))) (, ,) (NP (NNS data) (NN parallelism)) (VP (VBZ is) (ADVP (RB currently)) (NP (DT the) (ADJP (ADVP (RBS most) (RB commonly)) (JJ used)) (NN parallelization) (NN method))) (. .))
(S (ADVP (RB Nonetheless)) (, ,) (NP (NNS data) (NN parallelism)) (VP (NNS suffers) (PP (IN from) (NP (NP (JJ excessive) (JJ inter-GPU) (NN communication) (NN overhead)) (ADVP (JJ due) (PP (TO to) (NP (NP (JJ frequent) (JJ weight) (NN synchronization)) (PP (IN among) (NP (NNP GPUs))))))))) (. .))
(S (NP (DT Another) (NN approach)) (VP (VBZ is) (NP (NP (VBN pipelined) (NN model) (NN parallelism)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ partitions) (NP (DT a) (NNP DNN) (NN model)) (PP (IN among) (NP (NNP GPUs)))) (, ,) (CC and) (VP (VBZ processes) (NP (JJ multiple) (NNS mini-batches)) (ADVP (RB concurrently)))))))) (. .))
(S (NP (DT This) (NN approach)) (VP (MD can) (VP (ADVP (RB significantly)) (VB reduce) (NP (JJ inter-GPU) (NN communication) (NN cost)) (PP (VBN compared) (PP (TO to) (NP (NNS data) (NN parallelism)))))) (. .))
(S (S (ADVP (RB However)) (, ,) (NP (VBD pipelined) (NN model) (NN parallelism)) (VP (VBZ faces) (NP (DT the) (NN weight) (JJ staleness) (NN issue)))) (: ;) (S (S (NP (WDT that)) (VP (VBZ is))) (, ,) (NP (NNS gradients)) (VP (VBP are) (VP (VBN computed) (PP (IN with) (NP (JJ stale) (NNS weights))) (, ,) (S (VP (VBG leading) (PP (TO to) (NP (NP (VBG training) (NN instability)) (CC and) (NP (NN accuracy) (NN loss))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ pipelined) (NN model) (JJ parallel) (NN execution) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ enables) (NP (JJ high) (NNP GPU) (NN utilization)) (SBAR (IN while) (S (VP (VBG maintaining) (NP (JJ robust) (NN training) (NN accuracy))))) (PP (IN via) (NP (NP (DT a) (JJ novel) (NN weight) (NN prediction) (NN technique)) (, ,) (NP (NNP SpecTrain))))))))) (. .))
(S (NP (JJ Experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP$ our) (NN proposal)) (VP (VBZ achieves) (NP (QP (IN up) (TO to) (CD 8.91x)) (NNS speedup)) (PP (VBN compared) (PP (TO to) (NP (NNS data) (NN parallelism)))) (PP (IN on) (NP (DT a) (JJ 4-GPU) (NN platform))) (SBAR (IN while) (S (VP (VBG maintaining) (NP (JJ comparable) (NN model) (NN accuracy))))))))) (. .))
