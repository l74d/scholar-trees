(S (PP (VBG Following) (NP (NP (DT the) (JJ recent) (NN work)) (PP (IN on) (NP (NN capacity) (NN allocation))))) (, ,) (NP (PRP we)) (VP (VBP formulate) (NP (DT the) (NN conjecture) (SBAR (IN that) (S (NP (NP (DT the) (NN shattering) (NN problem)) (PP (IN in) (NP (JJ deep) (JJ neural) (NNS networks)))) (VP (MD can) (ADVP (RB only)) (VP (VB be) (VP (VBN avoided) (SBAR (IN if) (S (NP (NP (DT the) (NN capacity) (NN propagation)) (PP (IN through) (NP (NNS layers)))) (VP (VBZ has) (NP (DT a) (JJ non-degenerate) (JJ continuous) (NN limit)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS layers)))) (VP (NNS tends) (PP (TO to) (NP (NN infinity)))))))))))))))) (. .))
(S (NP (DT This)) (VP (VBZ allows) (S (NP (PRP us)) (VP (TO to) (VP (VP (VB study) (NP (NP (DT a) (NN number)) (PP (IN of) (NP (ADJP (RB commonly) (VBN used)) (NNS architectures))))) (CC and) (VP (NN determine) (SBAR (WHNP (WDT which) (VBG scaling) (NNS relations)) (S (VP (MD should) (VP (VB be) (VP (VBN enforced) (PP (IN in) (NP (NN practice))) (SBAR (IN as) (S (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS layers)))) (VP (NNS grows) (ADJP (JJ large))))))))))))))) (. .))
(S (PP (IN In) (NP (JJ particular))) (, ,) (S (NP (PRP we)) (VP (VBP recover) (NP (NP (DT the) (NNS conditions)) (PP (IN of) (NP (NNP Xavier) (NN initialization)))) (PP (IN in) (NP (DT the) (JJ multi-channel) (NN case))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP find) (SBAR (IN that) (S (NP (NNS weights) (CC and) (NNS biases)) (VP (MD should) (VP (VB be) (VP (VBN scaled) (ADVP (RP down)) (PP (PP (IN as) (NP (NP (DT the) (NN inverse) (JJ square) (NN root)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS layers))) (PP (IN for) (NP (JJ deep) (JJ residual) (NNS networks))))))) (CC and) (PP (IN as) (NP (NP (DT the) (NN inverse) (JJ square) (NN root)) (PP (IN of) (NP (NP (DT the) (JJ desired) (NN memory) (NN length)) (PP (IN for) (NP (NN recurrent) (NNS networks))))))))))))))) (. .))
