(S (NP (NP (NN Exploration)) (PP (IN in) (NP (JJ multi-agent) (NN reinforcement) (NN learning)))) (VP (VBZ is) (NP (DT a) (NN challenging) (NN problem)) (, ,) (PP (ADVP (RB especially)) (IN in) (NP (NP (NNS environments)) (PP (IN with) (NP (JJ sparse) (NNS rewards)))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ general) (NN method)) (PP (IN for) (NP (JJ efficient) (NN exploration))) (PP (IN by) (S (VP (VBG sharing) (NP (NN experience)) (PP (NN amongst) (NP (NNS agents)))))))) (. .))
(S (NP (NP (PRP$ Our) (VBN proposed) (NN algorithm)) (, ,) (VP (VBN called) (S (NP (S (NP (NNP Shared) (NNP Experience) (NNP Actor-Critic))) (PRN (-LRB- -LRB-) (NP (NNP SEAC)) (-RRB- -RRB-))))) (, ,)) (VP (VBZ applies) (NP (NN experience) (VBG sharing)) (PP (IN in) (NP (DT an) (JJ actor-critic) (NN framework)))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (NNP SEAC)) (PP (IN in) (NP (NP (DT a) (NN collection)) (PP (IN of) (NP (JJ sparse-reward) (JJ multi-agent) (NNS environments)))))) (CC and) (VP (VB find) (SBAR (IN that) (S (NP (PRP it)) (VP (ADVP (RB consistently)) (VBZ outperforms) (NP (NP (CD two) (NNS baselines)) (CC and) (NP (CD two) (JJ state-of-the-art) (NNS algorithms))) (PP (IN by) (S (VP (VP (VBG learning) (PP (IN in) (NP (JJR fewer) (NNS steps)))) (CC and) (VP (VBG converging) (PP (TO to) (NP (JJR higher) (NNS returns)))))))))))) (. .))
(S (PP (IN In) (NP (DT some) (NN harder) (NNS environments))) (, ,) (NP (NN experience) (NN sharing)) (VP (VBZ makes) (NP (NP (DT the) (NN difference)) (PP (IN between) (S (VP (S (VP (VBG learning) (S (VP (TO to) (VP (VB solve) (NP (DT the) (NN task))))))) (CC and) (VP (RB not) (VBG learning) (ADVP (IN at) (DT all)))))))) (. .))
