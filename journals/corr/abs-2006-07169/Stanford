(S (NP (NP (NN Exploration)) (PP (IN in) (NP (JJ multi-agent) (NN reinforcement) (NN learning)))) (VP (VBZ is) (NP (DT a) (JJ challenging) (NN problem)) (, ,) (ADVP (RB especially)) (PP (IN in) (NP (NP (NNS environments)) (PP (IN with) (NP (JJ sparse) (NNS rewards)))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ general) (NN method)) (PP (IN for) (NP (JJ efficient) (NN exploration)))) (PP (IN by) (S (VP (VBG sharing) (NP (NN experience)) (PP (IN amongst) (NP (NNS agents))))))) (. .))
(S (NP (NP (PRP$ Our) (VBN proposed) (NN algorithm)) (, ,) (VP (VBN called) (NP (NP (NML (NNP Shared) (NNP Experience)) (NN Actor) (HYPH -) (NN Critic)) (-LRB- -LRB-) (NP (NN SEAC)) (-RRB- -RRB-))) (, ,)) (VP (VBZ applies) (NP (NP (NN experience)) (VP (VBG sharing) (PP (IN in) (NP (DT an) (NML (NN actor) (HYPH -) (NN critic)) (NN framework)))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP evaluate) (NP (NN SEAC)) (PP (IN in) (NP (NP (DT a) (NN collection)) (PP (IN of) (NP (ADJP (NP (JJ sparse) (HYPH -) (NN reward)) (JJ multi-agent)) (NNS environments)))))) (CC and) (VP (VB find) (SBAR (IN that) (S (NP (PRP it)) (ADVP (RB consistently)) (VP (VBZ outperforms) (NP (NP (CD two) (NNS baselines)) (CC and) (NP (CD two) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS algorithms))) (PP (IN by) (S (VP (VP (VBG learning) (PP (IN in) (NP (JJR fewer) (NNS steps)))) (CC and) (VP (VBG converging) (PP (IN to) (NP (JJR higher) (NNS returns)))))))))))) (. .))
(S (PP (IN In) (NP (DT some) (JJR harder) (NNS environments))) (, ,) (NP (NN experience) (NN sharing)) (VP (VBZ makes) (NP (NP (DT the) (NN difference)) (PP (IN between) (NP (NN learning) (S (VP (TO to) (VP (VB solve) (NP (NP (DT the) (NN task)) (CC and) (S (RB not) (VP (VBG learning) (PP (IN at) (NP (DT all))))))))))))) (. .))
