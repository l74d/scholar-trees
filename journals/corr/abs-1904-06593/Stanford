(S (NP (JJ Recent) (NNS years)) (VP (VBP have) (VP (VBN witnessed) (NP (NP (DT the) (NN success)) (PP (IN of) (NP (JJ deep) (JJ neural) (NNS networks)))) (PP (IN in) (S (VP (VBG dealing) (PP (IN with) (NP (NP (DT a) (NN plenty)) (PP (IN of) (NP (JJ practical) (NNS problems)))))))))) (. .))
(S (NP (NN Dropout)) (VP (VBZ has) (VP (VBN played) (NP (DT an) (JJ essential) (NN role)) (PP (IN in) (NP (JJ many) (JJ successful) (JJ deep) (JJ neural) (NNS networks))) (, ,) (PP (IN by) (S (VP (VBG inducing) (NP (NN regularization)) (PP (IN in) (NP (DT the) (NN model) (NN training)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ new) (JJ regularized) (NN training) (NN approach)) (: :) (NP (NN Shakeout)))) (. .))
(S (PP (RB Instead) (IN of) (S (ADVP (RB randomly)) (VP (VBG discarding) (NP (NNS units)) (SBAR (IN as) (S (NP (NN Dropout)) (VP (VBZ does) (PP (IN at) (NP (DT the) (NN training) (NN stage))))))))) (, ,) (NP (NN Shakeout)) (ADVP (RB randomly)) (VP (VBZ chooses) (S (VP (TO to) (VP (VB enhance) (CC or) (VB reverse) (NP (NP (DT each) (NN unit) (POS 's)) (NN contribution)) (PP (IN to) (NP (DT the) (JJ next) (NN layer))))))) (. .))
(FRAG (S (NP (NP (DT This) (JJ minor) (NN modification)) (PP (IN of) (NP (NNP Dropout)))) (VP (VBZ has) (NP (NP (DT the) (JJ statistical) (NN trait)) (: :) (S (NP (NP (DT the) (NN regularizer)) (VP (VBN induced) (PP (IN by) (NP (NN Shakeout))))) (ADVP (RB adaptively)) (VP (VBZ combines)))))) (FRAG (FRAG (NP ($ $) (CD L_0)) (NP ($ $))) (, ,) (FRAG (NP ($ $) (CD L_1)) (NP ($ $))) (CC and) (FRAG (NP ($ $) (CD L_2)) (NP ($ $) (CD regularization)) (NP (NNS terms)))) (. .))
(FRAG (NP (NP (PRP$ Our) (NN classification) (NNS experiments)) (PP (IN with) (NP (NP (JJ representative) (JJ deep) (NNS architectures)) (PP (IN on) (NP (NN image) (NNS datasets)))))) (NP (NNP MNIST)) (, ,) (S (NP (NP (NNP CIFAR) (HYPH -) (CD 10)) (CC and) (NP (NNP ImageNet))) (VP (VBP show) (SBAR (IN that) (S (NP (NP (NN Shakeout) (NNS deals)) (PP (IN with) (NP (JJ over-fitting)))) (ADVP (RB effectively))))) (CC and) (VP (VBZ outperforms) (NP (NN Dropout)))) (. .))
(S (NP (PRP We)) (ADVP (RB empirically)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NN Shakeout)) (VP (VBZ leads) (PP (IN to) (NP (NP (JJR sparser) (NNS weights)) (PP (IN under) (NP (DT both) (ADJP (JJ unsupervised) (CC and) (JJ supervised)) (NNS settings))))))))) (. .))
(S (NP (NN Shakeout)) (ADVP (RB also)) (VP (VBZ leads) (PP (IN to) (NP (NP (DT the) (NN grouping) (NN effect)) (PP (IN of) (NP (NP (DT the) (NN input) (NNS units)) (PP (IN in) (NP (DT a) (NN layer)))))))) (. .))
(S (S (VP (VBG Considering) (NP (DT the) (NNS weights)) (PP (IN in) (S (VP (VBG reflecting) (NP (NP (DT the) (NN importance)) (PP (IN of) (NP (NNS connections))))))))) (, ,) (NP (NN Shakeout)) (VP (VBZ is) (ADJP (JJ superior) (PP (IN to) (NP (NP (NNP Dropout)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ valuable) (PP (IN for) (NP (DT the) (JJ deep) (NN model) (NN compression))))))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (PRP we)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NNP Shakeout)) (VP (MD can) (ADVP (RB effectively)) (VP (VB reduce) (NP (NP (DT the) (NN instability)) (PP (IN of) (NP (NP (DT the) (NN training) (NN process)) (PP (IN of) (NP (DT the) (JJ deep) (NN architecture))))))))))) (. .))
