(S (NP (NP (JJ Adaptive) (NN gradient) (NNS methods)) (PP (IN like) (NP (NNP AdaGrad)))) (VP (VBP are) (VP (ADVP (RB widely)) (VBN used) (PP (IN in) (S (VP (VBG optimizing) (NP (JJ neural) (NNS networks))))))) (. .))
(S (ADVP (RB Yet)) (, ,) (NP (NP (VBG existing) (NN convergence) (NNS guarantees)) (PP (IN for) (NP (JJ adaptive) (NN gradient) (NNS methods)))) (VP (VP (VBP require) (NP (DT either) (NN convexity) (CC or) (NN smoothness))) (, ,) (CC and) (VP (PRN (, ,) (PP (IN in) (NP (DT the) (JJ smooth) (NN setting))) (, ,)) (ADVP (RB only)) (NN guarantee) (NP (NP (NN convergence)) (PP (TO to) (NP (DT a) (JJ stationary) (NN point)))))) (. .))
(S (NP (PRP$ Our) (NN analysis)) (VP (VBZ indicates) (PP (IN in) (ADJP (JJ particular))) (SBAR (IN that) (S (NP (NN over-parametrization)) (VP (VBZ is) (ADJP (JJ crucial) (PP (IN for) (NP (DT the) (VBG harnessing) (NP (NP (DT the) (JJ full) (NN potential)) (PP (IN of) (NP (JJ adaptive) (NN gradient) (NNS methods)))) (PP (IN in) (NP (NP (DT the) (NN setting)) (PP (IN of) (NP (JJ neural) (NNS networks)))))))))))) (. .))
