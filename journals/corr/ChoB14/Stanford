(S (S (NP (NP (JJ Many) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (NNS results)) (VP (VBN obtained) (PP (IN with) (NP (JJ deep) (NNS networks))))) (VP (VBP are) (VP (VBN achieved) (PP (IN with) (NP (NP (DT the) (JJS largest) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (MD could) (VP (VB be) (VP (VBN trained))))))))))) (, ,) (CC and) (S (SBAR (IN if) (S (NP (JJR more) (JJ computation) (NN power)) (VP (VBD was) (ADJP (JJ available))))) (, ,) (NP (PRP we)) (VP (MD might) (VP (VB be) (ADJP (JJ able) (S (VP (TO to) (VP (VB exploit) (NP (ADJP (RB much) (JJR larger)) (NNS datasets)) (PP (IN in) (NP (NN order) (S (VP (TO to) (VP (VB improve) (NP (NN generalization) (NN ability)))))))))))))) (. .))
(S (SBAR (IN Whereas) (S (PP (IN in) (S (VP (VBG learning) (NP (NP (NNS algorithms)) (PP (JJ such) (IN as) (NP (NN decision) (NNS trees))))))) (NP (NP (DT the) (NN ratio)) (PP (IN of) (NP (NP (NP (NN capacity)) (-LRB- -LRB-) (NP (ADVP (FW e.g.)) (, ,) (NP (DT the) (NN number)) (PP (IN of) (NP (NNS parameters)))) (-RRB- -RRB-)) (PP (IN to) (NP (NN computation)))))) (VP (VBZ is) (ADJP (RB very) (JJ favorable)) (PRN (-LRB- -LRB-) (NP (NP (ADVP (IN up) (PP (IN to) (ADVP (RB exponentially)))) (JJR more) (NNS parameters)) (PP (IN than) (NP (NN computation)))) (-RRB- -RRB-))))) (, ,) (NP (DT the) (NN ratio)) (VP (VBZ is) (ADVP (RB essentially)) (NP (NP (CD 1)) (PP (IN for) (NP (JJ deep) (JJ neural) (NNS networks))))) (. .))
(S (NP (JJ Conditional) (NN computation)) (VP (VBZ has) (VP (VBN been) (VP (VBN proposed) (PP (IN as) (NP (DT a) (NN way))) (S (VP (TO to) (VP (VB increase) (NP (NP (DT the) (NN capacity)) (PP (IN of) (NP (DT a) (JJ deep) (JJ neural) (NN network)))) (PP (IN without) (S (VP (VBG increasing) (NP (NP (DT the) (NN amount)) (PP (IN of) (NP (NP (NN computation)) (VP (VBN required) (, ,) (PP (IN by) (S (VP (VBG activating) (NP (NP (DT some) (NNS parameters) (CC and) (NN computation)) ('' ") (PP (IN on) (HYPH -) (NP (NN demand))) ('' "))))) (, ,) (PP (IN on) (NP (DT a) (NML (PP (IN per) (HYPH -) (NP (NN example)))) (NN basis)))))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN note))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (NN parametrization)) (PP (IN of) (NP (NN weight) (NNS matrices)))) (PP (IN in) (NP (NP (JJ neural) (NNS networks)) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (NP (DT the) (JJ potential) (S (VP (TO to) (VP (VB increase) (PRT (RP up)) (PP (IN to) (NP (NP (ADVP (RB exponentially)) (DT the) (NN ratio)) (PP (IN of) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS parameters))))))) (PP (IN to) (NP (NN computation))))))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN approach)) (VP (VBZ is) (VP (VBN based) (PP (IN on) (S (VP (VBG turning) (PRT (RP on)) (NP (NP (NP (DT some) (NNS parameters)) (-LRB- -LRB-) (NP (NN weight) (NNS matrices)) (-RRB- -RRB-)) (SBAR (WHADVP (WRB when)) (S (NP (NP (JJ specific) (NN bit) (NNS patterns)) (PP (IN of) (NP (JJ hidden) (NN unit) (NNS activations)))) (VP (VBP are) (VP (VBN obtained))))))))))) (. .))
(S (PP (IN In) (NP (NN order) (S (VP (TO to) (ADVP (RBR better)) (VP (VB control) (PP (IN for) (NP (NP (DT the) (NN overfitting)) (SBAR (WHNP (WDT that)) (S (VP (MD might) (VP (VB result)))))))))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (NN parametrization)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (VP (NN tree) (HYPH -) (VBN structured)))))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT each) (NN node)) (PP (IN of) (NP (DT the) (NN tree)))) (VP (VBZ corresponds) (PP (IN to) (NP (NP (NP (DT a) (NN prefix)) (PP (IN of) (NP (NP (DT a) (NN sequence)) (PP (IN of) (NP (NN sign) (NNS bits)))))) (, ,) (CC or) (NP (NP (NN gating) (NNS units)) (, ,) (VP (VBN associated) (PP (IN with) (NP (VBN hidden) (NNS units))))))))))) (. .))
