(S (S (NP (NNP Research)) (VP (VBZ has) (VP (VBN shown) (SBAR (IN that) (S (NP (JJ deep) (JJ neural) (NNS networks)) (VP (VBP contain) (NP (JJ significant) (NN redundancy)))))))) (, ,) (CC and) (S (NP (DT that) (NML (JJ high) (NN classification)) (NNS accuracies)) (VP (MD can) (VP (VB be) (VP (VBN achieved) (ADVP (RB even)) (SBAR (WHADVP (WRB when)) (S (NP (NNS weights) (CC and) (NNS activations)) (VP (VBP are) (VP (VBN quantised) (PRT (RP down)) (PP (IN to) (NP (JJ binary) (NNS values))))))))))) (. .))
(S (NP (NP (NNP Network) (NNP binarisation)) (PP (IN on) (NP (NNPS FPGAs)))) (ADVP (RB greatly)) (VP (VBZ increases) (NP (NN area) (NN efficiency)) (PP (IN by) (S (VP (VBG replacing) (NP (ADJP (NP (NN resource)) (HYPH -) (JJ hungry)) (NNS multipliers)) (PP (IN with) (NP (JJ lightweight) (NN XNOR) (NNS gates))))))) (. .))
(S (S (ADVP (RB However)) (, ,) (NP (NP (NP (DT an) (NNP FPGA) (POS 's)) (JJ fundamental) (NN building) (NN block)) (, ,) (NP (DT the) (NML (NN K) (HYPH -) (NN LUT))) (, ,)) (VP (VBZ is) (ADJP (JJ capable) (PP (IN of) (S (VP (VBG implementing) (ADVP (RB far) (NP (QP (JJR more) (IN than) (DT an)) (NN XNOR))))))))) (: :) (S (NP (PRP it)) (VP (MD can) (VP (VB perform) (NP (DT any) (NML (NN K) (HYPH -) (NN input)) (JJ Boolean) (NN operation))))) (. .))
(S (S (VP (VBN Inspired) (PP (IN by) (NP (DT this) (NN observation))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NNP LUTNet)) (, ,) (NP (NP (DT an) (NML (NML (NN end)) (HYPH -) (PP (IN to) (HYPH -) (NP (NN end)))) (NML (NN hardware) (HYPH -) (NN software)) (NN framework)) (PP (IN for) (NP (NP (DT the) (NN construction)) (PP (IN of) (NP (NP (ADJP (NP (NP (NN area)) (HYPH -) (NP (JJ efficient) (NN FPGA))) (HYPH -) (VBN based)) (NML (JJ neural) (NN network)) (NNS accelerators)) (VP (VBG using) (NP (NP (DT the) (JJ native) (NNS LUTs)) (PP (IN as) (NP (NN inference) (NNS operators)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (NP (DT the) (NN exploitation)) (PP (IN of) (NP (NN LUT) (NN flexibility)))) (VP (VBZ allows) (PP (IN for) (NP (ADJP (RB far) (JJR heavier)) (NN pruning))) (PP (IN than) (ADJP (JJ possible))) (PP (IN in) (NP (JJ prior) (NNS works))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (JJ significant) (NN area) (NNS savings))) (PP (IN while) (S (VP (VBG achieving) (NP (JJ comparable) (NN accuracy))))))))))) (. .))
(S (PP (IN Against) (NP (NP (DT the) (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art))))) (VP (VBN binarised) (NP (JJ neural) (NN network) (NN implementation))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (PDT twice) (DT the) (NN area) (NN efficiency)) (PP (IN for) (NP (JJ several) (JJ standard) (NN network) (NNS models))) (SBAR (WHADVP (WRB when)) (S (VP (VBG inferencing) (NP (JJ popular) (NNS datasets)))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP demonstrate) (SBAR (IN that) (S (NP (ADJP (RB even) (JJR greater)) (NN energy) (NN efficiency) (NNS improvements)) (VP (VBP are) (ADJP (JJ obtainable)))))) (. .))
