(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (DT a) (JJ new) (ADJP (RB intrinsically) (JJ motivated)) (NML (NN actor) (HYPH -) (NN critic)) (NN algorithm)) (PP (IN for) (S (VP (VBG learning) (NP (JJ continuous) (NN motor) (NNS skills)) (ADVP (RB directly)) (PP (IN from) (NP (JJ raw) (JJ visual) (NN input)))))))) (. .))
(S (NP (PRP$ Our) (JJ neural) (NN architecture)) (VP (VBZ is) (VP (VBN composed) (PP (IN of) (NP (NP (DT a) (NN critic)) (CC and) (NP (DT an) (NN actor) (NN network)))))) (. .))
(S (NP (DT Both) (NNS networks)) (VP (VBP receive) (NP (NP (DT the) (JJ hidden) (NN representation)) (PP (IN of) (NP (NP (DT a) (JJ deep) (JJ convolutional) (NN autoencoder)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN trained) (S (VP (TO to) (VP (VB reconstruct) (NP (DT the) (JJ visual) (NN input)))))))))))) (, ,) (SBAR (IN while) (S (NP (DT the) (JJ centre-most) (JJ hidden) (NN representation)) (VP (VBZ is) (ADVP (RB also)) (VP (VBN optimized) (S (VP (TO to) (VP (VB estimate) (NP (DT the) (NN state) (NN value)))))))))) (. .))
(S (ADVP (RB Separately)) (, ,) (NP (NP (DT an) (NN ensemble)) (PP (IN of) (NP (JJ predictive) (NN world) (NNS models)))) (VP (VBZ generates) (, ,) (PP (VBN based) (PP (IN on) (NP (NP (PRP$ its) (NN learning) (NN progress)) (, ,) (NP (NP (DT an) (JJ intrinsic) (NN reward) (NN signal)) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN combined) (PP (IN with) (NP (DT the) (JJ extrinsic) (NN reward))) (S (VP (TO to) (VP (VB guide) (NP (NP (DT the) (NN exploration)) (PP (IN of) (NP (DT the) (NML (NN actor) (HYPH -) (NN critic)) (NN learner)))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ is) (ADJP (ADJP (RBR more) (NN data) (HYPH -) (JJ efficient)) (CC and) (ADJP (RB inherently) (RBR more) (JJ stable) (PP (IN than) (NP (DT the) (VBG existing) (NML (NN actor) (HYPH -) (NN critic)) (NNS methods))))) (PP (IN for) (NP (NP (JJ continuous) (NN control)) (PP (IN from) (NP (NN pixel) (NNS data)))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (PRP$ our) (NN algorithm)) (PP (IN for) (NP (NP (DT the) (NN task)) (PP (IN of) (S (VP (VP (VBG learning) (ADJP (JJ robotic) (VBG reaching))) (CC and) (VP (VBG grasping) (NP (NNS skills)) (PP (PP (IN on) (NP (DT a) (JJ realistic) (NN physics) (NN simulator))) (CC and) (PP (IN on) (NP (DT a) (JJ humanoid) (NN robot))))))))))) (. .))
(S (NP (DT The) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (DT the) (NN control) (NNS policies)) (VP (VBD learned) (SBAR (IN with) (S (NP (PRP$ our) (NN approach)) (VP (MD can) (VP (VB achieve) (NP (JJR better) (NN performance)) (PP (IN than) (NP (NP (DT the) (VBN compared) (ADJP (NN state) (HYPH -) (IN of) (HYPH -) (DT the) (HYPH -) (NN art))) (CC and) (NP (NP (NN baseline) (NNS algorithms)) (PP (IN in) (NP (NP (DT both) (JJ dense) (HYPH -) (NN reward)) (CC and) (NP (ADJP (JJ challenging) (NP (JJ sparse) (HYPH -) (NN reward))) (NNS settings))))))))))))))) (. .))
