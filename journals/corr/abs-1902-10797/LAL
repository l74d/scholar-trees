(S (NP (PRP We)) (VP (VBP aim) (S (VP (TO to) (VP (VB design) (NP (NP (JJ adaptive) (NN online) (VBG learning) (RP algorithms)) (SBAR (WHNP (DT that)) (S (VP (VBP take) (NP (NN advantage)) (PP (IN of) (NP (NP (DT any) (JJ special) (NN structure)) (SBAR (WHNP (WDT that)) (S (VP (MD might) (VP (VB be) (ADJP (JJ present) (PP (IN in) (NP (NP (DT the) (NN learning) (NN task)) (PP (IN at) (NP (NN hand)))))))))))) (, ,) (PP (IN with) (NP (NP (ADJP (RB as) (JJ little)) (JJ manual) (NN tuning)) (PP (IN by) (NP (DT the) (NN user))) (PP (IN as) (ADJP (JJ possible))))))))))))) (. .))
(S (NP (NP (DT A) (JJ fundamental) (NN obstacle)) (SBAR (WHNP (WDT that)) (S (VP (VBZ comes) (PRT (RP up)) (PP (IN in) (NP (NP (DT the) (NN design)) (PP (IN of) (NP (JJ such) (JJ adaptive) (NN algorithms))))))))) (VP (VBZ is) (S (VP (TO to) (VP (VB calibrate) (NP (DT a) (JJ so-called) (UCP (NN step-size) (CC or) (VBG learning)) (NN rate) (NN hyperparameter)) (PP (VBG depending) (PP (IN on) (NP (NP (NN variance)) (, ,) (NP (NN gradient) (NNS norms)) (, ,) (FW etc)))))))) (. .))
(S (NP (DT A) (JJ recent) (NN technique)) (VP (NNS promises) (S (VP (TO to) (VP (VB overcome) (NP (DT this) (NN difficulty)) (PP (IN by) (S (VP (VBG maintaining) (NP (JJ multiple) (VBG learning) (NNS rates)) (PP (IN in) (NP (NN parallel)))))))))) (. .))
(S (NP (DT This) (NN technique)) (VP (VBZ has) (VP (VBN been) (VP (VBN applied) (PP (IN in) (NP (NP (NP (DT the) (NNP MetaGrad) (NN algorithm)) (PP (IN for) (NP (JJ online) (NN convex) (NN optimization)))) (CC and) (NP (NP (NP (DT the) (NNP Squint) (NN algorithm)) (PP (IN for) (NP (NN prediction)))) (PP (IN with) (NP (JJ expert) (NN advice))))))))) (. .))
(S (ADVP (RB However)) (, ,) (PP (IN in) (NP (DT both) (NNS cases))) (NP (DT the) (NN user)) (ADVP (RB still)) (VP (VBZ has) (S (VP (TO to) (VP (VB provide) (PP (IN in) (NP (NN advance))) (NP (NP (DT a) (NNP Lipschitz) (NN hyperparameter)) (SBAR (WHNP (WDT that)) (S (VP (VBZ bounds) (NP (NP (DT the) (NN norm)) (PP (IN of) (NP (DT the) (NNS gradients)))))))))))) (. .))
(S (S (SBAR (IN Although) (S (NP (DT this) (NN hyperparameter)) (VP (VBZ is) (ADVP (RB typically)) (RB not) (JJ available) (PP (IN in) (NP (NN advance)))))) (, ,) (S (VP (VBG tuning) (NP (PRP it)) (ADVP (RB correctly)))) (VP (VBZ is) (ADJP (JJ crucial)))) (: :) (S (S (SBAR (IN if) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN set) (ADVP (RB too) (JJ small)))))) (, ,) (NP (DT the) (NNS methods)) (VP (MD may) (VP (VB fail) (ADVP (RB completely))))) (: ;) (CC but) (S (SBAR (IN if) (S (NP (PRP it)) (VP (VBZ is) (VP (VBN taken) (ADVP (RB too) (JJ large)))))) (, ,) (NP (NN performance)) (VP (NNS deteriorates) (ADVP (RB significantly))))) (. .))
(S (PP (IN In) (NP (DT the) (JJ present) (NN work))) (NP (PRP we)) (VP (VBP remove) (NP (DT this) (NNP Lipschitz) (NN hyperparameter)) (PP (IN by) (S (VP (VBG designing) (NP (NP (JJ new) (NNS versions)) (PP (IN of) (NP (NNP MetaGrad) (CC and) (NNP Squint))) (SBAR (WHNP (WDT that)) (S (VP (VBZ adapt) (PP (TO to) (NP (PRP$ its) (JJ optimal) (NN value))) (ADVP (RB automatically)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP achieve) (NP (DT this)) (PP (IN by) (S (VP (ADVP (RB dynamically)) (VBG updating) (NP (NP (DT the) (NN set)) (PP (IN of) (NP (JJ active) (NN learning) (NNS rates)))))))) (. .))
(S (PP (IN For) (NP (NNP MetaGrad))) (, ,) (S (NP (PRP we)) (VP (ADVP (VBP further)) (VB improve) (NP (NP (DT the) (JJ computational) (NN efficiency)) (PP (IN of) (S (VP (VBG handling) (NP (NP (NNS constraints)) (PP (IN on) (NP (NP (DT the) (NN domain)) (PP (IN of) (NP (NN prediction)))))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP remove) (NP (DT the) (NN need) (S (VP (TO to) (VP (VB specify) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS rounds)))) (PP (IN in) (NP (NN advance))))))))) (. .))
