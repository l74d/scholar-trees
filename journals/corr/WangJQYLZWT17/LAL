(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (`` ``) (NP (JJ Residual) (NNP Attention) (NNP Network)) ('' '') (, ,) (NP (NP (DT a) (JJ convolutional) (JJ neural) (NN network)) (VP (VBG using) (NP (NP (NN attention) (NN mechanism)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB incorporate) (PP (IN with) (NP (JJ state-of-art) (NN feed) (NN forward) (NN network) (NN architecture))) (PP (IN in) (NP (DT an) (JJ end-to-end) (NN training) (NN fashion)))))))))))) (. .))
(S (NP (PRP$ Our) (JJ Residual) (NNP Attention) (NNP Network)) (VP (VBZ is) (VP (VBN built) (PP (IN by) (S (VP (VBG stacking) (NP (NP (NNP Attention) (NNP Modules)) (SBAR (WHNP (WDT which)) (S (VP (VBP generate) (NP (NN attention-aware) (NNS features))))))))))) (. .))
(S (NP (NP (DT The) (JJ attention-aware) (NNS features)) (PP (IN from) (NP (JJ different) (NNS modules)))) (VP (VBP change) (ADVP (RB adaptively)) (PP (IN as) (S (NP (NNS layers)) (VP (VBG going) (ADVP (NN deeper)))))) (. .))
(S (PP (IN Inside) (NP (DT each) (NNP Attention) (NNP Module))) (, ,) (NP (ADJP (JJ bottom-up) (JJ top-down)) (NN feedforward) (NN structure)) (VP (VBZ is) (VP (VBN used) (S (VP (TO to) (VP (VB unfold) (NP (DT the) (NN feedforward) (CC and) (NN feedback) (NN attention) (NN process)) (PP (IN into) (NP (DT a) (JJ single) (NN feedforward) (NN process)))))))) (. .))
(S (ADVP (RB Importantly)) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NN attention) (JJ residual) (NN learning)) (S (VP (TO to) (VP (VB train) (NP (NP (ADJP (RB very) (JJ deep)) (NNP Residual) (NNP Attention) (NNP Networks)) (SBAR (WHNP (WDT which)) (S (VP (MD can) (VP (VB be) (VP (ADVP (RB easily)) (VBN scaled) (ADVP (RP up)) (PP (TO to) (NP (NP (NNS hundreds)) (PP (IN of) (NP (NNS layers))))))))))))))) (. .))
(S (NP (JJ Extensive) (NNS analyses)) (VP (VBP are) (VP (VBN conducted) (PP (IN on) (NP (NNP CIFAR-10) (CC and) (NNP CIFAR-100) (NNS datasets))) (S (VP (TO to) (VP (VB verify) (NP (NP (DT the) (NN effectiveness)) (PP (IN of) (NP (NP (DT every) (NN module)) (VP (VBN mentioned) (ADVP (IN above))))))))))) (. .))
(S (NP (PRP$ Our) (JJ Residual) (NNP Attention) (NNP Network)) (VP (VBZ achieves) (NP (JJ state-of-the-art) (JJ object) (NN recognition) (NN performance)) (PP (IN on) (NP (NP (CD three) (NN benchmark) (NNS datasets)) (PP (VBG including) (NP (NP (NP (NNP CIFAR-10)) (PRN (-LRB- -LRB-) (NP (ADJP (CD 3.90) (NN %)) (NN error)) (-RRB- -RRB-))) (, ,) (NP (NP (NNP CIFAR-100)) (PRN (-LRB- -LRB-) (NP (ADJP (CD 20.45) (NN %)) (NN error)) (-RRB- -RRB-))) (CC and) (NP (NP (NNP ImageNet)) (PRN (-LRB- -LRB-) (NP (NP (ADJP (CD 4.8) (NN %)) (NX (NX (JJ single) (NN model)) (CC and) (NX (JJ single) (NN crop)))) (, ,) (NP (JJ top-5) (NN error))) (-RRB- -RRB-)))))))) (. .))
(S (VP (NN Note) (SBAR (IN that) (, ,) (S (NP (PRP$ our) (NN method)) (VP (VBZ achieves) (NP (ADJP (CD 0.6) (NN %)) (JJ top-1) (NN accuracy) (NN improvement)) (PP (IN with) (NP (NP (ADJP (CD 46) (NN %)) (NN trunk) (NN depth)) (CC and) (NP (ADJP (CD 69) (NN %)) (RB forward) (NNP FLOPs)))) (S (VP (VBG comparing) (PP (TO to) (NP (NNP ResNet-200))))))))) (. .))
(S (NP (DT The) (NN experiment)) (ADVP (RB also)) (VP (VBZ demonstrates) (SBAR (IN that) (S (NP (PRP$ our) (NN network)) (VP (VBZ is) (ADJP (JJ robust) (PP (IN against) (NP (JJ noisy) (NNS labels)))))))) (. .))
