(S (SBAR (IN Although) (S (NP (NML (NML (NN state)) (HYPH -) (PP (IN of) (HYPH -) (NP (DT the) (HYPH -) (NN art)))) (PRN (-LRB- -LRB-) (NP (NN SOTA)) (-RRB- -RRB-)) (NNS CNNs)) (VP (VBP achieve) (NP (JJ outstanding) (NN performance)) (PP (IN on) (NP (JJ various) (NNS tasks)))))) (, ,) (NP (NP (PRP$ their) (NML (JJ high) (NN computation)) (NN demand)) (CC and) (NP (NP (JJ massive) (NN number)) (PP (IN of) (NP (NNS parameters))))) (VP (VBP make) (S (NP (PRP it)) (ADJP (JJ difficult) (S (VP (TO to) (VP (VB deploy) (NP (DT these) (NNP SOTA) (NNPS CNNs)) (PP (IN onto) (NP (ADJP (NP (NN resource)) (HYPH -) (VBN constrained)) (NNS devices))))))))) (. .))
(S (NP (NP (JJ Previous) (NNS works)) (PP (IN on) (NP (NNP CNN) (NN acceleration)))) (VP (VB utilize) (NP (NP (NML (JJ low) (HYPH -) (NN rank)) (NN approximation)) (PP (IN of) (NP (DT the) (JJ original) (NN convolution) (NNS layers)))) (S (VP (TO to) (VP (VB reduce) (NP (NN computation) (NN cost)))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT these) (NNS methods)) (VP (VBP are) (ADJP (RB very) (JJ difficult) (S (VP (TO to) (VP (VB conduct) (PP (IN upon) (NP (NP (JJ sparse) (NNS models)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ limits) (NP (NN execution) (NN speedup)) (SBAR (IN since) (S (NP (NP (NNS redundancies)) (PP (IN within) (NP (DT the) (NNP CNN) (NN model)))) (VP (VBP are) (RB not) (ADVP (RB fully)) (VP (VBN exploited))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP argue) (SBAR (IN that) (S (NP (NN kernel) (NN granularity) (NN decomposition)) (VP (MD can) (VP (VB be) (VP (VBN conducted) (PP (IN with) (NP (NML (JJ low) (HYPH -) (NN rank)) (NN assumption))) (PP (IN while) (S (VP (VBG exploiting) (NP (NP (DT the) (NN redundancy)) (PP (IN within) (NP (DT the) (VBG remaining) (JJ compact) (NNS coefficients))))))))))))) (. .))
(S (PP (VBN Based) (PP (IN on) (NP (DT this) (NN observation)))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NNP PENNI)) (, ,) (NP (NP (DT a) (NNP CNN) (NML (NN model) (NN compression)) (NN framework)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ able) (S (VP (TO to) (VP (VB achieve) (SBAR (WHNP (NP (NN model) (NN compactness) (CC and) (NN hardware) (NN efficiency)) (PP (ADVP (RB simultaneously)) (IN by) (PRN (-LRB- -LRB-) (NP (CD 1)) (-RRB- -RRB-)))) (S (S (VP (VBG implementing) (NP (NN kernel) (NN sharing)) (PP (IN in) (NP (NP (NN convolution) (NNS layers)) (PP (IN via) (NP (NP (DT a) (JJ small) (NN number)) (PP (IN of) (NP (NN basis) (NNS kernels))))))))) (CC and) (S (LST (-LRB- -LRB-) (LS 2) (-RRB- -RRB-)) (VP (ADVP (RB alternately)) (VBG adjusting) (NP (NP (NNS bases) (CC and) (NNS coefficients)) (PP (IN with) (NP (JJ sparse) (NNS constraints)))))))))))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (PRP we)) (VP (MD can) (VP (VP (VB prune) (NP (NP (NML (CD 97) (NN %)) (NNS parameters)) (CC and) (NP (NP (CD 92) (NN %) (NNS FLOPs)) (PP (IN on) (NP (NN ResNet18) (NN CIFAR10))))) (PP (IN with) (NP (DT no) (NN accuracy) (NN loss)))) (, ,) (CC and) (VP (VB achieve) (NP (NML (CD 44) (NN %)) (NN reduction)) (PP (IN in) (NP (NP (NML (NN run) (HYPH -) (NN time)) (NN memory) (NN consumption)) (CC and) (NP (DT a) (NML (CD 53) (NN %)) (NN reduction)))) (PP (IN in) (NP (NN inference) (NN latency))))))))) (. .))
