(S (NP (NP (JJ Recurrent) (NNP Neural) (NNP Networks)) (PRN (-LRB- -LRB-) (NP (NNP RNN)) (-RRB- -RRB-))) (VP (MD can) (VP (VB be) (ADJP (JJ difficult) (SBAR (S (VP (TO to) (VP (VB deploy) (PP (IN on) (NP (ADJP (NN resource) (VBN constrained)) (NNS devices)))))))) (PP (JJ due) (TO to) (NP (PRP$ their) (NN size))))) (. .))
(S (PP (IN As) (NP (DT a) (NN result))) (, ,) (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (NN need)) (PP (IN for) (NP (NP (NN compression) (NNS techniques)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (ADVP (RB significantly)) (VB compress) (NP (NNP RNNs)) (PP (IN without) (S (VP (ADVP (RB negatively)) (VBG impacting) (NP (NN task) (NN accuracy))))))))))))) (. .))
(S (NP (DT This) (NN paper)) (VP (VBZ introduces) (NP (NP (DT a) (NN method)) (SBAR (S (VP (TO to) (VP (VB compress) (NP (NNP RNNs)) (PP (IN for) (NP (ADJP (NN resource) (VBD constrained)) (NNS environments))) (S (VP (VBG using) (NP (NP (NNP Kronecker) (NN product)) (PRN (-LRB- -LRB-) (NP (NNP KP)) (-RRB- -RRB-))))))))))) (. .))
(S (NP (NNP KPs)) (VP (MD can) (VP (VB compress) (NP (NNP RNN) (NNS layers)) (PP (IN by) (NP (JJ 16-38x))) (PP (IN with) (NP (JJ minimal) (NN accuracy) (NN loss))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP KP)) (VP (MD can) (VP (VB beat) (NP (NP (DT the) (NN task) (NN accuracy)) (VP (VBN achieved) (PP (IN by) (NP (NP (JJ other) (JJ state-of-the-art) (NN compression) (NNS techniques)) (PRN (-LRB- -LRB-) (NP (NP (VBG pruning)) (CC and) (NP (JJ low-rank) (NN matrix) (NN factorization))) (-RRB- -RRB-)))))) (PP (IN across) (NP (NP (CD 4) (NNS benchmarks)) (VP (VBG spanning) (NP (CD 3) (JJ different) (NNS applications))))) (, ,) (SBAR (IN while) (S (ADVP (RB simultaneously)) (VP (VBG improving) (NP (NN inference) (NN run-time)))))))))) (. .))
