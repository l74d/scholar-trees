(S (NP (NP (JJ Many) (NNS approaches)) (SBAR (S (VP (TO to) (VP (VB transform) (NP (NN classification) (NNS problems)) (PP (IN from) (ADJP (JJ non-linear))) (PP (TO to) (ADJP (VB linear))) (PP (IN by) (NP (NN feature) (NN transformation)))))))) (VP (VBP have) (VP (VBN been) (ADVP (RB recently)) (VP (VBN presented) (PP (IN in) (NP (DT the) (NN literature)))))) (. .))
(S (NP (DT These)) (ADVP (RB notably)) (VP (VBP include) (NP (NP (JJ sparse) (VBG coding) (NNS methods)) (CC and) (NP (JJ deep) (JJ neural) (NNS networks)))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (JJ many)) (PP (IN of) (NP (DT these) (NNS approaches)))) (VP (VP (VBP require) (NP (NP (DT the) (JJ repeated) (NN application)) (PP (IN of) (NP (DT a) (NN learning) (NN process))) (PP (IN upon) (NP (NP (DT the) (NN presentation)) (PP (IN of) (NP (JJ unseen) (NNS data) (NN input) (NNS vectors))))))) (, ,) (CC or) (ADVP (RB else)) (VP (VB involve) (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NP (JJ large) (NNS numbers)) (PP (IN of) (NP (NNS parameters) (CC and) (NNS hyper-parameters))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD must) (VP (VB be) (VP (VBN chosen) (PP (IN through) (NP (NN cross-validation))) (, ,) (S (ADVP (RB thus)) (VP (VBG increasing) (NP (VBG running) (NN time)) (ADVP (RB dramatically)))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VP (VBP propose)) (CC and) (VP (ADVP (RB experimentally)) (VB investigate)) (NP (DT a) (JJ new) (NN approach)) (PP (IN for) (NP (NP (DT the) (NN purpose)) (PP (IN of) (S (VP (VBG overcoming) (NP (NP (NNS limitations)) (PP (IN of) (NP (DT both) (NNS kinds)))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN approach)) (VP (VBZ makes) (NP (NP (NN use)) (PP (IN of) (NP (NP (DT a) (JJ linear) (JJ auto-associative) (NN network)) (PRN (-LRB- -LRB-) (VP (VBN called) (S (NP (NNP SCNN)))) (-RRB- -RRB-)) (PP (IN with) (NP (QP (RB just) (CD one)) (JJ hidden) (NN layer))))))) (. .))
(S (NP (NP (DT The) (NN combination)) (PP (IN of) (NP (DT this) (NN architecture))) (PP (IN with) (NP (NP (DT a) (JJ specific) (NN error) (NN function)) (SBAR (S (VP (TO to) (VP (VB be) (VP (VBN minimized))))))))) (VP (VBZ enables) (S (NP (CD one)) (VP (TO to) (VP (VB learn) (NP (NP (DT a) (JJ linear) (NN encoder)) (VP (VBG computing) (NP (NP (DT a) (NN sparse) (NN code)) (SBAR (WHNP (WDT which)) (S (VP (VBZ turns) (PRT (RP out)) (S (VP (TO to) (VP (VB be) (ADJP (ADJP (RB as) (JJ similar)) (PP (IN as) (ADJP (JJ possible))) (PP (TO to) (NP (NP (DT the) (NN sparse) (VBG coding)) (SBAR (WHNP (IN that)) (S (NP (CD one)) (VP (NNS obtains) (PP (IN by) (S (VP (VBG re-training) (NP (DT the) (JJ neural) (NN network)))))))))))))))))))))))) (. .))
(S (ADVP (RB Importantly)) (, ,) (NP (NP (NP (DT the) (NN linearity)) (PP (IN of) (NP (NNP SCNN)))) (CC and) (NP (NP (DT the) (NN choice)) (PP (IN of) (NP (DT the) (NN error) (NN function))))) (VP (VB allow) (S (NP (CD one)) (VP (TO to) (VP (VB achieve) (NP (VBN reduced) (JJ running) (NN time)) (PP (IN in) (NP (DT the) (JJ learning) (NN phase))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN architecture)) (VP (VBZ is) (VP (VBN evaluated) (PP (IN on) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (CD two) (JJ standard) (NN machine) (NN learning) (NNS tasks))))))) (. .))
(S (NP (PRP$ Its) (NNS performances)) (VP (VBP are) (VP (VBN compared) (PP (IN with) (NP (NP (DT those)) (PP (IN of) (NP (ADJP (RB recently) (VBN proposed)) (JJ non-linear) (JJ auto-associative) (JJ neural) (NNS networks))))))) (. .))
(S (NP (DT The) (JJ overall) (NNS results)) (VP (VBP suggest) (SBAR (IN that) (S (NP (JJ linear) (NNS encoders)) (VP (MD can) (VP (VB be) (VP (ADVP (RB profitably)) (VBN used) (S (VP (TO to) (VP (VB obtain) (NP (JJ sparse) (NNS data) (NNS representations))))) (PP (IN in) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (NN machine) (NN learning) (NNS problems))))) (, ,) (PP (VBD provided) (SBAR (IN that) (S (NP (DT an) (JJ appropriate) (NN error) (NN function)) (VP (VBZ is) (VP (VBN used) (PP (IN during) (NP (DT the) (JJ learning) (NN phase)))))))))))))) (. .))
