(S (S (NP (NP (NP (NNP Monte) (NNP Carlo) (NNP Tree) (NNP Search)) (-LRB- -LRB-) (NP (NNP MCTS)) (-RRB- -RRB-)) (NP (NNS methods))) (VP (VBP have) (VP (VBN proven) (S (ADJP (JJ powerful) (PP (IN in) (S (VP (VBG planning) (PP (IN for) (NP (NP (JJ sequential) (ADJP (NN decision) (HYPH -) (VBG making)) (NNS problems)) (PP (JJ such) (IN as) (NP (NML (NML (NNP Go)) (CC and) (NML (NN video))) (NNS games))))))))))))) (, ,) (CC but) (S (NP (PRP$ their) (NN performance)) (VP (MD can) (VP (VB be) (ADJP (JJ poor)) (SBAR (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NML (NN planning) (NN depth) (CC and) (NN sampling)) (NNS trajectories)) (VP (VBP are) (ADJP (JJ limited))))) (CC or) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NNS rewards)) (VP (VBP are) (ADJP (JJ sparse))))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT an) (NN adaptation)) (PP (IN of) (NP (NN PGRD) (PRN (-LRB- -LRB-) (NP (NP (NN policy) (HYPH -) (NN gradient)) (PP (IN for) (NP (NN reward) (HYPH -) (NN design)))) (-RRB- -RRB-))))) (PP (IN for) (S (VP (VBG learning) (NP (DT a) (NML (NN reward) (HYPH -) (NN bonus)) (NN function)) (S (VP (TO to) (VP (VB improve) (NP (NP (NNP UCT)) (-LRB- -LRB-) (NP (DT a) (NNP MCTS) (NN algorithm)) (-RRB- -RRB-))))))))) (. .))
(S (PP (IN Unlike) (NP (NP (JJ previous) (NNS applications)) (PP (IN of) (NP (NP (NN PGRD)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NP (DT the) (NN space)) (PP (IN of) (NP (NML (NN reward) (HYPH -) (NN bonus)) (NNS functions)))) (VP (VBD was) (VP (VBN limited) (PP (IN to) (NP (NP (JJ linear) (NNS functions)) (PP (IN of) (NP (ADJP (NN hand) (HYPH -) (VBN coded)) (NML (NN state) (HYPH -) (NN action) (HYPH -)) (NNS features))))))))))))) (, ,) (NP (PRP we)) (VP (VBP use) (NP (NP (NNP PGRD)) (PP (IN with) (NP (DT a) (JJ multi-layer) (JJ convolutional) (JJ neural) (NN network)))) (S (VP (VP (TO to) (ADVP (RB automatically)) (VP (VB learn) (NP (NNS features)) (PP (IN from) (NP (JJ raw) (NN perception))))) (CONJP (RB as) (RB well) (IN as)) (VP (TO to) (VP (VB adapt) (NP (DT the) (JJ non-linear) (NML (NN reward) (HYPH -) (NN bonus)) (NN function) (NNS parameters))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VB adopt) (NP (DT a) (ADJP (NN variance) (HYPH -) (VBG reducing)) (NN gradient) (NN method)) (S (VP (TO to) (VP (VB improve) (NP (NP (NNP PGRD) (POS 's)) (NN performance)))))) (. .))
(S (NP (DT The) (JJ new) (NN method)) (VP (VBZ improves) (NP (NP (NP (NNP UCT) (POS 's)) (NN performance)) (PP (IN on) (NP (JJ multiple) (NNP ATARI) (NNS games)))) (PP (VBN compared) (PP (IN to) (NP (NP (NNP UCT)) (PP (IN without) (NP (DT the) (NN reward) (NN bonus))))))) (. .))
(S (NP (NP (VBG Combining) (NN PGRD)) (CC and) (NP (NP (JJ Deep) (NN Learning)) (PP (IN in) (NP (DT this) (NN way))))) (VP (MD should) (VP (VB make) (S (VP (VBG adapting) (S (NP (NP (NNS rewards)) (PP (IN for) (NP (NNP MCTS) (NNS algorithms)))) (ADJP (ADJP (ADVP (RB far) (RBR more) (RB widely) (CC and) (RB practically)) (JJ applicable)) (PP (IN than) (ADVP (RB before))))))))) (. .))
