(S (NP (JJ Deep) (NN Learning) (NNS models)) (VP (VBP have) (VP (VBN become) (NP (NP (DT the) (JJ dominant) (NN approach)) (PP (IN in) (NP (JJ several) (NNS areas)))) (PP (IN due) (PP (IN to) (NP (PRP$ their) (JJ high) (NN performance)))))) (. .))
(S (ADVP (RB Unfortunately)) (, ,) (NP (NP (DT the) (NN size)) (CC and) (NP (NP (RB hence) (JJ computational) (NNS requirements)) (PP (IN of) (NP (VBG operating) (JJ such) (NNS models))))) (VP (MD can) (VP (VB be) (ADJP (RB considerably) (JJ high)))) (. .))
(S (ADVP (RB Therefore)) (, ,) (NP (DT this)) (VP (VBZ constitutes) (NP (NP (DT a) (NN limitation)) (PP (IN for) (NP (NP (NP (NN deployment)) (PP (IN on) (NP (NN memory)))) (CC and) (NP (NP (ADJP (NN battery) (VBN constrained)) (NNS devices)) (PP (JJ such) (IN as) (NP (NP (JJ mobile) (NNS phones)) (CC or) (NP (VBN embedded) (NNS systems))))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT these) (NNS limitations))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (DT a) (NN novel)) (CC and) (NP (JJ simple) (NN pruning) (NN method))) (SBAR (WHNP (WDT that)) (S (VP (VBZ compresses) (NP (JJ neural) (NNS networks)) (PP (IN by) (S (VP (VBG removing) (NP (JJ entire) (NNS filters) (CC and) (NNS neurons)) (PP (VBG according) (PP (IN to) (NP (NP (DT a) (JJ global) (NN threshold)) (PP (IN across) (NP (NP (DT the) (NN network)) (PP (IN without) (NP (NP (DT any) (NN pre-calculation)) (PP (IN of) (NP (NN layer) (NN sensitivity)))))))))))))))))) (. .))
(S (NP (DT The) (VBG resulting) (NN model)) (VP (VP (VBZ is) (ADJP (JJ compact) (, ,) (JJ non-sparse)) (, ,) (PP (IN with) (NP (NP (DT the) (JJ same) (NN accuracy)) (PP (IN as) (NP (DT the) (JJ non-compressed) (NN model)))))) (, ,) (CC and) (ADVP (RBS most) (RB importantly)) (VP (VBZ requires) (NP (DT no) (JJ special) (NN infrastructure)) (PP (IN for) (NP (NN deployment))))) (. .))
(S (NP (PRP We)) (VP (VBP prove) (NP (NP (DT the) (NN viability)) (PP (IN of) (NP (PRP$ our) (NN method)))) (PP (IN by) (S (VP (VBG producing) (NP (NP (ADJP (RB highly) (JJ compressed)) (NNS models)) (, ,) (ADVP (RB namely)) (NP (NP (NML (NML (NN VGG) (HYPH -) (CD 16)) (, ,) (NML (NNP ResNet) (HYPH -) (CD 56)) (, ,) (CC and) (NML (NNP ResNet) (HYPH -) (CD 110)))) (PP (ADVP (RB respectively)) (PP (IN on) (NP (NP (NN CIFAR10)) (PP (IN without) (S (VP (VBG losing) (NP (DT any) (NN performance)) (PP (VBN compared) (PP (IN to) (NP (DT the) (NN baseline))))))))) (, ,) (CONJP (RB as) (RB well) (IN as) (NP (NP (NML (NML (NNP ResNet) (HYPH -) (CD 34)) (CC and) (NML (NNP ResNet))) (HYPH -) (CD 50)) (PP (IN on) (NP (NNP ImageNet))))) (PP (IN without) (NP (NP (DT a) (JJ significant) (NN loss)) (PP (IN of) (NP (NN accuracy)))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB also)) (VP (VBP provide) (NP (NP (NP (DT a) (RB well)) (HYPH -) (VP (VBN retrained) (NP (ADJP (NP (CD 30) (NN %)) (JJ compressed)) (NML (NNP ResNet) (HYPH -) (CD 50))))) (SBAR (WHNP (WDT that)) (S (ADVP (RB slightly)) (VP (VBZ surpasses) (NP (DT the) (NN base) (NN model) (NN accuracy))))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (VP (VBG compressing) (NP (NP (QP (JJR more) (IN than) (CD 56) (NN %) (CC and) (CD 97)) (NN %)) (PP (IN of) (NP (NP (NNP AlexNet)) (CC and) (NP (NNP LeNet) (HYPH -) (CD 5))))) (ADVP (RB respectively))) (. .))
(S (ADVP (RB Interestingly)) (, ,) (NP (NP (DT the)) (VP (VBN resulted) (NP (NP (NNS models) (POS ')) (NN pruning) (NNS patterns)))) (VP (VBP are) (ADJP (RB highly) (JJ similar) (PP (IN to) (NP (NP (DT the) (JJ other) (NNS methods)) (VP (VBG using) (NP (NN layer) (NN sensitivity) (NN pre-calculation) (NN step))))))) (. .))
(S (S (NP (PRP$ Our) (NN method)) (VP (VP (VBZ does)) (CONJP (RB not) (RB only)) (VP (VBP exhibit) (NP (JJ good) (NN performance))))) (CC but) (FRAG (SBAR (WHNP (WP what)) (S (VP (VBZ is) (ADJP (JJR more))))) (ADVP (RB also)) (ADJP (JJ easy) (S (VP (TO to) (VP (VB implement)))))) (. .))
