(S (PP (IN For) (NP (JJ model-free) (NN reinforcement) (NN learning))) (, ,) (NP (NP (DT the) (JJ main) (NN difficulty)) (PP (IN of) (NP (JJ stochastic) (NNP Bellman) (JJ residual) (NN minimization)))) (VP (VBZ is) (NP (NP (DT the) (JJ double) (NN sampling) (NN problem)) (, ,) (FW i.e.) (, ,) (S (SBAR (IN while) (S (NP (NP (QP (RB only) (CD one)) (JJ single) (NN sample)) (PP (IN for) (NP (DT the) (JJ next) (NN state)))) (VP (VBZ is) (ADJP (JJ available)) (PP (IN in) (NP (DT the) (JJ model-free) (NN setting)))))) (, ,) (NP (NP (CD two) (JJ independent) (NNS samples)) (PP (IN for) (NP (DT the) (JJ next) (NN state)))) (VP (VBP are) (VP (VBN required) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB perform) (NP (JJ unbiased) (JJ stochastic) (NN gradient) (NN descent))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (JJ new) (NN algorithms)) (PP (IN for) (S (VP (VBG addressing) (NP (DT this) (NN problem))))) (VP (VBN based) (PP (IN on) (NP (NP (DT the) (JJ key) (NN idea)) (PP (IN of) (S (VP (VBG borrowing) (NP (JJ extra) (NN randomness)) (PP (IN from) (NP (DT the) (NN future))))))))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (NP (DT the) (NN transition) (NN kernel)) (VP (VBZ varies) (ADVP (RB slowly)) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (DT the) (NN state)))))))) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBN shown) (SBAR (IN that) (S (NP (NP (DT the) (NN training) (NN trajectory)) (PP (IN of) (NP (JJ new) (NN algorithms)))) (VP (VBZ is) (ADJP (RB close) (PP (TO to) (NP (NP (DT the) (CD one)) (PP (IN of) (NP (JJ unbiased) (JJ stochastic) (NN gradient) (NN descent))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP apply) (NP (DT the) (JJ new) (NN algorithms)) (PP (TO to) (NP (NN policy) (NN evaluation))) (PP (IN in) (NP (UCP (DT both) (JJ tabular) (CC and) (JJ neural)) (NN network) (NNS settings))) (S (VP (TO to) (VP (VB confirm) (NP (DT the) (JJ theoretical) (NNS findings)))))) (. .))
