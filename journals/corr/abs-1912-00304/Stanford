(S (S (PP (IN For) (NP (NML (NN model) (HYPH -) (JJ free)) (NN reinforcement) (NN learning))) (, ,) (NP (NP (DT the) (JJ main) (NN difficulty)) (PP (IN of) (NP (JJ stochastic) (NNP Bellman) (JJ residual) (NN minimization)))) (VP (VBZ is) (NP (NP (DT the) (NML (JJ double) (NN sampling)) (NN problem)) (, ,) (ADVP (FW i.e.))) (, ,) (SBAR (IN while) (S (NP (NP (RB only) (CD one) (JJ single) (NN sample)) (PP (IN for) (NP (DT the) (JJ next) (NN state)))) (VP (VBZ is) (ADJP (JJ available) (PP (IN in) (NP (DT the) (NML (NN model) (HYPH -) (JJ free)) (NN setting))))))))) (, ,) (NP (NP (CD two) (JJ independent) (NNS samples)) (PP (IN for) (NP (DT the) (JJ next) (NN state)))) (VP (VBP are) (VP (VBN required) (PP (IN in) (NP (NN order))) (S (VP (TO to) (VP (VB perform) (NP (JJ unbiased) (JJ stochastic) (NN gradient) (NN descent))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (JJ new) (NNS algorithms)) (PP (IN for) (S (VP (VBG addressing) (NP (DT this) (NN problem)) (PP (VBN based) (PP (IN on) (NP (NP (DT the) (JJ key) (NN idea)) (PP (IN of) (S (VP (VBG borrowing) (NP (JJ extra) (NN randomness)) (PP (IN from) (NP (DT the) (NN future))))))))))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (NP (DT the) (NN transition) (NN kernel)) (VP (VBZ varies) (ADVP (RB slowly) (PP (IN with) (NP (NN respect)))) (PP (IN to) (NP (DT the) (NN state)))))) (, ,) (NP (PRP it)) (VP (VBZ is) (VP (VBN shown) (SBAR (IN that) (S (NP (NP (DT the) (NN training) (NN trajectory)) (PP (IN of) (NP (JJ new) (NNS algorithms)))) (VP (VBZ is) (ADJP (JJ close) (PP (IN to) (NP (NP (DT the) (CD one)) (PP (IN of) (NP (JJ unbiased) (JJ stochastic) (NN gradient) (NN descent))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP apply) (NP (DT the) (JJ new) (NNS algorithms)) (PP (IN to) (NP (NP (NN policy) (NN evaluation)) (PP (IN in) (NP (DT both) (ADJP (JJ tabular) (CC and) (JJ neural)) (NN network) (NNS settings))))) (S (VP (TO to) (VP (VB confirm) (NP (DT the) (JJ theoretical) (NNS findings)))))) (. .))
