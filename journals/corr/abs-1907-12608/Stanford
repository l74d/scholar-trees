(S (NP (JJ Stochastic) (NN gradient) (NN descent) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))) (VP (VBZ has) (VP (VBN been) (NP (NP (DT the) (JJ dominant) (NN optimization) (NN method)) (PP (IN for) (NP (NN training) (JJ deep) (JJ neural) (NNS networks)))) (PP (IN due) (PP (IN to) (NP (PRP$ its) (JJ many) (JJ desirable) (NNS properties)))))) (. .))
(S (NP (NP (CD One)) (PP (IN of) (NP (NP (DT the) (ADJP (ADJP (RBR more) (JJ remarkable)) (CC and) (ADJP (JJS least) (JJ understood))) (NN quality)) (PP (IN of) (NP (NNP SGD)))))) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ generalizes) (ADJP (RB relatively) (RB well) (PP (IN on) (NP (JJ unseen) (NNS data)))) (SBAR (WHADVP (RB even) (WRB when)) (S (NP (DT the) (JJ neural) (NN network)) (VP (VBZ has) (NP (NP (NNS millions)) (PP (IN of) (NP (NNS parameters))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP hypothesize) (SBAR (IN that) (S (PP (IN in) (NP (JJ certain) (NNS cases))) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ desirable) (S (VP (TO to) (VP (VP (VB relax) (NP (PRP$ its) (JJ intrinsic) (NN generalization) (NNS properties))) (CC and) (VP (VB introduce) (SBAR (S (NP (NP (DT an) (NN extension)) (PP (IN of) (NP (NNP SGD)))) (VP (VBD called) (NP (NP (JJ deep) (NN gradient)) (VP (VBG boosting))) (PRN (-LRB- -LRB-) (NP (NN DGB)) (-RRB- -RRB-)))))))))))))) (. .))
(S (NP (NP (DT The) (JJ key) (NN idea)) (PP (IN of) (NP (NNP DGB)))) (VP (VBZ is) (SBAR (IN that) (S (NP (NP (ADJP (RB back) (HYPH -) (VBN propagated)) (NNS gradients)) (VP (VBN inferred) (S (VP (VBG using) (NP (DT the) (NN chain) (NN rule)))))) (VP (MD can) (VP (VB be) (VP (VBN viewed) (PP (IN as) (NP (NP (JJ pseudo-residual) (NNS targets)) (PP (IN of) (NP (NP (DT a) (NN gradient)) (VP (VBG boosting) (NP (NN problem))))))))))))) (. .))
(S (ADVP (RB Thus)) (PP (IN at) (NP (NP (DT each) (NN layer)) (PP (IN of) (NP (DT a) (JJ neural) (NN network))))) (NP (DT the) (NN weight) (NN update)) (VP (VBZ is) (VP (VBN calculated) (PP (IN by) (S (VP (VBG solving) (NP (DT the) (VBG corresponding) (NML (S (VP (VBG boosting) (NP (NN problem)) (S (VP (VBG using) (NP (DT a) (JJ linear) (NN base))))))) (NN learner))))))) (. .))
(S (NP (DT The) (VBG resulting) (NN weight) (NN update) (NN formula)) (VP (MD can) (ADVP (RB also)) (VP (VB be) (VP (VBN viewed) (PP (IN as) (NP (NP (DT a) (NN normalization) (NN procedure)) (PP (IN of) (NP (NP (DT the) (NNS data)) (SBAR (WHNP (WDT that)) (S (VP (VBZ arrives) (PP (IN at) (NP (DT each) (NN layer))) (PP (IN during) (NP (DT the) (JJ forward) (NN pass))))))))))))) (. .))
(S (SBAR (WHADVP (WRB When)) (S (VP (VBN implemented) (PP (IN as) (NP (DT a) (JJ separate) (NN input) (NN normalization) (NN layer) (PRN (-LRB- -LRB-) (NP (NN INN)) (-RRB- -RRB-))))))) (NP (DT the) (JJ new) (NN architecture)) (VP (VBZ shows) (NP (VBN improved) (NN performance)) (PP (IN on) (NP (NML (NN image) (NN recognition)) (NNS tasks))) (SBAR (WHADVP (WRB when)) (S (VP (VBN compared) (PP (IN to) (NP (DT the) (JJ same) (NN architecture))) (PP (IN without) (NP (NN normalization) (NNS layers))))))) (. .))
(S (SBAR (IN As) (S (PP (VBN opposed) (PP (IN to) (NP (NN batch) (NN normalization) (PRN (-LRB- -LRB-) (NP (NN BN)) (-RRB- -RRB-))))) (, ,) (NP (NN INN)) (VP (VBZ has) (NP (DT no) (JJ learnable) (NNS parameters))))) (ADVP (RB however)) (NP (PRP it)) (VP (VBZ matches) (NP (PRP$ its) (NN performance)) (PP (IN on) (NP (NML (NML (NN CIFAR10)) (CC and) (NML (NNP ImageNet) (NN classification))) (NNS tasks)))) (. .))
