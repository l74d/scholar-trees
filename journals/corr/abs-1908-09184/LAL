(S (NP (PRP We)) (VP (VBP explore) (NP (NP (DT a) (ADJP (NN collaborative) (CC and) (JJ cooperative)) (JJ multi-agent) (NN reinforcement) (VBG learning) (VBG setting)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT a) (NN team)) (PP (IN of) (NP (NN reinforcement) (VBG learning) (NNS agents)))) (VP (VB attempt) (S (VP (TO to) (VP (VB solve) (NP (DT a) (JJ single) (JJ cooperative) (NN task)) (PP (IN in) (NP (DT a) (JJ multi-scenario) (NN setting))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (JJ multi-agent) (NN reinforcement) (VBG learning) (NNS algorithm)) (VP (VBN inspired) (PP (IN by) (NP (JJ universal) (NN value) (NN function) (NNS approximators)))) (SBAR (WHNP (IN that)) (S (VP (CONJP (RB not) (RB only)) (VP (VBZ generalizes) (PP (PP (IN over) (NP (NN state) (NN space))) (CONJP (CC but) (RB also)) (PP (IN over) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ different) (NNS scenarios)))))))))))) (. .))
(S (ADVP (RB Additionally)) (, ,) (S (VP (TO to) (VP (VB prove) (NP (PRP$ our) (NN claim))))) (, ,) (NP (PRP we)) (VP (VBP are) (VP (VBG introducing) (NP (NP (DT a) (VBG challenging) (CD 2D) (JJ multi-agent) (JJ urban) (NN security) (NN environment)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN learning) (NNS agents)) (VP (VBP are) (VP (VBG trying) (S (VP (TO to) (VP (VB protect) (NP (DT a) (NN person)) (PP (IN from) (NP (JJ nearby) (NNS bystanders))) (PP (IN in) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNS scenarios))))))))))))))) (. .))
(S (NP (PRP$ Our) (NN study)) (VP (VBZ shows) (SBAR (IN that) (S (NP (JJ state-of-the-art) (JJ multi-agent) (NN reinforcement) (VBG learning) (JJ algorithms)) (VP (NN fail) (S (VP (TO to) (VP (VB generalize) (NP (DT a) (JJ single) (NN task)) (PP (IN over) (NP (JJ multiple) (NNS scenarios)))))) (SBAR (IN while) (S (NP (PRP$ our) (VBN proposed) (NN solution)) (VP (VBZ works) (ADVP (RB equally) (RB well)) (PP (IN as) (NP (JJ scenario-dependent) (NNS policies)))))))))) (. .))
