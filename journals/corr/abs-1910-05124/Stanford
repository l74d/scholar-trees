(NP (NP (NNP Pipeline) (NN parallelism) (-LRB- -LRB-) (NN PP) (-RRB- -RRB-)) (SBAR (WHADVP (WRB when)) (S (NP (VBG training) (JJ neural) (NNS networks)) (VP (VBZ enables) (NP (JJR larger) (NNS models) (S (VP (TO to) (VP (VB be) (VP (VBN partitioned) (ADVP (RB spatially)) (, ,) (S (VP (VBG leading) (PP (IN to) (NP (NP (DT both) (JJR lower) (NN network) (NN communication)) (CC and) (NP (ADJP (RB overall) (JJR higher)) (NN hardware) (NN utilization)))))))))))))) (. .))
(S (ADVP (RB Unfortunately)) (, ,) (VP (TO to) (VP (VB preserve) (NP (NP (DT the) (JJ statistical) (NN efficiency)) (PP (IN of) (NP (NP (JJ sequential) (NN training)) (, ,) (NP (NP (VBG existing) (NN PP) (NNS techniques)) (NP (NN sacrifice) (NN hardware) (NN efficiency)))))) (PP (IN by) (S (VP (VP (VBG decreasing) (NP (NN pipeline) (NN utilization))) (CC or) (VP (VBG incurring) (NP (JJ extra) (NN memory) (NNS costs)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP investigate) (PP (IN to) (SBAR (WHNP (WP what) (NN extent)) (S (NP (DT these) (NNS sacrifices)) (VP (VBP are) (ADJP (JJ necessary))))))) (. .))
(S (NP (PRP We)) (VP (VBP devise) (NP (NP (NNP PipeMare)) (, ,) (NP (NP (DT a) (ADJP (JJ simple) (CC yet) (JJ robust)) (NN training) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VBZ tolerates) (NP (JJ asynchronous) (NNS updates)) (PP (IN during) (NP (NN PP) (NN execution))) (PP (IN without) (S (VP (VBG sacrificing) (NP (NP (NN utilization) (CC or) (NN memory)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ allows) (NP (NP (JJ efficient) (NN use)) (PP (IN of) (NP (ADJP (JJ fine) (HYPH -) (JJ grained)) (NN pipeline) (NN parallelism))))))))))))))))) (. .))
