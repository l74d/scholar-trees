(S (NP (JJ Recent) (NN work)) (VP (VBZ has) (VP (VBN established) (NP (NP (DT an) (ADJP (RB empirically) (JJ successful)) (NN framework)) (PP (IN for) (S (VP (VBG adapting) (NP (NP (VBG learning) (NNS rates)) (PP (IN for) (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))))))))))) (. .))
(S (NP (DT This)) (VP (ADVP (JJ effectively)) (VBZ removes) (NP (NP (DT all) (NNS needs)) (PP (IN for) (NP (NN tuning)))) (, ,) (SBAR (IN while) (S (VP (VP (ADVP (RB automatically)) (VBG reducing) (NP (VBG learning) (NNS rates)) (PP (IN over) (NP (NN time))) (PP (IN on) (NP (JJ stationary) (NNS problems)))) (, ,) (CC and) (VP (VBG permitting) (S (NP (VBG learning) (NNS rates)) (VP (TO to) (VP (VB grow) (ADVP (RB appropriately)) (PP (IN in) (NP (JJ non-stationary) (NNS tasks))))))))))) (. .))
(S (ADVP (RB Here)) (, ,) (NP (PRP we)) (VP (VBP extend) (NP (DT the) (NN idea)) (PP (IN in) (NP (CD three) (NNS directions))) (, ,) (S (VP (VBG addressing) (NP (NP (JJ proper) (NN minibatch) (NN parallelization)) (, ,) (PP (VBG including) (NP (NP (VBN reweighted) (NNS updates)) (PP (IN for) (NP (ADJP (NN sparse) (CC or) (JJ orthogonal)) (NNS gradients)))))) (, ,) (S (VP (VBG improving) (NP (NP (NN robustness)) (PP (IN on) (NP (JJ non-smooth) (NN loss) (NNS functions)))))) (, ,) (S (PP (IN in) (NP (DT the) (NN process))) (VP (VBG replacing) (NP (NP (DT the) (JJ diagonal) (JJ Hessian) (NN estimation) (NN procedure)) (SBAR (WHNP (WDT that)) (S (VP (MD may) (RB not) (ADVP (RB always)) (VP (VB be) (ADJP (JJ available))))))) (PP (IN by) (NP (DT a) (JJ robust) (NN finite-difference) (NN approximation)))))))) (. .))
(S (NP (DT The) (JJ final) (NN algorithm)) (VP (VP (VBZ integrates) (NP (PDT all) (DT these) (NNS components))) (, ,) (VP (VBZ has) (NP (JJ linear) (NN complexity))) (CC and) (VP (VBZ is) (ADJP (JJ hyper-parameter) (JJ free)))) (. .))
