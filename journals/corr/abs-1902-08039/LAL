(S (PP (IN In) (NP (NP (NNP Reinforcement) (NNP Learning)) (PRN (-LRB- -LRB-) (NP (NNP RL)) (-RRB- -RRB-)))) (, ,) (NP (DT an) (NN agent)) (VP (VP (VBZ explores) (NP (DT the) (NN environment))) (CC and) (VP (VBZ collects) (NP (NNS trajectories)) (PP (IN into) (NP (DT the) (NN memory) (NN buffer))) (PP (IN for) (NP (RB later) (VBG learning))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT the) (JJ collected) (NNS trajectories)) (VP (MD can) (VP (ADVP (RB easily)) (VB be) (VP (VBN imbalanced) (PP (IN with) (NP (NP (NN respect)) (PP (TO to) (NP (DT the) (VBN achieved) (NN goal) (NNS states)))))))) (. .))
(S (NP (NP (DT The) (NN problem)) (PP (IN of) (S (VP (VBG learning) (PP (IN from) (NP (VBN imbalanced) (NN data))))))) (VP (VP (VBZ is) (NP (NP (DT a) (JJ well-known) (NN problem)) (PP (IN in) (NP (JJ supervised) (NN learning))))) (, ,) (CC but) (VP (VBZ has) (RB not) (ADVP (RB yet)) (VP (VBN been) (VP (ADVP (RB thoroughly)) (VBN researched) (PP (IN in) (NP (NNP RL))))))) (. .))
(S (S (VP (TO To) (VP (VB address) (NP (DT this) (NN problem))))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ novel) (JJ Curiosity-Driven) (NNP Prioritization) (PRN (-LRB- -LRB-) (NNP CDP) (-RRB- -RRB-)) (NN framework)) (SBAR (S (VP (TO to) (VP (VB encourage) (S (NP (DT the) (NN agent)) (VP (TO to) (VP (JJ over-sample) (NP (NP (DT those) (NNS trajectories)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (VP (VBN rare) (NP (VBN achieved) (NN goal) (NNS states)))))))))))))))) (. .))
(S (NP (DT The) (NNP CDP) (NN framework)) (VP (VP (VBD mimics) (NP (DT the) (JJ human) (NN learning) (NN process))) (CC and) (VP (VBZ focuses) (ADVP (RBR more)) (PP (IN on) (NP (ADJP (RB relatively) (JJ uncommon)) (NNS events))))) (. .))
(S (NP (PRP We)) (VP (VBP evaluate) (NP (PRP$ our) (NNS methods)) (S (VP (VBG using) (NP (NP (DT the) (JJ robotic) (NN environment)) (VP (VBN provided) (PP (IN by) (NP (NNP OpenAI) (NNP Gym)))))))) (. .))
(S (NP (DT The) (NN environment)) (VP (VBZ contains) (NP (CD six) (NN robot) (NN manipulation) (NNS tasks))) (. .))
(S (PP (IN In) (NP (PRP$ our) (NNS experiments))) (, ,) (NP (PRP we)) (VP (VBD combined) (NP (NNP CDP)) (PP (IN with) (NP (NP (NNP Deep) (NNP Deterministic) (NNP Policy) (NNP Gradient)) (PRN (-LRB- -LRB-) (NP (NNP DDPG)) (-RRB- -RRB-)))) (PP (IN with) (CC or) (IN without) (NP (NP (NNP Hindsight) (NNP Experience) (NNP Replay)) (PRN (-LRB- -LRB-) (NP (NNP HER)) (-RRB- -RRB-))))) (. .))
(S (NP (DT The) (JJ experimental) (NNS results)) (VP (VBP show) (SBAR (IN that) (S (NP (NNP CDP)) (VP (VBZ improves) (NP (NP (DT both) (NN performance) (CC and) (NN sample-efficiency)) (PP (IN of) (NP (NN reinforcement) (VBG learning) (NNS agents)))) (, ,) (PP (VBN compared) (PP (TO to) (NP (JJ state-of-the-art) (NNS methods)))))))) (. .))
