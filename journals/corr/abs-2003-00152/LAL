(S (S (NP (NP (NN Batch) (NN normalization)) (PRN (-LRB- -LRB-) (NP (NNP BatchNorm)) (-RRB- -RRB-))) (VP (VBZ has) (VP (VBN become) (NP (NP (DT an) (JJ indispensable) (NN tool)) (PP (IN for) (S (VP (VBG training) (NP (JJ deep) (JJ neural) (NNS networks))))))))) (, ,) (ADVP (CC yet)) (S (NP (PRP it)) (VP (VBZ is) (ADVP (RB still)) (ADJP (RB poorly) (NN understood)))) (. .))
(S (SBAR (IN Although) (S (NP (JJ previous) (NN work)) (VP (VBZ has) (ADVP (RB typically)) (VP (VBN focused) (PP (IN on) (NP (PRP$ its) (NN normalization) (NN component))))))) (, ,) (NP (NNP BatchNorm)) (ADVP (RB also)) (VP (VBZ adds) (NP (NP (CD two) (NN per-feature) (JJ trainable) (NNS parameters)) (PRN (: -) (NP (NP (DT a) (NN coefficient)) (CC and) (NP (DT a) (JJ bias))) (: -)) (SBAR (WHNP (WP$ whose) (NN role) (CC and) (JJ expressive) (NN power)) (S (VP (VBP remain) (ADJP (JJ unclear))))))) (. .))
(S (S (VP (TO To) (VP (VB study) (NP (DT this) (NN question))))) (, ,) (NP (PRP we)) (VP (VBP investigate) (NP (NP (DT the) (NN performance)) (VP (VBD achieved) (SBAR (WHADVP (WRB when)) (S (VP (VP (VBG training) (NP (RB only) (DT these) (NNS parameters))) (CC and) (VP (VBG freezing) (NP (DT all) (NNS others)) (PP (IN at) (NP (PRP$ their) (JJ random) (NNS initializations)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (S (VP (VBG doing) (ADVP (RB so)))) (VP (VBZ leads) (PP (TO to) (NP (ADJP (RB surprisingly) (JJ high)) (NN performance))))))) (. .))
(S (PP (IN For) (NP (NN example))) (, ,) (NP (ADJP (RB sufficiently) (JJ deep)) (NNP ResNets)) (VP (VBP reach) (NP (NP (NP (NP (CD 82) (NN %)) (PRN (-LRB- -LRB-) (NP (NNP CIFAR-10)) (-RRB- -RRB-))) (CC and) (NP (NP (CD 32) (NN %)) (PRN (-LRB- -LRB-) (NP (NP (NNP ImageNet)) (, ,) (NP (NN top-5))) (-RRB- -RRB-)))) (NN accuracy)) (PP (IN in) (NP (DT this) (NN configuration))) (, ,) (ADJP (ADJP (RB far) (JJR higher)) (PP (IN than) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (NP (DT an) (JJ equivalent) (NN number)) (PP (IN of) (NP (NP (ADJP (JJ randomly) (VBN chosen)) (NNS parameters)) (PP (IN from) (NP (NP (RB elsewhere)) (PP (IN in) (NP (DT the) (NN network)))))))))))))) (. .))
(S (NP (NNP BatchNorm)) (VP (VBZ achieves) (NP (DT this) (NN performance)) (PP (PP (IN in) (NP (NN part))) (IN by) (S (VP (ADVP (RB naturally)) (VBG learning) (S (VP (TO to) (VP (VB disable) (NP (NP (QP (RP around) (DT a) (NN third))) (PP (IN of) (NP (DT the) (NN random) (NNS features))))))))))) (. .))
(S (CONJP (RB Not) (RB only)) (SINV (VBP do) (NP (DT these) (NNS results)) (VP (VBD highlight) (NP (NP (DT the) (JJ under-appreciated) (NN role)) (PP (IN of) (NP (NP (DT the) (NN affine) (NNS parameters)) (PP (IN in) (NP (NNP BatchNorm)))))))) (, ,) (CC but) (S (: -) (PP (IN in) (NP (DT a) (JJR broader) (NN sense))) (: -) (NP (PRP they)) (VP (VBP characterize) (NP (NP (DT the) (JJ expressive) (NN power)) (PP (IN of) (NP (NP (JJ neural) (NNS networks)) (VP (VBN constructed) (PP (ADVP (RB simply)) (IN by) (S (VP (VBG shifting) (CC and) (VBG rescaling) (NP (NN random) (NNS features))))))))))) (. .))
