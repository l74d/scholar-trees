(S (PP (IN In) (NP (JJ classical) (NN Q-learning))) (, ,) (NP (DT the) (NN objective)) (VP (VBZ is) (S (VP (TO to) (VP (VB maximize) (NP (NP (DT the) (NN sum)) (PP (IN of) (NP (VBN discounted) (NNS rewards)))) (PP (IN through) (S (VP (ADVP (RB iteratively)) (VBG using) (NP (DT the) (NNP Bellman) (NN equation)) (PP (IN as) (NP (DT an) (NN update))) (, ,) (PP (IN in) (NP (DT an) (NN attempt) (S (VP (TO to) (VP (VB estimate) (NP (NP (DT the) (NN action) (NN value) (NN function)) (PP (IN of) (NP (DT the) (JJ optimal) (NN policy)))))))))))))))) (. .))
(S (S (ADVP (RB Conventionally)) (, ,) (NP (DT the) (NN loss) (NN function)) (VP (VBZ is) (VP (VBN defined) (PP (IN as) (NP (NP (DT the) (JJ temporal) (NN difference)) (PP (IN between) (NP (NP (DT the) (NN action) (NN value)) (CC and) (NP (DT the) (VBN expected) (PRN (-LRB- -LRB-) (VBN discounted) (-RRB- -RRB-)) (NN reward))))))))) (, ,) (S (ADVP (RB however)) (NP (PRP it)) (VP (VBZ focuses) (ADVP (RB solely)) (PP (IN on) (NP (DT the) (NN future))) (, ,) (S (VP (VBG leading) (PP (TO to) (NP (JJ overestimation) (NNS errors))))))) (. .))
(S (NP (PRP We)) (VP (VBP extend) (NP (DT the) (JJ well-established) (NNP Q-learning) (NNS techniques)) (PP (PP (IN by) (S (VP (VBG introducing) (NP (NP (DT the) (NN hindsight) (NN factor)) (, ,) (NP (NP (DT an) (JJ additional) (NN loss) (NN term)) (SBAR (WHNP (WDT that)) (S (VP (VBZ takes) (PP (IN into) (NP (NN account))) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN model)) (VP (VBZ progresses)))))))))))) (, ,) (PP (IN by) (S (VP (VBG integrating) (NP (DT the) (JJ historic) (JJ temporal) (NN difference)) (PP (IN as) (NP (NP (NN part)) (PP (IN of) (NP (DT the) (NN reward)))))))))) (. .))
(S (NP (NP (DT The) (NN effect)) (PP (IN of) (NP (DT this) (NN modification)))) (VP (VBZ is) (VP (VBN examined) (PP (IN in) (NP (NP (DT a) (JJ deterministic) (JJ continuous-state) (NN space) (NN function) (NN estimation) (NN problem)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN overestimation) (NN phenomenon)) (VP (VP (VBZ is) (VP (ADVP (RB significantly)) (VBN reduced))) (CC and) (VP (NNS results) (PP (IN in) (NP (JJ improved) (NN stability))))))))))) (. .))
(S (NP (NP (DT The) (JJ underlying) (NN effect)) (PP (IN of) (NP (DT the) (JJ hindsight) (NN factor)))) (VP (VBZ is) (VP (VBN modeled) (PP (IN as) (NP (NP (DT an) (JJ adaptive) (NN learning) (NN rate)) (, ,) (SBAR (WHNP (WDT which)) (S (PP (IN unlike) (NP (VBG existing) (JJ adaptive) (NNS optimizers))) (, ,) (VP (VBZ takes) (PP (IN into) (NP (NN account))) (NP (DT the) (ADJP (RB previously) (VBN estimated)) (NN action) (NN value))))))))) (. .))
(S (NP (DT The) (VBN proposed) (NN method)) (VP (VBZ outperforms) (NP (NP (NNS variations)) (PP (IN of) (NP (NNP Q-learning)))) (, ,) (PP (IN with) (NP (NP (DT an) (JJ overall) (JJR higher) (JJ average) (NN reward)) (CC and) (NP (JJR lower) (NN action) (NNS values)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ supports) (NP (DT the) (JJ deterministic) (NN evaluation))) (, ,) (CC and) (VP (VBZ proves) (SBAR (IN that) (S (NP (DT the) (JJ hindsight) (NN factor)) (VP (NNS contributes) (PP (TO to) (NP (VB lower) (NN overestimation) (NNS errors))))))))))) (. .))
(S (NP (NP (DT The) (JJ mean) (JJ average) (NN score)) (PP (IN of) (NP (CD 100) (NNS episodes))) (VP (VBN obtained) (PP (IN after) (S (VP (VBG training) (PP (IN for) (NP (QP (CD 10) (CD million)) (NNS frames)))))))) (VP (VBZ shows) (SBAR (IN that) (S (NP (DT the) (JJ hindsight) (NN factor)) (VP (NNS outperforms) (NP (NP (JJ deep) (NNS Q-networks)) (, ,) (NP (JJ double) (JJ deep) (NNS Q-networks)) (CC and) (NP (VBG dueling) (NNS networks))) (PP (IN for) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (NNP ATARI) (NNS games))))))))) (. .))
