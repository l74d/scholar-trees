(S (NP (NNP Neural) (NN text) (NN decoding)) (VP (VBZ is) (ADJP (JJ important) (PP (IN for) (S (VP (VBG generating) (NP (NP (NN high-quality) (NN texts)) (VP (VBG using) (NP (NN language) (NNS models))))))))) (. .))
(S (S (VP (TO To) (VP (VB generate) (NP (NN high-quality) (NN text))))) (, ,) (NP (NP (JJ popular) (VBG decoding) (NNS algorithms)) (PP (IN like) (NP (NP (JJ top-k)) (, ,) (NP (NP (JJ top-p)) (PRN (-LRB- -LRB-) (NP (JJ nucleus)) (-RRB- -RRB-))) (, ,) (CC and) (NP (JJ temperature-based) (NN sampling))))) (VP (NN truncate) (CC or) (VB distort) (NP (NP (DT the) (JJ unreliable) (JJ low) (NN probability) (NN tail)) (PP (IN of) (NP (DT the) (NN language) (NN model))))) (. .))
(S (SBAR (IN Though) (S (NP (DT these) (NNS methods)) (VP (VBP generate) (NP (NN high-quality) (NN text)) (PP (IN after) (NP (NN parameter) (NN tuning)))))) (, ,) (NP (PRP they)) (VP (VBP are) (ADJP (NN ad) (NN hoc))) (. .))
(S (NP (NP (RB Not) (JJ much))) (VP (VBZ is) (VP (VBN known) (PP (IN about) (NP (NP (DT the) (NN control)) (SBAR (S (NP (PRP they)) (VP (VP (VBP provide)) (PP (IN over) (NP (NP (DT the) (NNS statistics)) (PP (IN of) (NP (DT the) (NN output)))))))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ important)) (SBAR (IN since) (S (NP (JJ recent) (NNS reports)) (VP (VBP show) (SBAR (S (NP (JJ text) (NN quality)) (VP (VBZ is) (ADJP (JJS highest)) (PP (IN for) (NP (NP (DT a) (JJ specific) (NN range)) (PP (IN of) (NP (NNS likelihoods)))))))))))))))) (. .))
(S (ADVP (RB Here)) (, ,) (ADVP (RB first)) (NP (PRP we)) (VP (VBP provide) (NP (NP (DT a) (JJ theoretical) (NN analysis)) (PP (IN of) (NP (NP (NN perplexity)) (PP (IN in) (NP (JJ top-k) (, ,) (JJ top-p) (, ,) (CC and) (NN temperature) (NN sampling)))))) (, ,) (S (VP (VBG finding) (SBAR (IN that) (S (NP (JJ cross-entropy)) (VP (NNS behaves) (ADVP (RB approximately) (RB linearly)) (PP (IN as) (NP (NP (DT a) (NN function)) (PP (IN of) (NP (NN p))))) (PP (IN in) (NP (JJ top-p) (NN sampling))) (SBAR (IN whereas) (S (NP (PRP it)) (VP (VBZ is) (NP (NP (DT a) (JJ nonlinear) (NN function)) (PP (IN of) (NP (NN k)))) (PP (IN in) (NP (JJ top-k) (NN sampling))) (, ,) (PP (IN under) (NP (JJ Zipfian) (NNS statistics)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP use) (NP (DT this) (NN analysis)) (S (VP (TO to) (VP (VB design) (NP (NP (DT a) (JJ feedback-based) (JJ adaptive) (JJ top-k) (NN text) (NN decoding) (NN algorithm)) (VP (VBN called) (S (NP (NN mirostat)))) (SBAR (WHNP (WDT that)) (S (VP (VBZ generates) (NP (NP (NP (JJ text)) (PRN (-LRB- -LRB-) (PP (IN of) (NP (DT any) (NN length))) (-RRB- -RRB-)) (PP (IN with) (NP (NP (DT a) (JJ predetermined) (NN value)) (PP (IN of) (NP (NN perplexity)))))) (, ,) (CC and) (ADVP (RB thereby)) (NP (NP (JJ high-quality) (NN text)) (PP (IN without) (NP (DT any) (NN tuning))))))))))))) (. .))
(S (NP (NNS Experiments)) (VP (VBP show) (SBAR (IN that) (S (PP (IN for) (NP (NP (JJ low) (NNS values)) (PP (IN of) (NP (NN k) (CC and) (NN p))) (PP (IN in) (NP (JJ top-k) (CC and) (JJ top-p) (NN sampling))))) (, ,) (NP (NN perplexity)) (VP (NNS drops) (ADVP (RB significantly)) (PP (IN with) (NP (NP (VBN generated) (NN text) (NN length)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADVP (RB also)) (VP (VBN correlated) (PP (IN with) (NP (NP (NP (JJ excessive) (NNS repetitions)) (PP (IN in) (NP (DT the) (NN text)))) (PRN (-LRB- -LRB-) (NP (DT the) (NN boredom) (NN trap)) (-RRB- -RRB-)))))))))))))) (. .))
(S (PP (IN On) (NP (DT the) (JJ other) (NN hand))) (, ,) (PP (IN for) (NP (NP (JJ large) (NNS values)) (PP (IN of) (NP (NN k) (CC and) (NN p))))) (, ,) (NP (PRP we)) (VP (VBP find) (SBAR (DT that) (S (NP (NN perplexity)) (VP (VBZ increases) (PP (IN with) (NP (NP (VBN generated) (NN text) (NN length)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN correlated) (PP (IN with) (NP (NP (NP (NN incoherence)) (PP (IN in) (NP (DT the) (NN text)))) (PRN (-LRB- -LRB-) (NP (NN confusion) (NN trap)) (-RRB- -RRB-)))))))))))))) (. .))
(S (S (NP (NNP Mirostat)) (VP (NNS avoids) (NP (DT both) (NNS traps)))) (: :) (S (NP (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NN cross-entropy)) (VP (VBZ has) (NP (NP (DT a) (JJ near-linear) (NN relation)) (PP (IN with) (NP (NN repetition)))) (PP (IN in) (NP (JJ generated) (NN text)))))))) (. .))
(S (NP (DT This) (NN relation)) (VP (VBZ is) (ADJP (ADJP (RB almost) (JJ independent) (PP (IN of) (NP (DT the) (VBG sampling) (NN method)))) (CC but) (ADJP (RB slightly) (JJ dependent) (PP (IN on) (NP (NP (DT the) (NN model)) (VP (VBN used))))))) (. .))
(S (ADVP (NNP Hence)) (, ,) (PP (IN for) (NP (DT a) (VBN given) (NN language) (NN model))) (, ,) (NP (NP (NN control)) (PP (IN over) (NP (NN perplexity)))) (ADVP (RB also)) (VP (VBZ gives) (NP (NP (NN control)) (PP (IN over) (NP (NNS repetitions))))) (. .))
