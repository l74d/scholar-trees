(S (SBAR (IN Although) (S (NP (NN ADAM)) (VP (VBZ is) (NP (NP (DT a) (ADJP (RB very) (JJ popular)) (NN algorithm)) (PP (IN for) (S (VP (VBG optimizing) (NP (NP (DT the) (NNS weights)) (PP (IN of) (NP (JJ neural) (NNS networks))))))))))) (, ,) (NP (PRP it)) (VP (VBZ has) (VP (VBN been) (ADVP (RB recently)) (VP (VBN shown) (SBAR (IN that) (S (NP (PRP it)) (VP (MD can) (VP (VB diverge) (ADVP (RB even)) (PP (IN in) (NP (JJ simple) (NN convex) (NN optimization) (NNS examples)))))))))) (. .))
(S (NP (NP (JJ Several) (NNS variants)) (PP (IN of) (NP (NN ADAM)))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (S (VP (TO to) (VP (VB circumvent) (NP (DT this) (NN convergence) (NN issue)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT the) (NN ADAM) (NN algorithm)) (PP (IN for) (NP (JJ smooth) (NN nonconvex) (NN optimization)))) (PP (IN under) (NP (NP (DT a) (NN boundedness) (NN assumption)) (PP (IN on) (NP (DT the) (JJ adaptive) (NN learning) (NN rate)))))) (. .))
(S (NP (DT The) (ADJP (VBN bound) (PP (IN on) (NP (DT the) (JJ adaptive) (NN step)))) (NN size)) (VP (VP (VBZ depends) (PP (IN on) (NP (NP (DT the) (NNP Lipschitz) (NN constant)) (PP (IN of) (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (DT the) (JJ objective) (NN function)))))))) (CC and) (VP (VBZ provides) (NP (JJ safe) (JJ theoretical) (JJ adaptive) (NN step) (NNS sizes)))) (. .))
(S (PP (IN Under) (NP (DT this) (NN boundedness) (NN assumption))) (, ,) (NP (PRP we)) (VP (VBP show) (NP (DT a) (JJ novel) (JJ first) (NN order) (NN convergence) (NN rate) (NN result)) (PP (IN in) (NP (DT both) (JJ deterministic) (CC and) (JJ stochastic) (NNS contexts)))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VBP establish) (NP (NP (NN convergence) (NNS rates)) (PP (IN of) (NP (DT the) (NN function) (NN value) (NN sequence)))) (S (VP (VBG using) (NP (DT the) (NML (NNP Kurdyka) (HYPH -) (NNP Lojasiewicz)) (NN property))))) (. .))
