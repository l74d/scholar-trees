(S (SBAR (IN Although) (S (NP (NNP ADAM)) (VP (VBZ is) (NP (NP (DT a) (ADJP (RB very) (JJ popular)) (NN algorithm)) (PP (IN for) (S (VP (VBG optimizing) (NP (NP (DT the) (NNS weights)) (PP (IN of) (NP (JJ neural) (NNS networks))))))))))) (, ,) (NP (PRP it)) (VP (VBZ has) (VP (VBN been) (ADVP (RB recently)) (VP (VBN shown) (SBAR (IN that) (S (NP (PRP it)) (VP (MD can) (VP (VB diverge) (PP (ADVP (RB even)) (IN in) (NP (JJ simple) (JJ convex) (NN optimization) (NNS examples)))))))))) (. .))
(S (NP (NP (JJ Several) (NNS variants)) (PP (IN of) (NP (NNP ADAM)))) (VP (VBP have) (VP (VBN been) (VP (VBN proposed) (S (VP (TO to) (VP (VB circumvent) (NP (DT this) (NN convergence) (NN issue)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP study) (NP (NP (DT the) (NNP ADAM) (NN algorithm)) (PP (IN for) (NP (JJ smooth) (JJ nonconvex) (NN optimization)))) (PP (IN under) (NP (NP (DT a) (JJ boundedness) (NN assumption)) (PP (IN on) (NP (DT the) (JJ adaptive) (NN learning) (NN rate)))))) (. .))
(S (NP (NP (DT The) (NN bound)) (PP (IN on) (NP (DT the) (JJ adaptive) (NN step) (NN size)))) (VP (VP (VBZ depends) (PP (IN on) (NP (NP (DT the) (NNP Lipschitz) (NN constant)) (PP (IN of) (NP (NP (DT the) (NN gradient)) (PP (IN of) (NP (DT the) (JJ objective) (NN function)))))))) (CC and) (VP (VBZ provides) (NP (JJ safe) (JJ theoretical) (JJ adaptive) (NN step) (NNS sizes)))) (. .))
(S (PP (IN Under) (NP (DT this) (NN boundedness) (NN assumption))) (, ,) (NP (PRP we)) (VP (VBP show) (NP (DT a) (NN novel) (RB first) (NN order) (NN convergence) (NN rate) (NN result)) (PP (IN in) (NP (UCP (DT both) (JJ deterministic) (CC and) (JJ stochastic)) (NN contexts)))) (. .))
(S (ADVP (RB Furthermore)) (, ,) (NP (PRP we)) (VP (VB establish) (NP (NP (NN convergence) (NNS rates)) (PP (IN of) (NP (DT the) (NN function) (NN value) (NN sequence)))) (S (VP (VBG using) (NP (DT the) (NNP Kurdyka-Lojasiewicz) (NN property))))) (. .))
