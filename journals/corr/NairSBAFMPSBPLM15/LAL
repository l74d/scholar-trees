(S (NP (PRP We)) (VP (VBP present) (NP (NP (DT the) (JJ first) (ADJP (RB massively) (JJ distributed)) (NN architecture)) (PP (IN for) (NP (JJ deep) (NN reinforcement) (NN learning))))) (. .))
(S (NP (DT This) (NN architecture)) (VP (VBZ uses) (NP (NP (CD four) (JJ main) (NNS components)) (: :) (NP (NP (NP (JJ parallel) (NNS actors)) (SBAR (WHNP (WDT that)) (S (VP (VBP generate) (NP (JJ new) (NN behaviour)))))) (: ;) (NP (NP (CC parallel) (NNS learners)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (VP (VBN trained) (PP (IN from) (NP (JJ stored) (NN experience)))))))) (: ;) (NP (NP (DT a) (JJ distributed) (JJ neural) (NN network)) (SBAR (S (VP (TO to) (VP (VB represent) (NP (DT the) (NX (NX (NN value) (NN function)) (CC or) (NX (NN behaviour) (NN policy))))))))) (: ;) (CC and) (NP (NP (DT a) (JJ distributed) (NN store)) (PP (IN of) (NP (NN experience))))))) (. .))
(S (NP (PRP We)) (VP (VBD used) (NP (PRP$ our) (NN architecture)) (S (VP (TO to) (VP (VB implement) (NP (NP (DT the) (NNP Deep) (NNP Q-Network) (NN algorithm)) (PRN (-LRB- -LRB-) (NP (NNP DQN)) (-RRB- -RRB-))))))) (. .))
(S (NP (PRP$ Our) (JJ distributed) (NN algorithm)) (VP (VBD was) (VP (VBN applied) (PP (TO to) (NP (NP (CD 49) (NNS games)) (PP (IN from) (NP (NNP Atari) (CD 2600) (NNS games))) (PP (IN from) (NP (DT the) (NNP Arcade) (NNP Learning) (NNP Environment))))) (, ,) (S (VP (VBG using) (NP (JJ identical) (NNS hyperparameters)))))) (. .))
(S (NP (PRP$ Our) (NN performance)) (VP (VP (VBD surpassed) (NP (JJ non-distributed) (NNP DQN)) (PP (IN in) (NP (NP (CD 41)) (PP (IN of) (NP (DT the) (CD 49) (NNS games)))))) (CC and) (ADVP (RB also)) (VP (VBD reduced) (NP (NP (DT the) (NN wall-time)) (VP (VBN required) (S (VP (TO to) (VP (VB achieve) (NP (DT these) (NNS results))))))) (PP (IN by) (NP (NP (DT an) (NN order)) (PP (IN of) (NP (NN magnitude))))) (PP (IN on) (NP (JJS most) (NNS games))))) (. .))
