(S (NP (NP (JJ Recurrent) (JJ Neural) (NNS Networks)) (-LRB- -LRB-) (NP (NNS RNNs)) (-RRB- -RRB-)) (VP (VBP are) (NP (NP (JJ powerful) (NNS models)) (SBAR (WHNP (WDT that)) (S (VP (VBP achieve) (NP (JJ exceptional) (NN performance)) (PP (IN on) (NP (JJ several) (NML (NN pattern) (NN recognition)) (NNS problems)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (NP (DT the) (NN training)) (PP (IN of) (NP (NNS RNNs)))) (VP (VBZ is) (NP (DT a) (ADJP (ADVP (RB computationally)) (JJ difficult)) (NN task)) (PP (VBG owing) (PP (IN to) (NP (DT the) (ADJP (NN well) (HYPH -) (VBN known)) (`` ") (NML (S (VP (VP (VBG vanishing)) (, /) (VP (VBG exploding) (`` ") (NP (NN gradient) (NN problem)))))))))) (. .))
(S (NP (NP (NNS Algorithms)) (VP (VBN proposed) (PP (IN for) (NP (NN training) (NNS RNNs))))) (VP (VP (CC either) (VP (VBP exploit) (NP (NP (NP (DT no)) (-LRB- -LRB-) (CC or) (NP (JJ limited)) (-RRB- -RRB-)) (NN curvature) (NN information))) (CC and) (VP (VBP have) (NP (JJ cheap) (NML (PP (IN per) (HYPH -) (NP (NN iteration)))) (NN complexity)))) (, ,) (CC or) (VP (NP (NN attempt)) (S (VP (TO to) (VP (VB gain) (NP (JJ significant) (NN curvature) (NN information)) (PP (IN at) (NP (NP (DT the) (NN cost)) (PP (IN of) (NP (VBN increased) (NML (IN per) (HYPH -) (NN iteration)) (NN cost)))))))))) (. .))
(S (NP (DT The) (JJ former) (NN set)) (VP (VBZ includes) (NP (NP (ADJP (RB diagonally) (HYPH -) (VBN scaled)) (NML (JJ first) (HYPH -) (NN order)) (NNS methods)) (PP (JJ such) (IN as) (NP (NN ADAGRAD) (CC and) (NN ADAM)))) (, ,) (SBAR (IN while) (S (NP (DT the) (JJ latter)) (VP (VBZ consists) (PP (IN of) (NP (NML (JJ second) (HYPH -) (NN order)) (NNS algorithms))) (PP (IN like) (NP (ADJP (JJ Hessian) (HYPH -) (JJ Free)) (NML (NML (NNP Newton)) (CC and) (NML (NNP K) (HYPH -) (NNP FAC))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP present) (NP (NP (NNP adaQN)) (, ,) (NP (NP (DT a) (JJ stochastic) (NN quasi-Newton) (NN algorithm)) (PP (IN for) (NP (NN training) (NNS RNNs)))))) (. .))
(S (NP (PRP$ Our) (NN approach)) (VP (VBZ retains) (NP (DT a) (JJ low) (NML (PP (IN per) (HYPH -) (NP (NN iteration)))) (NN cost)) (PP (IN while) (S (VP (VBG allowing) (PP (IN for) (NP (JJ non-diagonal) (NN scaling))) (PP (IN through) (NP (NP (DT a) (JJ stochastic) (NN L) (HYPH -) (NN BFGS)) (VP (VBG updating) (NP (NN scheme))))))))) (. .))
(S (NP (DT The) (NN method)) (VP (VP (VBZ uses) (NP (DT a) (JJ novel) (NML (NN L) (HYPH -) (NN BFGS)) (NN scaling) (NN initialization) (NN scheme))) (CC and) (VP (VBZ is) (ADJP (JJ judicious) (PP (IN in) (S (VP (VBG storing) (CC and) (VBG retaining) (NP (NML (NN L) (HYPH -) (NN BFGS)) (NN curvature) (NNS pairs)))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP present) (NP (JJ numerical) (NNS experiments)) (PP (IN on) (NP (CD two) (NML (NN language) (NN modeling)) (NNS tasks)))) (CC and) (VP (VBP show) (SBAR (IN that) (S (NP (NN adaQN)) (VP (VBZ is) (ADJP (JJ competitive) (PP (IN with) (NP (JJ popular) (NN RNN) (NN training) (NNS algorithms))))))))) (. .))
