(S (NP (NP (DT The) (NN performance)) (PP (IN of) (NP (NN policy) (NN gradient) (NNS methods)))) (VP (VBZ is) (ADJP (JJ sensitive) (PP (TO to) (NP (NP (VB hyperparameter) (NNS settings)) (SBAR (WHNP (WDT that)) (S (VP (MD must) (VP (VB be) (VP (VBN tuned) (PP (IN for) (NP (DT any) (JJ new) (NN application)))))))))))) (. .))
(S (NP (NP (ADJP (RB Widely) (VBN used)) (JJ grid) (NN search) (NNS methods)) (PP (IN for) (S (VP (VBG tuning) (NP (NNS hyperparameters)))))) (VP (VBP are) (ADJP (ADJP (JJ sample) (JJ inefficient)) (CC and) (ADJP (RB computationally) (JJ expensive)))) (. .))
(S (NP (NP (ADJP (RBR More) (JJ advanced)) (NNS methods)) (PP (IN like) (NP (NNP Population) (VBD Based) (NNP Training))) (SBAR (WHNP (IN that)) (S (VP (VBP learn) (NP (NP (NP (JJ optimal) (NNS schedules)) (PP (IN for) (NP (NNS hyperparameters)))) (PP (RB instead) (IN of) (NP (JJ fixed) (NNS settings)))))))) (VP (VP (MD can) (VP (VB yield) (NP (JJR better) (NNS results)))) (, ,) (CC but) (VP (VBP are) (ADVP (RB also)) (ADJP (ADJP (JJ sample) (NN inefficient)) (CC and) (ADJP (RB computationally) (JJ expensive))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP propose) (NP (NP (NP (NNP Hyperparameter) (NNP Optimisation)) (PP (IN on) (NP (DT the) (NNP Fly)))) (PRN (-LRB- -LRB-) (NP (NNP HOOF)) (-RRB- -RRB-)) (, ,) (NP (NP (DT a) (JJ gradient-free) (NN algorithm)) (SBAR (WHNP (WDT that)) (S (VP (VBZ requires) (NP (QP (DT no) (JJR more) (IN than) (CD one)) (NN training) (NN run)) (S (VP (TO to) (VP (ADVP (RB automatically)) (VB adapt) (NP (NP (DT the) (NN hyperparameter)) (SBAR (WHNP (WDT that)) (S (VP (VBP affect) (NP (DT the) (NN policy) (NN update)) (ADVP (RB directly)) (PP (IN through) (NP (DT the) (NN gradient)))))))))))))))) (. .))
(S (NP (DT The) (JJ main) (NN idea)) (VP (VBZ is) (S (VP (TO to) (VP (VB use) (NP (NP (VBG existing) (NNS trajectories)) (VP (VBN sampled) (PP (IN by) (NP (DT the) (NN policy) (NN gradient) (NN method))))) (S (VP (TO to) (VP (VB optimise) (NP (DT a) (JJ one-step) (NN improvement) (NN objective))))) (, ,) (S (VP (VBG yielding) (NP (NP (DT a) (NX (NX (NN sample)) (CC and) (NX (ADJP (RB computationally) (JJ efficient)) (NN algorithm)))) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ easy) (SBAR (S (VP (TO to) (VP (VB implement)))))))))))))))) (. .))
(S (NP (NP (PRP$ Our) (JJ experimental) (NNS results)) (PP (IN across) (NP (JJ multiple) (NNS domains) (CC and) (VB algorithms)))) (VP (NN show) (SBAR (IN that) (S (S (VP (VBG using) (NP (NNP HOOF)) (S (VP (TO to) (VP (VB learn) (NP (DT these) (NN hyperparameter) (NNS schedules))))))) (VP (VBZ leads) (PP (TO to) (NP (NP (VB faster) (VBG learning)) (PP (IN with) (NP (JJ improved) (NN performance))))))))) (. .))
