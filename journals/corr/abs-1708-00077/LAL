(S (NP (JJ Recurrent) (JJ neural) (NNS networks)) (VP (VP (VBP show) (NP (JJ state-of-the-art) (NNS results)) (PP (IN in) (NP (JJ many) (JJ text) (NN analysis) (NNS tasks)))) (CC but) (VP (ADVP (RB often)) (VBP require) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NN memory)))) (S (VP (TO to) (VP (VB store) (NP (PRP$ their) (NNS weights))))))) (. .))
(S (NP (ADJP (RB Recently) (VBN proposed)) (NNP Sparse) (NNP Variational) (NNP Dropout)) (VP (VBZ eliminates) (NP (NP (DT the) (NN majority)) (PP (IN of) (NP (NP (DT the) (NNS weights)) (PP (IN in) (NP (DT a) (JJ feed-forward) (JJ neural) (NN network)))))) (PP (IN without) (NP (NP (JJ significant) (NN loss)) (PP (IN of) (NP (NN quality)))))) (. .))
(S (NP (PRP We)) (VP (VBP apply) (NP (DT this) (NN technique)) (S (VP (TO to) (VP (VB sparsify) (NP (JJ recurrent) (JJ neural) (NNS networks)))))) (. .))
(S (S (VP (TO To) (VP (VB account) (PP (IN for) (NP (JJ recurrent) (NNS specifics)))))) (NP (PRP we)) (ADVP (RB also)) (VP (VBP rely) (PP (IN on) (NP (NNP Binary) (NNP Variational) (NNP Dropout))) (PP (IN for) (NP (NNP RNN)))) (. .))
(S (NP (PRP We)) (VP (VBP report) (NP (NP (NP (ADJP (CD 99.5) (NN %)) (NN sparsity) (NN level)) (PP (IN on) (NP (NN sentiment) (NN analysis) (NN task))) (PP (IN without) (NP (DT a) (NN quality) (NN drop)))) (CC and) (NP (NP (ADJP (QP (RB up) (TO to) (CD 87)) (NN %)) (NN sparsity) (NN level)) (PP (IN on) (NP (NN language) (VBG modeling) (NN task))) (PP (IN with) (NP (NP (JJ slight) (NN loss)) (PP (IN of) (NP (NN accuracy)))))))) (. .))
