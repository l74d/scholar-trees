(S (NP (PRP We)) (VP (VBP introduce) (NP (NP (DT a) (NN learning) (NN method)) (VP (VBN called) (S (NP (`` ``) (NP (JJ gradient-based) (NN reinforcement) (NN planning)) ('' '') (PRN (-LRB- -LRB-) (NP (NNP GREP)) (-RRB- -RRB-))))))) (. .))
(S (PP (IN Unlike) (NP (NP (JJ traditional) (NNP DP) (NNS methods)) (SBAR (WHNP (WDT that)) (S (VP (VBP improve) (NP (PRP$ their) (NN policy)) (ADVP (NNS backwards) (PP (IN in) (NP (NN time))))))))) (, ,) (NP (NNP GREP)) (VP (VBZ is) (NP (NP (DT a) (JJ gradient-based) (NN method)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ plans) (ADVP (RB ahead))) (CC and) (VP (VBZ improves) (NP (PRP$ its) (NN policy))) (SBAR (IN before) (S (NP (PRP it)) (ADVP (RB actually)) (VP (VBZ acts) (PP (IN in) (NP (DT the) (NN environment))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP derive) (NP (NP (NNS formulas)) (PP (IN for) (NP (NP (DT the) (JJ exact) (NN policy) (NN gradient)) (SBAR (WHNP (WDT that)) (S (VP (VBZ maximizes) (NP (DT the) (JJ expected) (NN future) (NN reward))))))))) (CC and) (VP (VB confirm) (NP (PRP$ our) (NNS ideas)) (PP (IN with) (NP (JJ numerical) (NNS experiments))))) (. .))
