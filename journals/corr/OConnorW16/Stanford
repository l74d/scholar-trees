(S (NP (PRP We)) (VP (VBP introduce) (NP (DT an) (NN algorithm)) (S (VP (TO to) (VP (VB do) (NP (NN backpropagation)) (PP (IN on) (NP (DT a) (NN spiking) (NN network))))))) (. .))
(S (NP (PRP$ Our) (NN network)) (VP (VBZ is) (NP (`` ") (NP (VBG spiking)) ('' ") (PP (IN in) (NP (NP (DT the) (NN sense)) (SBAR (IN that) (S (NP (PRP$ our) (NNS neurons)) (VP (VP (VBP accumulate) (NP (PRP$ their) (NN activation)) (PP (IN into) (NP (NP (DT a) (NN potential)) (PP (IN over) (NP (NN time)))))) (, ,) (CC and) (ADVP (RB only)) (VP (VB send) (PRT (RP out)) (NP (NP (NP (DT a) (NN signal)) (-LRB- -LRB-) (NP (DT a) (`` ") (NN spike) ('' ")) (-RRB- -RRB-)) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT this) (JJ potential) (NNS crosses)) (NP (NP (DT a) (NN threshold)) (CC and) (NP (DT the) (NN neuron)))) (VP (VBZ is) (VP (VBN reset)))))))))))))) (. .))
(S (NP (NNS Neurons)) (ADVP (RB only)) (VP (VBP update) (NP (PRP$ their) (NNS states)) (SBAR (WHADVP (WRB when)) (S (VP (VBG receiving) (NP (NNS signals)) (PP (IN from) (NP (JJ other) (NNS neurons))))))) (. .))
(S (NP (NP (JJ Total) (NN computation)) (PP (IN of) (NP (DT the) (NN network)))) (ADVP (RB thus)) (VP (VBZ scales) (PP (IN with) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS spikes)) (VP (VBN caused) (PP (IN by) (NP (DT an) (NML (NN input) (CONJP (RB rather) (IN than)) (NN network)) (NN size))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN spiking)) (NP (NNP Multi-Layer) (NNP Perceptron))) (VP (VBZ behaves) (ADVP (RB identically)) (, ,) (PP (IN during) (NP (DT both) (NN prediction) (CC and) (NN training))) (, ,) (PP (IN to) (NP (NP (DT a) (JJ conventional) (JJ deep) (NN network)) (PP (IN of) (NP (NML (VBN rectified) (HYPH -) (JJ linear)) (NNS units))))) (, ,) (PP (IN in) (NP (NP (DT the) (VBG limiting) (NN case)) (SBAR (WHADVP (WRB where)) (S (NP (PRP we)) (VP (VBP run) (NP (DT the) (NN spiking) (NN network)) (PP (IN for) (NP (DT a) (JJ long) (NN time)))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP apply) (NP (DT this) (NN architecture)) (PP (IN to) (NP (DT a) (NML (JJ conventional) (NN classification)) (NN problem) (PRN (-LRB- -LRB-) (NP (NN MNIST)) (-RRB- -RRB-))))) (CC and) (VP (VB achieve) (NP (NN performance)) (ADVP (RB very) (RB close)) (PP (IN to) (NP (NP (DT that)) (PP (IN of) (NP (NP (DT a) (JJ conventional) (NNP Multi-Layer) (NNP Perceptron)) (PP (IN with) (NP (DT the) (JJ same) (NN architecture))))))))) (. .))
(S (NP (PRP$ Our) (NN network)) (VP (VP (VBZ is) (NP (NP (DT a) (JJ natural) (NN architecture)) (PP (IN for) (S (VP (VBG learning) (PP (VBN based) (PP (IN on) (S (VP (VBG streaming) (NP (ADJP (NN event) (HYPH -) (VBN based)) (NNS data))))))))))) (, ,) (CC and) (VP (VBZ is) (NP (NP (DT a) (VBG stepping) (NN stone)) (PP (IN towards) (S (VP (VBG using) (S (VP (VBG spiking) (NP (JJ neural) (NNS networks)) (S (VP (TO to) (VP (VB learn) (ADVP (RB efficiently)) (PP (IN on) (NP (VBG streaming) (NNS data)))))))))))))) (. .))
