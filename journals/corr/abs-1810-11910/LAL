(S (NP (NP (NN Lack)) (PP (IN of) (NP (NN performance))) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBZ comes) (PP (TO to) (NP (NP (JJ continual) (NN learning)) (PP (IN over) (NP (NP (JJ non-stationary) (NNS distributions)) (PP (IN of) (NP (NN data))))))))))) (VP (VBZ remains) (NP (NP (DT a) (JJ major) (NN challenge)) (PP (IN in) (S (VP (VBG scaling) (NP (JJ neural) (NN network) (VBG learning)) (PP (TO to) (NP (ADJP (RBR more) (JJ human) (JJ realistic)) (NNS settings)))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN work))) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (NN conceptualization)) (PP (IN of) (NP (DT the) (JJ continual) (NN learning) (NN problem))) (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (DT a) (ADJP (RB temporally) (JJ symmetric)) (NN trade-off)) (PP (IN between) (NP (NN transfer) (CC and) (NN interference))) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN optimized) (PP (IN by) (S (VP (VBG enforcing) (NP (JJ gradient) (NN alignment)) (PP (IN across) (NP (NNS examples))))))))))))))))) (. .))
(S (NP (PRP We)) (ADVP (RB then)) (VP (VB propose) (NP (NP (DT a) (JJ new) (NN algorithm)) (, ,) (NP (NP (NNP Meta-Experience) (NNP Replay)) (PRN (-LRB- -LRB-) (NP (NNP MER)) (-RRB- -RRB-))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (ADVP (RB directly)) (VBZ exploits) (NP (DT this) (NN view)) (PP (IN by) (S (VP (VBG combining) (NP (NN experience) (NN replay)) (PP (IN with) (NP (ADJP (NN optimization) (VBN based)) (NN meta-learning))))))))))) (. .))
(S (NP (DT This) (NN method)) (VP (VBZ learns) (NP (NP (NNS parameters)) (SBAR (WHNP (WDT that)) (S (VP (VBP make) (S (S (NP (NP (NN interference)) (PP (VBN based) (PP (IN on) (NP (JJ future) (NNS gradients))))) (ADJP (RBR less) (JJ likely))) (CC and) (S (NP (NP (VB transfer)) (VP (VBN based) (PP (IN on) (NP (JJ future) (NNS gradients))))) (ADJP (RBR more) (JJ likely))))))))) (. .))
(S (NP (PRP We)) (VP (VBP conduct) (NP (NNS experiments)) (PP (IN across) (NP (NP (JJ continual) (NN lifelong) (VBD supervised) (VBG learning) (NNS benchmarks)) (CC and) (NP (JJ non-stationary) (NN reinforcement) (VBG learning) (NNS environments)))) (S (VP (VBG demonstrating) (SBAR (IN that) (S (NP (PRP$ our) (NN approach)) (VP (ADVP (RB consistently)) (VBZ outperforms) (NP (NP (ADJP (RB recently) (VBN proposed)) (NNS baselines)) (PP (IN for) (NP (JJ continual) (NN learning)))))))))) (. .))
(S (NP (PRP$ Our) (NNS experiments)) (VP (VBP show) (SBAR (IN that) (S (NP (NP (DT the) (NN gap)) (PP (IN between) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NP (NNP MER)) (CC and) (NP (VB baseline) (NN algorithms))))))) (VP (VBZ grows) (SBAR (CC both) (SBAR (IN as) (S (NP (DT the) (NN environment)) (VP (VBZ gets) (ADJP (JJR more) (JJ non-stationary))))) (CC and) (SBAR (IN as) (S (NP (NP (DT the) (NN fraction)) (PP (IN of) (NP (NP (DT the) (JJ total) (NNS experiences)) (VP (VBD stored))))) (VP (VBZ gets) (ADJP (JJR smaller)))))))))) (. .))
