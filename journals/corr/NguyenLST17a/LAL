(S (PP (IN In) (NP (DT this) (NN paper))) (, ,) (NP (PRP we)) (VP (VBP study) (CC and) (VBP analyze) (NP (NP (DT the) (JJ mini-batch) (NN version)) (PP (IN of) (NP (NP (NP (NNP StochAstic) (NNP Recursive) (NN grAdient) (NN algoritHm)) (PRN (-LRB- -LRB-) (NP (NNP SARAH)) (-RRB- -RRB-))) (, ,) (NP (NP (DT a) (NN method)) (VP (VBG employing) (NP (DT the) (JJ stochastic) (JJ recursive) (NN gradient)))) (, ,) (PP (IN for) (S (VP (VBG solving) (NP (JJ empirical) (NN loss) (NN minimization)) (PP (IN for) (NP (NP (DT the) (NN case)) (PP (IN of) (NP (JJ nonconvex) (NNS losses)))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP provide) (NP (NP (NP (DT a) (JJ sublinear) (NN convergence) (NN rate)) (PRN (-LRB- -LRB-) (PP (TO to) (NP (VB stationary) (NNS points))) (-RRB- -RRB-)) (PP (IN for) (NP (JJ general) (JJ nonconvex) (NNS functions)))) (CC and) (NP (NP (DT a) (JJ linear) (NN convergence) (NN rate)) (PP (IN for) (NP (NN gradient) (VBN dominated) (NNS functions)))) (, ,) (SBAR (WHNP (WHNP (DT both)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBP have) (NP (DT some) (NNS advantages)) (PP (VBN compared) (PP (TO to) (NP (NP (JJ other) (JJ modern) (JJ stochastic) (NN gradient) (NN algorithms)) (PP (IN for) (NP (JJ nonconvex) (NNS losses))))))))))) (. .))
