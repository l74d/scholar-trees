(S (NP (JJ Deep) (JJ neural) (NNS networks)) (VP (VBP achieve) (NP (JJ stellar) (NN generalisation)) (SBAR (WHADVP (RB even) (WRB when)) (S (NP (PRP they)) (VP (VBP have) (NP (NP (JJ enough) (NNS parameters)) (SBAR (S (VP (TO to) (VP (ADVP (RB easily)) (VB fit) (NP (DT all) (PRP$ their) (NN training) (NNS data))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP study) (NP (DT this) (NN phenomenon)) (PP (IN by) (S (VP (VBG analysing) (NP (NP (NP (DT the) (NNS dynamics)) (CC and) (NP (DT the) (NN performance))) (PP (IN of) (NP (JJ over-parameterised) (JJ two-layer) (JJ neural) (NNS networks))) (PP (IN in) (NP (NP (DT the) (JJ teacher-student) (NN setup)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (CD one) (NN network)) (, ,) (NP (DT the) (NN student)) (, ,)) (VP (VBZ is) (VP (VBN trained) (PP (IN on) (NP (NP (NNS data)) (VP (VBN generated) (PP (IN by) (NP (NP (DT another) (NN network)) (, ,) (VP (VBD called) (S (NP (DT the) (NN teacher)))))))))))))))))))) (. .))
(S (NP (PRP We)) (VP (VP (VBP show) (SBAR (WHADVP (WRB how)) (S (NP (NP (DT the) (NNS dynamics)) (PP (IN of) (NP (NP (JJ stochastic) (NN gradient) (NN descent)) (PRN (-LRB- -LRB-) (NP (NNP SGD)) (-RRB- -RRB-))))) (VP (VBZ is) (VP (VBN captured) (PP (IN by) (NP (NP (DT a) (NN set)) (PP (IN of) (NP (JJ differential) (NNS equations)))))))))) (CC and) (VP (VB prove) (SBAR (IN that) (S (NP (DT this) (NN description)) (VP (VBZ is) (ADJP (RB asymptotically) (JJ exact)) (PP (IN in) (NP (NP (DT the) (NN limit)) (PP (IN of) (NP (JJ large) (NNS inputs)))))))))) (. .))
(S (S (VP (VBG Using) (NP (DT this) (NN framework)))) (, ,) (NP (PRP we)) (VP (VBP calculate) (NP (NP (DT the) (JJ final) (NN generalisation) (NN error)) (PP (IN of) (NP (NP (NN student) (NNS networks)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (NP (NP (JJR more) (NNS parameters)) (PP (IN than) (NP (PRP$ their) (NNS teachers))))))))))) (. .))
(S (NP (PRP We)) (VP (VBP find) (SBAR (IN that) (S (NP (NP (DT the) (JJ final) (NN generalisation) (NN error)) (PP (IN of) (NP (DT the) (NN student)))) (VP (VP (VBZ increases) (PP (IN with) (NP (NN network) (NN size))) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (RB only) (DT the) (JJ first) (NN layer)))))) (, ,) (CC but) (VP (VP (VBZ stays) (ADJP (VBP constant))) (CC or) (VP (ADVP (RB even)) (NNS decreases) (PP (IN with) (NP (NN size)))) (SBAR (WHADVP (WRB when)) (S (VP (VBG training) (NP (DT both) (NNS layers)))))))))) (. .))
(S (NP (PRP We)) (VP (VBP show) (SBAR (IN that) (S (NP (DT these) (JJ different) (NNS behaviours)) (VP (VBP have) (NP (PRP$ their) (NN root)) (PP (IN in) (NP (NP (DT the) (JJ different) (NNS solutions)) (SBAR (S (NP (NNP SGD)) (VP (VBZ finds) (PP (IN for) (NP (JJ different) (NN activation) (NNS functions)))))))))))) (. .))
(S (NP (PRP$ Our) (NNS results)) (VP (VBP indicate) (SBAR (IN that) (S (S (VP (VBG achieving) (NP (JJ good) (NN generalisation)) (PP (IN in) (NP (JJ neural) (NNS networks))))) (VP (VP (VBZ goes) (PP (IN beyond) (NP (NP (DT the) (NNS properties)) (PP (IN of) (NP (NP (NNP SGD)) (ADVP (RB alone))))))) (CC and) (VP (VBZ depends) (PP (IN on) (NP (NP (DT the) (NN interplay)) (PP (IN of) (NP (NP (ADVP (IN at) (JJS least)) (NP (DT the) (NN algorithm))) (, ,) (NP (DT the) (NN model) (NN architecture)) (, ,) (CC and) (NP (DT the) (NN data) (NN set))))))))))) (. .))
