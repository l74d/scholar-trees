(S (NP (NP (NNS Parameters)) (PP (IN of) (NP (JJ recent) (JJ neural) (NNS networks)))) (VP (VBP require) (NP (NP (DT a) (JJ huge) (NN amount)) (PP (IN of) (NP (NN memory))))) (. .))
(S (NP (DT These) (NNS parameters)) (VP (VBP are) (VP (VBN used) (PP (IN by) (NP (JJ neural) (NNS networks))) (S (VP (TO to) (VP (VB perform) (NP (NML (NN machine) (NN learning)) (NNS tasks)) (SBAR (WHADVP (WRB when)) (S (VP (VBG processing) (NP (NNS inputs)))))))))) (. .))
(S (S (VP (TO To) (VP (VB speed) (PRT (RP up)) (NP (NN inference))))) (, ,) (NP (PRP we)) (VP (VBP develop) (NP (NP (NN Partition) (NN Pruning)) (, ,) (NP (DT an) (JJ innovative) (NN scheme) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NNS parameters)) (VP (VBN used) (PP (IN while) (S (VP (VBG taking) (PP (IN into) (NP (NN consideration) (NN parallelization)))))))))))))) (. .))
(S (NP (PRP We)) (VP (VBD evaluated) (NP (NP (DT the) (NML (NN performance) (CC and) (NN energy)) (NN consumption)) (PP (IN of) (NP (NP (JJ parallel) (NN inference)) (PP (IN of) (NP (NP (VBN partitioned) (NNS models)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD showed) (NP (NP (DT a) (NML (QP (CD 7.72) (SYM x))) (NN speed)) (ADVP (IN up) (PP (IN of) (NP (NP (NN performance)) (CC and) (NP (NP (DT a) (NML (QP (CD 2.73) (SYM x))) (NN reduction)) (PP (IN in) (NP (NP (DT the) (NN energy)) (VP (VBN used) (PP (IN for) (NP (NP (VBG computing)) (VP (VBN pruned) (NP (NP (NNS layers)) (PP (IN of) (NP (NN TinyVGG16)))) (PP (IN in) (NP (NN comparison))) (PP (IN to) (S (VP (VBG running) (NP (DT the) (JJ unpruned) (NN model)) (PP (IN on) (NP (DT a) (JJ single) (NN accelerator)))))))))))))))))))))))))) (. .))
(S (PP (IN In) (NP (NN addition))) (, ,) (NP (PRP$ our) (NN method)) (VP (VBD showed) (NP (DT a) (JJ limited) (NN reduction)) (NP (NP (DT some) (NNS numbers)) (PP (IN in) (NP (NN accuracy)))) (PP (IN while) (S (VP (VBG partitioning) (NP (ADJP (RB fully) (JJ connected)) (NNS layers)))))) (. .))
