(S (S (VP (VBG Learning) (PP (IN in) (NP (DT a) (JJ non-stationary) (NN environment))))) (VP (VBZ is) (NP (DT an) (JJ inevitable) (NN problem)) (SBAR (WHADVP (WRB when)) (S (VP (VBG applying) (NP (NN machine) (VBG learning) (NN algorithm)) (PP (TO to) (NP (ADJP (JJ real) (NN world)) (NN environment))))))) (. .))
(S (S (VP (VBG Learning) (NP (JJ new) (NNS tasks)) (PP (IN without) (S (VP (VBG forgetting) (NP (DT the) (JJ previous) (NN knowledge))))))) (VP (VBZ is) (NP (DT a) (JJ challenge) (NN issue)) (PP (IN in) (NP (NN machine) (NN learning)))) (. .))
(S (NP (PRP We)) (VP (VBP propose) (NP (NP (DT a) (ADJP (NNP Kalman) (NNP Filter) (VBN based)) (NN modifier)) (SBAR (S (VP (TO to) (VP (VB maintain) (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (NNP Neural) (NNP Network) (NNS models)))) (PP (IN under) (NP (JJ non-stationary) (NNS environments))))))))) (. .))
(S (NP (DT The) (NN result)) (VP (VBZ shows) (SBAR (IN that) (S (NP (PRP$ our) (VBN proposed) (NN model)) (VP (VP (MD can) (VP (VB preserve) (NP (DT the) (JJ key) (NN information)))) (CC and) (VP (NNS adapts) (ADVP (RBR better)) (PP (TO to) (NP (DT the) (NNS changes)))))))) (. .))
(S (NP (NP (DT The) (NN accuracy)) (PP (IN of) (NP (VBN proposed) (NN model)))) (VP (NNS decreases) (PP (IN by) (NP (CD 0.4) (NN %))) (PP (IN in) (NP (PRP$ our) (NNS experiments))) (, ,) (SBAR (IN while) (S (NP (NP (DT the) (NN accuracy)) (PP (IN of) (NP (JJ conventional) (NN model)))) (VP (NNS decreases) (PP (IN by) (NP (CD 90) (NN %))) (PP (IN in) (NP (DT the) (JJ drifts) (NN environment))))))) (. .))
