(S (NP (NN Self-attention)) (VP (VBZ has) (VP (VBN been) (NP (DT a) (JJ huge) (NN success)) (PP (IN for) (NP (NP (JJ many) (NN downstream) (NNS tasks)) (PP (IN in) (NP (NNP NLP))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD led) (PP (TO to) (NP (NP (NN exploration)) (PP (IN of) (S (VP (VBG applying) (NP (NN self-attention)) (PP (TO to) (NP (VB speech) (NNS problems))) (ADVP (RB as) (RB well)))))))))))) (. .))
(S (NP (NP (DT The) (NN efficacy)) (PP (IN of) (NP (NN self-attention))) (PP (IN in) (NP (NN speech) (NNS applications)))) (, ,) (ADVP (RB however)) (, ,) (VP (VBZ seems) (RB not) (VP (ADVP (RB fully)) (VBN blown) (ADVP (RB yet)) (SBAR (IN since) (S (NP (NP (PRP it))) (VP (VBZ is) (ADJP (VBG challenging)) (S (VP (TO to) (VP (VB handle) (NP (ADJP (RB highly) (VBN correlated)) (NN speech) (NNS frames)) (PP (IN in) (NP (NP (DT the) (NN context)) (PP (IN of) (NP (NN self-attention))))))))))))) (. .))
(S (PP (IN In) (NP (DT this) (NN paper))) (NP (PRP we)) (VP (VBP propose) (NP (NP (DT a) (JJ new) (JJ neural) (NN network) (NN model) (NN architecture)) (, ,) (NP (ADVP (RB namely)) (JJ multi-stream) (NN self-attention)) (, ,) (SBAR (S (VP (TO to) (VP (VP (VB address) (NP (DT the) (NN issue))) (ADVP (RB thus)) (VP (VB make) (S (NP (DT the) (NN self-attention) (NN mechanism)) (ADJP (RBR more) (JJ effective) (PP (IN for) (NP (NN speech) (NN recognition)))))))))))) (. .))
(S (S (NP (DT The) (VBN proposed) (NN model) (NN architecture)) (VP (VBZ consists) (PP (IN of) (NP (NP (JJ parallel) (NNS streams)) (PP (IN of) (NP (NN self-attention) (NNS encoders))))))) (, ,) (CC and) (S (NP (DT each) (NN stream)) (VP (VBZ has) (NP (NP (NP (NNS layers)) (PP (IN of) (NP (NP (CD 1D) (NNS convolutions)) (PP (IN with) (NP (NP (JJ dilated) (NNS kernels)) (SBAR (WHNP (WP$ whose) (NN dilation) (NNS rates)) (S (VP (VBP are) (NP (JJ unique) (VBN given) (NN stream)))))))))) (, ,) (VP (VBN followed) (PP (IN by) (NP (DT a) (NN self-attention) (NN layer))))))) (. .))
(S (S (NP (NP (DT The) (NN self-attention) (NN mechanism)) (PP (IN in) (NP (DT each) (NN stream)))) (VP (VBZ pays) (NP (NN attention)) (PP (TO to) (NP (NP (QP (RB only) (CD one)) (NN resolution)) (PP (IN of) (NP (NN input) (NN speech) (NNS frames))))))) (CC and) (S (NP (DT the) (JJ attentive) (NN computation)) (VP (MD can) (VP (VB be) (ADJP (RBR more) (JJ efficient))))) (. .))
(S (PP (IN In) (NP (DT a) (JJ later) (NN stage))) (, ,) (NP (NP (VBZ outputs)) (PP (IN from) (NP (PDT all) (DT the) (NNS streams)))) (VP (VBP are) (VP (VP (VBN concatenated)) (RB then) (VP (ADVP (RB linearly)) (VBN projected) (PP (TO to) (NP (DT the) (JJ final) (NN embedding)))))) (. .))
(S (PP (IN By) (S (VP (VP (VBG stacking) (NP (DT the) (VBN proposed) (NN multi-stream) (NN self-attention) (NN encoder) (NNS blocks))) (CC and) (VP (VBG rescoring) (NP (DT the) (JJ resultant) (NNS lattices)) (PP (IN with) (NP (JJ neural) (NN network) (NN language) (NNS models))))))) (, ,) (NP (PRP we)) (VP (VBP achieve) (NP (NP (NP (DT the) (NN word) (NN error) (NN rate)) (PP (IN of) (NP (CD 2.2) (NN %))) (PP (IN on) (NP (NP (DT the) (JJ test-clean) (NN dataset)) (PP (IN of) (NP (DT the) (NNP LibriSpeech) (NN corpus)))))) (, ,) (NP (NP (DT the) (JJS best) (NN number)) (VP (VBD reported) (ADVP (RB thus) (RB far)) (PP (IN on) (NP (DT the) (NN dataset))))))) (. .))
