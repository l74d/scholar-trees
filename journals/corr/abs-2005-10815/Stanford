(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (NP (DT the) (NN gradient) (NN descent) (NN training)) (PP (IN of) (NP (NP (DT a) (NML (CD two) (HYPH -) (NN layer)) (JJ neural) (NN network)) (PP (IN on) (NP (NP (JJ empirical)) (CC or) (NP (NN population) (NN risk))))))) (VP (MD may) (RB not) (VP (VB decrease) (NP (NN population) (NN risk)) (PP (IN at) (NP (NP (NP (NP (DT an) (NN order)) (ADVP (RBR faster) (PP (IN than) (NP (NP (QP ($ $) (CD t)) (SYM ^)) (-LRB- {) (PP (HYPH -) (NP (CD 4))))))) (HYPH /) (NP (-LRB- -LRB-) (NP (NN d) (HYPH -) (CD 2)) (-RRB- -RRB-))) (-RRB- }) (NP (NP ($ $)) (PP (IN under) (NP (JJ mean) (NN field) (NN scaling))))))))))) (. .))
(S (ADVP (RB Thus)) (NP (NP (NN gradient) (NN descent) (NN training)) (PP (IN for) (NP (JJ fitting) (ADJP (ADJP (RB reasonably) (JJ smooth)) (, ,) (CC but) (ADJP (RB truly) (JJ high) (HYPH -) (JJ dimensional))) (NNS data)))) (VP (MD may) (VP (VB be) (ADJP (JJ subject) (PP (IN to) (NP (NP (DT the) (NN curse)) (PP (IN of) (NP (NN dimensionality)))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (JJ numerical) (NN evidence)) (SBAR (IN that) (S (NP (NP (NN gradient) (NN descent) (NN training)) (PP (IN with) (NP (JJ general) (NNP Lipschitz) (NN target)))) (VP (VBZ functions) (SBAR (S (VP (VP (VBZ becomes) (ADJP (JJR slower) (CC and) (JJR slower)) (PP (IN as) (NP (DT the) (NN dimension) (NNS increases)))) (, ,) (CC but) (VP (VBZ converges) (PP (IN at) (NP (NP (RB approximately) (DT the) (JJ same) (NN rate)) (PP (IN in) (NP (DT all) (NNS dimensions))))) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN target) (NN function)) (VP (VBZ lies) (PP (IN in) (NP (NP (DT the) (JJ natural) (NN function) (NN space)) (PP (IN for) (NP (NML (CD two) (HYPH -) (NN layer)) (NN ReLU) (NNS networks)))))))))))))))) (. .))
