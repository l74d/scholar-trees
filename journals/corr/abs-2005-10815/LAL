(S (NP (PRP We)) (VP (VBP prove) (SBAR (IN that) (S (NP (NP (DT the) (JJ gradient) (NN descent) (NN training)) (PP (IN of) (NP (DT a) (JJ two-layer) (JJ neural) (NN network))) (PP (IN on) (NP (ADJP (JJ empirical) (CC or) (NN population)) (NN risk)))) (VP (MD may) (RB not) (VP (VB decrease) (NP (NN population) (NN risk)) (PP (IN at) (NP (NP (DT an) (NN order)) (ADJP (ADJP (JJR faster)) (PP (IN than) (NP ($ $) (JJ t^) (PRN (-LRB- -LCB-) (JJ -4/) (PRN (PRN (-LRB- -LRB-) (JJ d-2) (-RRB- -RRB-)) (-RRB- -RCB-))) ($ $))) (PP (IN under) (NP (JJ mean) (NN field) (NN scaling))))))))))) (. .))
(S (ADVP (RB Thus)) (NP (NP (JJ gradient) (NN descent) (NN training)) (PP (IN for) (S (VP (VBG fitting) (NP (ADJP (ADJP (RB reasonably) (JJ smooth)) (, ,) (CC but) (ADJP (RB truly) (JJ high-dimensional))) (NNS data)))))) (VP (MD may) (VP (VB be) (ADJP (JJ subject) (PP (TO to) (NP (NP (DT the) (NN curse)) (PP (IN of) (NP (NN dimensionality)))))))) (. .))
(S (NP (PRP We)) (VP (VBP present) (NP (JJ numerical) (NN evidence) (SBAR (WDT that) (S (NP (NP (JJ gradient) (NN descent) (NN training)) (PP (IN with) (NP (JJ general) (NNP Lipschitz) (NN target) (NNS functions)))) (VP (VP (VBZ becomes) (ADJP (JJR slower) (CC and) (JJR slower)) (SBAR (IN as) (S (NP (DT the) (NN dimension)) (VP (NNS increases))))) (, ,) (CC but) (VP (NNS converges) (PP (IN at) (NP (RB approximately) (DT the) (JJ same) (NN rate))) (PP (IN in) (NP (DT all) (NNS dimensions))) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN target) (NN function)) (VP (VBZ lies) (PP (IN in) (NP (NP (DT the) (JJ natural) (NN function) (NN space)) (PP (IN for) (NP (JJ two-layer) (NNP ReLU) (NNS networks)))))))))))))) (. .))
