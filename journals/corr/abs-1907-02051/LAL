(S (PP (IN In) (NP (DT this) (NN work))) (, ,) (NP (PRP we)) (VP (VBP leverage) (NP (NP (NNS advances)) (PP (IN in) (NP (JJ sparse) (VBG coding) (NNS techniques)))) (S (VP (TO to) (VP (VB reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ trainable) (NNS parameters))) (PP (IN in) (NP (DT a) (ADJP (RB fully) (VBN connected)) (JJ neural) (NN network)))))))) (. .))
(S (NP (DT The) (NNP DropOut/DropConnect) (NNS techniques)) (VP (VB reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (JJ trainable) (NNS parameters))) (PP (IN in) (NP (DT the) (NN training) (NN stage)))) (PP (IN by) (S (VP (VBG dropping) (NP (NP (DT a) (JJ random) (NN collection)) (PP (IN of) (NP (NNS neurons/edges))) (PP (IN in) (NP (DT the) (JJ hidden) (NNS layers)))))))) (. .))
(S (ADVP (RB However)) (, ,) (NP (DT both) (DT these) (NNS techniques)) (VP (VBP do) (RB not) (VP (VB pay) (NP (NN heed)) (PP (TO to) (NP (NP (DT the) (JJ underlying) (NN structure)) (PP (IN in) (NP (DT the) (NN data))))) (SBAR (WHADVP (WRB when)) (S (VP (VBG dropping) (NP (DT the) (NNS neurons/edges))))))) (. .))
(S (ADVP (RB Moreover)) (, ,) (NP (DT these) (NNS frameworks)) (VP (VBP require) (NP (NP (DT a) (NN storage) (NN space)) (ADJP (NN equivalent) (PP (TO to) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS parameters))) (PP (IN in) (NP (DT a) (ADJP (RB fully) (VBN connected)) (JJ neural) (NN network)))))))) (. .))
(S (NP (PRP We)) (VP (VBP address) (NP (DT the) (JJ above) (NNS issues)) (PP (IN with) (NP (NP (DT a) (ADJP (RBR more) (JJ structured)) (NN architecture)) (VP (VBN inspired) (PP (IN from) (NP (JJ spatially-coupled) (JJ sparse) (NNS constructions))))))) (. .))
(S (S (NP (JJ Extensive) (NNS simulations)) (VP (VBP are) (VP (VBN presented)))) (CC and) (S (NP (NP (DT the) (NN performance)) (PP (IN of) (NP (DT the) (VBN proposed) (NN scheme)))) (VP (VBZ is) (VP (VBN compared) (PP (IN against) (NP (JJ traditional) (JJ neural) (NN network) (NNS architectures)))))) (. .))
